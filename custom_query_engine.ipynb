{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dotenv\n",
    "import sys\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "import openai\n",
    "\n",
    "from llama_index import ServiceContext, set_global_service_context\n",
    "from llama_index.llms import OpenAI\n",
    "\n",
    "# Use local embeddings + gpt-3.5-turbo-16k\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    llm=OpenAI(model=\"gpt-3.5-turbo-16k\", max_tokens=512, temperature=0.1),\n",
    "    embed_model=\"local:BAAI/bge-base-en\"\n",
    ")\n",
    "\n",
    "set_global_service_context(service_context)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ir-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
