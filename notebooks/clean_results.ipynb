{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory found: c:\\Users\\todor\\Repositories\\ir-project/results/not_cleaned\n",
      "Directory found: c:\\Users\\todor\\Repositories\\ir-project/results/cleaned\n"
     ]
    }
   ],
   "source": [
    "# Get the directory containing the notebook\n",
    "notebook_dir = Path(os.getcwd())\n",
    "# Get the parent directory (project root)\n",
    "project_root = str(notebook_dir.parent)\n",
    "# Add to Python path if not already there\n",
    "\n",
    "\n",
    "not_cleaned_results_path = project_root + \"/results/not_cleaned\"\n",
    "cleaned_results_path = project_root + \"/results/cleaned\"\n",
    "\n",
    "# Check if the directories exist, create them if they don't\n",
    "if not os.path.exists(not_cleaned_results_path):\n",
    "    print(f\"Directory not found: {not_cleaned_results_path}\")\n",
    "else:\n",
    "    print(f\"Directory found: {not_cleaned_results_path}\")\n",
    "\n",
    "if not os.path.exists(cleaned_results_path):\n",
    "    print(f\"Directory not found: {cleaned_results_path}\")\n",
    "\n",
    "else:\n",
    "    print(f\"Directory found: {cleaned_results_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows for nq and pinecone: 100\n",
      "Number of rows for nq and openai: 50\n",
      "Number of rows for nq and hybrid: 150\n",
      "Number of rows for nq and auto_merge: 50\n",
      "Number of rows for hotpotqa and pinecone: 100\n",
      "Number of rows for hotpotqa and openai: 50\n",
      "Number of rows for hotpotqa and hybrid: 200\n",
      "Number of rows for hotpotqa and auto_merge: 300\n",
      "Number of rows for sse_single and pinecone: 50\n",
      "Number of rows for sse_single and openai: 50\n",
      "Number of rows for sse_single and hybrid: 49\n",
      "Number of rows for sse_single and auto_merge: 50\n",
      "Number of rows for sse_multi and pinecone: 22\n",
      "Number of rows for sse_multi and openai: 22\n",
      "Number of rows for sse_multi and hybrid: 44\n",
      "Number of rows for sse_multi and auto_merge: 66\n"
     ]
    }
   ],
   "source": [
    "agents = [\"pinecone\", \"openai\", \"hybrid\", \"auto_merge\"]\n",
    "datasets = [\"nq\", \"hotpotqa\", \"sse_single\", \"sse_multi\"]\n",
    "metrics_columns = [\"context_precision\", \"context_recall\", \"faithfulness\", \"factual_correctness(mode=f1)\", \"context_entity_recall\", \"answer_relevancy\"]\n",
    "\n",
    "not_cleaned_results = {dataset: {} for dataset in datasets}  # Initialize nested structure\n",
    "for dataset in datasets:\n",
    "    for agent in agents:\n",
    "        path = not_cleaned_results_path + f\"/{dataset}/{agent}/evaluation_results.csv\"\n",
    "        if not os.path.exists(path):\n",
    "            print(f\"Evaluation results file not found for {path}\")\n",
    "        else:\n",
    "            full_table = pd.read_csv(path)\n",
    "            # metrics = full_table[metrics_columns]\n",
    "            not_cleaned_results[dataset][agent] = full_table\n",
    "            print(f\"Number of rows for {dataset} and {agent}: {full_table.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the experiments it was initially appending results to same evaluation dataset so results of agents were appended one after another instead of renewing, the solution for this is to take the last n instances since they belong to the actual agent and the ones before are from other agents if there are any before. Below we get the actual sizes the result tables should be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum number of rows is 50 for dataset: nq\n",
      "Minimum number of rows is 50 for dataset: hotpotqa\n",
      "Minimum number of rows is 49 for dataset: sse_single\n",
      "Minimum number of rows is 22 for dataset: sse_multi\n"
     ]
    }
   ],
   "source": [
    "min_per_dataset= {dataset: {} for dataset in datasets}\n",
    "for dataset in datasets:\n",
    "    min_num_rows = float('inf')\n",
    "    for agent in agents:\n",
    "        min_num_rows = min(min_num_rows, not_cleaned_results[dataset][agent].shape[0])\n",
    "    min_per_dataset[dataset] = min_num_rows\n",
    "    print(f\"Minimum number of rows is {min_num_rows} for dataset: {dataset}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally for hotpotqa we first evaluated on 100 queries but due to excessive costs we cut down to 50. This was done only after all agents except openai were evaluated. So for these agents, since we need the first 50 samples, its not the last 50 rows we need for hotpotqa but the 50 rows before the last 50 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum number of rows is 50 for dataset: nq\n",
      "Minimum number of rows is 100 for dataset: hotpotqa\n",
      "Minimum number of rows is 49 for dataset: sse_single\n",
      "Minimum number of rows is 22 for dataset: sse_multi\n"
     ]
    }
   ],
   "source": [
    "min_per_dataset_not_openai = {dataset: {} for dataset in datasets}\n",
    "for dataset in datasets:\n",
    "    min_num_rows = float('inf')\n",
    "    for agent in agents:\n",
    "        if agent != \"openai\":\n",
    "            min_num_rows = min(min_num_rows, not_cleaned_results[dataset][agent].shape[0])\n",
    "            \n",
    "    min_per_dataset_not_openai[dataset] = min_num_rows\n",
    "    print(f\"Minimum number of rows is {min_num_rows} for dataset: {dataset}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows for nq and pinecone: 50\n",
      "Number of rows for nq and openai: 50\n",
      "Number of rows for nq and hybrid: 50\n",
      "Number of rows for nq and auto_merge: 50\n",
      "Number of rows for hotpotqa and pinecone: 50\n",
      "Number of rows for hotpotqa and openai: 50\n",
      "Number of rows for hotpotqa and hybrid: 50\n",
      "Number of rows for hotpotqa and auto_merge: 50\n",
      "Number of rows for sse_single and pinecone: 49\n",
      "Number of rows for sse_single and openai: 49\n",
      "Number of rows for sse_single and hybrid: 49\n",
      "Number of rows for sse_single and auto_merge: 49\n",
      "Number of rows for sse_multi and pinecone: 22\n",
      "Number of rows for sse_multi and openai: 22\n",
      "Number of rows for sse_multi and hybrid: 22\n",
      "Number of rows for sse_multi and auto_merge: 22\n"
     ]
    }
   ],
   "source": [
    "cleaned_results = {dataset: {} for dataset in datasets}\n",
    "for dataset in datasets:\n",
    "    for agent in agents:\n",
    "        if not_cleaned_results[dataset][agent].shape[0] == min_per_dataset[dataset]:\n",
    "            cleaned_metrics = not_cleaned_results[dataset][agent]\n",
    "        elif agent != \"openai\" and dataset == \"hotpotqa\":\n",
    "            cleaned_metrics = not_cleaned_results[dataset][agent].iloc[-2 * min_per_dataset[dataset]: -min_per_dataset[dataset]]\n",
    "        else:\n",
    "            cleaned_metrics = not_cleaned_results[dataset][agent].iloc[-min_per_dataset[dataset]:]\n",
    "            \n",
    "        cleaned_results[dataset][agent] = cleaned_metrics\n",
    "        print(f\"Number of rows for {dataset} and {agent}: {cleaned_metrics.shape[0]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store in cleaned results directory\n",
    "for dataset in datasets:\n",
    "    for agent in agents:\n",
    "        # Create the directory if it doesn't exist\n",
    "        os.makedirs(cleaned_results_path + f\"/{dataset}/{agent}\", exist_ok=True)\n",
    "        cleaned_results[dataset][agent].to_csv(cleaned_results_path + f\"/{dataset}/{agent}/evaluation_results.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ir-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
