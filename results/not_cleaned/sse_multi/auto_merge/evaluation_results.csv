user_input,retrieved_contexts,reference_contexts,response,reference,context_precision,context_recall,faithfulness,factual_correctness(mode=f1),context_entity_recall,answer_relevancy
How EcoAndroid reduce risk by reduce size?,"['‚Ä¢ Software consumers have started to worry about the climate impact \nof their behaviour as users. \n‚Ä¢ Being environmentally sustainable is now an important competitive \nfactor \n‚Ä¢ Marketing teams are already using all eco-friendly labels. Technical \nteams are not there yet, though. \n‚Ä¢ It‚Äôs easier said than done!\n$\n16\n\nGreen Washing\n‚Ä¢ Deceptively use marketing techniques to \nclaim being eco-friendly. \n‚Ä¢ Opting for green-coloured designs. \n‚Ä¢ Red/orange is usually perceived as \ntasty. \n‚Ä¢ Green is perceived as eco-friendly. \n‚Ä¢ The VW case. (?)\n17\n\nThe VW scandal\nGreenwashing\n‚Ä¢ Used software to cheat on vehicle emissions \ntests. \n‚Ä¢ The vehicle‚Äôs software could detect whether they \nwere being tested, changing the performance \naccordingly to improve results. \n‚Ä¢ Affected 11M cars worldwide, 8M in Europe.\n18\n\nHow can we drive sustainability \nin the SE industry?\n\nGreen Procurement\n‚Ä¢ Customers decide on providers that share their values \n‚Ä¢ This is currently the main trigger reason why organisations \nworry about Sustainability and Green Software. \n‚Ä¢ Examples of green procurement: \n‚Ä¢ Customers that only buy green services/products \n‚Ä¢ Companies that only use green providers \n‚Ä¢ Developers that only work for green companies \n‚Ä¢ Green procurement makes environmental sustainability \nessential for economical sustainability.\n20\n\nSustainability via compliance\n‚Ä¢ EU wants to be carbon neutral by 2030 \n‚Ä¢ This also affects the ICT sector. Estimated to impact \n14% of the global carbon footprint by 2040. \n‚Ä¢ Some initiatives are already being negotiated. \n‚Ä¢ Extending the smartphone lifetime to 7 years. \n‚Ä¢ Right-to-repair movement. https://repair.eu \n‚Ä¢ Making IT services relying on clean energy more \naccessible (e.g., less taxes).\n21\n\nSoftware for Sustainability \n‚Ä¢ We are not covering it in this course.\n\nCarbon-free giants\n‚Ä¢ Google, Microsoft, Meta/Facebook want to be carbon free by 2030 \n‚Ä¢ Carbon free is different from carbon neutral \n‚Ä¢ Green IT experts are needed to meet these goals\n23\n\n\nRebound effect*\n‚Ä¢ Energy consumption decreases ‚Üì‚Üì but demand also increases ‚Üë‚Üë. \n‚Ä¢ *a.k.a. Jevons Paradox in economics; Downs‚ÄìThomson paradox in\xa0mobility.', '[‚Ä¶]\n13\n\nAvoid Extraneous Graphics and \nAnimations  \n‚Ä¢ Context: Mobile apps that feature impressive graphics \nand animations. [‚Ä¶] \n‚Ä¢ Solution: Study the importance of graphics and \nanimations to the user experience and reduce them when \napplicable. [‚Ä¶]\n‚Ä¢ Example: Resort to low frame rates for animations when \npossible. \nDespite being important to improve user experience, graphics \nand animations are battery intensive and should be used with \nmoderation.  \n14\n\nEnergy Patterns are \nmore Frequent\nin Android Apps\n\nExample case: Nextcloud\nFOSS\n\nExample case: Nextcloud\n‚Ä¢ Users complain that sometimes they go on a trip and  Nextcloud drains their \nbattery. Users consider uninstalling the app when battery life is essential. \n‚Ä¢ File sync can be energy-greedy. Send large files to the server, long 3G/4G data connections. \n‚Ä¢ It is mostly used for backup. No real-time collaboration is needed. \n‚Ä¢ Energy requirements vary depending on context and user. Some days you really \nneed all the battery you can get. \n‚Ä¢ https://github.com/nextcloud/android/commit/\n8bc432027e0d33e8043cf40192203203a40ca29c\nSolutions?\n17\n\nExample case: K-9 mail\n18\n\nExample case: K-9 mail\n19\nSolutions?\n‚Ä¢ Some users noticed that K-9 mail was spending more energy than usual. üôâ \n‚Ä¢ A user that was having issues with a personal mail server  noticed that K-9 \nmail was the one of the most energy-greedy apps. IMAP IDLE protocol for real-time \nnotifications. \n‚Ä¢ When a connection is not possible, the app automatically retries later.', '‚Ä¢ Some users noticed that K-9 mail was spending more energy than usual. üôâ \n‚Ä¢ A user that was having issues with a personal mail server  noticed that K-9 \nmail was the one of the most energy-greedy apps. IMAP IDLE protocol for real-time \nnotifications. \n‚Ä¢ When a connection is not possible, the app automatically retries later. \n‚Ä¢ https://github.com/k9mail/k-9/commit/\n86f3b28f79509d1a4d613eb39f60603e08579ea3\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio) \n‚Ä¢ Dynamic Retry Delay \n‚Ä¢ Push Over Poll \n‚Ä¢ Reduce Size \n‚Ä¢ Cache \n‚Ä¢ Avoid Graphics and Animations\n20\n\nCarbon-Aware Computing for \nDatacenters \nhttps://sites.google.com/view/energy-efficiency-languages\n21\nAna Radovanovic ÃÅ, Ross Koningstein, Ian Schneider, Bokan \nChen, Alexandre Duarte, Binz Roy, Diyue Xiao, Maya \nHaridasan, Patrick Hung, Nick Care, Saurav Talukdar, Eric \nMullen, Kendal Smith, MariEllen Cottman, and Walfredo Cirne \n\n\n‚Ä¢ Google‚Äôs Carbon-Intelligent Computing System (CICS) \n‚Ä¢ Main idea: use carbon-intensity data to shift datacenter jobs in time \n‚Ä¢ Typically, job schedulers use a metric of cluster capacity to schedule a job in \na particular cluster. \n‚Ä¢ CICS overrides this metric with the virtual capacity curve (VCC) that \nfactors in Carbon intensity \n‚Ä¢ When a new job comes in, the scheduler estimates its CPU load and power \nusage and assigns it to a cluster if the VCC is not exceeded.\n23\n\n‚Ä¢ Jobs are divided between flexible and inflexible. \n‚Ä¢ Flexible load is considered shapeable/shiftable as long as its total daily \ncompute (CPU) demand is preserved \n‚Ä¢ The system needs to consider that, while running a job, the virtual capacity \ncurve (VCC) might drop. Hence, this job should not start in the first place. \n‚Ä¢ They forecast VCC for the next day\n24\n\n\nVirtual Cluster Capacity (VCC)\n‚Ä¢ Aims at reducing the peak load at carbon intensive hours but in total it should allow for the \nsome amount of daily computation!']","['<1-hop>\n\nShuffle \nüîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them.\n‚Ä¢ If you run 30 executions for version A and another batch for version B:\n‚Ä¢ External conditions that change over time will have a diÔ¨Äerent bias in \nthe 2 versions (e.g., room temperature changes).\n‚Ä¢ If you shuÔ¨Ñe, you reduce this risk.\n11', '<2-hop>\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio)\n‚Ä¢ Dynamic Retry Delay\n‚Ä¢ Push Over Poll\n‚Ä¢ Reduce Size\n‚Ä¢ Cache\n‚Ä¢ Avoid Graphics and Animations\n20', '<1-hop>\n\nShuffle \nüîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them.\n‚Ä¢ If you run 30 executions for version A and another batch for version B:\n‚Ä¢ External conditions that change over time will have a diÔ¨Äerent bias in \nthe 2 versions (e.g., room temperature changes).\n‚Ä¢ If you shuÔ¨Ñe, you reduce this risk.\n11', '<2-hop>\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio)\n‚Ä¢ Dynamic Retry Delay\n‚Ä¢ Push Over Poll\n‚Ä¢ Reduce Size\n‚Ä¢ Cache\n‚Ä¢ Avoid Graphics and Animations\n20']","EcoAndroid reduces risk by reducing size through optimizing the application to consume less energy and resources. By minimizing the size of the app, it can decrease the energy consumption required for data processing and storage, which in turn reduces the environmental impact and operational costs associated with running the app. This approach aligns with the broader goal of making software more sustainable and efficient.",EcoAndroid reduce risk by using Reduce Size feature which help minimize energy consumption and reduce impact of external factors like temperature changes.,0.0,0.5,0.5,0.55,0.249999999375,0.9425463305396282
How can static code analysis in data science be used to improve the energy efficiency of data centers and contribute to sustainable software engineering?,"['‚Ä¢\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy efficiency using static code analysis. \n‚Ä¢ We don‚Äôt need an accurate value. \n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention. \n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27\n\nC7 - Education\n‚Ä¢ Educational game for Software \nSustainability practices \n‚Ä¢ Purpose: use within software teams to \ndiscuss or learn about different sustainable \nIT practices: at the organisation level, \nsoftware, etc.\n28\nhttps://github.com/OttoKaaij/Ticket-To-Sustainability/?tab=readme-ov-file\n\nProject ideas (old)\n‚Ä¢ Plugin from EnergiBridge (GUI, report generator, python library, etc.) \n‚Ä¢ Plugin for ChatGPT (carbon emissions per chat window) \n‚Ä¢ Seamless measurements for AI libraries \n‚Ä¢ Energy patterns for Green AI \n‚Ä¢ Sustainable SW dev gamification \n‚Ä¢ Sustainability auditor for AI projects \n‚Ä¢ Energy Profiling of screen colour filter tools (or display settings) \n‚Ä¢ ‚Ä¶ you can also propose yours!\n\nhttps://edu.nl/64gpk\nedu.nl/64gpk', 'Revisiting Research Questions\n‚Ä¢ Can we compare the energy efficiency of software languages?  \n‚Ä¢ Is the faster language always the most energy efficient? \n‚Ä¢ How does memory usage relate to energy consumption?  \n‚Ä¢ Can we automatically decide what is the best programming language considering \nenergy, time, and memory usage?  \n‚Ä¢ How do the results of our energy consumption analysis of programming \nlanguages gathered from rigorous performance benchmarking solutions \ncompare to results of average day-to-day solutions?  \n‚Ä¢ What would happen if we cherry picked the tasks?\u2028\n44\n\n\nLu√≠s Cruz \nL.Cruz@tudelft.nl \n3. Scientific Guide for Reliable \nEnergy Experiments\nSustainable Software Engineering\u2028\nCS4575\nSustainableSE 2025\nCarolin Brandt \nC.E.Brandt@tudelft.nl \nEnrique Barba Roque \nE.BarbaRoque@tudelft.nl', 'data to understand state of software: \nbuildable?, open dev. history?, requirements documentation? \n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!\n\nB7. Queue - but better for the student / TA society\n‚Ä¢ Requirements analysis regarding social and individual sustainability effects \nof Queue \n‚Ä¢ Other EIP / TUD used software also possible: e.g., Answers EWI \n‚Ä¢ Non-technical project ‚Üí proper process (workshops? Interviews?) & rich \ndescription of outcomes focus of grading\nhttps://eip.pages.ewi.tudelft.nl/eip-website/queue.html\n\nC1. Compare energy consumption of docker images for \nML workloads.\n‚Ä¢ Similar to what we have seen in the lectures but for ML-specific workloads. \n‚Ä¢ We can reuse existing experiment replication packages.\n22\n\nC2. Plugin to visualize Hugging Face carbon emissions.\n‚Ä¢ https://huggingface.co/blog/leaderboard-emissions-\nanalysis \n‚Ä¢\nYoo, Taewon, et al. ""Visualizing the Carbon Intensity of Machine Learning Inference for Image Analysis on TensorFlow Hub.""\n\nC3. Plugin for ChatGPT\n‚Ä¢ Users seldom know how much carbon they are emitting when they interact \nwith chat GPT. \n‚Ä¢ Let‚Äôs make it transparent to the users. Browser plugin?\n24\nCO2\n\nC4. NutriScore for software libraries\n25\n‚Ä¢ NutriScore labels are not perfect but they are a good starting point! \n‚Ä¢ What if we could do the same thing for the energy efficiency of software. \n‚Ä¢ (Also open to individual or social sustainability) \n‚Ä¢ This work can be scoped in particular domains/ecossystems/use cases. \n‚Ä¢ Libraries for stats? ML? Web Dev? Cloud?\n\nC5. Add energy-awareness to existing software\n26\n‚Ä¢ Streamlit, Notebooks, JSFiddle, \nPyScript, zsh, etc. \n‚Ä¢\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy efficiency using static code analysis. \n‚Ä¢ We don‚Äôt need an accurate value. \n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention. \n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)']","['<1-hop>\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy eÔ¨Éciency using static code analysis.\n‚Ä¢ We don‚Äôt need an accurate value.\n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.\n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27', '<2-hop>\n\nWhy?\n‚Ä¢ Throughout your career you might:\n‚Ä¢ Design/maintain/contract data centers\n‚Ä¢ Set up operations/devops\n‚Ä¢ Develop AI for IoT devices\n‚Ä¢ Be the next CEO/CTO of a software company\n‚Ä¢ Sustainability can be your main role:\n‚Ä¢ Green Software Developer\n‚Ä¢ Sustainability Consultant\n‚Ä¢ Green Advocate \n‚Ä¢ Founder of a Green Tech startup (B2B?)\n28', '<1-hop>\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy eÔ¨Éciency using static code analysis.\n‚Ä¢ We don‚Äôt need an accurate value.\n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.\n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27', '<2-hop>\n\nWhy?\n‚Ä¢ Throughout your career you might:\n‚Ä¢ Design/maintain/contract data centers\n‚Ä¢ Set up operations/devops\n‚Ä¢ Develop AI for IoT devices\n‚Ä¢ Be the next CEO/CTO of a software company\n‚Ä¢ Sustainability can be your main role:\n‚Ä¢ Green Software Developer\n‚Ä¢ Sustainability Consultant\n‚Ä¢ Green Advocate \n‚Ä¢ Founder of a Green Tech startup (B2B?)\n28', '<1-hop>\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy eÔ¨Éciency using static code analysis.\n‚Ä¢ We don‚Äôt need an accurate value.\n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.\n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27', '<2-hop>\n\nWhy?\n‚Ä¢ Throughout your career you might:\n‚Ä¢ Design/maintain/contract data centers\n‚Ä¢ Set up operations/devops\n‚Ä¢ Develop AI for IoT devices\n‚Ä¢ Be the next CEO/CTO of a software company\n‚Ä¢ Sustainability can be your main role:\n‚Ä¢ Green Software Developer\n‚Ä¢ Sustainability Consultant\n‚Ä¢ Green Advocate \n‚Ä¢ Founder of a Green Tech startup (B2B?)\n28', '<1-hop>\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy eÔ¨Éciency using static code analysis.\n‚Ä¢ We don‚Äôt need an accurate value.\n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.\n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27', '<2-hop>\n\nWhy?\n‚Ä¢ Throughout your career you might:\n‚Ä¢ Design/maintain/contract data centers\n‚Ä¢ Set up operations/devops\n‚Ä¢ Develop AI for IoT devices\n‚Ä¢ Be the next CEO/CTO of a software company\n‚Ä¢ Sustainability can be your main role:\n‚Ä¢ Green Software Developer\n‚Ä¢ Sustainability Consultant\n‚Ä¢ Green Advocate \n‚Ä¢ Founder of a Green Tech startup (B2B?)\n28']","Static code analysis in data science can be used to improve the energy efficiency of data centers by identifying code that is likely to introduce energy hotspots. By estimating energy efficiency through static code analysis, developers can pinpoint which parts of the codebase require more attention and optimization. This proactive approach allows for targeted improvements that can reduce energy consumption, thereby contributing to sustainable software engineering. While the analysis does not need to provide an accurate value, it helps in highlighting potential inefficiencies that, when addressed, can lead to significant energy savings in data centers. This method can be scoped specifically to data science domains, allowing for tailored optimizations that align with the specific computational demands of data science workloads.","Static code analysis in data science can be used to estimate energy efficiency by identifying potential energy hotspots in the code. This helps in reviewing and optimizing the code to reduce energy consumption. By applying this approach, developers can contribute to the design and maintenance of more energy-efficient data centers, aligning with sustainable software engineering practices.",0.8333333332916666,0.6666666666666666,1.0,0.89,0.0,0.9741397758691273
How can static code analysis in data science contribute to the development of more sustainable data centers?,"['‚Ä¢\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy efficiency using static code analysis. \n‚Ä¢ We don‚Äôt need an accurate value. \n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention. \n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27\n\nC7 - Education\n‚Ä¢ Educational game for Software \nSustainability practices \n‚Ä¢ Purpose: use within software teams to \ndiscuss or learn about different sustainable \nIT practices: at the organisation level, \nsoftware, etc.\n28\nhttps://github.com/OttoKaaij/Ticket-To-Sustainability/?tab=readme-ov-file\n\nProject ideas (old)\n‚Ä¢ Plugin from EnergiBridge (GUI, report generator, python library, etc.) \n‚Ä¢ Plugin for ChatGPT (carbon emissions per chat window) \n‚Ä¢ Seamless measurements for AI libraries \n‚Ä¢ Energy patterns for Green AI \n‚Ä¢ Sustainable SW dev gamification \n‚Ä¢ Sustainability auditor for AI projects \n‚Ä¢ Energy Profiling of screen colour filter tools (or display settings) \n‚Ä¢ ‚Ä¶ you can also propose yours!\n\nhttps://edu.nl/64gpk\nedu.nl/64gpk', 'data to understand state of software: \nbuildable?, open dev. history?, requirements documentation? \n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!\n\nB7. Queue - but better for the student / TA society\n‚Ä¢ Requirements analysis regarding social and individual sustainability effects \nof Queue \n‚Ä¢ Other EIP / TUD used software also possible: e.g., Answers EWI \n‚Ä¢ Non-technical project ‚Üí proper process (workshops? Interviews?) & rich \ndescription of outcomes focus of grading\nhttps://eip.pages.ewi.tudelft.nl/eip-website/queue.html\n\nC1. Compare energy consumption of docker images for \nML workloads.\n‚Ä¢ Similar to what we have seen in the lectures but for ML-specific workloads. \n‚Ä¢ We can reuse existing experiment replication packages.\n22\n\nC2. Plugin to visualize Hugging Face carbon emissions.\n‚Ä¢ https://huggingface.co/blog/leaderboard-emissions-\nanalysis \n‚Ä¢\nYoo, Taewon, et al. ""Visualizing the Carbon Intensity of Machine Learning Inference for Image Analysis on TensorFlow Hub.""\n\nC3. Plugin for ChatGPT\n‚Ä¢ Users seldom know how much carbon they are emitting when they interact \nwith chat GPT. \n‚Ä¢ Let‚Äôs make it transparent to the users. Browser plugin?\n24\nCO2\n\nC4. NutriScore for software libraries\n25\n‚Ä¢ NutriScore labels are not perfect but they are a good starting point! \n‚Ä¢ What if we could do the same thing for the energy efficiency of software. \n‚Ä¢ (Also open to individual or social sustainability) \n‚Ä¢ This work can be scoped in particular domains/ecossystems/use cases. \n‚Ä¢ Libraries for stats? ML? Web Dev? Cloud?\n\nC5. Add energy-awareness to existing software\n26\n‚Ä¢ Streamlit, Notebooks, JSFiddle, \nPyScript, zsh, etc. \n‚Ä¢\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy efficiency using static code analysis. \n‚Ä¢ We don‚Äôt need an accurate value. \n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention. \n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)', 'Green Data-centric AI\n‚Ä¢ How do different ML algorithms compare \nin terms of energy consumption? \n‚Ä¢ How does number of rows relate to the \nenergy consumption of ML models? \n‚Ä¢ How does number of features relate to \nthe energy consumption of ML models? \n‚Ä¢ What is the impact of reducing data in the \nperformance of the model? \n‚Ä¢ Method -> results -> discussion\n17\n\nMethod\n‚Ä¢ Single object of study: natural language model to detect spam messages. \n‚Ä¢ 6 machine learning algorithms: SVM, Decision Tree, KNN, Random Forrest, \nAdaBoost, Bagging Classifier. \n‚Ä¢ Reduce the number of rows. 10%, 20%, .., 100% \n‚Ä¢ Stratified random sampling (?) \n‚Ä¢ Reduce the number of features. 10%, 20%, .., 100% \n‚Ä¢ Feature importance metric based on the Chi-Square Test (Chi2) \n‚Ä¢ Estimate energy consumption using a RAPL-based tool. (?)\n18\n\n‚Ä¢ Repeat 30 times \n‚Ä¢ Fix random seeds \n‚Ä¢ ‚Ä¶ \n‚Ä¢ Data was not Normal => tailed Normal distribution.\n19\n(?)\n\nResults: energy consumption of algorithms\n\nResults: energy vs data shape\n\nResults: performance vs data shape\n\nDiscussion\n‚Ä¢ Other data properties should be investigated. \n‚Ä¢ E.g., data types \n‚Ä¢ Reporting energy data is essential. It can lead to different model selection \nwithout hindering model performance. \n‚Ä¢ There is a big opportunity in Model and Data Simplification.\n23\n\nData/Model Simplification\n‚Ä¢ (?) \n‚Ä¢ Data selection \n‚Ä¢ Data quantisation. Posit? \n‚Ä¢ Data distillation \n‚Ä¢ Coreset extraction (?) \n‚Ä¢ Model distillation \n‚Ä¢ Model quantisation \n‚Ä¢ Model pruning \n‚Ä¢ ‚Ä¶\n24\n\nPosit vs Float\nMore about this: https://spectrum.ieee.org/floating-point-numbers-posits-processor\nBetter for DL use cases\n\nHow can we tune \nlearning \nparameters \nefficiently?\n\nHyper parameter tuning\n‚Ä¢ When training an ML model, there are several parameters that need to be \ntuned. \n‚Ä¢ E.g., in SVM we have the Regularization parameter C, the kernel function, \nthe degree of the kernel function, and depending on the case, many other. \n‚Ä¢ The common approach revolves around grid search. The user provides a \nsequence of possible values for each parameter and the pipeline runs all \npossible combinations.']","['<1-hop>\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy eÔ¨Éciency using static code analysis.\n‚Ä¢ We don‚Äôt need an accurate value.\n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.\n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27', '<2-hop>\n\nWhy?\n‚Ä¢ Throughout your career you might:\n‚Ä¢ Design/maintain/contract data centers\n‚Ä¢ Set up operations/devops\n‚Ä¢ Develop AI for IoT devices\n‚Ä¢ Be the next CEO/CTO of a software company\n‚Ä¢ Sustainability can be your main role:\n‚Ä¢ Green Software Developer\n‚Ä¢ Sustainability Consultant\n‚Ä¢ Green Advocate \n‚Ä¢ Founder of a Green Tech startup (B2B?)\n28']","Static code analysis in data science can contribute to the development of more sustainable data centers by estimating energy efficiency and identifying potential energy hotspots in the code. By analyzing the code without executing it, developers can pinpoint which parts of the code are likely to consume more energy and therefore should be reviewed with more attention. This proactive approach allows for optimizations that can reduce energy consumption, leading to more efficient use of resources in data centers. This process can be scoped to specific domains, such as data science, to tailor the analysis to the particular needs and characteristics of the field.","Static code analysis in data science can contribute to the development of more sustainable data centers by estimating energy efficiency and identifying potential energy hotspots within the code. This approach allows developers to focus on reviewing code segments that are more likely to introduce inefficiencies, thereby optimizing resource usage. By integrating such practices, especially in domains like data science, developers can help create more sustainable solutions, which aligns with broader career goals in sustainability, such as designing or maintaining energy-efficient data centers.",0.99999999995,1.0,0.7272727272727273,0.75,0.2222222219753086,0.9885357282970041
How can static code analysis in data science projects help in designing more sustainablility-focused data centers?,"['‚Ä¢\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy efficiency using static code analysis. \n‚Ä¢ We don‚Äôt need an accurate value. \n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention. \n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27\n\nC7 - Education\n‚Ä¢ Educational game for Software \nSustainability practices \n‚Ä¢ Purpose: use within software teams to \ndiscuss or learn about different sustainable \nIT practices: at the organisation level, \nsoftware, etc.\n28\nhttps://github.com/OttoKaaij/Ticket-To-Sustainability/?tab=readme-ov-file\n\nProject ideas (old)\n‚Ä¢ Plugin from EnergiBridge (GUI, report generator, python library, etc.) \n‚Ä¢ Plugin for ChatGPT (carbon emissions per chat window) \n‚Ä¢ Seamless measurements for AI libraries \n‚Ä¢ Energy patterns for Green AI \n‚Ä¢ Sustainable SW dev gamification \n‚Ä¢ Sustainability auditor for AI projects \n‚Ä¢ Energy Profiling of screen colour filter tools (or display settings) \n‚Ä¢ ‚Ä¶ you can also propose yours!\n\nhttps://edu.nl/64gpk\nedu.nl/64gpk', 'data to understand state of software: \nbuildable?, open dev. history?, requirements documentation? \n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!\n\nB7. Queue - but better for the student / TA society\n‚Ä¢ Requirements analysis regarding social and individual sustainability effects \nof Queue \n‚Ä¢ Other EIP / TUD used software also possible: e.g., Answers EWI \n‚Ä¢ Non-technical project ‚Üí proper process (workshops? Interviews?) & rich \ndescription of outcomes focus of grading\nhttps://eip.pages.ewi.tudelft.nl/eip-website/queue.html\n\nC1. Compare energy consumption of docker images for \nML workloads.\n‚Ä¢ Similar to what we have seen in the lectures but for ML-specific workloads. \n‚Ä¢ We can reuse existing experiment replication packages.\n22\n\nC2. Plugin to visualize Hugging Face carbon emissions.\n‚Ä¢ https://huggingface.co/blog/leaderboard-emissions-\nanalysis \n‚Ä¢\nYoo, Taewon, et al. ""Visualizing the Carbon Intensity of Machine Learning Inference for Image Analysis on TensorFlow Hub.""\n\nC3. Plugin for ChatGPT\n‚Ä¢ Users seldom know how much carbon they are emitting when they interact \nwith chat GPT. \n‚Ä¢ Let‚Äôs make it transparent to the users. Browser plugin?\n24\nCO2\n\nC4. NutriScore for software libraries\n25\n‚Ä¢ NutriScore labels are not perfect but they are a good starting point! \n‚Ä¢ What if we could do the same thing for the energy efficiency of software. \n‚Ä¢ (Also open to individual or social sustainability) \n‚Ä¢ This work can be scoped in particular domains/ecossystems/use cases. \n‚Ä¢ Libraries for stats? ML? Web Dev? Cloud?\n\nC5. Add energy-awareness to existing software\n26\n‚Ä¢ Streamlit, Notebooks, JSFiddle, \nPyScript, zsh, etc. \n‚Ä¢\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy efficiency using static code analysis. \n‚Ä¢ We don‚Äôt need an accurate value. \n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention. \n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)', 'Revisiting Research Questions\n‚Ä¢ Can we compare the energy efficiency of software languages?  \n‚Ä¢ Is the faster language always the most energy efficient? \n‚Ä¢ How does memory usage relate to energy consumption?  \n‚Ä¢ Can we automatically decide what is the best programming language considering \nenergy, time, and memory usage?  \n‚Ä¢ How do the results of our energy consumption analysis of programming \nlanguages gathered from rigorous performance benchmarking solutions \ncompare to results of average day-to-day solutions?  \n‚Ä¢ What would happen if we cherry picked the tasks?\u2028\n44\n\n\nLu√≠s Cruz \nL.Cruz@tudelft.nl \n3. Scientific Guide for Reliable \nEnergy Experiments\nSustainable Software Engineering\u2028\nCS4575\nSustainableSE 2025\nCarolin Brandt \nC.E.Brandt@tudelft.nl \nEnrique Barba Roque \nE.BarbaRoque@tudelft.nl']","['<1-hop>\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy eÔ¨Éciency using static code analysis.\n‚Ä¢ We don‚Äôt need an accurate value.\n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.\n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27', '<2-hop>\n\nWhy?\n‚Ä¢ Throughout your career you might:\n‚Ä¢ Design/maintain/contract data centers\n‚Ä¢ Set up operations/devops\n‚Ä¢ Develop AI for IoT devices\n‚Ä¢ Be the next CEO/CTO of a software company\n‚Ä¢ Sustainability can be your main role:\n‚Ä¢ Green Software Developer\n‚Ä¢ Sustainability Consultant\n‚Ä¢ Green Advocate \n‚Ä¢ Founder of a Green Tech startup (B2B?)\n28', '<1-hop>\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy eÔ¨Éciency using static code analysis.\n‚Ä¢ We don‚Äôt need an accurate value.\n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.\n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27', '<2-hop>\n\nWhy?\n‚Ä¢ Throughout your career you might:\n‚Ä¢ Design/maintain/contract data centers\n‚Ä¢ Set up operations/devops\n‚Ä¢ Develop AI for IoT devices\n‚Ä¢ Be the next CEO/CTO of a software company\n‚Ä¢ Sustainability can be your main role:\n‚Ä¢ Green Software Developer\n‚Ä¢ Sustainability Consultant\n‚Ä¢ Green Advocate \n‚Ä¢ Founder of a Green Tech startup (B2B?)\n28', '<1-hop>\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy eÔ¨Éciency using static code analysis.\n‚Ä¢ We don‚Äôt need an accurate value.\n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.\n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27', '<2-hop>\n\nWhy?\n‚Ä¢ Throughout your career you might:\n‚Ä¢ Design/maintain/contract data centers\n‚Ä¢ Set up operations/devops\n‚Ä¢ Develop AI for IoT devices\n‚Ä¢ Be the next CEO/CTO of a software company\n‚Ä¢ Sustainability can be your main role:\n‚Ä¢ Green Software Developer\n‚Ä¢ Sustainability Consultant\n‚Ä¢ Green Advocate \n‚Ä¢ Founder of a Green Tech startup (B2B?)\n28']","Static code analysis in data science projects can help in designing more sustainability-focused data centers by estimating energy efficiency. Although it doesn't provide an accurate value, it identifies which parts of the code are more likely to introduce energy hotspots. By focusing on these areas, developers can optimize code to reduce energy consumption, which in turn can lead to more energy-efficient data centers. This approach allows for targeted improvements that can contribute to the overall sustainability of data center operations. (Source: C6 - Green Shift Left)","Static code analysis in data science projects can help in designing more sustainablility-focused data centers by identifying energy hotspots in the code. This allows developers to review and optimize code that may contribute to higher energy consumption, thereby supporting the development of more efficient and sustainable data centers.",0.99999999995,1.0,0.5,0.67,,0.9539320023174316
How does the use of static code analysis in data science projects contribute to the design and optimization of more sustanable data centers?,"['‚Ä¢\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy efficiency using static code analysis. \n‚Ä¢ We don‚Äôt need an accurate value. \n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention. \n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27\n\nC7 - Education\n‚Ä¢ Educational game for Software \nSustainability practices \n‚Ä¢ Purpose: use within software teams to \ndiscuss or learn about different sustainable \nIT practices: at the organisation level, \nsoftware, etc.\n28\nhttps://github.com/OttoKaaij/Ticket-To-Sustainability/?tab=readme-ov-file\n\nProject ideas (old)\n‚Ä¢ Plugin from EnergiBridge (GUI, report generator, python library, etc.) \n‚Ä¢ Plugin for ChatGPT (carbon emissions per chat window) \n‚Ä¢ Seamless measurements for AI libraries \n‚Ä¢ Energy patterns for Green AI \n‚Ä¢ Sustainable SW dev gamification \n‚Ä¢ Sustainability auditor for AI projects \n‚Ä¢ Energy Profiling of screen colour filter tools (or display settings) \n‚Ä¢ ‚Ä¶ you can also propose yours!\n\nhttps://edu.nl/64gpk\nedu.nl/64gpk', 'data to understand state of software: \nbuildable?, open dev. history?, requirements documentation? \n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!\n\nB7. Queue - but better for the student / TA society\n‚Ä¢ Requirements analysis regarding social and individual sustainability effects \nof Queue \n‚Ä¢ Other EIP / TUD used software also possible: e.g., Answers EWI \n‚Ä¢ Non-technical project ‚Üí proper process (workshops? Interviews?) & rich \ndescription of outcomes focus of grading\nhttps://eip.pages.ewi.tudelft.nl/eip-website/queue.html\n\nC1. Compare energy consumption of docker images for \nML workloads.\n‚Ä¢ Similar to what we have seen in the lectures but for ML-specific workloads. \n‚Ä¢ We can reuse existing experiment replication packages.\n22\n\nC2. Plugin to visualize Hugging Face carbon emissions.\n‚Ä¢ https://huggingface.co/blog/leaderboard-emissions-\nanalysis \n‚Ä¢\nYoo, Taewon, et al. ""Visualizing the Carbon Intensity of Machine Learning Inference for Image Analysis on TensorFlow Hub.""\n\nC3. Plugin for ChatGPT\n‚Ä¢ Users seldom know how much carbon they are emitting when they interact \nwith chat GPT. \n‚Ä¢ Let‚Äôs make it transparent to the users. Browser plugin?\n24\nCO2\n\nC4. NutriScore for software libraries\n25\n‚Ä¢ NutriScore labels are not perfect but they are a good starting point! \n‚Ä¢ What if we could do the same thing for the energy efficiency of software. \n‚Ä¢ (Also open to individual or social sustainability) \n‚Ä¢ This work can be scoped in particular domains/ecossystems/use cases. \n‚Ä¢ Libraries for stats? ML? Web Dev? Cloud?\n\nC5. Add energy-awareness to existing software\n26\n‚Ä¢ Streamlit, Notebooks, JSFiddle, \nPyScript, zsh, etc. \n‚Ä¢\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy efficiency using static code analysis. \n‚Ä¢ We don‚Äôt need an accurate value. \n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention. \n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)', 'Revisiting Research Questions\n‚Ä¢ Can we compare the energy efficiency of software languages?  \n‚Ä¢ Is the faster language always the most energy efficient? \n‚Ä¢ How does memory usage relate to energy consumption?  \n‚Ä¢ Can we automatically decide what is the best programming language considering \nenergy, time, and memory usage?  \n‚Ä¢ How do the results of our energy consumption analysis of programming \nlanguages gathered from rigorous performance benchmarking solutions \ncompare to results of average day-to-day solutions?  \n‚Ä¢ What would happen if we cherry picked the tasks?\u2028\n44\n\n\nLu√≠s Cruz \nL.Cruz@tudelft.nl \n3. Scientific Guide for Reliable \nEnergy Experiments\nSustainable Software Engineering\u2028\nCS4575\nSustainableSE 2025\nCarolin Brandt \nC.E.Brandt@tudelft.nl \nEnrique Barba Roque \nE.BarbaRoque@tudelft.nl']","['<1-hop>\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy eÔ¨Éciency using static code analysis.\n‚Ä¢ We don‚Äôt need an accurate value.\n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.\n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27', '<2-hop>\n\nWhy?\n‚Ä¢ Throughout your career you might:\n‚Ä¢ Design/maintain/contract data centers\n‚Ä¢ Set up operations/devops\n‚Ä¢ Develop AI for IoT devices\n‚Ä¢ Be the next CEO/CTO of a software company\n‚Ä¢ Sustainability can be your main role:\n‚Ä¢ Green Software Developer\n‚Ä¢ Sustainability Consultant\n‚Ä¢ Green Advocate \n‚Ä¢ Founder of a Green Tech startup (B2B?)\n28', '<1-hop>\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy eÔ¨Éciency using static code analysis.\n‚Ä¢ We don‚Äôt need an accurate value.\n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.\n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27', '<2-hop>\n\nWhy?\n‚Ä¢ Throughout your career you might:\n‚Ä¢ Design/maintain/contract data centers\n‚Ä¢ Set up operations/devops\n‚Ä¢ Develop AI for IoT devices\n‚Ä¢ Be the next CEO/CTO of a software company\n‚Ä¢ Sustainability can be your main role:\n‚Ä¢ Green Software Developer\n‚Ä¢ Sustainability Consultant\n‚Ä¢ Green Advocate \n‚Ä¢ Founder of a Green Tech startup (B2B?)\n28']","The use of static code analysis in data science projects can contribute to the design and optimization of more sustainable data centers by estimating energy efficiency. Although it does not provide an accurate value, static code analysis helps identify which parts of the code are more likely to introduce energy hotspots. By focusing on these areas, developers can optimize the code to reduce energy consumption, which in turn can lead to more efficient use of resources in data centers. This approach can be scoped to specific domains, such as data science, to ensure targeted improvements in energy efficiency. (Source: C6 - Green Shift Left)","The use of static code analysis in data science projects contributes to the design and optimization of more sustainable data centers by identifying energy hotspots within the code. This process allows developers to focus on reviewing and optimizing sections of code that are more likely to introduce energy inefficiencies. By doing so, it supports the broader goal of creating more energy-efficient systems, which is crucial for the sustainable operation of data centers. This approach aligns with the growing need for green software development practices, where professionals can play roles such as green software developers or sustainability consultants, ensuring that energy efficiency is a key consideration throughout the software lifecycle.",0.99999999995,0.75,0.7142857142857143,0.57,0.0,0.9605090641898218
How reduce risk and reduce size in software engineering?,"['Lu√≠s Cruz \nL.Cruz@tudelft.nl \n10. Project 2\nSustainable Software Engineering\u2028\nCS4575\nSustainableSE 2025\nCarolin Brandt \nC.E.Brandt@tudelft.nl \nEnrique Barba Roque \nE.BarbaRoque@tudelft.nl\n\n1. Goal/assignment \n2. Deliverables \n3. Strategy \n4. Ideas\n\nAssignment\n‚Ä¢ Goal: Solve a Sustainable Software Engineering problem. \n‚Ä¢ Identify 1 problem that should be fixed to help enabling sustainability in \nthe software engineering industry/community. \n‚Ä¢ Propose a solution. A tool, framework, guidelines, etc. \n‚Ä¢ Implementation. \n‚Ä¢ Validation. (Depending on the idea) \n‚Ä¢ Dissemination/social impact. (Solution should be open source, welcome \ncontributors, post on social media? Tool website? Available in a package \nmanager?)\n3\n\nDeliverables\n‚Ä¢ Paper-like article. (Min 4 pages, max 10) \n‚Ä¢ Online git repo with open source codebase and/or replication package. \n‚Ä¢ Presentation: 5 min + 5min Q&A\n4\n\nArticle\n‚Ä¢ Different projects will have different expectations -> Make agreements with \nyour coach. \n‚Ä¢ Some projects are more technical and some projects more theoretical. \n‚Ä¢ Common requirements: \n‚Ä¢ Motivation, formulation of the problem being addressed, etc. \n‚Ä¢ Description of the solution. \n‚Ä¢ Validation of the solution (if applicable -> discuss with coach) \n‚Ä¢ Discussion of the solution. (Including limitations)\n5\n\nStrategy\n‚Ä¢ Starting next week, there are no lectures  \n‚Ä¢ Steering meetings from week 5 till week 9 (either online or in person).  \n‚Ä¢ 1 steering meeting per week. (4+1 sprints) \n‚Ä¢ Every week, you need to plan different tasks and assignments. \n‚Ä¢ Deadline April 4.\n6\n\nStrategy\n‚Ä¢ Week 0 \n‚Ä¢ Decide project idea (today) \n‚Ä¢ Define steering meeting schedule \n‚Ä¢ Create working document of the \narticle: Problem statement and solution \nproposal! \n‚Ä¢ Define and assign tasks for each week. \n‚Ä¢ Week 1 \n‚Ä¢ Implementation \n‚Ä¢ Agreements with supervisor. \n‚Ä¢ Week 2 \n‚Ä¢ Implementation \n‚Ä¢ Week 3 \n‚Ä¢ Implementation, Full draft of article, \ndissemination.', 'data to understand state of software: \nbuildable?, open dev. history?, requirements documentation? \n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!\n\nB7. Queue - but better for the student / TA society\n‚Ä¢ Requirements analysis regarding social and individual sustainability effects \nof Queue \n‚Ä¢ Other EIP / TUD used software also possible: e.g., Answers EWI \n‚Ä¢ Non-technical project ‚Üí proper process (workshops? Interviews?) & rich \ndescription of outcomes focus of grading\nhttps://eip.pages.ewi.tudelft.nl/eip-website/queue.html\n\nC1. Compare energy consumption of docker images for \nML workloads.\n‚Ä¢ Similar to what we have seen in the lectures but for ML-specific workloads. \n‚Ä¢ We can reuse existing experiment replication packages.\n22\n\nC2. Plugin to visualize Hugging Face carbon emissions.\n‚Ä¢ https://huggingface.co/blog/leaderboard-emissions-\nanalysis \n‚Ä¢\nYoo, Taewon, et al. ""Visualizing the Carbon Intensity of Machine Learning Inference for Image Analysis on TensorFlow Hub.""\n\nC3. Plugin for ChatGPT\n‚Ä¢ Users seldom know how much carbon they are emitting when they interact \nwith chat GPT. \n‚Ä¢ Let‚Äôs make it transparent to the users. Browser plugin?\n24\nCO2\n\nC4. NutriScore for software libraries\n25\n‚Ä¢ NutriScore labels are not perfect but they are a good starting point! \n‚Ä¢ What if we could do the same thing for the energy efficiency of software. \n‚Ä¢ (Also open to individual or social sustainability) \n‚Ä¢ This work can be scoped in particular domains/ecossystems/use cases. \n‚Ä¢ Libraries for stats? ML? Web Dev? Cloud?\n\nC5. Add energy-awareness to existing software\n26\n‚Ä¢ Streamlit, Notebooks, JSFiddle, \nPyScript, zsh, etc. \n‚Ä¢\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy efficiency using static code analysis. \n‚Ä¢ We don‚Äôt need an accurate value. \n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention. \n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)', 'Revisiting Research Questions\n‚Ä¢ Can we compare the energy efficiency of software languages?  \n‚Ä¢ Is the faster language always the most energy efficient? \n‚Ä¢ How does memory usage relate to energy consumption?  \n‚Ä¢ Can we automatically decide what is the best programming language considering \nenergy, time, and memory usage?  \n‚Ä¢ How do the results of our energy consumption analysis of programming \nlanguages gathered from rigorous performance benchmarking solutions \ncompare to results of average day-to-day solutions?  \n‚Ä¢ What would happen if we cherry picked the tasks?\u2028\n44\n\n\nLu√≠s Cruz \nL.Cruz@tudelft.nl \n3. Scientific Guide for Reliable \nEnergy Experiments\nSustainable Software Engineering\u2028\nCS4575\nSustainableSE 2025\nCarolin Brandt \nC.E.Brandt@tudelft.nl \nEnrique Barba Roque \nE.BarbaRoque@tudelft.nl']","['<1-hop>\n\nShuffle \nüîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them.\n‚Ä¢ If you run 30 executions for version A and another batch for version B:\n‚Ä¢ External conditions that change over time will have a diÔ¨Äerent bias in \nthe 2 versions (e.g., room temperature changes).\n‚Ä¢ If you shuÔ¨Ñe, you reduce this risk.\n11', '<2-hop>\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio)\n‚Ä¢ Dynamic Retry Delay\n‚Ä¢ Push Over Poll\n‚Ä¢ Reduce Size\n‚Ä¢ Cache\n‚Ä¢ Avoid Graphics and Animations\n20', '<1-hop>\n\nShuffle \nüîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them.\n‚Ä¢ If you run 30 executions for version A and another batch for version B:\n‚Ä¢ External conditions that change over time will have a diÔ¨Äerent bias in \nthe 2 versions (e.g., room temperature changes).\n‚Ä¢ If you shuÔ¨Ñe, you reduce this risk.\n11', '<2-hop>\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio)\n‚Ä¢ Dynamic Retry Delay\n‚Ä¢ Push Over Poll\n‚Ä¢ Reduce Size\n‚Ä¢ Cache\n‚Ä¢ Avoid Graphics and Animations\n20']","The provided sources do not directly address the question of reducing risk and size in software engineering. However, based on general software engineering principles, here are some strategies that can be applied:

1. **Modular Design**: Break down the software into smaller, manageable modules. This reduces complexity and makes it easier to manage changes and identify issues.

2. **Code Refactoring**: Regularly refactor code to improve its structure and reduce size without changing its functionality. This can help in maintaining a clean codebase and reducing technical debt.

3. **Automated Testing**: Implement automated testing to quickly identify and fix bugs, reducing the risk of defects in the software.

4. **Version Control**: Use version control systems to manage changes and track the history of the codebase, which helps in mitigating risks associated with changes.

5. **Static Code Analysis**: Use tools for static code analysis to identify potential issues in the code early in the development process.

6. **Continuous Integration/Continuous Deployment (CI/CD)**: Implement CI/CD pipelines to automate the process of testing and deploying code, reducing the risk of human error.

7. **Documentation**: Maintain thorough documentation to ensure that the software is understandable and maintainable by different team members.

These strategies can help in reducing both the risk and size of software projects, leading to more sustainable and efficient software engineering practices.","To reduce risk, shuffling executions helps control external factors like temperature changes. To reduce size, EcoAndroid uses features like dynamic retry delay and push over poll.",0.0,1.0,0.1875,0.29,0.0,0.9805639151252591
How shuffling reduce risk and EcoAndroid reduce size?,"['[‚Ä¶]\n13\n\nAvoid Extraneous Graphics and \nAnimations  \n‚Ä¢ Context: Mobile apps that feature impressive graphics \nand animations. [‚Ä¶] \n‚Ä¢ Solution: Study the importance of graphics and \nanimations to the user experience and reduce them when \napplicable. [‚Ä¶]\n‚Ä¢ Example: Resort to low frame rates for animations when \npossible. \nDespite being important to improve user experience, graphics \nand animations are battery intensive and should be used with \nmoderation.  \n14\n\nEnergy Patterns are \nmore Frequent\nin Android Apps\n\nExample case: Nextcloud\nFOSS\n\nExample case: Nextcloud\n‚Ä¢ Users complain that sometimes they go on a trip and  Nextcloud drains their \nbattery. Users consider uninstalling the app when battery life is essential. \n‚Ä¢ File sync can be energy-greedy. Send large files to the server, long 3G/4G data connections. \n‚Ä¢ It is mostly used for backup. No real-time collaboration is needed. \n‚Ä¢ Energy requirements vary depending on context and user. Some days you really \nneed all the battery you can get. \n‚Ä¢ https://github.com/nextcloud/android/commit/\n8bc432027e0d33e8043cf40192203203a40ca29c\nSolutions?\n17\n\nExample case: K-9 mail\n18\n\nExample case: K-9 mail\n19\nSolutions?\n‚Ä¢ Some users noticed that K-9 mail was spending more energy than usual. üôâ \n‚Ä¢ A user that was having issues with a personal mail server  noticed that K-9 \nmail was the one of the most energy-greedy apps. IMAP IDLE protocol for real-time \nnotifications. \n‚Ä¢ When a connection is not possible, the app automatically retries later.', '‚Ä¢\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy efficiency using static code analysis. \n‚Ä¢ We don‚Äôt need an accurate value. \n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention. \n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27\n\nC7 - Education\n‚Ä¢ Educational game for Software \nSustainability practices \n‚Ä¢ Purpose: use within software teams to \ndiscuss or learn about different sustainable \nIT practices: at the organisation level, \nsoftware, etc.\n28\nhttps://github.com/OttoKaaij/Ticket-To-Sustainability/?tab=readme-ov-file\n\nProject ideas (old)\n‚Ä¢ Plugin from EnergiBridge (GUI, report generator, python library, etc.) \n‚Ä¢ Plugin for ChatGPT (carbon emissions per chat window) \n‚Ä¢ Seamless measurements for AI libraries \n‚Ä¢ Energy patterns for Green AI \n‚Ä¢ Sustainable SW dev gamification \n‚Ä¢ Sustainability auditor for AI projects \n‚Ä¢ Energy Profiling of screen colour filter tools (or display settings) \n‚Ä¢ ‚Ä¶ you can also propose yours!\n\nhttps://edu.nl/64gpk\nedu.nl/64gpk', '‚Ä¢ Some users noticed that K-9 mail was spending more energy than usual. üôâ \n‚Ä¢ A user that was having issues with a personal mail server  noticed that K-9 \nmail was the one of the most energy-greedy apps. IMAP IDLE protocol for real-time \nnotifications. \n‚Ä¢ When a connection is not possible, the app automatically retries later. \n‚Ä¢ https://github.com/k9mail/k-9/commit/\n86f3b28f79509d1a4d613eb39f60603e08579ea3\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio) \n‚Ä¢ Dynamic Retry Delay \n‚Ä¢ Push Over Poll \n‚Ä¢ Reduce Size \n‚Ä¢ Cache \n‚Ä¢ Avoid Graphics and Animations\n20\n\nCarbon-Aware Computing for \nDatacenters \nhttps://sites.google.com/view/energy-efficiency-languages\n21\nAna Radovanovic ÃÅ, Ross Koningstein, Ian Schneider, Bokan \nChen, Alexandre Duarte, Binz Roy, Diyue Xiao, Maya \nHaridasan, Patrick Hung, Nick Care, Saurav Talukdar, Eric \nMullen, Kendal Smith, MariEllen Cottman, and Walfredo Cirne \n\n\n‚Ä¢ Google‚Äôs Carbon-Intelligent Computing System (CICS) \n‚Ä¢ Main idea: use carbon-intensity data to shift datacenter jobs in time \n‚Ä¢ Typically, job schedulers use a metric of cluster capacity to schedule a job in \na particular cluster. \n‚Ä¢ CICS overrides this metric with the virtual capacity curve (VCC) that \nfactors in Carbon intensity \n‚Ä¢ When a new job comes in, the scheduler estimates its CPU load and power \nusage and assigns it to a cluster if the VCC is not exceeded.\n23\n\n‚Ä¢ Jobs are divided between flexible and inflexible. \n‚Ä¢ Flexible load is considered shapeable/shiftable as long as its total daily \ncompute (CPU) demand is preserved \n‚Ä¢ The system needs to consider that, while running a job, the virtual capacity \ncurve (VCC) might drop. Hence, this job should not start in the first place. \n‚Ä¢ They forecast VCC for the next day\n24\n\n\nVirtual Cluster Capacity (VCC)\n‚Ä¢ Aims at reducing the peak load at carbon intensive hours but in total it should allow for the \nsome amount of daily computation!']","['<1-hop>\n\nShuffle \nüîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them.\n‚Ä¢ If you run 30 executions for version A and another batch for version B:\n‚Ä¢ External conditions that change over time will have a diÔ¨Äerent bias in \nthe 2 versions (e.g., room temperature changes).\n‚Ä¢ If you shuÔ¨Ñe, you reduce this risk.\n11', '<2-hop>\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio)\n‚Ä¢ Dynamic Retry Delay\n‚Ä¢ Push Over Poll\n‚Ä¢ Reduce Size\n‚Ä¢ Cache\n‚Ä¢ Avoid Graphics and Animations\n20', '<1-hop>\n\nShuffle \nüîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them.\n‚Ä¢ If you run 30 executions for version A and another batch for version B:\n‚Ä¢ External conditions that change over time will have a diÔ¨Äerent bias in \nthe 2 versions (e.g., room temperature changes).\n‚Ä¢ If you shuÔ¨Ñe, you reduce this risk.\n11', '<2-hop>\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio)\n‚Ä¢ Dynamic Retry Delay\n‚Ä¢ Push Over Poll\n‚Ä¢ Reduce Size\n‚Ä¢ Cache\n‚Ä¢ Avoid Graphics and Animations\n20', '<1-hop>\n\nShuffle \nüîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them.\n‚Ä¢ If you run 30 executions for version A and another batch for version B:\n‚Ä¢ External conditions that change over time will have a diÔ¨Äerent bias in \nthe 2 versions (e.g., room temperature changes).\n‚Ä¢ If you shuÔ¨Ñe, you reduce this risk.\n11', '<2-hop>\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio)\n‚Ä¢ Dynamic Retry Delay\n‚Ä¢ Push Over Poll\n‚Ä¢ Reduce Size\n‚Ä¢ Cache\n‚Ä¢ Avoid Graphics and Animations\n20']","The sources provided do not specifically mention ""shuffling"" in the context of reducing risk. However, in general, shuffling can reduce risk by randomizing the order of operations or data, which can help prevent patterns that might lead to vulnerabilities or inefficiencies.

Regarding EcoAndroid, the source mentions ""Reduce Size"" as one of the strategies. While the specific details on how EcoAndroid achieves size reduction are not provided, generally, reducing size in an application can involve optimizing code, removing unnecessary resources, and compressing assets, which can lead to lower energy consumption and improved performance.",Shuffling reduce risk by controlling external factors like room temperature changes. EcoAndroid reduce size by using features like caching and avoiding graphics and animations.,0.0,0.5,0.42857142857142855,0.18,0.16666666638888888,0.0
How shuffling reduce risk when compare to EcoAndroid reduce size?,"['[‚Ä¶]\n13\n\nAvoid Extraneous Graphics and \nAnimations  \n‚Ä¢ Context: Mobile apps that feature impressive graphics \nand animations. [‚Ä¶] \n‚Ä¢ Solution: Study the importance of graphics and \nanimations to the user experience and reduce them when \napplicable. [‚Ä¶]\n‚Ä¢ Example: Resort to low frame rates for animations when \npossible. \nDespite being important to improve user experience, graphics \nand animations are battery intensive and should be used with \nmoderation.  \n14\n\nEnergy Patterns are \nmore Frequent\nin Android Apps\n\nExample case: Nextcloud\nFOSS\n\nExample case: Nextcloud\n‚Ä¢ Users complain that sometimes they go on a trip and  Nextcloud drains their \nbattery. Users consider uninstalling the app when battery life is essential. \n‚Ä¢ File sync can be energy-greedy. Send large files to the server, long 3G/4G data connections. \n‚Ä¢ It is mostly used for backup. No real-time collaboration is needed. \n‚Ä¢ Energy requirements vary depending on context and user. Some days you really \nneed all the battery you can get. \n‚Ä¢ https://github.com/nextcloud/android/commit/\n8bc432027e0d33e8043cf40192203203a40ca29c\nSolutions?\n17\n\nExample case: K-9 mail\n18\n\nExample case: K-9 mail\n19\nSolutions?\n‚Ä¢ Some users noticed that K-9 mail was spending more energy than usual. üôâ \n‚Ä¢ A user that was having issues with a personal mail server  noticed that K-9 \nmail was the one of the most energy-greedy apps. IMAP IDLE protocol for real-time \nnotifications. \n‚Ä¢ When a connection is not possible, the app automatically retries later.', '‚Ä¢ Some users noticed that K-9 mail was spending more energy than usual. üôâ \n‚Ä¢ A user that was having issues with a personal mail server  noticed that K-9 \nmail was the one of the most energy-greedy apps. IMAP IDLE protocol for real-time \nnotifications. \n‚Ä¢ When a connection is not possible, the app automatically retries later. \n‚Ä¢ https://github.com/k9mail/k-9/commit/\n86f3b28f79509d1a4d613eb39f60603e08579ea3\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio) \n‚Ä¢ Dynamic Retry Delay \n‚Ä¢ Push Over Poll \n‚Ä¢ Reduce Size \n‚Ä¢ Cache \n‚Ä¢ Avoid Graphics and Animations\n20\n\nCarbon-Aware Computing for \nDatacenters \nhttps://sites.google.com/view/energy-efficiency-languages\n21\nAna Radovanovic ÃÅ, Ross Koningstein, Ian Schneider, Bokan \nChen, Alexandre Duarte, Binz Roy, Diyue Xiao, Maya \nHaridasan, Patrick Hung, Nick Care, Saurav Talukdar, Eric \nMullen, Kendal Smith, MariEllen Cottman, and Walfredo Cirne \n\n\n‚Ä¢ Google‚Äôs Carbon-Intelligent Computing System (CICS) \n‚Ä¢ Main idea: use carbon-intensity data to shift datacenter jobs in time \n‚Ä¢ Typically, job schedulers use a metric of cluster capacity to schedule a job in \na particular cluster. \n‚Ä¢ CICS overrides this metric with the virtual capacity curve (VCC) that \nfactors in Carbon intensity \n‚Ä¢ When a new job comes in, the scheduler estimates its CPU load and power \nusage and assigns it to a cluster if the VCC is not exceeded.\n23\n\n‚Ä¢ Jobs are divided between flexible and inflexible. \n‚Ä¢ Flexible load is considered shapeable/shiftable as long as its total daily \ncompute (CPU) demand is preserved \n‚Ä¢ The system needs to consider that, while running a job, the virtual capacity \ncurve (VCC) might drop. Hence, this job should not start in the first place. \n‚Ä¢ They forecast VCC for the next day\n24\n\n\nVirtual Cluster Capacity (VCC)\n‚Ä¢ Aims at reducing the peak load at carbon intensive hours but in total it should allow for the \nsome amount of daily computation!', 'Green Data-centric AI\n‚Ä¢ How do different ML algorithms compare \nin terms of energy consumption? \n‚Ä¢ How does number of rows relate to the \nenergy consumption of ML models? \n‚Ä¢ How does number of features relate to \nthe energy consumption of ML models? \n‚Ä¢ What is the impact of reducing data in the \nperformance of the model? \n‚Ä¢ Method -> results -> discussion\n17\n\nMethod\n‚Ä¢ Single object of study: natural language model to detect spam messages. \n‚Ä¢ 6 machine learning algorithms: SVM, Decision Tree, KNN, Random Forrest, \nAdaBoost, Bagging Classifier. \n‚Ä¢ Reduce the number of rows. 10%, 20%, .., 100% \n‚Ä¢ Stratified random sampling (?) \n‚Ä¢ Reduce the number of features. 10%, 20%, .., 100% \n‚Ä¢ Feature importance metric based on the Chi-Square Test (Chi2) \n‚Ä¢ Estimate energy consumption using a RAPL-based tool. (?)\n18\n\n‚Ä¢ Repeat 30 times \n‚Ä¢ Fix random seeds \n‚Ä¢ ‚Ä¶ \n‚Ä¢ Data was not Normal => tailed Normal distribution.\n19\n(?)\n\nResults: energy consumption of algorithms\n\nResults: energy vs data shape\n\nResults: performance vs data shape\n\nDiscussion\n‚Ä¢ Other data properties should be investigated. \n‚Ä¢ E.g., data types \n‚Ä¢ Reporting energy data is essential. It can lead to different model selection \nwithout hindering model performance. \n‚Ä¢ There is a big opportunity in Model and Data Simplification.\n23\n\nData/Model Simplification\n‚Ä¢ (?) \n‚Ä¢ Data selection \n‚Ä¢ Data quantisation. Posit? \n‚Ä¢ Data distillation \n‚Ä¢ Coreset extraction (?) \n‚Ä¢ Model distillation \n‚Ä¢ Model quantisation \n‚Ä¢ Model pruning \n‚Ä¢ ‚Ä¶\n24\n\nPosit vs Float\nMore about this: https://spectrum.ieee.org/floating-point-numbers-posits-processor\nBetter for DL use cases\n\nHow can we tune \nlearning \nparameters \nefficiently?\n\nHyper parameter tuning\n‚Ä¢ When training an ML model, there are several parameters that need to be \ntuned. \n‚Ä¢ E.g., in SVM we have the Regularization parameter C, the kernel function, \nthe degree of the kernel function, and depending on the case, many other. \n‚Ä¢ The common approach revolves around grid search. The user provides a \nsequence of possible values for each parameter and the pipeline runs all \npossible combinations.']","['<1-hop>\n\nShuffle \nüîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them.\n‚Ä¢ If you run 30 executions for version A and another batch for version B:\n‚Ä¢ External conditions that change over time will have a diÔ¨Äerent bias in \nthe 2 versions (e.g., room temperature changes).\n‚Ä¢ If you shuÔ¨Ñe, you reduce this risk.\n11', '<2-hop>\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio)\n‚Ä¢ Dynamic Retry Delay\n‚Ä¢ Push Over Poll\n‚Ä¢ Reduce Size\n‚Ä¢ Cache\n‚Ä¢ Avoid Graphics and Animations\n20']","The sources provided do not contain specific information about shuffling or how it reduces risk in comparison to EcoAndroid's ""reduce size"" strategy. However, I can provide a general explanation:

Shuffling in the context of data processing or machine learning typically refers to randomizing the order of data points to prevent any bias that might arise from the order of data. This can reduce the risk of overfitting to specific patterns in the data sequence.

On the other hand, EcoAndroid's ""reduce size"" strategy likely involves minimizing the size of data or resources used by an application to conserve energy and improve performance. This can reduce the risk of excessive energy consumption and improve the efficiency of the app.

Both strategies aim to optimize performance and efficiency, but they address different aspects: shuffling focuses on data integrity and model robustness, while reducing size focuses on resource efficiency and energy conservation.",Shuffling reduce risk by balance external factor like room temperature change while EcoAndroid reduce size by optimize resource use.,0.0,0.0,0.4444444444444444,0.0,0.249999999375,0.9667081116261674
How shuffling reduce risk when reduce size in software engineering?,"['‚Ä¢\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy efficiency using static code analysis. \n‚Ä¢ We don‚Äôt need an accurate value. \n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention. \n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27\n\nC7 - Education\n‚Ä¢ Educational game for Software \nSustainability practices \n‚Ä¢ Purpose: use within software teams to \ndiscuss or learn about different sustainable \nIT practices: at the organisation level, \nsoftware, etc.\n28\nhttps://github.com/OttoKaaij/Ticket-To-Sustainability/?tab=readme-ov-file\n\nProject ideas (old)\n‚Ä¢ Plugin from EnergiBridge (GUI, report generator, python library, etc.) \n‚Ä¢ Plugin for ChatGPT (carbon emissions per chat window) \n‚Ä¢ Seamless measurements for AI libraries \n‚Ä¢ Energy patterns for Green AI \n‚Ä¢ Sustainable SW dev gamification \n‚Ä¢ Sustainability auditor for AI projects \n‚Ä¢ Energy Profiling of screen colour filter tools (or display settings) \n‚Ä¢ ‚Ä¶ you can also propose yours!\n\nhttps://edu.nl/64gpk\nedu.nl/64gpk', 'Rest ‚è∏\n‚Ä¢ It is common practice to do a pause/sleep between executions/\nmeasurements. \n‚Ä¢ Prevent tail energy consumption from previous measurements. ? \n‚Ä¢ Prevent collateral tasks of previous measurement from affecting the next \nmeasurement. \n‚Ä¢ There is no golden rule but one minute should be enough. It can be more or \nless depending on your hardware or the duration of your energy test.\n9\n\nt\nP\nTail Energy Consumption\n\nShuffle üîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them. \n‚Ä¢ If you run 30 executions for version A and another batch for version B: \n‚Ä¢ External conditions that change over time will have a different bias in \nthe 2 versions (e.g., room temperature changes). \n‚Ä¢ If you shuffle, you reduce this risk.\n11\n\nKeep it cool üå°\n‚Ä¢ Always make sure there is a stable room temperature. \n‚Ä¢ Tricky because, some times, experiments may have to run over a few days. \n‚Ä¢ If you cannot control room temperature: collect temperature data and filter \nout measurements where the room temperature is clearly deviating.\n12\n\nAutomate Executions ü§ñ\n‚Ä¢ (Already mentioned in the previous classes) \n‚Ä¢ One cannot run 30 shuffled experiments per version without automation‚Ä¶\n13\n\nData analysis\n14\n\n1. Exploratory Analysis\n‚Ä¢ Plot the data and inspect outliers or \nunexpected biases. \n‚Ä¢ Violin+box plots are usually handy. (?) \n‚Ä¢ It‚Äôs a nice way of combining the 30 \nexperiments, and of showing \ndescriptive statistics. (?) \n‚Ä¢ Shows the shape of the distribution \nof the data.\n15\n\n1. Exploratory Analysis (II)\n‚Ä¢ Data should be Normal. Unless there‚Äôs a \ngood reason. \n‚Ä¢ E.g., somewhere amongst the 30 executions, \nthere might be 1 or 2 that failed to finish due \nto some unexpected error. \n‚Ä¢ (It happens and that‚Äôs ok!)‚Äì consequently, \nthe execution is shorter and spends less \nenergy ‚Äì falsely appearing as more \nenergy efficient. \n‚Ä¢ If data is not Normal there might be some \nissues affecting the measurements that \nmight be ruining results. It is important to \ninvestigate this.\n16\n\nEnergy data is not normal. Why?', 'Revisiting Research Questions\n‚Ä¢ Can we compare the energy efficiency of software languages?  \n‚Ä¢ Is the faster language always the most energy efficient? \n‚Ä¢ How does memory usage relate to energy consumption?  \n‚Ä¢ Can we automatically decide what is the best programming language considering \nenergy, time, and memory usage?  \n‚Ä¢ How do the results of our energy consumption analysis of programming \nlanguages gathered from rigorous performance benchmarking solutions \ncompare to results of average day-to-day solutions?  \n‚Ä¢ What would happen if we cherry picked the tasks?\u2028\n44\n\n\nLu√≠s Cruz \nL.Cruz@tudelft.nl \n3. Scientific Guide for Reliable \nEnergy Experiments\nSustainable Software Engineering\u2028\nCS4575\nSustainableSE 2025\nCarolin Brandt \nC.E.Brandt@tudelft.nl \nEnrique Barba Roque \nE.BarbaRoque@tudelft.nl']","['<1-hop>\n\nShuffle \nüîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them.\n‚Ä¢ If you run 30 executions for version A and another batch for version B:\n‚Ä¢ External conditions that change over time will have a diÔ¨Äerent bias in \nthe 2 versions (e.g., room temperature changes).\n‚Ä¢ If you shuÔ¨Ñe, you reduce this risk.\n11', '<2-hop>\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio)\n‚Ä¢ Dynamic Retry Delay\n‚Ä¢ Push Over Poll\n‚Ä¢ Reduce Size\n‚Ä¢ Cache\n‚Ä¢ Avoid Graphics and Animations\n20', '<1-hop>\n\nShuffle \nüîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them.\n‚Ä¢ If you run 30 executions for version A and another batch for version B:\n‚Ä¢ External conditions that change over time will have a diÔ¨Äerent bias in \nthe 2 versions (e.g., room temperature changes).\n‚Ä¢ If you shuÔ¨Ñe, you reduce this risk.\n11', '<2-hop>\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio)\n‚Ä¢ Dynamic Retry Delay\n‚Ä¢ Push Over Poll\n‚Ä¢ Reduce Size\n‚Ä¢ Cache\n‚Ä¢ Avoid Graphics and Animations\n20']","Shuffling reduces risk in software engineering experiments by minimizing the impact of external conditions that can introduce bias. When you run multiple executions for different versions of software, external factors such as room temperature changes can affect the results. By shuffling the order of these executions, you reduce the risk that these external conditions will consistently bias one version over another, leading to more reliable and unbiased results.","Shuffling reduce risk by controlling external factors like room temperature changes, which help in reducing size in software engineering.",0.0,0.5,1.0,0.75,0.0,0.9551598280926026
How spiking neural networks relate to McCulloch-Pitts model?,"['McCulloch-Pitts neuron [1, 2]\n1940s: How do biological neurons compute basic \nlogic functions? (e.g. logic gates)\nNote: Ref. [3] gives a nice brief history on the ideas which lead to the \nMcCulloch-Pitts neuron.\n\nWhat is a neural network?\n1950s: How are neurons organized to perform \nsensory perception?\n\nWhat is a neural network?\n1950s: How are neurons organized to perform \nsensory perception?\nThe first ""neural network"": Perceptron (1958). [4]\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\nFrank Rosenblatt (Psychologist)\nwith a Mark I Perceptron computer in 1960\n\nWhat is a neural network?\n1950s: How are neurons organized to perform \nsensory perception?\nThe first ""neural network"": Perceptron (1958). [4]\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\nFrank Rosenblatt (Psychologist)\nwith a Mark I Perceptron computer in 1960\nPower-efficient\n\nNeuromorphic computing\nWhy neuromorphic computing?\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\n\nNeuromorphic computing\nWhy neuromorphic computing?\n‚ÄòBiological inspiration‚Äô for artificial neural networks (ANNs) is not a new idea.\nEmulation (as opposed to simulation) of neural networks in hardware is not a new idea.\nQuestion: What can we gain from increasing biological realism in existing neural networks?\n\nPower-efficiency at scale\nModern, deep neural networks*\nare trained using GPUs.\n* It is estimated that ChatGPT was trained on \n10,000-20,000 GPUs and that it will require\n30,000 GPUs to keep running stably in the future.\n* It is estimated that ChatGPT has 10-20 billion \nparameters.', 'Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002.', 'Neural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568']","[""<1-hop>\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant"", '<2-hop>\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \n(not publicly available) doi:10.1037/h0042519\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568', ""<1-hop>\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant"", '<2-hop>\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \n(not publicly available) doi:10.1037/h0042519\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568', ""<1-hop>\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant"", '<2-hop>\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \n(not publicly available) doi:10.1037/h0042519\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568']","The McCulloch-Pitts model, developed in the 1940s, is one of the earliest models of artificial neurons. It represents neurons as simple binary devices that compute basic logic functions, such as logic gates, based on weighted inputs and a threshold. This model laid the groundwork for understanding how biological neurons might perform computations.

Spiking neural networks (SNNs), on the other hand, are a more biologically realistic model of neural computation. They incorporate the concept of time into the firing of neurons, where neurons communicate by sending discrete spikes at particular times, rather than continuous signals. This allows SNNs to capture the temporal dynamics of neural activity more accurately than the McCulloch-Pitts model.

While the McCulloch-Pitts model provides a foundational understanding of neural computation in terms of logic functions, spiking neural networks extend this by incorporating temporal aspects, making them more aligned with how actual biological neurons operate. Both models contribute to the broader field of neural networks, with SNNs offering a more detailed emulation of biological processes.","Spiking neural networks relate to the McCulloch-Pitts model by building upon the foundational concepts of neural computation, where the McCulloch-Pitts model introduced the idea of binary neuron states, which is extended in spiking networks to model more complex information processing through spike timing and patterns.",0.0,0.0,0.4375,0.84,,0.9373263275700353
How spiking neural networks used in encoding strategies?,"['Different encoding strategies with spiking neurons\n\nDifferent encoding strategies with spiking neurons\nUsing latency or spatio-temporal codes\nour encoding is faster and more spike-efficient (sparser)!\n\nDifferent encoding strategies with spiking neurons\nUsing latency or spatio-temporal codes\nour encoding is faster and more spike-efficient (sparser)!\nQuestions?\n\nNeuromorphic computing\nWhat is the advantage for applications?\n-\nLess spikes = less energy consumption in specialized neuromorphic hardware\n(e.g. Intel Loihi [12])\nBrains are energy efficient: \n2. Sparse encoding\n\nMultiply-accumulate (MAC) operations:\nNormal neuron: Multiplies input with \nweights, then adds.\nSpiking neuron: Consider binary input (e.g. input currents are piecewise \nconstant and assume values {0,1}). There is no multiplication, only addition.\n\nAssume one multiplier and one adder circuit uses M and A energy respectively with AÔπ§M\n(e.g., for a 45nm CMOS process, standard energy usage is A = 0.9 pJ and M = 3.7 pJ).\nNormal neuron: nin x nout multiplications,\n(nin‚Äì 1) x nout additions\nSpiking neuron: 0 multiplications, (nactive‚Äì 1) x nout \nadditions, with nactive ‚â§ nin\nEnergy consumption:\nEnormal = M nin nout + A (nin‚Äì 1) nout = 17.5 pJ\nEnergy consumption:\nEspiking = A (nactive‚Äì 1) nout = 2.7 pJ\nMultiply-accumulate (MAC) operations:\n\nAssume one multiplier and one adder circuit uses M and A energy respectively with AÔπ§M\n(e.g., for a 45nm CMOS process, standard energy usage is A = 0.9 pJ and M = 3.7 pJ).', ""- Higher firing rate (spikes per unit time) for \n'selected' feature.\nAdapted from Hubel & Wiesel, 1959\n\nFiring rates\nClassical view of the brain:\n- Each neuron is selective for one specific \nfeature in the input.\n- Higher firing rate (spikes per unit time) for \n'selected' feature.\n- Link to modern ANNs: The scalar output of \nan artificial neuron is interpreted as the firing \nrate.\nAdapted from Hubel & Wiesel, 1959\n\nFiring rates\nClassical view of the brain:\n- Each neuron is selective for one specific \nfeature in the input.\n- Higher firing rate (spikes per unit time) for \n'selected' feature.\n- Link to modern ANNs: The scalar output of \nan artificial neuron is interpreted as the firing \nrate.\nAdapted from Hubel & Wiesel, 1959\nBut rate coding is inefficient and slow‚Ä¶\n(i.e. each neuron needs to fire many spikes to get good precision)\nboth in vivo and in silico.\n\nDifferent encoding strategies with spiking neurons [8]\n7 neurons\n7 time bins\n\nDifferent encoding strategies with spiking neurons\n7 neurons\n7 time bins\nn\n6\n(in the general \ncase a \nnumber \nbetween 0-7)\n\nDifferent encoding strategies with spiking neurons\n7 neurons\n7 time bins\nn\nTotal spike \ncount can \nencode 3 bits.\n\nDifferent encoding strategies with spiking neurons\n7 neurons\n7 time bins\nIndividual rates \ncan encode 7 \nbits.\n\nDifferent encoding strategies with spiking neurons\n7 neurons\n7 time bins\nLatency can \nencode ~3*7 or \n~19 bits.\n\nDifferent encoding strategies with spiking neurons\n7 neurons\n7 time bins\nRank order can \nencode ~12 bits.\n\nDifferent encoding strategies with spiking neurons\n\nDifferent encoding strategies with spiking neurons\nUsing latency or spatio-temporal codes\nour encoding is faster and more spike-efficient (sparser)!\n\nDifferent encoding strategies with spiking neurons\nUsing latency or spatio-temporal codes\nour encoding is faster and more spike-efficient (sparser)!\nQuestions?\n\nNeuromorphic computing\nWhat is the advantage for applications?\n-\nLess spikes = less energy consumption in specialized neuromorphic hardware\n(e.g."", 'Neural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568']","[""<1-hop>\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant"", '<2-hop>\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \n(not publicly available) doi:10.1037/h0042519\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568']","Spiking neural networks (SNNs) use different encoding strategies such as latency or spatio-temporal codes, which are faster and more spike-efficient (sparser) compared to traditional rate coding. These encoding strategies allow SNNs to use fewer spikes, leading to less energy consumption, especially in specialized neuromorphic hardware. This efficiency is achieved because spiking neurons do not require multiplications, only additions, which consume less energy. Additionally, spiking neurons can encode information in various ways, such as using total spike count, individual rates, latency, and rank order, each capable of encoding different amounts of bits. This makes SNNs more efficient for certain applications compared to traditional neural networks.",Spiking neural networks use single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0) to encode information about 'features' in a large network with many spikes. This approach is supported by foundational works such as McCulloch and Pitts' logical calculus of nervous activity and later developments in spiking neuron models.,0.0,0.0,1.0,0.0,0.0,0.9112887367548348
What are the benefits of neuromorphic computing in the context of green software practices?,"[""Neuromorphic computing\nCS4575\nSustainable Software Engineering\n05.03.2025\nNergis T√∂men\n\nIntroduction\nComputer Vision Lab\nBiomorphic Intelligence Lab\nBiomedical Intervention Optimisation Lab\nNergis\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing\n\nHow many of you are familiar \nwith neural networks?\n\nSimple model of an artificial neuron\nhttps://medium.com/@cprasenjit32/perceptron-a-simple-yet-mighty-machine-learning-algorithm-9ff6b7d86a71\n\nWhat is a neural network?\nhttps://www.tibco.com/reference-center/what-is-a-neural-network\n\nWhy is it called a 'neural network'?\nhttps://www.tibco.com/reference-center/what-is-a-neural-network\n\nWhat is a neural network?\nWhy is it called a 'neural network'?\nMcCulloch-Pitts neuron [1, 2] (1943)\nWarren Sturgis McCulloch\n(Neurophysiologist)\nWalter Pitts\n(Logician)\n\nHow do biological neurons work?\nhttps://commons.wikimedia.org/wiki/File:Coincidence_detection_in_dendrites_of_pyramidal_neurons.gif\n'Input current' travels down the dendrites (top),\nget integrated (summed!) in the cell body\nwhich generates an 'output current' (bottom)\nwhich is chemically transmitted to the dendrites of \nother neurons.\n\nSimplified picture\nReal neuron\nArtificial neuron\nhttps://vajiramandravi.com/quest-upsc-notes/artificial-neural-network/\n\nWhat is a neural network?\nMcCulloch-Pitts neuron [1, 2]\n1940s: How do biological neurons compute basic \nlogic functions? (e.g. logic gates)\nNote: Ref. [3] gives a nice brief history on the ideas which lead to the \nMcCulloch-Pitts neuron.\n\nWhat is a neural network?"", '8. Green AI\nSustainable Software Engineering\u2028\nCS4575\nSustainableSE 2025\nLu√≠s Cruz \nL.Cruz@tudelft.nl \nCarolin Brandt \nC.E.Brandt@tudelft.nl \nEnrique Barba Roque \nE.BarbaRoque@tudelft.nl\n\n- Overview of Green AI \n- Large language models \n- Green data-centric AI \n- Model simplification \n- Hyper parameter tuning \n- Mixture of Experts and DeepSeek \n- Green AI at Meta \n\nAI\n‚Ä¢ Artificial Intelligence (AI) is the branch of computer science that deals with \nautomating tasks that typically require human intelligence. \n‚Ä¢ In the past years AI has been widely applied across different domains.\u2028\nE.g., health care, transportation, finance. \n‚Ä¢ To deploy AI systems, we test them against benchmarks (or validation sets). \n‚Ä¢ The goal is to outperform the previous existing models. \n‚Ä¢ E.g., in Machine Learning we usually resort to accuracy metrics. The \nhighest the accuracy, the better the model.\n3\n\nSince 2012, the amount of computing used for AI \ntraining has been doubling every 6 months\n‚Ä¢ https://epoch.ai/blog/compute-trends\n4\n\n‚Ä¢ To create better AI systems we are currently adding \n‚Ä¢ More data \n‚Ä¢ More experiments \n‚Ä¢ Larger models\n5\n\nThe Equation of Red AI\nCost(R) ‚àùE¬∑D¬∑H\nCost of a single (E)xample\nSize of (D)ataset\nNumber of (H)yperparameters\nBy Schwartz et al. (2020)\n\nIssues of Red AI\n‚Ä¢ High costs (hardware, electricity, data access, etc.) \n‚Ä¢ Limited reproducibility.  \n‚Ä¢ Energy consumption. \n‚Ä¢ Carbon emissions. \n‚Ä¢ SMEs can hardly be competitive. \n‚Ä¢ Groundbreaking AI research is mostly done by tech giants.', '‚Ä¢ Software consumers have started to worry about the climate impact \nof their behaviour as users. \n‚Ä¢ Being environmentally sustainable is now an important competitive \nfactor \n‚Ä¢ Marketing teams are already using all eco-friendly labels. Technical \nteams are not there yet, though. \n‚Ä¢ It‚Äôs easier said than done!\n$\n16\n\nGreen Washing\n‚Ä¢ Deceptively use marketing techniques to \nclaim being eco-friendly. \n‚Ä¢ Opting for green-coloured designs. \n‚Ä¢ Red/orange is usually perceived as \ntasty. \n‚Ä¢ Green is perceived as eco-friendly. \n‚Ä¢ The VW case. (?)\n17\n\nThe VW scandal\nGreenwashing\n‚Ä¢ Used software to cheat on vehicle emissions \ntests. \n‚Ä¢ The vehicle‚Äôs software could detect whether they \nwere being tested, changing the performance \naccordingly to improve results. \n‚Ä¢ Affected 11M cars worldwide, 8M in Europe.\n18\n\nHow can we drive sustainability \nin the SE industry?\n\nGreen Procurement\n‚Ä¢ Customers decide on providers that share their values \n‚Ä¢ This is currently the main trigger reason why organisations \nworry about Sustainability and Green Software. \n‚Ä¢ Examples of green procurement: \n‚Ä¢ Customers that only buy green services/products \n‚Ä¢ Companies that only use green providers \n‚Ä¢ Developers that only work for green companies \n‚Ä¢ Green procurement makes environmental sustainability \nessential for economical sustainability.\n20\n\nSustainability via compliance\n‚Ä¢ EU wants to be carbon neutral by 2030 \n‚Ä¢ This also affects the ICT sector. Estimated to impact \n14% of the global carbon footprint by 2040. \n‚Ä¢ Some initiatives are already being negotiated. \n‚Ä¢ Extending the smartphone lifetime to 7 years. \n‚Ä¢ Right-to-repair movement. https://repair.eu \n‚Ä¢ Making IT services relying on clean energy more \naccessible (e.g., less taxes).\n21\n\nSoftware for Sustainability \n‚Ä¢ We are not covering it in this course.\n\nCarbon-free giants\n‚Ä¢ Google, Microsoft, Meta/Facebook want to be carbon free by 2030 \n‚Ä¢ Carbon free is different from carbon neutral \n‚Ä¢ Green IT experts are needed to meet these goals\n23\n\n\nRebound effect*\n‚Ä¢ Energy consumption decreases ‚Üì‚Üì but demand also increases ‚Üë‚Üë. \n‚Ä¢ *a.k.a. Jevons Paradox in economics; Downs‚ÄìThomson paradox in\xa0mobility.']","['<1-hop>\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing', '<2-hop>\n\nReading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.', '<1-hop>\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing', '<2-hop>\n\nReading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.', '<1-hop>\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing', '<2-hop>\n\nReading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.']","The sources provided do not explicitly discuss the benefits of neuromorphic computing in the context of green software practices. However, I can infer that neuromorphic computing, which is inspired by the structure and function of the human brain, could potentially offer energy efficiency benefits. This is because neuromorphic systems are designed to mimic the brain's ability to process information in a highly parallel and efficient manner, which could reduce the energy consumption associated with traditional computing methods. This aligns with the goals of green software practices, which aim to reduce energy consumption and carbon emissions. Therefore, neuromorphic computing could contribute to more sustainable and environmentally friendly computing solutions.","Neuromorphic computing offers several benefits in the context of green software practices. It is inspired by the structure and function of the human brain, making it highly energy-efficient compared to traditional computing methods. This efficiency is particularly relevant for sustainable software development, as it reduces the environmental impact of computing systems. Additionally, neuromorphic systems can process information in a way that mimics biological neural networks, which can lead to more efficient and sustainable computing solutions. These aspects make neuromorphic computing a promising approach for developers looking to implement green software practices.",0.0,0.6,0.5714285714285714,0.91,0.1111111109876543,0.0
What are the challenges in creating a dataset of government-developed OS software?,"['data to understand state of software: \nbuildable?, open dev. history?, requirements documentation? \n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!\n\nB7. Queue - but better for the student / TA society\n‚Ä¢ Requirements analysis regarding social and individual sustainability effects \nof Queue \n‚Ä¢ Other EIP / TUD used software also possible: e.g., Answers EWI \n‚Ä¢ Non-technical project ‚Üí proper process (workshops? Interviews?) & rich \ndescription of outcomes focus of grading\nhttps://eip.pages.ewi.tudelft.nl/eip-website/queue.html\n\nC1. Compare energy consumption of docker images for \nML workloads.\n‚Ä¢ Similar to what we have seen in the lectures but for ML-specific workloads. \n‚Ä¢ We can reuse existing experiment replication packages.\n22\n\nC2. Plugin to visualize Hugging Face carbon emissions.\n‚Ä¢ https://huggingface.co/blog/leaderboard-emissions-\nanalysis \n‚Ä¢\nYoo, Taewon, et al. ""Visualizing the Carbon Intensity of Machine Learning Inference for Image Analysis on TensorFlow Hub.""\n\nC3. Plugin for ChatGPT\n‚Ä¢ Users seldom know how much carbon they are emitting when they interact \nwith chat GPT. \n‚Ä¢ Let‚Äôs make it transparent to the users. Browser plugin?\n24\nCO2\n\nC4. NutriScore for software libraries\n25\n‚Ä¢ NutriScore labels are not perfect but they are a good starting point! \n‚Ä¢ What if we could do the same thing for the energy efficiency of software. \n‚Ä¢ (Also open to individual or social sustainability) \n‚Ä¢ This work can be scoped in particular domains/ecossystems/use cases. \n‚Ä¢ Libraries for stats? ML? Web Dev? Cloud?\n\nC5. Add energy-awareness to existing software\n26\n‚Ä¢ Streamlit, Notebooks, JSFiddle, \nPyScript, zsh, etc. \n‚Ä¢\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy efficiency using static code analysis. \n‚Ä¢ We don‚Äôt need an accurate value. \n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention. \n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)', '‚Ä¢ Software consumers have started to worry about the climate impact \nof their behaviour as users. \n‚Ä¢ Being environmentally sustainable is now an important competitive \nfactor \n‚Ä¢ Marketing teams are already using all eco-friendly labels. Technical \nteams are not there yet, though. \n‚Ä¢ It‚Äôs easier said than done!\n$\n16\n\nGreen Washing\n‚Ä¢ Deceptively use marketing techniques to \nclaim being eco-friendly. \n‚Ä¢ Opting for green-coloured designs. \n‚Ä¢ Red/orange is usually perceived as \ntasty. \n‚Ä¢ Green is perceived as eco-friendly. \n‚Ä¢ The VW case. (?)\n17\n\nThe VW scandal\nGreenwashing\n‚Ä¢ Used software to cheat on vehicle emissions \ntests. \n‚Ä¢ The vehicle‚Äôs software could detect whether they \nwere being tested, changing the performance \naccordingly to improve results. \n‚Ä¢ Affected 11M cars worldwide, 8M in Europe.\n18\n\nHow can we drive sustainability \nin the SE industry?\n\nGreen Procurement\n‚Ä¢ Customers decide on providers that share their values \n‚Ä¢ This is currently the main trigger reason why organisations \nworry about Sustainability and Green Software. \n‚Ä¢ Examples of green procurement: \n‚Ä¢ Customers that only buy green services/products \n‚Ä¢ Companies that only use green providers \n‚Ä¢ Developers that only work for green companies \n‚Ä¢ Green procurement makes environmental sustainability \nessential for economical sustainability.\n20\n\nSustainability via compliance\n‚Ä¢ EU wants to be carbon neutral by 2030 \n‚Ä¢ This also affects the ICT sector. Estimated to impact \n14% of the global carbon footprint by 2040. \n‚Ä¢ Some initiatives are already being negotiated. \n‚Ä¢ Extending the smartphone lifetime to 7 years. \n‚Ä¢ Right-to-repair movement. https://repair.eu \n‚Ä¢ Making IT services relying on clean energy more \naccessible (e.g., less taxes).\n21\n\nSoftware for Sustainability \n‚Ä¢ We are not covering it in this course.\n\nCarbon-free giants\n‚Ä¢ Google, Microsoft, Meta/Facebook want to be carbon free by 2030 \n‚Ä¢ Carbon free is different from carbon neutral \n‚Ä¢ Green IT experts are needed to meet these goals\n23\n\n\nRebound effect*\n‚Ä¢ Energy consumption decreases ‚Üì‚Üì but demand also increases ‚Üë‚Üë. \n‚Ä¢ *a.k.a. Jevons Paradox in economics; Downs‚ÄìThomson paradox in\xa0mobility.', 'Revisiting Research Questions\n‚Ä¢ Can we compare the energy efficiency of software languages?  \n‚Ä¢ Is the faster language always the most energy efficient? \n‚Ä¢ How does memory usage relate to energy consumption?  \n‚Ä¢ Can we automatically decide what is the best programming language considering \nenergy, time, and memory usage?  \n‚Ä¢ How do the results of our energy consumption analysis of programming \nlanguages gathered from rigorous performance benchmarking solutions \ncompare to results of average day-to-day solutions?  \n‚Ä¢ What would happen if we cherry picked the tasks?\u2028\n44\n\n\nLu√≠s Cruz \nL.Cruz@tudelft.nl \n3. Scientific Guide for Reliable \nEnergy Experiments\nSustainable Software Engineering\u2028\nCS4575\nSustainableSE 2025\nCarolin Brandt \nC.E.Brandt@tudelft.nl \nEnrique Barba Roque \nE.BarbaRoque@tudelft.nl']","['<1-hop>\n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise\n‚Ä¢ But studying government software is diÔ¨Écult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation?\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!', '<2-hop>\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption\n‚Ä¢ B3. Energy proÔ¨Åling of static analysis tools\n‚Ä¢ B4. Detailed energy proÔ¨Åling of build pipelines\n‚Ä¢ B5. Tool supporting SusAF workshop / process\n‚Ä¢ B6. Dataset of government-developed OS software\n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability', '<1-hop>\n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise\n‚Ä¢ But studying government software is diÔ¨Écult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation?\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!', '<2-hop>\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption\n‚Ä¢ B3. Energy proÔ¨Åling of static analysis tools\n‚Ä¢ B4. Detailed energy proÔ¨Åling of build pipelines\n‚Ä¢ B5. Tool supporting SusAF workshop / process\n‚Ä¢ B6. Dataset of government-developed OS software\n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability', '<1-hop>\n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise\n‚Ä¢ But studying government software is diÔ¨Écult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation?\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!', '<2-hop>\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption\n‚Ä¢ B3. Energy proÔ¨Åling of static analysis tools\n‚Ä¢ B4. Detailed energy proÔ¨Åling of build pipelines\n‚Ä¢ B5. Tool supporting SusAF workshop / process\n‚Ä¢ B6. Dataset of government-developed OS software\n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability']","The sources provided do not directly address the challenges in creating a dataset of government-developed open-source software. However, based on general knowledge, some potential challenges could include:

1. **Data Availability**: Government-developed software may not always be open or easily accessible due to security, privacy, or proprietary concerns.

2. **Standardization**: Different government bodies may use different standards and formats, making it difficult to compile a consistent dataset.

3. **Documentation**: There may be a lack of comprehensive documentation or metadata accompanying the software, which is crucial for understanding and categorizing the software effectively.

4. **Licensing Issues**: Understanding and verifying the open-source licenses under which the software is released can be complex.

5. **Language and Localization**: Software developed by governments in different countries may be in different languages, requiring translation and localization efforts.

6. **Version Control and History**: Accessing the full development history and version control information might be challenging if not properly maintained or shared.

These challenges require careful planning and collaboration with government entities to ensure a comprehensive and useful dataset.","Creating a dataset of government-developed OS software faces challenges such as a lack of incentive to make the software popular and language barriers, which hinder comprehensive understanding of the software's buildability, open development history, and requirements documentation.",0.0,0.0,0.0,0.43,0.0,0.9655848143242188
"What are the practical applications of neuromorphic computing, and how does its biological inspiration influence its implementation in modern computing systems?","[""Neuromorphic computing\nCS4575\nSustainable Software Engineering\n05.03.2025\nNergis T√∂men\n\nIntroduction\nComputer Vision Lab\nBiomorphic Intelligence Lab\nBiomedical Intervention Optimisation Lab\nNergis\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing\n\nHow many of you are familiar \nwith neural networks?\n\nSimple model of an artificial neuron\nhttps://medium.com/@cprasenjit32/perceptron-a-simple-yet-mighty-machine-learning-algorithm-9ff6b7d86a71\n\nWhat is a neural network?\nhttps://www.tibco.com/reference-center/what-is-a-neural-network\n\nWhy is it called a 'neural network'?\nhttps://www.tibco.com/reference-center/what-is-a-neural-network\n\nWhat is a neural network?\nWhy is it called a 'neural network'?\nMcCulloch-Pitts neuron [1, 2] (1943)\nWarren Sturgis McCulloch\n(Neurophysiologist)\nWalter Pitts\n(Logician)\n\nHow do biological neurons work?\nhttps://commons.wikimedia.org/wiki/File:Coincidence_detection_in_dendrites_of_pyramidal_neurons.gif\n'Input current' travels down the dendrites (top),\nget integrated (summed!) in the cell body\nwhich generates an 'output current' (bottom)\nwhich is chemically transmitted to the dendrites of \nother neurons.\n\nSimplified picture\nReal neuron\nArtificial neuron\nhttps://vajiramandravi.com/quest-upsc-notes/artificial-neural-network/\n\nWhat is a neural network?\nMcCulloch-Pitts neuron [1, 2]\n1940s: How do biological neurons compute basic \nlogic functions? (e.g. logic gates)\nNote: Ref. [3] gives a nice brief history on the ideas which lead to the \nMcCulloch-Pitts neuron.\n\nWhat is a neural network?"", 'McCulloch-Pitts neuron [1, 2]\n1940s: How do biological neurons compute basic \nlogic functions? (e.g. logic gates)\nNote: Ref. [3] gives a nice brief history on the ideas which lead to the \nMcCulloch-Pitts neuron.\n\nWhat is a neural network?\n1950s: How are neurons organized to perform \nsensory perception?\n\nWhat is a neural network?\n1950s: How are neurons organized to perform \nsensory perception?\nThe first ""neural network"": Perceptron (1958). [4]\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\nFrank Rosenblatt (Psychologist)\nwith a Mark I Perceptron computer in 1960\n\nWhat is a neural network?\n1950s: How are neurons organized to perform \nsensory perception?\nThe first ""neural network"": Perceptron (1958). [4]\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\nFrank Rosenblatt (Psychologist)\nwith a Mark I Perceptron computer in 1960\nPower-efficient\n\nNeuromorphic computing\nWhy neuromorphic computing?\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\n\nNeuromorphic computing\nWhy neuromorphic computing?\n‚ÄòBiological inspiration‚Äô for artificial neural networks (ANNs) is not a new idea.\nEmulation (as opposed to simulation) of neural networks in hardware is not a new idea.\nQuestion: What can we gain from increasing biological realism in existing neural networks?\n\nPower-efficiency at scale\nModern, deep neural networks*\nare trained using GPUs.\n* It is estimated that ChatGPT was trained on \n10,000-20,000 GPUs and that it will require\n30,000 GPUs to keep running stably in the future.\n* It is estimated that ChatGPT has 10-20 billion \nparameters.', 'Reading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020.']","['<1-hop>\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing', '<2-hop>\n\nReading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.', '<1-hop>\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing', '<2-hop>\n\nReading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.']","Neuromorphic computing is inspired by the structure and function of the human brain, using physical artificial neurons to perform computations. This approach offers several practical applications and influences modern computing systems in various ways:

1. **Power Efficiency**: Neuromorphic computing is designed to be power-efficient, which is crucial for large-scale applications like deep neural networks. This efficiency is achieved by emulating the brain's ability to perform complex computations with minimal energy consumption.

2. **Real-time Processing**: Due to its architecture, neuromorphic computing can handle real-time data processing, making it suitable for applications in robotics, autonomous vehicles, and real-time sensory data analysis.

3. **Scalability**: Neuromorphic systems can scale efficiently, which is beneficial for handling large datasets and complex models, such as those used in artificial intelligence and machine learning.

4. **Biological Realism**: The biological inspiration behind neuromorphic computing allows for more natural and efficient processing of information, similar to how the human brain processes sensory inputs and makes decisions.

5. **Emulation of Neural Networks**: Neuromorphic computing emulates neural networks in hardware, which can lead to faster and more efficient computations compared to traditional software simulations.

Overall, the biological inspiration of neuromorphic computing influences its implementation by focusing on energy efficiency, real-time processing capabilities, and the ability to emulate complex neural processes in hardware.","Neuromorphic computing, inspired by the human brain, offers practical applications such as event-based vision systems and efficient processing of sensory data. Its biological inspiration influences its implementation through the use of spiking neural networks and physical artificial neurons, enabling more energy-efficient and brain-like computation methods.",0.3333333333,1.0,0.45454545454545453,0.67,0.33333333277777777,0.9403798655223063
"What are the practical applications of neuromorphic computing, and how does its biological inspiration influence its implementation?","[""Neuromorphic computing\nCS4575\nSustainable Software Engineering\n05.03.2025\nNergis T√∂men\n\nIntroduction\nComputer Vision Lab\nBiomorphic Intelligence Lab\nBiomedical Intervention Optimisation Lab\nNergis\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing\n\nHow many of you are familiar \nwith neural networks?\n\nSimple model of an artificial neuron\nhttps://medium.com/@cprasenjit32/perceptron-a-simple-yet-mighty-machine-learning-algorithm-9ff6b7d86a71\n\nWhat is a neural network?\nhttps://www.tibco.com/reference-center/what-is-a-neural-network\n\nWhy is it called a 'neural network'?\nhttps://www.tibco.com/reference-center/what-is-a-neural-network\n\nWhat is a neural network?\nWhy is it called a 'neural network'?\nMcCulloch-Pitts neuron [1, 2] (1943)\nWarren Sturgis McCulloch\n(Neurophysiologist)\nWalter Pitts\n(Logician)\n\nHow do biological neurons work?\nhttps://commons.wikimedia.org/wiki/File:Coincidence_detection_in_dendrites_of_pyramidal_neurons.gif\n'Input current' travels down the dendrites (top),\nget integrated (summed!) in the cell body\nwhich generates an 'output current' (bottom)\nwhich is chemically transmitted to the dendrites of \nother neurons.\n\nSimplified picture\nReal neuron\nArtificial neuron\nhttps://vajiramandravi.com/quest-upsc-notes/artificial-neural-network/\n\nWhat is a neural network?\nMcCulloch-Pitts neuron [1, 2]\n1940s: How do biological neurons compute basic \nlogic functions? (e.g. logic gates)\nNote: Ref. [3] gives a nice brief history on the ideas which lead to the \nMcCulloch-Pitts neuron.\n\nWhat is a neural network?"", 'McCulloch-Pitts neuron [1, 2]\n1940s: How do biological neurons compute basic \nlogic functions? (e.g. logic gates)\nNote: Ref. [3] gives a nice brief history on the ideas which lead to the \nMcCulloch-Pitts neuron.\n\nWhat is a neural network?\n1950s: How are neurons organized to perform \nsensory perception?\n\nWhat is a neural network?\n1950s: How are neurons organized to perform \nsensory perception?\nThe first ""neural network"": Perceptron (1958). [4]\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\nFrank Rosenblatt (Psychologist)\nwith a Mark I Perceptron computer in 1960\n\nWhat is a neural network?\n1950s: How are neurons organized to perform \nsensory perception?\nThe first ""neural network"": Perceptron (1958). [4]\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\nFrank Rosenblatt (Psychologist)\nwith a Mark I Perceptron computer in 1960\nPower-efficient\n\nNeuromorphic computing\nWhy neuromorphic computing?\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\n\nNeuromorphic computing\nWhy neuromorphic computing?\n‚ÄòBiological inspiration‚Äô for artificial neural networks (ANNs) is not a new idea.\nEmulation (as opposed to simulation) of neural networks in hardware is not a new idea.\nQuestion: What can we gain from increasing biological realism in existing neural networks?\n\nPower-efficiency at scale\nModern, deep neural networks*\nare trained using GPUs.\n* It is estimated that ChatGPT was trained on \n10,000-20,000 GPUs and that it will require\n30,000 GPUs to keep running stably in the future.\n* It is estimated that ChatGPT has 10-20 billion \nparameters.', 'Reading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020.']","['<1-hop>\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing', '<2-hop>\n\nReading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.']","Neuromorphic computing is inspired by the structure and function of the human brain, which influences its implementation by using physical artificial neurons to perform computations. This biological inspiration allows neuromorphic systems to emulate the brain's efficiency and adaptability, leading to potential practical applications in areas that require power-efficient and real-time processing.

Practical applications of neuromorphic computing include:

1. **Computer Vision**: Neuromorphic systems can process visual information efficiently, making them suitable for applications in autonomous vehicles and surveillance systems.

2. **Robotics**: The ability to process sensory information in real-time makes neuromorphic computing ideal for robotics, enabling more adaptive and responsive robotic systems.

3. **Biomedical Devices**: Neuromorphic chips can be used in biomedical devices for real-time monitoring and intervention, such as in prosthetics or brain-machine interfaces.

4. **Internet of Things (IoT)**: Due to their power efficiency, neuromorphic systems are well-suited for IoT devices that require low-power, real-time data processing.

The biological inspiration of neuromorphic computing influences its implementation by focusing on emulating the brain's neural networks in hardware, which can lead to increased power efficiency and scalability compared to traditional computing methods. This approach aims to achieve more biologically realistic neural network models that can perform complex tasks with lower energy consumption.","Neuromorphic computing, inspired by the human brain, offers practical applications through its ability to process information in a manner similar to biological neurons. This biological inspiration influences its implementation by enabling the development of systems that can efficiently handle tasks such as pattern recognition and adaptive learning, as detailed in resources like 'Computing with spiking neuron networks' and discussions on the convergence of deep learning with biological systems.",0.3333333333,1.0,0.4117647058823529,0.44,0.24999999968749997,0.9584266558837133
What are the practical applications of neuromorphic systems that leverage biological inspiration and advanced training methods for efficient computation?,"[""Neuromorphic computing\nCS4575\nSustainable Software Engineering\n05.03.2025\nNergis T√∂men\n\nIntroduction\nComputer Vision Lab\nBiomorphic Intelligence Lab\nBiomedical Intervention Optimisation Lab\nNergis\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing\n\nHow many of you are familiar \nwith neural networks?\n\nSimple model of an artificial neuron\nhttps://medium.com/@cprasenjit32/perceptron-a-simple-yet-mighty-machine-learning-algorithm-9ff6b7d86a71\n\nWhat is a neural network?\nhttps://www.tibco.com/reference-center/what-is-a-neural-network\n\nWhy is it called a 'neural network'?\nhttps://www.tibco.com/reference-center/what-is-a-neural-network\n\nWhat is a neural network?\nWhy is it called a 'neural network'?\nMcCulloch-Pitts neuron [1, 2] (1943)\nWarren Sturgis McCulloch\n(Neurophysiologist)\nWalter Pitts\n(Logician)\n\nHow do biological neurons work?\nhttps://commons.wikimedia.org/wiki/File:Coincidence_detection_in_dendrites_of_pyramidal_neurons.gif\n'Input current' travels down the dendrites (top),\nget integrated (summed!) in the cell body\nwhich generates an 'output current' (bottom)\nwhich is chemically transmitted to the dendrites of \nother neurons.\n\nSimplified picture\nReal neuron\nArtificial neuron\nhttps://vajiramandravi.com/quest-upsc-notes/artificial-neural-network/\n\nWhat is a neural network?\nMcCulloch-Pitts neuron [1, 2]\n1940s: How do biological neurons compute basic \nlogic functions? (e.g. logic gates)\nNote: Ref. [3] gives a nice brief history on the ideas which lead to the \nMcCulloch-Pitts neuron.\n\nWhat is a neural network?"", 'Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002.', 'Neural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568']","['<1-hop>\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing', '<2-hop>\n\nReading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.', '<1-hop>\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing', '<2-hop>\n\nReading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.', '<1-hop>\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing', '<2-hop>\n\nReading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.']","Neuromorphic systems, inspired by the structure and function of the human brain, have several practical applications. These include:

1. **Event-based Vision**: Neuromorphic systems are used in event cameras, which are beneficial for applications requiring high-speed and low-latency visual processing, such as autonomous vehicles and robotics. These cameras capture changes in a scene rather than static frames, mimicking the way biological vision systems work.

2. **Efficient Computation**: Neuromorphic computing is designed to perform computations more efficiently than traditional systems, particularly for tasks involving pattern recognition and sensory data processing. This efficiency is due to the parallel and distributed nature of neuromorphic architectures, which resemble neural networks in the brain.

3. **Spiking Neural Networks (SNNs)**: These networks are a type of artificial neural network that more closely mimic the way biological neurons communicate through spikes. They are used in applications that require real-time processing and low power consumption, such as mobile devices and edge computing.

4. **Biomedical Applications**: Neuromorphic systems can be used in biomedical intervention optimization, potentially improving the efficiency and effectiveness of medical treatments by modeling complex biological processes.

These applications leverage the biological inspiration of neuromorphic systems to achieve advanced training methods and efficient computation, offering advantages in speed, power consumption, and adaptability.","Neuromorphic systems, inspired by the human brain, have practical applications such as event-based vision, which is detailed in the reading materials. These systems use advanced training methods like surrogate gradient learning to optimize spiking neural networks, enabling efficient computation and real-world applications.",0.3333333333,1.0,0.75,0.47,0.12499999984374999,0.9609441315216459
"What is the biological basis of neuromorphic computing, and how does it differ from conventional neural networks?","[""Neuromorphic computing\nCS4575\nSustainable Software Engineering\n05.03.2025\nNergis T√∂men\n\nIntroduction\nComputer Vision Lab\nBiomorphic Intelligence Lab\nBiomedical Intervention Optimisation Lab\nNergis\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing\n\nHow many of you are familiar \nwith neural networks?\n\nSimple model of an artificial neuron\nhttps://medium.com/@cprasenjit32/perceptron-a-simple-yet-mighty-machine-learning-algorithm-9ff6b7d86a71\n\nWhat is a neural network?\nhttps://www.tibco.com/reference-center/what-is-a-neural-network\n\nWhy is it called a 'neural network'?\nhttps://www.tibco.com/reference-center/what-is-a-neural-network\n\nWhat is a neural network?\nWhy is it called a 'neural network'?\nMcCulloch-Pitts neuron [1, 2] (1943)\nWarren Sturgis McCulloch\n(Neurophysiologist)\nWalter Pitts\n(Logician)\n\nHow do biological neurons work?\nhttps://commons.wikimedia.org/wiki/File:Coincidence_detection_in_dendrites_of_pyramidal_neurons.gif\n'Input current' travels down the dendrites (top),\nget integrated (summed!) in the cell body\nwhich generates an 'output current' (bottom)\nwhich is chemically transmitted to the dendrites of \nother neurons.\n\nSimplified picture\nReal neuron\nArtificial neuron\nhttps://vajiramandravi.com/quest-upsc-notes/artificial-neural-network/\n\nWhat is a neural network?\nMcCulloch-Pitts neuron [1, 2]\n1940s: How do biological neurons compute basic \nlogic functions? (e.g. logic gates)\nNote: Ref. [3] gives a nice brief history on the ideas which lead to the \nMcCulloch-Pitts neuron.\n\nWhat is a neural network?"", 'McCulloch-Pitts neuron [1, 2]\n1940s: How do biological neurons compute basic \nlogic functions? (e.g. logic gates)\nNote: Ref. [3] gives a nice brief history on the ideas which lead to the \nMcCulloch-Pitts neuron.\n\nWhat is a neural network?\n1950s: How are neurons organized to perform \nsensory perception?\n\nWhat is a neural network?\n1950s: How are neurons organized to perform \nsensory perception?\nThe first ""neural network"": Perceptron (1958). [4]\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\nFrank Rosenblatt (Psychologist)\nwith a Mark I Perceptron computer in 1960\n\nWhat is a neural network?\n1950s: How are neurons organized to perform \nsensory perception?\nThe first ""neural network"": Perceptron (1958). [4]\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\nFrank Rosenblatt (Psychologist)\nwith a Mark I Perceptron computer in 1960\nPower-efficient\n\nNeuromorphic computing\nWhy neuromorphic computing?\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\n\nNeuromorphic computing\nWhy neuromorphic computing?\n‚ÄòBiological inspiration‚Äô for artificial neural networks (ANNs) is not a new idea.\nEmulation (as opposed to simulation) of neural networks in hardware is not a new idea.\nQuestion: What can we gain from increasing biological realism in existing neural networks?\n\nPower-efficiency at scale\nModern, deep neural networks*\nare trained using GPUs.\n* It is estimated that ChatGPT was trained on \n10,000-20,000 GPUs and that it will require\n30,000 GPUs to keep running stably in the future.\n* It is estimated that ChatGPT has 10-20 billion \nparameters.', 'Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002.']","['<1-hop>\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing', '<2-hop>\n\nReading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.']","Neuromorphic computing is inspired by the structure and function of the human brain. It involves using physical artificial neurons to perform computations, emulating the way biological neurons work. This approach is distinct from conventional neural networks, which are typically implemented in software and run on general-purpose hardware like GPUs.

The biological basis of neuromorphic computing lies in its attempt to mimic the brain's architecture and processes more closely than conventional neural networks. While conventional neural networks are inspired by the brain, they often simplify or abstract away many biological details to focus on mathematical models that can be efficiently computed on traditional hardware.

In contrast, neuromorphic computing aims to increase biological realism by using hardware that emulates the brain's neural circuits. This can lead to power-efficient computation, as neuromorphic systems can potentially perform complex tasks with less energy compared to conventional systems that rely on power-hungry GPUs.","Neuromorphic computing is based on the biological principles of the human brain, utilizing physical artificial neurons to perform computations. Unlike conventional neural networks, which rely on traditional computing architectures, neuromorphic systems are designed to mimic the brain's structure and function, enabling more efficient and biologically inspired processing.",0.99999999995,0.5,1.0,0.73,,0.9475118438101008
What is the difference between spiking neural networks and spiking neuron networks?,"['Neural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568', 'Different encoding strategies with spiking neurons\n\nDifferent encoding strategies with spiking neurons\nUsing latency or spatio-temporal codes\nour encoding is faster and more spike-efficient (sparser)!\n\nDifferent encoding strategies with spiking neurons\nUsing latency or spatio-temporal codes\nour encoding is faster and more spike-efficient (sparser)!\nQuestions?\n\nNeuromorphic computing\nWhat is the advantage for applications?\n-\nLess spikes = less energy consumption in specialized neuromorphic hardware\n(e.g. Intel Loihi [12])\nBrains are energy efficient: \n2. Sparse encoding\n\nMultiply-accumulate (MAC) operations:\nNormal neuron: Multiplies input with \nweights, then adds.\nSpiking neuron: Consider binary input (e.g. input currents are piecewise \nconstant and assume values {0,1}). There is no multiplication, only addition.\n\nAssume one multiplier and one adder circuit uses M and A energy respectively with AÔπ§M\n(e.g., for a 45nm CMOS process, standard energy usage is A = 0.9 pJ and M = 3.7 pJ).\nNormal neuron: nin x nout multiplications,\n(nin‚Äì 1) x nout additions\nSpiking neuron: 0 multiplications, (nactive‚Äì 1) x nout \nadditions, with nactive ‚â§ nin\nEnergy consumption:\nEnormal = M nin nout + A (nin‚Äì 1) nout = 17.5 pJ\nEnergy consumption:\nEspiking = A (nactive‚Äì 1) nout = 2.7 pJ\nMultiply-accumulate (MAC) operations:\n\nAssume one multiplier and one adder circuit uses M and A energy respectively with AÔπ§M\n(e.g., for a 45nm CMOS process, standard energy usage is A = 0.9 pJ and M = 3.7 pJ).', 'Reading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020.']","[""<1-hop>\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant"", '<2-hop>\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \n(not publicly available) doi:10.1037/h0042519\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568', ""<1-hop>\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant"", '<2-hop>\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \n(not publicly available) doi:10.1037/h0042519\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568']","The terms ""spiking neural networks"" (SNNs) and ""spiking neuron networks"" are often used interchangeably to refer to the same concept. Both describe a type of artificial neural network that more closely mimics the way biological neurons communicate, using discrete spikes or action potentials to transmit information. These networks leverage the timing of spikes to encode and process information, which can lead to more energy-efficient computations compared to traditional artificial neural networks.

In the context of the provided sources, there is no explicit distinction made between ""spiking neural networks"" and ""spiking neuron networks."" Both terms refer to networks that utilize spiking neurons to perform computations, often with the goal of achieving more biologically plausible and energy-efficient processing. If there is any difference, it would likely be in the context or preference of terminology rather than a fundamental difference in the concept.","Spiking neural networks (SNNs) are a type of neural network model that processes information using spikes, similar to biological neurons. Spiking neuron networks refer to the individual components within these networks, focusing on how each neuron processes and communicates information through spikes.",0.0,0.6,0.36363636363636365,0.46,0.0,0.9718582506279204
What is the foundational concepts of spiking neural networks and how they are used in encoding strategies?,"['Different encoding strategies with spiking neurons\n\nDifferent encoding strategies with spiking neurons\nUsing latency or spatio-temporal codes\nour encoding is faster and more spike-efficient (sparser)!\n\nDifferent encoding strategies with spiking neurons\nUsing latency or spatio-temporal codes\nour encoding is faster and more spike-efficient (sparser)!\nQuestions?\n\nNeuromorphic computing\nWhat is the advantage for applications?\n-\nLess spikes = less energy consumption in specialized neuromorphic hardware\n(e.g. Intel Loihi [12])\nBrains are energy efficient: \n2. Sparse encoding\n\nMultiply-accumulate (MAC) operations:\nNormal neuron: Multiplies input with \nweights, then adds.\nSpiking neuron: Consider binary input (e.g. input currents are piecewise \nconstant and assume values {0,1}). There is no multiplication, only addition.\n\nAssume one multiplier and one adder circuit uses M and A energy respectively with AÔπ§M\n(e.g., for a 45nm CMOS process, standard energy usage is A = 0.9 pJ and M = 3.7 pJ).\nNormal neuron: nin x nout multiplications,\n(nin‚Äì 1) x nout additions\nSpiking neuron: 0 multiplications, (nactive‚Äì 1) x nout \nadditions, with nactive ‚â§ nin\nEnergy consumption:\nEnormal = M nin nout + A (nin‚Äì 1) nout = 17.5 pJ\nEnergy consumption:\nEspiking = A (nactive‚Äì 1) nout = 2.7 pJ\nMultiply-accumulate (MAC) operations:\n\nAssume one multiplier and one adder circuit uses M and A energy respectively with AÔπ§M\n(e.g., for a 45nm CMOS process, standard energy usage is A = 0.9 pJ and M = 3.7 pJ).', 'Neural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568', 'Reading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020.']","[""<1-hop>\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant"", '<2-hop>\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \n(not publicly available) doi:10.1037/h0042519\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568', ""<1-hop>\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant"", '<2-hop>\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \n(not publicly available) doi:10.1037/h0042519\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568', ""<1-hop>\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant"", '<2-hop>\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \n(not publicly available) doi:10.1037/h0042519\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568', ""<1-hop>\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant"", '<2-hop>\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \n(not publicly available) doi:10.1037/h0042519\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568']","Spiking neural networks (SNNs) are a type of neural network that more closely mimic the way biological neurons communicate. The foundational concept of SNNs is that they use spikes, or discrete events, to transmit information, rather than continuous signals. This allows them to perform computations in a way that is more similar to the brain, potentially leading to more efficient processing.

In terms of encoding strategies, SNNs can use latency or spatio-temporal codes. These strategies are designed to be faster and more spike-efficient, meaning they use fewer spikes to encode information. This sparsity in spike usage leads to less energy consumption, which is particularly advantageous for applications in neuromorphic computing. Neuromorphic hardware, such as Intel's Loihi, benefits from this efficiency because it reduces the energy required for computation, making it more sustainable and scalable.

Overall, the use of spiking neurons in encoding strategies allows for more efficient and biologically plausible computation, leveraging the advantages of sparse and event-driven processing.","Spiking neural networks use spikes to encode information, with foundational concepts including the work of McCulloch and Pitts on logical calculus of nervous activity, and later developments in spiking neuron models.",0.0,0.6666666666666666,0.8636363636363636,0.31,0.0,0.9092523972120737
What is the project idea about government-developed OS software?,"['data to understand state of software: \nbuildable?, open dev. history?, requirements documentation? \n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!\n\nB7. Queue - but better for the student / TA society\n‚Ä¢ Requirements analysis regarding social and individual sustainability effects \nof Queue \n‚Ä¢ Other EIP / TUD used software also possible: e.g., Answers EWI \n‚Ä¢ Non-technical project ‚Üí proper process (workshops? Interviews?) & rich \ndescription of outcomes focus of grading\nhttps://eip.pages.ewi.tudelft.nl/eip-website/queue.html\n\nC1. Compare energy consumption of docker images for \nML workloads.\n‚Ä¢ Similar to what we have seen in the lectures but for ML-specific workloads. \n‚Ä¢ We can reuse existing experiment replication packages.\n22\n\nC2. Plugin to visualize Hugging Face carbon emissions.\n‚Ä¢ https://huggingface.co/blog/leaderboard-emissions-\nanalysis \n‚Ä¢\nYoo, Taewon, et al. ""Visualizing the Carbon Intensity of Machine Learning Inference for Image Analysis on TensorFlow Hub.""\n\nC3. Plugin for ChatGPT\n‚Ä¢ Users seldom know how much carbon they are emitting when they interact \nwith chat GPT. \n‚Ä¢ Let‚Äôs make it transparent to the users. Browser plugin?\n24\nCO2\n\nC4. NutriScore for software libraries\n25\n‚Ä¢ NutriScore labels are not perfect but they are a good starting point! \n‚Ä¢ What if we could do the same thing for the energy efficiency of software. \n‚Ä¢ (Also open to individual or social sustainability) \n‚Ä¢ This work can be scoped in particular domains/ecossystems/use cases. \n‚Ä¢ Libraries for stats? ML? Web Dev? Cloud?\n\nC5. Add energy-awareness to existing software\n26\n‚Ä¢ Streamlit, Notebooks, JSFiddle, \nPyScript, zsh, etc. \n‚Ä¢\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy efficiency using static code analysis. \n‚Ä¢ We don‚Äôt need an accurate value. \n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention. \n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)', 'Lu√≠s Cruz \nL.Cruz@tudelft.nl \n10. Project 2\nSustainable Software Engineering\u2028\nCS4575\nSustainableSE 2025\nCarolin Brandt \nC.E.Brandt@tudelft.nl \nEnrique Barba Roque \nE.BarbaRoque@tudelft.nl\n\n1. Goal/assignment \n2. Deliverables \n3. Strategy \n4. Ideas\n\nAssignment\n‚Ä¢ Goal: Solve a Sustainable Software Engineering problem. \n‚Ä¢ Identify 1 problem that should be fixed to help enabling sustainability in \nthe software engineering industry/community. \n‚Ä¢ Propose a solution. A tool, framework, guidelines, etc. \n‚Ä¢ Implementation. \n‚Ä¢ Validation. (Depending on the idea) \n‚Ä¢ Dissemination/social impact. (Solution should be open source, welcome \ncontributors, post on social media? Tool website? Available in a package \nmanager?)\n3\n\nDeliverables\n‚Ä¢ Paper-like article. (Min 4 pages, max 10) \n‚Ä¢ Online git repo with open source codebase and/or replication package. \n‚Ä¢ Presentation: 5 min + 5min Q&A\n4\n\nArticle\n‚Ä¢ Different projects will have different expectations -> Make agreements with \nyour coach. \n‚Ä¢ Some projects are more technical and some projects more theoretical. \n‚Ä¢ Common requirements: \n‚Ä¢ Motivation, formulation of the problem being addressed, etc. \n‚Ä¢ Description of the solution. \n‚Ä¢ Validation of the solution (if applicable -> discuss with coach) \n‚Ä¢ Discussion of the solution. (Including limitations)\n5\n\nStrategy\n‚Ä¢ Starting next week, there are no lectures  \n‚Ä¢ Steering meetings from week 5 till week 9 (either online or in person).  \n‚Ä¢ 1 steering meeting per week. (4+1 sprints) \n‚Ä¢ Every week, you need to plan different tasks and assignments. \n‚Ä¢ Deadline April 4.\n6\n\nStrategy\n‚Ä¢ Week 0 \n‚Ä¢ Decide project idea (today) \n‚Ä¢ Define steering meeting schedule \n‚Ä¢ Create working document of the \narticle: Problem statement and solution \nproposal! \n‚Ä¢ Define and assign tasks for each week. \n‚Ä¢ Week 1 \n‚Ä¢ Implementation \n‚Ä¢ Agreements with supervisor. \n‚Ä¢ Week 2 \n‚Ä¢ Implementation \n‚Ä¢ Week 3 \n‚Ä¢ Implementation, Full draft of article, \ndissemination.', 'Lu√≠s Cruz \nL.Cruz@tudelft.nl \n7. Green SE ‚Äì Research\nSustainable Software Engineering\u2028\nCS4575\nSustainableSE 2025\nCarolin Brandt \nC.E.Brandt@tudelft.nl \nEnrique Barba Roque \nE.BarbaRoque@tudelft.nl\n\n1. Energy patterns for mobile apps \n2. Carbon-aware datacenters \n3. Energy Regression Testing \n4. Debugging Energy with Docker images \n5. Energy Efficiency vs Code Quality \n\n‚Ä¢ While learning about these works, try to be critical about them and find their \npitfalls.\n3\n\n‚Ä¢ We have seen that measuring energy consumption is not trivial \n‚Ä¢ It is not practical considering that developers have other priorities above \nenergy efficiency \n‚Ä¢ At the same time, every now and then there are some efforts to improve \nenergy efficiency in some cases. This is time consuming and requires \nexpertise. \n‚Ä¢ How can we reuse these efforts?\n4\n\nEnergy Patterns for Mobile \nApps\nhttps://tqrg.github.io/energy-patterns/\n\nMethodology\n5. Catalog of Energy Patterns\n22 \npatterns\nF-droid\nCurated Lists\n1. App Collection\n1783 \napps\n3. Manual Refinement of Subjects of \nInterest\n1563 \nchanges\n4. Thematic Analysis\n431 \nreusable \nchanges\n2. Collect Changes With Potential Interest\n/.*(energy|power|battery).*/\n6028 \nchanges\n\nThematic Analysis\n1. Familiarization with data \n2. Generating initial labels \n3. Reviewing themes\n4. Defining and naming themes\n\n‚Ä¢ Energy Pattern: design pattern to improve energy efficiency.. \n‚Ä¢ 22 energy patterns. \n‚Ä¢ Each pattern is described by Context, Solution, Example, References from \nliterature, and Occurences (links to code changes from git repositories).\n8\n\nhttps://tqrg.github.io/energy-patterns\n\nDark UI Colors \nProvide a dark UI color theme to \nsave battery on devices with \nAMOLED screens.\n‚Ä¢ Context: [‚Ä¶] Apps that require heavy usage of screen can \nhave a substantial negative impact on battery life. \n‚Ä¢ Solution: Provide a UI theme with dark background colors.']","['<1-hop>\n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise\n‚Ä¢ But studying government software is diÔ¨Écult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation?\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!', '<2-hop>\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption\n‚Ä¢ B3. Energy proÔ¨Åling of static analysis tools\n‚Ä¢ B4. Detailed energy proÔ¨Åling of build pipelines\n‚Ä¢ B5. Tool supporting SusAF workshop / process\n‚Ä¢ B6. Dataset of government-developed OS software\n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability']","The provided sources do not mention a project idea specifically about government-developed OS software. However, if you are interested in sustainable software engineering projects, the sources discuss various ideas such as energy consumption comparison of docker images for ML workloads, plugins to visualize carbon emissions, and adding energy-awareness to existing software. If you have a specific interest in government-developed OS software, you might consider exploring how such software can be made more sustainable or energy-efficient.","The project idea involves creating a comprehensive dataset of government-developed OS software to understand its state, including buildability, open development history, and requirements documentation. This addresses challenges like lack of incentives and language barriers.",0.0,0.0,0.8333333333333334,0.0,0.0,0.0
What is the project idea related to creating a dataset of goverment-developed OS software?,"['data to understand state of software: \nbuildable?, open dev. history?, requirements documentation? \n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!\n\nB7. Queue - but better for the student / TA society\n‚Ä¢ Requirements analysis regarding social and individual sustainability effects \nof Queue \n‚Ä¢ Other EIP / TUD used software also possible: e.g., Answers EWI \n‚Ä¢ Non-technical project ‚Üí proper process (workshops? Interviews?) & rich \ndescription of outcomes focus of grading\nhttps://eip.pages.ewi.tudelft.nl/eip-website/queue.html\n\nC1. Compare energy consumption of docker images for \nML workloads.\n‚Ä¢ Similar to what we have seen in the lectures but for ML-specific workloads. \n‚Ä¢ We can reuse existing experiment replication packages.\n22\n\nC2. Plugin to visualize Hugging Face carbon emissions.\n‚Ä¢ https://huggingface.co/blog/leaderboard-emissions-\nanalysis \n‚Ä¢\nYoo, Taewon, et al. ""Visualizing the Carbon Intensity of Machine Learning Inference for Image Analysis on TensorFlow Hub.""\n\nC3. Plugin for ChatGPT\n‚Ä¢ Users seldom know how much carbon they are emitting when they interact \nwith chat GPT. \n‚Ä¢ Let‚Äôs make it transparent to the users. Browser plugin?\n24\nCO2\n\nC4. NutriScore for software libraries\n25\n‚Ä¢ NutriScore labels are not perfect but they are a good starting point! \n‚Ä¢ What if we could do the same thing for the energy efficiency of software. \n‚Ä¢ (Also open to individual or social sustainability) \n‚Ä¢ This work can be scoped in particular domains/ecossystems/use cases. \n‚Ä¢ Libraries for stats? ML? Web Dev? Cloud?\n\nC5. Add energy-awareness to existing software\n26\n‚Ä¢ Streamlit, Notebooks, JSFiddle, \nPyScript, zsh, etc. \n‚Ä¢\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy efficiency using static code analysis. \n‚Ä¢ We don‚Äôt need an accurate value. \n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention. \n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)', 'Lu√≠s Cruz \nL.Cruz@tudelft.nl \n10. Project 2\nSustainable Software Engineering\u2028\nCS4575\nSustainableSE 2025\nCarolin Brandt \nC.E.Brandt@tudelft.nl \nEnrique Barba Roque \nE.BarbaRoque@tudelft.nl\n\n1. Goal/assignment \n2. Deliverables \n3. Strategy \n4. Ideas\n\nAssignment\n‚Ä¢ Goal: Solve a Sustainable Software Engineering problem. \n‚Ä¢ Identify 1 problem that should be fixed to help enabling sustainability in \nthe software engineering industry/community. \n‚Ä¢ Propose a solution. A tool, framework, guidelines, etc. \n‚Ä¢ Implementation. \n‚Ä¢ Validation. (Depending on the idea) \n‚Ä¢ Dissemination/social impact. (Solution should be open source, welcome \ncontributors, post on social media? Tool website? Available in a package \nmanager?)\n3\n\nDeliverables\n‚Ä¢ Paper-like article. (Min 4 pages, max 10) \n‚Ä¢ Online git repo with open source codebase and/or replication package. \n‚Ä¢ Presentation: 5 min + 5min Q&A\n4\n\nArticle\n‚Ä¢ Different projects will have different expectations -> Make agreements with \nyour coach. \n‚Ä¢ Some projects are more technical and some projects more theoretical. \n‚Ä¢ Common requirements: \n‚Ä¢ Motivation, formulation of the problem being addressed, etc. \n‚Ä¢ Description of the solution. \n‚Ä¢ Validation of the solution (if applicable -> discuss with coach) \n‚Ä¢ Discussion of the solution. (Including limitations)\n5\n\nStrategy\n‚Ä¢ Starting next week, there are no lectures  \n‚Ä¢ Steering meetings from week 5 till week 9 (either online or in person).  \n‚Ä¢ 1 steering meeting per week. (4+1 sprints) \n‚Ä¢ Every week, you need to plan different tasks and assignments. \n‚Ä¢ Deadline April 4.\n6\n\nStrategy\n‚Ä¢ Week 0 \n‚Ä¢ Decide project idea (today) \n‚Ä¢ Define steering meeting schedule \n‚Ä¢ Create working document of the \narticle: Problem statement and solution \nproposal! \n‚Ä¢ Define and assign tasks for each week. \n‚Ä¢ Week 1 \n‚Ä¢ Implementation \n‚Ä¢ Agreements with supervisor. \n‚Ä¢ Week 2 \n‚Ä¢ Implementation \n‚Ä¢ Week 3 \n‚Ä¢ Implementation, Full draft of article, \ndissemination.', '‚Ä¢ Deadline April 4.\n6\n\nStrategy\n‚Ä¢ Week 0 \n‚Ä¢ Decide project idea (today) \n‚Ä¢ Define steering meeting schedule \n‚Ä¢ Create working document of the \narticle: Problem statement and solution \nproposal! \n‚Ä¢ Define and assign tasks for each week. \n‚Ä¢ Week 1 \n‚Ä¢ Implementation \n‚Ä¢ Agreements with supervisor. \n‚Ä¢ Week 2 \n‚Ä¢ Implementation \n‚Ä¢ Week 3 \n‚Ä¢ Implementation, Full draft of article, \ndissemination. \n‚Ä¢ Week 4 \n‚Ä¢ Final refinements \n‚Ä¢ Prepare presentation\n7\n\nProject ideas\n‚Ä¢ A1. Prototype cross-machine comparable benchmarks \n‚Ä¢ A2. Add energy metrics to LMstudio/Ollama \n‚Ä¢ A3. Visualizations built-in with EnergiBridge \n‚Ä¢ A4. Service-based version of EnergiBridge\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption \n‚Ä¢ B3. Energy profiling of static analysis tools \n‚Ä¢ B4. Detailed energy profiling of build pipelines \n‚Ä¢ B5. Tool supporting SusAF workshop / process \n‚Ä¢ B6. Dataset of government-developed OS software \n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability\n\nProject ideas\n‚Ä¢ C1. Compare energy consumption of docker images for ML workloads. \n‚Ä¢ C2. Create a plugin to visualize Hugging Face carbon emissions in detail. \n‚Ä¢ C3. Plugin for ChatGPT (footprint per chat window) \n‚Ä¢ C4. NutriScore for software libraries. \n‚Ä¢ C5. Add energy-awareness to existing software \n‚Ä¢ C6. Green Shift Left \n‚Ä¢ C7. Education for Sustainable SE\n\nA1. Prototype cross-machine comparable benchmarks\n‚Ä¢ Energy-usage comparisons require running both baseline + software on the \nsame machine ‚Üí limits how extensive our experiments can be \n‚Ä¢ Research community is in need of benchmarks that make energy \nmeasurements comparable even if executed on different machines \n‚Ä¢ Focus on a single task or model (i.e. computing vision, classification)\n\nA2.']","['<1-hop>\n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise\n‚Ä¢ But studying government software is diÔ¨Écult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation?\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!', '<2-hop>\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption\n‚Ä¢ B3. Energy proÔ¨Åling of static analysis tools\n‚Ä¢ B4. Detailed energy proÔ¨Åling of build pipelines\n‚Ä¢ B5. Tool supporting SusAF workshop / process\n‚Ä¢ B6. Dataset of government-developed OS software\n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability', '<1-hop>\n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise\n‚Ä¢ But studying government software is diÔ¨Écult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation?\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!', '<2-hop>\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption\n‚Ä¢ B3. Energy proÔ¨Åling of static analysis tools\n‚Ä¢ B4. Detailed energy proÔ¨Åling of build pipelines\n‚Ä¢ B5. Tool supporting SusAF workshop / process\n‚Ä¢ B6. Dataset of government-developed OS software\n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability', '<1-hop>\n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise\n‚Ä¢ But studying government software is diÔ¨Écult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation?\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!', '<2-hop>\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption\n‚Ä¢ B3. Energy proÔ¨Åling of static analysis tools\n‚Ä¢ B4. Detailed energy proÔ¨Åling of build pipelines\n‚Ä¢ B5. Tool supporting SusAF workshop / process\n‚Ä¢ B6. Dataset of government-developed OS software\n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability', '<1-hop>\n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise\n‚Ä¢ But studying government software is diÔ¨Écult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation?\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!', '<2-hop>\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption\n‚Ä¢ B3. Energy proÔ¨Åling of static analysis tools\n‚Ä¢ B4. Detailed energy proÔ¨Åling of build pipelines\n‚Ä¢ B5. Tool supporting SusAF workshop / process\n‚Ä¢ B6. Dataset of government-developed OS software\n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability', '<1-hop>\n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise\n‚Ä¢ But studying government software is diÔ¨Écult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation?\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!', '<2-hop>\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption\n‚Ä¢ B3. Energy proÔ¨Åling of static analysis tools\n‚Ä¢ B4. Detailed energy proÔ¨Åling of build pipelines\n‚Ä¢ B5. Tool supporting SusAF workshop / process\n‚Ä¢ B6. Dataset of government-developed OS software\n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability']",The project idea related to creating a dataset of government-developed OS software is labeled as B6. The focus of this project is to compile a dataset that includes open-source software developed by government entities. This project falls under the category of Quality Assurance & Testing and Social & Individual Sustainability.,"The project idea is to create a dataset of government-developed OS software, which would help in understanding the state of such software, including whether it is buildable, has open development history, and has requirements documentation.",0.3333333333,1.0,0.75,0.25,0.0,0.9104486205676773
What is the project idea related to creating a dataset of government-developed OS software?,"['data to understand state of software: \nbuildable?, open dev. history?, requirements documentation? \n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!\n\nB7. Queue - but better for the student / TA society\n‚Ä¢ Requirements analysis regarding social and individual sustainability effects \nof Queue \n‚Ä¢ Other EIP / TUD used software also possible: e.g., Answers EWI \n‚Ä¢ Non-technical project ‚Üí proper process (workshops? Interviews?) & rich \ndescription of outcomes focus of grading\nhttps://eip.pages.ewi.tudelft.nl/eip-website/queue.html\n\nC1. Compare energy consumption of docker images for \nML workloads.\n‚Ä¢ Similar to what we have seen in the lectures but for ML-specific workloads. \n‚Ä¢ We can reuse existing experiment replication packages.\n22\n\nC2. Plugin to visualize Hugging Face carbon emissions.\n‚Ä¢ https://huggingface.co/blog/leaderboard-emissions-\nanalysis \n‚Ä¢\nYoo, Taewon, et al. ""Visualizing the Carbon Intensity of Machine Learning Inference for Image Analysis on TensorFlow Hub.""\n\nC3. Plugin for ChatGPT\n‚Ä¢ Users seldom know how much carbon they are emitting when they interact \nwith chat GPT. \n‚Ä¢ Let‚Äôs make it transparent to the users. Browser plugin?\n24\nCO2\n\nC4. NutriScore for software libraries\n25\n‚Ä¢ NutriScore labels are not perfect but they are a good starting point! \n‚Ä¢ What if we could do the same thing for the energy efficiency of software. \n‚Ä¢ (Also open to individual or social sustainability) \n‚Ä¢ This work can be scoped in particular domains/ecossystems/use cases. \n‚Ä¢ Libraries for stats? ML? Web Dev? Cloud?\n\nC5. Add energy-awareness to existing software\n26\n‚Ä¢ Streamlit, Notebooks, JSFiddle, \nPyScript, zsh, etc. \n‚Ä¢\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy efficiency using static code analysis. \n‚Ä¢ We don‚Äôt need an accurate value. \n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention. \n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)', '‚Ä¢ Deadline April 4.\n6\n\nStrategy\n‚Ä¢ Week 0 \n‚Ä¢ Decide project idea (today) \n‚Ä¢ Define steering meeting schedule \n‚Ä¢ Create working document of the \narticle: Problem statement and solution \nproposal! \n‚Ä¢ Define and assign tasks for each week. \n‚Ä¢ Week 1 \n‚Ä¢ Implementation \n‚Ä¢ Agreements with supervisor. \n‚Ä¢ Week 2 \n‚Ä¢ Implementation \n‚Ä¢ Week 3 \n‚Ä¢ Implementation, Full draft of article, \ndissemination. \n‚Ä¢ Week 4 \n‚Ä¢ Final refinements \n‚Ä¢ Prepare presentation\n7\n\nProject ideas\n‚Ä¢ A1. Prototype cross-machine comparable benchmarks \n‚Ä¢ A2. Add energy metrics to LMstudio/Ollama \n‚Ä¢ A3. Visualizations built-in with EnergiBridge \n‚Ä¢ A4. Service-based version of EnergiBridge\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption \n‚Ä¢ B3. Energy profiling of static analysis tools \n‚Ä¢ B4. Detailed energy profiling of build pipelines \n‚Ä¢ B5. Tool supporting SusAF workshop / process \n‚Ä¢ B6. Dataset of government-developed OS software \n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability\n\nProject ideas\n‚Ä¢ C1. Compare energy consumption of docker images for ML workloads. \n‚Ä¢ C2. Create a plugin to visualize Hugging Face carbon emissions in detail. \n‚Ä¢ C3. Plugin for ChatGPT (footprint per chat window) \n‚Ä¢ C4. NutriScore for software libraries. \n‚Ä¢ C5. Add energy-awareness to existing software \n‚Ä¢ C6. Green Shift Left \n‚Ä¢ C7. Education for Sustainable SE\n\nA1. Prototype cross-machine comparable benchmarks\n‚Ä¢ Energy-usage comparisons require running both baseline + software on the \nsame machine ‚Üí limits how extensive our experiments can be \n‚Ä¢ Research community is in need of benchmarks that make energy \nmeasurements comparable even if executed on different machines \n‚Ä¢ Focus on a single task or model (i.e. computing vision, classification)\n\nA2.', 'Lu√≠s Cruz \nL.Cruz@tudelft.nl \n10. Project 2\nSustainable Software Engineering\u2028\nCS4575\nSustainableSE 2025\nCarolin Brandt \nC.E.Brandt@tudelft.nl \nEnrique Barba Roque \nE.BarbaRoque@tudelft.nl\n\n1. Goal/assignment \n2. Deliverables \n3. Strategy \n4. Ideas\n\nAssignment\n‚Ä¢ Goal: Solve a Sustainable Software Engineering problem. \n‚Ä¢ Identify 1 problem that should be fixed to help enabling sustainability in \nthe software engineering industry/community. \n‚Ä¢ Propose a solution. A tool, framework, guidelines, etc. \n‚Ä¢ Implementation. \n‚Ä¢ Validation. (Depending on the idea) \n‚Ä¢ Dissemination/social impact. (Solution should be open source, welcome \ncontributors, post on social media? Tool website? Available in a package \nmanager?)\n3\n\nDeliverables\n‚Ä¢ Paper-like article. (Min 4 pages, max 10) \n‚Ä¢ Online git repo with open source codebase and/or replication package. \n‚Ä¢ Presentation: 5 min + 5min Q&A\n4\n\nArticle\n‚Ä¢ Different projects will have different expectations -> Make agreements with \nyour coach. \n‚Ä¢ Some projects are more technical and some projects more theoretical. \n‚Ä¢ Common requirements: \n‚Ä¢ Motivation, formulation of the problem being addressed, etc. \n‚Ä¢ Description of the solution. \n‚Ä¢ Validation of the solution (if applicable -> discuss with coach) \n‚Ä¢ Discussion of the solution. (Including limitations)\n5\n\nStrategy\n‚Ä¢ Starting next week, there are no lectures  \n‚Ä¢ Steering meetings from week 5 till week 9 (either online or in person).  \n‚Ä¢ 1 steering meeting per week. (4+1 sprints) \n‚Ä¢ Every week, you need to plan different tasks and assignments. \n‚Ä¢ Deadline April 4.\n6\n\nStrategy\n‚Ä¢ Week 0 \n‚Ä¢ Decide project idea (today) \n‚Ä¢ Define steering meeting schedule \n‚Ä¢ Create working document of the \narticle: Problem statement and solution \nproposal! \n‚Ä¢ Define and assign tasks for each week. \n‚Ä¢ Week 1 \n‚Ä¢ Implementation \n‚Ä¢ Agreements with supervisor. \n‚Ä¢ Week 2 \n‚Ä¢ Implementation \n‚Ä¢ Week 3 \n‚Ä¢ Implementation, Full draft of article, \ndissemination.']","['<1-hop>\n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise\n‚Ä¢ But studying government software is diÔ¨Écult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation?\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!', '<2-hop>\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption\n‚Ä¢ B3. Energy proÔ¨Åling of static analysis tools\n‚Ä¢ B4. Detailed energy proÔ¨Åling of build pipelines\n‚Ä¢ B5. Tool supporting SusAF workshop / process\n‚Ä¢ B6. Dataset of government-developed OS software\n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability']","The project idea related to creating a dataset of government-developed OS software is labeled as B6. This project involves compiling a dataset that includes open-source software developed by government entities. The focus is on understanding the state of such software, including aspects like whether it is buildable, has an open development history, and includes requirements documentation.","The project idea is to create a comprehensive dataset of government-developed OS software to understand the state of such software, including its buildability, open development history, and requirements documentation. This addresses challenges like the lack of incentive to make software popular and language barriers.",0.49999999995,0.5,1.0,0.67,,0.8373559158371174
How EcoAndroid reduce risk by reduce size?,"['‚Ä¢ Some users noticed that K-9 mail was spending more energy than usual. üôâ \n‚Ä¢ A user that was having issues with a personal mail server  noticed that K-9 \nmail was the one of the most energy-greedy apps. IMAP IDLE protocol for real-time \nnotifications. \n‚Ä¢ When a connection is not possible, the app automatically retries later. \n‚Ä¢ https://github.com/k9mail/k-9/commit/\n86f3b28f79509d1a4d613eb39f60603e08579ea3\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio) \n‚Ä¢ Dynamic Retry Delay \n‚Ä¢ Push Over Poll \n‚Ä¢ Reduce Size \n‚Ä¢ Cache \n‚Ä¢ Avoid Graphics and Animations\n20\n\nCarbon-Aware Computing for \nDatacenters \nhttps://sites.google.com/view/energy-efficiency-languages\n21\nAna Radovanovic ÃÅ, Ross Koningstein, Ian Schneider, Bokan \nChen, Alexandre Duarte, Binz Roy, Diyue Xiao, Maya \nHaridasan, Patrick Hung, Nick Care, Saurav Talukdar, Eric \nMullen, Kendal Smith, MariEllen Cottman, and Walfredo Cirne \n\n\n‚Ä¢ Google‚Äôs Carbon-Intelligent Computing System (CICS) \n‚Ä¢ Main idea: use carbon-intensity data to shift datacenter jobs in time \n‚Ä¢ Typically, job schedulers use a metric of cluster capacity to schedule a job in \na particular cluster. \n‚Ä¢ CICS overrides this metric with the virtual capacity curve (VCC) that \nfactors in Carbon intensity \n‚Ä¢ When a new job comes in, the scheduler estimates its CPU load and power \nusage and assigns it to a cluster if the VCC is not exceeded.\n23\n\n‚Ä¢ Jobs are divided between flexible and inflexible. \n‚Ä¢ Flexible load is considered shapeable/shiftable as long as its total daily \ncompute (CPU) demand is preserved \n‚Ä¢ The system needs to consider that, while running a job, the virtual capacity \ncurve (VCC) might drop. Hence, this job should not start in the first place. \n‚Ä¢ They forecast VCC for the next day\n24\n\n\nVirtual Cluster Capacity (VCC)\n‚Ä¢ Aims at reducing the peak load at carbon intensive hours but in total it should allow for the \nsome amount of daily computation!', '‚Ä¢ Opt for low-power hardware (e.g., Nvidia Jetson boards) \n‚Ä¢ Or GPUs that provide energy metrics (e.g., NVIDIA GPUs via the nvidia-smi tool) \n‚Ä¢ Report energy/carbon metrics (e.g., embed in MLFlow?) \n‚Ä¢ Use pre-trained models (Transfer Learning) \n‚Ä¢ Preprocess dataset to reduce size. \n‚Ä¢ Improve parameter-tuning strategy.\n11\n\nReporting energy/carbon footprint\n‚Ä¢ We need benchmarks. \n‚Ä¢ AllenAI leaderboard\u2028\nhttps://leaderboard.allenai.org \n‚Ä¢ No carbon metrics, yet \n‚Ä¢ Report comparable proxies for energy \nconsumption. \n‚Ä¢ ‚ö† Learning algorithms behave in a non-\ndeterministic \n‚Ä¢ ‚ö† Different data-points lead to different \nenergy consumption\n12\n\nReporting energy/carbon footprint\n‚Ä¢ Reporting measured energy consumption \n‚Ä¢ + Accurate \n‚Ä¢ + Easy to map to carbon emissions \n‚Ä¢ - Hard to measure \n‚Ä¢ - Low replicability \n‚Ä¢ Reporting time / estimation based on time & hardware \n‚Ä¢ + Easy to measure \n‚Ä¢ + Correlates with energy consumption in most cases. \n‚Ä¢ -  Difficult to compare with measurements from other setups \n‚Ä¢ E.g., floating point operations (FPOs) (?) \n‚Ä¢ + comparable across different setups \n‚Ä¢ + cheap \n‚Ä¢ - does not factor in memory energy consumption \n‚Ä¢ - does not reflect carbon emissions\n13\n\nData-centric AI\n\nData-centric AI\n‚Ä¢ Emerging discipline that deals with systematically engineering data to build AI \nsystems. \n‚Ä¢ Shift from improving the training strategy to improving the data. \n‚Ä¢ It is better to have small but reliable datasets than large but noisy \ndatasets. \n‚Ä¢ => Improve data collection, data labelling, and data preprocessing. \n‚Ä¢ More about data-centric AI by Andrew Ng:\u2028\nhttps://www.youtube.com/watch?v=06-AZXmwHjo\n15\n\n\nGreen Data-centric AI\n‚Ä¢ How do different ML algorithms compare \nin terms of energy consumption? \n‚Ä¢ How does number of rows relate to the \nenergy consumption of ML models? \n‚Ä¢ How does number of features relate to \nthe energy consumption of ML models? \n‚Ä¢ What is the impact of reducing data in the \nperformance of the model? \n‚Ä¢ Method -> results -> discussion\n17\n\nMethod\n‚Ä¢ Single object of study: natural language model to detect spam messages.']","['<1-hop>\n\nShuffle \nüîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them.\n‚Ä¢ If you run 30 executions for version A and another batch for version B:\n‚Ä¢ External conditions that change over time will have a diÔ¨Äerent bias in \nthe 2 versions (e.g., room temperature changes).\n‚Ä¢ If you shuÔ¨Ñe, you reduce this risk.\n11', '<2-hop>\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio)\n‚Ä¢ Dynamic Retry Delay\n‚Ä¢ Push Over Poll\n‚Ä¢ Reduce Size\n‚Ä¢ Cache\n‚Ä¢ Avoid Graphics and Animations\n20', '<1-hop>\n\nShuffle \nüîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them.\n‚Ä¢ If you run 30 executions for version A and another batch for version B:\n‚Ä¢ External conditions that change over time will have a diÔ¨Äerent bias in \nthe 2 versions (e.g., room temperature changes).\n‚Ä¢ If you shuÔ¨Ñe, you reduce this risk.\n11', '<2-hop>\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio)\n‚Ä¢ Dynamic Retry Delay\n‚Ä¢ Push Over Poll\n‚Ä¢ Reduce Size\n‚Ä¢ Cache\n‚Ä¢ Avoid Graphics and Animations\n20']","EcoAndroid reduces risk by reducing size through several strategies, such as implementing dynamic retry delays, using push over poll, caching, and avoiding graphics and animations. These strategies help in minimizing the app's resource consumption, which in turn reduces energy usage and the risk of excessive battery drain.",EcoAndroid reduce risk by using Reduce Size feature which help minimize energy consumption and reduce impact of external factors like temperature changes.,0.49999999995,0.0,0.625,0.4,0.249999999375,0.9330530734155084
How can static code analysis in data science be used to improve the energy efficiency of data centers and contribute to sustainable software engineering?,"['‚Ä¢\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy efficiency using static code analysis. \n‚Ä¢ We don‚Äôt need an accurate value. \n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention. \n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27\n\nC7 - Education\n‚Ä¢ Educational game for Software \nSustainability practices \n‚Ä¢ Purpose: use within software teams to \ndiscuss or learn about different sustainable \nIT practices: at the organisation level, \nsoftware, etc.\n28\nhttps://github.com/OttoKaaij/Ticket-To-Sustainability/?tab=readme-ov-file\n\nProject ideas (old)\n‚Ä¢ Plugin from EnergiBridge (GUI, report generator, python library, etc.) \n‚Ä¢ Plugin for ChatGPT (carbon emissions per chat window) \n‚Ä¢ Seamless measurements for AI libraries \n‚Ä¢ Energy patterns for Green AI \n‚Ä¢ Sustainable SW dev gamification \n‚Ä¢ Sustainability auditor for AI projects \n‚Ä¢ Energy Profiling of screen colour filter tools (or display settings) \n‚Ä¢ ‚Ä¶ you can also propose yours!\n\nhttps://edu.nl/64gpk\nedu.nl/64gpk', 'data to understand state of software: \nbuildable?, open dev. history?, requirements documentation? \n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!\n\nB7. Queue - but better for the student / TA society\n‚Ä¢ Requirements analysis regarding social and individual sustainability effects \nof Queue \n‚Ä¢ Other EIP / TUD used software also possible: e.g., Answers EWI \n‚Ä¢ Non-technical project ‚Üí proper process (workshops? Interviews?) & rich \ndescription of outcomes focus of grading\nhttps://eip.pages.ewi.tudelft.nl/eip-website/queue.html\n\nC1. Compare energy consumption of docker images for \nML workloads.\n‚Ä¢ Similar to what we have seen in the lectures but for ML-specific workloads. \n‚Ä¢ We can reuse existing experiment replication packages.\n22\n\nC2. Plugin to visualize Hugging Face carbon emissions.\n‚Ä¢ https://huggingface.co/blog/leaderboard-emissions-\nanalysis \n‚Ä¢\nYoo, Taewon, et al. ""Visualizing the Carbon Intensity of Machine Learning Inference for Image Analysis on TensorFlow Hub.""\n\nC3. Plugin for ChatGPT\n‚Ä¢ Users seldom know how much carbon they are emitting when they interact \nwith chat GPT. \n‚Ä¢ Let‚Äôs make it transparent to the users. Browser plugin?\n24\nCO2\n\nC4. NutriScore for software libraries\n25\n‚Ä¢ NutriScore labels are not perfect but they are a good starting point! \n‚Ä¢ What if we could do the same thing for the energy efficiency of software. \n‚Ä¢ (Also open to individual or social sustainability) \n‚Ä¢ This work can be scoped in particular domains/ecossystems/use cases. \n‚Ä¢ Libraries for stats? ML? Web Dev? Cloud?\n\nC5. Add energy-awareness to existing software\n26\n‚Ä¢ Streamlit, Notebooks, JSFiddle, \nPyScript, zsh, etc. \n‚Ä¢\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy efficiency using static code analysis. \n‚Ä¢ We don‚Äôt need an accurate value. \n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention. \n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)']","['<1-hop>\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy eÔ¨Éciency using static code analysis.\n‚Ä¢ We don‚Äôt need an accurate value.\n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.\n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27', '<2-hop>\n\nWhy?\n‚Ä¢ Throughout your career you might:\n‚Ä¢ Design/maintain/contract data centers\n‚Ä¢ Set up operations/devops\n‚Ä¢ Develop AI for IoT devices\n‚Ä¢ Be the next CEO/CTO of a software company\n‚Ä¢ Sustainability can be your main role:\n‚Ä¢ Green Software Developer\n‚Ä¢ Sustainability Consultant\n‚Ä¢ Green Advocate \n‚Ä¢ Founder of a Green Tech startup (B2B?)\n28', '<1-hop>\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy eÔ¨Éciency using static code analysis.\n‚Ä¢ We don‚Äôt need an accurate value.\n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.\n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27', '<2-hop>\n\nWhy?\n‚Ä¢ Throughout your career you might:\n‚Ä¢ Design/maintain/contract data centers\n‚Ä¢ Set up operations/devops\n‚Ä¢ Develop AI for IoT devices\n‚Ä¢ Be the next CEO/CTO of a software company\n‚Ä¢ Sustainability can be your main role:\n‚Ä¢ Green Software Developer\n‚Ä¢ Sustainability Consultant\n‚Ä¢ Green Advocate \n‚Ä¢ Founder of a Green Tech startup (B2B?)\n28', '<1-hop>\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy eÔ¨Éciency using static code analysis.\n‚Ä¢ We don‚Äôt need an accurate value.\n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.\n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27', '<2-hop>\n\nWhy?\n‚Ä¢ Throughout your career you might:\n‚Ä¢ Design/maintain/contract data centers\n‚Ä¢ Set up operations/devops\n‚Ä¢ Develop AI for IoT devices\n‚Ä¢ Be the next CEO/CTO of a software company\n‚Ä¢ Sustainability can be your main role:\n‚Ä¢ Green Software Developer\n‚Ä¢ Sustainability Consultant\n‚Ä¢ Green Advocate \n‚Ä¢ Founder of a Green Tech startup (B2B?)\n28', '<1-hop>\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy eÔ¨Éciency using static code analysis.\n‚Ä¢ We don‚Äôt need an accurate value.\n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.\n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27', '<2-hop>\n\nWhy?\n‚Ä¢ Throughout your career you might:\n‚Ä¢ Design/maintain/contract data centers\n‚Ä¢ Set up operations/devops\n‚Ä¢ Develop AI for IoT devices\n‚Ä¢ Be the next CEO/CTO of a software company\n‚Ä¢ Sustainability can be your main role:\n‚Ä¢ Green Software Developer\n‚Ä¢ Sustainability Consultant\n‚Ä¢ Green Advocate \n‚Ä¢ Founder of a Green Tech startup (B2B?)\n28']","Static code analysis in data science can be used to improve the energy efficiency of data centers by identifying code that is likely to introduce energy hotspots. This process involves estimating energy efficiency without needing an exact value, allowing developers to focus on reviewing and optimizing parts of the code that are more likely to consume excessive energy. By targeting these areas, developers can make informed decisions to refactor or optimize code, leading to more energy-efficient software. This approach contributes to sustainable software engineering by reducing the energy consumption of software applications, which in turn can lower the overall energy usage of data centers. This method can be scoped specifically to data science domains, ensuring that the analysis is relevant and effective for the specific types of workloads and computations typical in data science projects.","Static code analysis in data science can be used to estimate energy efficiency by identifying potential energy hotspots in the code. This helps in reviewing and optimizing the code to reduce energy consumption. By applying this approach, developers can contribute to the design and maintenance of more energy-efficient data centers, aligning with sustainable software engineering practices.",0.99999999995,0.6666666666666666,0.5714285714285714,0.89,0.14285714265306124,0.9747480087951278
How can static code analysis in data science contribute to the development of more sustainable data centers?,"['‚Ä¢\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy efficiency using static code analysis. \n‚Ä¢ We don‚Äôt need an accurate value. \n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention. \n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27\n\nC7 - Education\n‚Ä¢ Educational game for Software \nSustainability practices \n‚Ä¢ Purpose: use within software teams to \ndiscuss or learn about different sustainable \nIT practices: at the organisation level, \nsoftware, etc.\n28\nhttps://github.com/OttoKaaij/Ticket-To-Sustainability/?tab=readme-ov-file\n\nProject ideas (old)\n‚Ä¢ Plugin from EnergiBridge (GUI, report generator, python library, etc.) \n‚Ä¢ Plugin for ChatGPT (carbon emissions per chat window) \n‚Ä¢ Seamless measurements for AI libraries \n‚Ä¢ Energy patterns for Green AI \n‚Ä¢ Sustainable SW dev gamification \n‚Ä¢ Sustainability auditor for AI projects \n‚Ä¢ Energy Profiling of screen colour filter tools (or display settings) \n‚Ä¢ ‚Ä¶ you can also propose yours!\n\nhttps://edu.nl/64gpk\nedu.nl/64gpk', 'Carbon-free giants\n‚Ä¢ Google, Microsoft, Meta/Facebook want to be carbon free by 2030 \n‚Ä¢ Carbon free is different from carbon neutral \n‚Ä¢ Green IT experts are needed to meet these goals\n23\n\n\nRebound effect*\n‚Ä¢ Energy consumption decreases ‚Üì‚Üì but demand also increases ‚Üë‚Üë. \n‚Ä¢ *a.k.a. Jevons Paradox in economics; Downs‚ÄìThomson paradox in\xa0mobility.\nEnergy per prompt\nPrompts\n100\n80\n30\n38\nChat \nGPT\n‚ÄúEnergy-efficient‚Äù \nChat GPT\n0\n\nIs sustainability an\u2028\nethical issue?\n‚Ä¢ Climate change is more likely to affect the \npoorest countries. \n‚Ä¢ Less financial resources to adapt \n‚Ä¢ Climate-impact does not necessarily affect \npolluting countries. \n‚Ä¢ Poorest countries have contributed less to the \nclimate change. \n‚Ä¢ We need to figure out how to do more using \nless resources.\n26\n\nMorality ‚â† Moralising\n‚Ä¢ We should not use climate action as a \nshaming weapon \n‚Ä¢ Climate action should be agnostic of political \nviews, ideology, social status, etc. \n‚Ä¢ We need everyone to take action!\n27\n\nWhy?\n‚Ä¢ Throughout your career you might: \n‚Ä¢ Design/maintain/contract data centers \n‚Ä¢ Set up operations/devops \n‚Ä¢ Develop AI for IoT devices \n‚Ä¢ Be the next CEO/CTO of a software company \n‚Ä¢ Sustainability can be your main role: \n‚Ä¢ Green Software Developer \n‚Ä¢ Sustainability Consultant \n‚Ä¢ Green Advocate  \n‚Ä¢ Founder of a Green Tech startup (B2B?)\n28\n\nFormat of classes\n‚Ä¢ In-person. \n‚Ä¢ Collegerama recordings. \n‚Ä¢ Lectures and Labs. \n‚Ä¢ Guest lectures. \n‚Ä¢ Steering meetings (after week 5, new schedule)\n29\n\nFormat of classes\n‚Ä¢ There‚Äôs no exam in this course. It‚Äôs more important that we learn how to \ndiscuss this topic and come up with new ideas than learning all the theory. \nCritical thinking over checkboxes. \n‚Ä¢ Mix of content and discussion \n‚Ä¢ Ultimately, the lectures aim to give you food for thought and the necessary \nknowledge to excel in Project 2.']","['<1-hop>\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy eÔ¨Éciency using static code analysis.\n‚Ä¢ We don‚Äôt need an accurate value.\n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.\n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27', '<2-hop>\n\nWhy?\n‚Ä¢ Throughout your career you might:\n‚Ä¢ Design/maintain/contract data centers\n‚Ä¢ Set up operations/devops\n‚Ä¢ Develop AI for IoT devices\n‚Ä¢ Be the next CEO/CTO of a software company\n‚Ä¢ Sustainability can be your main role:\n‚Ä¢ Green Software Developer\n‚Ä¢ Sustainability Consultant\n‚Ä¢ Green Advocate \n‚Ä¢ Founder of a Green Tech startup (B2B?)\n28']","Static code analysis in data science can contribute to the development of more sustainable data centers by estimating energy efficiency. Although it doesn't provide an accurate value, it helps identify which parts of the code are more likely to introduce energy hotspots. By focusing on these areas, developers can optimize code to reduce energy consumption, thereby contributing to the overall sustainability of data centers. This approach allows for targeted improvements in energy efficiency, which is crucial for reducing the carbon footprint of data centers.","Static code analysis in data science can contribute to the development of more sustainable data centers by estimating energy efficiency and identifying potential energy hotspots within the code. This approach allows developers to focus on reviewing code segments that are more likely to introduce inefficiencies, thereby optimizing resource usage. By integrating such practices, especially in domains like data science, developers can help create more sustainable solutions, which aligns with broader career goals in sustainability, such as designing or maintaining energy-efficient data centers.",0.9999999999,1.0,0.625,0.5,0.1999999998,0.9772216761575173
How can static code analysis in data science projects help in designing more sustainablility-focused data centers?,"['data to understand state of software: \nbuildable?, open dev. history?, requirements documentation? \n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!\n\nB7. Queue - but better for the student / TA society\n‚Ä¢ Requirements analysis regarding social and individual sustainability effects \nof Queue \n‚Ä¢ Other EIP / TUD used software also possible: e.g., Answers EWI \n‚Ä¢ Non-technical project ‚Üí proper process (workshops? Interviews?) & rich \ndescription of outcomes focus of grading\nhttps://eip.pages.ewi.tudelft.nl/eip-website/queue.html\n\nC1. Compare energy consumption of docker images for \nML workloads.\n‚Ä¢ Similar to what we have seen in the lectures but for ML-specific workloads. \n‚Ä¢ We can reuse existing experiment replication packages.\n22\n\nC2. Plugin to visualize Hugging Face carbon emissions.\n‚Ä¢ https://huggingface.co/blog/leaderboard-emissions-\nanalysis \n‚Ä¢\nYoo, Taewon, et al. ""Visualizing the Carbon Intensity of Machine Learning Inference for Image Analysis on TensorFlow Hub.""\n\nC3. Plugin for ChatGPT\n‚Ä¢ Users seldom know how much carbon they are emitting when they interact \nwith chat GPT. \n‚Ä¢ Let‚Äôs make it transparent to the users. Browser plugin?\n24\nCO2\n\nC4. NutriScore for software libraries\n25\n‚Ä¢ NutriScore labels are not perfect but they are a good starting point! \n‚Ä¢ What if we could do the same thing for the energy efficiency of software. \n‚Ä¢ (Also open to individual or social sustainability) \n‚Ä¢ This work can be scoped in particular domains/ecossystems/use cases. \n‚Ä¢ Libraries for stats? ML? Web Dev? Cloud?\n\nC5. Add energy-awareness to existing software\n26\n‚Ä¢ Streamlit, Notebooks, JSFiddle, \nPyScript, zsh, etc. \n‚Ä¢\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy efficiency using static code analysis. \n‚Ä¢ We don‚Äôt need an accurate value. \n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention. \n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)', '‚Ä¢\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy efficiency using static code analysis. \n‚Ä¢ We don‚Äôt need an accurate value. \n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention. \n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27\n\nC7 - Education\n‚Ä¢ Educational game for Software \nSustainability practices \n‚Ä¢ Purpose: use within software teams to \ndiscuss or learn about different sustainable \nIT practices: at the organisation level, \nsoftware, etc.\n28\nhttps://github.com/OttoKaaij/Ticket-To-Sustainability/?tab=readme-ov-file\n\nProject ideas (old)\n‚Ä¢ Plugin from EnergiBridge (GUI, report generator, python library, etc.) \n‚Ä¢ Plugin for ChatGPT (carbon emissions per chat window) \n‚Ä¢ Seamless measurements for AI libraries \n‚Ä¢ Energy patterns for Green AI \n‚Ä¢ Sustainable SW dev gamification \n‚Ä¢ Sustainability auditor for AI projects \n‚Ä¢ Energy Profiling of screen colour filter tools (or display settings) \n‚Ä¢ ‚Ä¶ you can also propose yours!\n\nhttps://edu.nl/64gpk\nedu.nl/64gpk']","['<1-hop>\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy eÔ¨Éciency using static code analysis.\n‚Ä¢ We don‚Äôt need an accurate value.\n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.\n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27', '<2-hop>\n\nWhy?\n‚Ä¢ Throughout your career you might:\n‚Ä¢ Design/maintain/contract data centers\n‚Ä¢ Set up operations/devops\n‚Ä¢ Develop AI for IoT devices\n‚Ä¢ Be the next CEO/CTO of a software company\n‚Ä¢ Sustainability can be your main role:\n‚Ä¢ Green Software Developer\n‚Ä¢ Sustainability Consultant\n‚Ä¢ Green Advocate \n‚Ä¢ Founder of a Green Tech startup (B2B?)\n28', '<1-hop>\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy eÔ¨Éciency using static code analysis.\n‚Ä¢ We don‚Äôt need an accurate value.\n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.\n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27', '<2-hop>\n\nWhy?\n‚Ä¢ Throughout your career you might:\n‚Ä¢ Design/maintain/contract data centers\n‚Ä¢ Set up operations/devops\n‚Ä¢ Develop AI for IoT devices\n‚Ä¢ Be the next CEO/CTO of a software company\n‚Ä¢ Sustainability can be your main role:\n‚Ä¢ Green Software Developer\n‚Ä¢ Sustainability Consultant\n‚Ä¢ Green Advocate \n‚Ä¢ Founder of a Green Tech startup (B2B?)\n28', '<1-hop>\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy eÔ¨Éciency using static code analysis.\n‚Ä¢ We don‚Äôt need an accurate value.\n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.\n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27', '<2-hop>\n\nWhy?\n‚Ä¢ Throughout your career you might:\n‚Ä¢ Design/maintain/contract data centers\n‚Ä¢ Set up operations/devops\n‚Ä¢ Develop AI for IoT devices\n‚Ä¢ Be the next CEO/CTO of a software company\n‚Ä¢ Sustainability can be your main role:\n‚Ä¢ Green Software Developer\n‚Ä¢ Sustainability Consultant\n‚Ä¢ Green Advocate \n‚Ä¢ Founder of a Green Tech startup (B2B?)\n28']","Static code analysis in data science projects can help in designing more sustainability-focused data centers by identifying code that is likely to introduce energy hotspots. By analyzing the code statically, developers can estimate energy efficiency and pinpoint areas that may require optimization to reduce energy consumption. This proactive approach allows for more efficient use of resources, leading to reduced energy usage in data centers. By focusing on optimizing code for energy efficiency, data centers can operate more sustainably, minimizing their carbon footprint and overall environmental impact. This process can be scoped to particular domains such as data science, ensuring that the specific needs and characteristics of these projects are taken into account.","Static code analysis in data science projects can help in designing more sustainablility-focused data centers by identifying energy hotspots in the code. This allows developers to review and optimize code that may contribute to higher energy consumption, thereby supporting the development of more efficient and sustainable data centers.",0.99999999995,1.0,0.4444444444444444,1.0,0.0,0.9693034754686899
How does the use of static code analysis in data science projects contribute to the design and optimization of more sustanable data centers?,"['Carbon-free giants\n‚Ä¢ Google, Microsoft, Meta/Facebook want to be carbon free by 2030 \n‚Ä¢ Carbon free is different from carbon neutral \n‚Ä¢ Green IT experts are needed to meet these goals\n23\n\n\nRebound effect*\n‚Ä¢ Energy consumption decreases ‚Üì‚Üì but demand also increases ‚Üë‚Üë. \n‚Ä¢ *a.k.a. Jevons Paradox in economics; Downs‚ÄìThomson paradox in\xa0mobility.\nEnergy per prompt\nPrompts\n100\n80\n30\n38\nChat \nGPT\n‚ÄúEnergy-efficient‚Äù \nChat GPT\n0\n\nIs sustainability an\u2028\nethical issue?\n‚Ä¢ Climate change is more likely to affect the \npoorest countries. \n‚Ä¢ Less financial resources to adapt \n‚Ä¢ Climate-impact does not necessarily affect \npolluting countries. \n‚Ä¢ Poorest countries have contributed less to the \nclimate change. \n‚Ä¢ We need to figure out how to do more using \nless resources.\n26\n\nMorality ‚â† Moralising\n‚Ä¢ We should not use climate action as a \nshaming weapon \n‚Ä¢ Climate action should be agnostic of political \nviews, ideology, social status, etc. \n‚Ä¢ We need everyone to take action!\n27\n\nWhy?\n‚Ä¢ Throughout your career you might: \n‚Ä¢ Design/maintain/contract data centers \n‚Ä¢ Set up operations/devops \n‚Ä¢ Develop AI for IoT devices \n‚Ä¢ Be the next CEO/CTO of a software company \n‚Ä¢ Sustainability can be your main role: \n‚Ä¢ Green Software Developer \n‚Ä¢ Sustainability Consultant \n‚Ä¢ Green Advocate  \n‚Ä¢ Founder of a Green Tech startup (B2B?)\n28\n\nFormat of classes\n‚Ä¢ In-person. \n‚Ä¢ Collegerama recordings. \n‚Ä¢ Lectures and Labs. \n‚Ä¢ Guest lectures. \n‚Ä¢ Steering meetings (after week 5, new schedule)\n29\n\nFormat of classes\n‚Ä¢ There‚Äôs no exam in this course. It‚Äôs more important that we learn how to \ndiscuss this topic and come up with new ideas than learning all the theory. \nCritical thinking over checkboxes. \n‚Ä¢ Mix of content and discussion \n‚Ä¢ Ultimately, the lectures aim to give you food for thought and the necessary \nknowledge to excel in Project 2.', '‚Ä¢\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy efficiency using static code analysis. \n‚Ä¢ We don‚Äôt need an accurate value. \n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention. \n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27\n\nC7 - Education\n‚Ä¢ Educational game for Software \nSustainability practices \n‚Ä¢ Purpose: use within software teams to \ndiscuss or learn about different sustainable \nIT practices: at the organisation level, \nsoftware, etc.\n28\nhttps://github.com/OttoKaaij/Ticket-To-Sustainability/?tab=readme-ov-file\n\nProject ideas (old)\n‚Ä¢ Plugin from EnergiBridge (GUI, report generator, python library, etc.) \n‚Ä¢ Plugin for ChatGPT (carbon emissions per chat window) \n‚Ä¢ Seamless measurements for AI libraries \n‚Ä¢ Energy patterns for Green AI \n‚Ä¢ Sustainable SW dev gamification \n‚Ä¢ Sustainability auditor for AI projects \n‚Ä¢ Energy Profiling of screen colour filter tools (or display settings) \n‚Ä¢ ‚Ä¶ you can also propose yours!\n\nhttps://edu.nl/64gpk\nedu.nl/64gpk']","['<1-hop>\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy eÔ¨Éciency using static code analysis.\n‚Ä¢ We don‚Äôt need an accurate value.\n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.\n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27', '<2-hop>\n\nWhy?\n‚Ä¢ Throughout your career you might:\n‚Ä¢ Design/maintain/contract data centers\n‚Ä¢ Set up operations/devops\n‚Ä¢ Develop AI for IoT devices\n‚Ä¢ Be the next CEO/CTO of a software company\n‚Ä¢ Sustainability can be your main role:\n‚Ä¢ Green Software Developer\n‚Ä¢ Sustainability Consultant\n‚Ä¢ Green Advocate \n‚Ä¢ Founder of a Green Tech startup (B2B?)\n28', '<1-hop>\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy eÔ¨Éciency using static code analysis.\n‚Ä¢ We don‚Äôt need an accurate value.\n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.\n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27', '<2-hop>\n\nWhy?\n‚Ä¢ Throughout your career you might:\n‚Ä¢ Design/maintain/contract data centers\n‚Ä¢ Set up operations/devops\n‚Ä¢ Develop AI for IoT devices\n‚Ä¢ Be the next CEO/CTO of a software company\n‚Ä¢ Sustainability can be your main role:\n‚Ä¢ Green Software Developer\n‚Ä¢ Sustainability Consultant\n‚Ä¢ Green Advocate \n‚Ä¢ Founder of a Green Tech startup (B2B?)\n28']","The use of static code analysis in data science projects helps estimate energy efficiency by identifying code that is likely to introduce energy hotspots. By reviewing and optimizing such code, data centers can reduce energy consumption, contributing to more sustainable operations. This process allows for targeted improvements in energy efficiency without needing precise energy values, thus supporting the design and optimization of more sustainable data centers.","The use of static code analysis in data science projects contributes to the design and optimization of more sustainable data centers by identifying energy hotspots within the code. This process allows developers to focus on reviewing and optimizing sections of code that are more likely to introduce energy inefficiencies. By doing so, it supports the broader goal of creating more energy-efficient systems, which is crucial for the sustainable operation of data centers. This approach aligns with the growing need for green software development practices, where professionals can play roles such as green software developers or sustainability consultants, ensuring that energy efficiency is a key consideration throughout the software lifecycle.",0.49999999995,1.0,0.5,0.73,0.0,0.9453024925655987
How reduce risk and reduce size in software engineering?,"['‚Ä¢ Opt for low-power hardware (e.g., Nvidia Jetson boards) \n‚Ä¢ Or GPUs that provide energy metrics (e.g., NVIDIA GPUs via the nvidia-smi tool) \n‚Ä¢ Report energy/carbon metrics (e.g., embed in MLFlow?) \n‚Ä¢ Use pre-trained models (Transfer Learning) \n‚Ä¢ Preprocess dataset to reduce size. \n‚Ä¢ Improve parameter-tuning strategy.\n11\n\nReporting energy/carbon footprint\n‚Ä¢ We need benchmarks. \n‚Ä¢ AllenAI leaderboard\u2028\nhttps://leaderboard.allenai.org \n‚Ä¢ No carbon metrics, yet \n‚Ä¢ Report comparable proxies for energy \nconsumption. \n‚Ä¢ ‚ö† Learning algorithms behave in a non-\ndeterministic \n‚Ä¢ ‚ö† Different data-points lead to different \nenergy consumption\n12\n\nReporting energy/carbon footprint\n‚Ä¢ Reporting measured energy consumption \n‚Ä¢ + Accurate \n‚Ä¢ + Easy to map to carbon emissions \n‚Ä¢ - Hard to measure \n‚Ä¢ - Low replicability \n‚Ä¢ Reporting time / estimation based on time & hardware \n‚Ä¢ + Easy to measure \n‚Ä¢ + Correlates with energy consumption in most cases. \n‚Ä¢ -  Difficult to compare with measurements from other setups \n‚Ä¢ E.g., floating point operations (FPOs) (?) \n‚Ä¢ + comparable across different setups \n‚Ä¢ + cheap \n‚Ä¢ - does not factor in memory energy consumption \n‚Ä¢ - does not reflect carbon emissions\n13\n\nData-centric AI\n\nData-centric AI\n‚Ä¢ Emerging discipline that deals with systematically engineering data to build AI \nsystems. \n‚Ä¢ Shift from improving the training strategy to improving the data. \n‚Ä¢ It is better to have small but reliable datasets than large but noisy \ndatasets. \n‚Ä¢ => Improve data collection, data labelling, and data preprocessing. \n‚Ä¢ More about data-centric AI by Andrew Ng:\u2028\nhttps://www.youtube.com/watch?v=06-AZXmwHjo\n15\n\n\nGreen Data-centric AI\n‚Ä¢ How do different ML algorithms compare \nin terms of energy consumption? \n‚Ä¢ How does number of rows relate to the \nenergy consumption of ML models? \n‚Ä¢ How does number of features relate to \nthe energy consumption of ML models? \n‚Ä¢ What is the impact of reducing data in the \nperformance of the model? \n‚Ä¢ Method -> results -> discussion\n17\n\nMethod\n‚Ä¢ Single object of study: natural language model to detect spam messages.', 'Rest ‚è∏\n‚Ä¢ It is common practice to do a pause/sleep between executions/\nmeasurements. \n‚Ä¢ Prevent tail energy consumption from previous measurements. ? \n‚Ä¢ Prevent collateral tasks of previous measurement from affecting the next \nmeasurement. \n‚Ä¢ There is no golden rule but one minute should be enough. It can be more or \nless depending on your hardware or the duration of your energy test.\n9\n\nt\nP\nTail Energy Consumption\n\nShuffle üîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them. \n‚Ä¢ If you run 30 executions for version A and another batch for version B: \n‚Ä¢ External conditions that change over time will have a different bias in \nthe 2 versions (e.g., room temperature changes). \n‚Ä¢ If you shuffle, you reduce this risk.\n11\n\nKeep it cool üå°\n‚Ä¢ Always make sure there is a stable room temperature. \n‚Ä¢ Tricky because, some times, experiments may have to run over a few days. \n‚Ä¢ If you cannot control room temperature: collect temperature data and filter \nout measurements where the room temperature is clearly deviating.\n12\n\nAutomate Executions ü§ñ\n‚Ä¢ (Already mentioned in the previous classes) \n‚Ä¢ One cannot run 30 shuffled experiments per version without automation‚Ä¶\n13\n\nData analysis\n14\n\n1. Exploratory Analysis\n‚Ä¢ Plot the data and inspect outliers or \nunexpected biases. \n‚Ä¢ Violin+box plots are usually handy. (?) \n‚Ä¢ It‚Äôs a nice way of combining the 30 \nexperiments, and of showing \ndescriptive statistics. (?) \n‚Ä¢ Shows the shape of the distribution \nof the data.\n15\n\n1. Exploratory Analysis (II)\n‚Ä¢ Data should be Normal. Unless there‚Äôs a \ngood reason. \n‚Ä¢ E.g., somewhere amongst the 30 executions, \nthere might be 1 or 2 that failed to finish due \nto some unexpected error. \n‚Ä¢ (It happens and that‚Äôs ok!)‚Äì consequently, \nthe execution is shorter and spends less \nenergy ‚Äì falsely appearing as more \nenergy efficient. \n‚Ä¢ If data is not Normal there might be some \nissues affecting the measurements that \nmight be ruining results. It is important to \ninvestigate this.\n16\n\nEnergy data is not normal. Why?']","['<1-hop>\n\nShuffle \nüîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them.\n‚Ä¢ If you run 30 executions for version A and another batch for version B:\n‚Ä¢ External conditions that change over time will have a diÔ¨Äerent bias in \nthe 2 versions (e.g., room temperature changes).\n‚Ä¢ If you shuÔ¨Ñe, you reduce this risk.\n11', '<2-hop>\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio)\n‚Ä¢ Dynamic Retry Delay\n‚Ä¢ Push Over Poll\n‚Ä¢ Reduce Size\n‚Ä¢ Cache\n‚Ä¢ Avoid Graphics and Animations\n20', '<1-hop>\n\nShuffle \nüîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them.\n‚Ä¢ If you run 30 executions for version A and another batch for version B:\n‚Ä¢ External conditions that change over time will have a diÔ¨Äerent bias in \nthe 2 versions (e.g., room temperature changes).\n‚Ä¢ If you shuÔ¨Ñe, you reduce this risk.\n11', '<2-hop>\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio)\n‚Ä¢ Dynamic Retry Delay\n‚Ä¢ Push Over Poll\n‚Ä¢ Reduce Size\n‚Ä¢ Cache\n‚Ä¢ Avoid Graphics and Animations\n20']","To reduce risk and reduce size in software engineering, consider the following strategies:

1. **Opt for Low-Power Hardware**: Use energy-efficient hardware like Nvidia Jetson boards or GPUs that provide energy metrics, which can help in reducing the energy footprint and potentially the size of the hardware setup.

2. **Use Pre-trained Models (Transfer Learning)**: This approach can reduce the size of the training dataset needed and the computational resources required, thereby minimizing risk and resource consumption.

3. **Preprocess Dataset to Reduce Size**: By preprocessing the dataset, you can eliminate unnecessary data, which reduces the size and complexity of the data, leading to more efficient processing and reduced risk of errors.

4. **Improve Parameter-Tuning Strategy**: Efficient parameter tuning can lead to better model performance with less computational overhead, reducing both risk and resource usage.

5. **Data-Centric AI**: Focus on improving data quality rather than just the training strategy. Reliable, smaller datasets are preferable to large, noisy ones, reducing the risk of errors and inefficiencies.

6. **Automate Executions**: Automation can help manage and reduce the risk of human error in repetitive tasks, ensuring consistency and efficiency.

7. **Shuffle and Control External Conditions**: Shuffling experiments and controlling external conditions like room temperature can help reduce biases and risks associated with environmental factors.

These strategies collectively help in managing risk and reducing the size and complexity of software engineering projects.","To reduce risk, shuffling executions helps control external factors like temperature changes. To reduce size, EcoAndroid uses features like dynamic retry delay and push over poll.",0.0,0.5,0.7647058823529411,0.36,0.0,0.980885315377629
How shuffling reduce risk and EcoAndroid reduce size?,"['Rest ‚è∏\n‚Ä¢ It is common practice to do a pause/sleep between executions/\nmeasurements. \n‚Ä¢ Prevent tail energy consumption from previous measurements. ? \n‚Ä¢ Prevent collateral tasks of previous measurement from affecting the next \nmeasurement. \n‚Ä¢ There is no golden rule but one minute should be enough. It can be more or \nless depending on your hardware or the duration of your energy test.\n9\n\nt\nP\nTail Energy Consumption\n\nShuffle üîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them. \n‚Ä¢ If you run 30 executions for version A and another batch for version B: \n‚Ä¢ External conditions that change over time will have a different bias in \nthe 2 versions (e.g., room temperature changes). \n‚Ä¢ If you shuffle, you reduce this risk.\n11\n\nKeep it cool üå°\n‚Ä¢ Always make sure there is a stable room temperature. \n‚Ä¢ Tricky because, some times, experiments may have to run over a few days. \n‚Ä¢ If you cannot control room temperature: collect temperature data and filter \nout measurements where the room temperature is clearly deviating.\n12\n\nAutomate Executions ü§ñ\n‚Ä¢ (Already mentioned in the previous classes) \n‚Ä¢ One cannot run 30 shuffled experiments per version without automation‚Ä¶\n13\n\nData analysis\n14\n\n1. Exploratory Analysis\n‚Ä¢ Plot the data and inspect outliers or \nunexpected biases. \n‚Ä¢ Violin+box plots are usually handy. (?) \n‚Ä¢ It‚Äôs a nice way of combining the 30 \nexperiments, and of showing \ndescriptive statistics. (?) \n‚Ä¢ Shows the shape of the distribution \nof the data.\n15\n\n1. Exploratory Analysis (II)\n‚Ä¢ Data should be Normal. Unless there‚Äôs a \ngood reason. \n‚Ä¢ E.g., somewhere amongst the 30 executions, \nthere might be 1 or 2 that failed to finish due \nto some unexpected error. \n‚Ä¢ (It happens and that‚Äôs ok!)‚Äì consequently, \nthe execution is shorter and spends less \nenergy ‚Äì falsely appearing as more \nenergy efficient. \n‚Ä¢ If data is not Normal there might be some \nissues affecting the measurements that \nmight be ruining results. It is important to \ninvestigate this.\n16\n\nEnergy data is not normal. Why?', '‚Ä¢ Some users noticed that K-9 mail was spending more energy than usual. üôâ \n‚Ä¢ A user that was having issues with a personal mail server  noticed that K-9 \nmail was the one of the most energy-greedy apps. IMAP IDLE protocol for real-time \nnotifications. \n‚Ä¢ When a connection is not possible, the app automatically retries later. \n‚Ä¢ https://github.com/k9mail/k-9/commit/\n86f3b28f79509d1a4d613eb39f60603e08579ea3\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio) \n‚Ä¢ Dynamic Retry Delay \n‚Ä¢ Push Over Poll \n‚Ä¢ Reduce Size \n‚Ä¢ Cache \n‚Ä¢ Avoid Graphics and Animations\n20\n\nCarbon-Aware Computing for \nDatacenters \nhttps://sites.google.com/view/energy-efficiency-languages\n21\nAna Radovanovic ÃÅ, Ross Koningstein, Ian Schneider, Bokan \nChen, Alexandre Duarte, Binz Roy, Diyue Xiao, Maya \nHaridasan, Patrick Hung, Nick Care, Saurav Talukdar, Eric \nMullen, Kendal Smith, MariEllen Cottman, and Walfredo Cirne \n\n\n‚Ä¢ Google‚Äôs Carbon-Intelligent Computing System (CICS) \n‚Ä¢ Main idea: use carbon-intensity data to shift datacenter jobs in time \n‚Ä¢ Typically, job schedulers use a metric of cluster capacity to schedule a job in \na particular cluster. \n‚Ä¢ CICS overrides this metric with the virtual capacity curve (VCC) that \nfactors in Carbon intensity \n‚Ä¢ When a new job comes in, the scheduler estimates its CPU load and power \nusage and assigns it to a cluster if the VCC is not exceeded.\n23\n\n‚Ä¢ Jobs are divided between flexible and inflexible. \n‚Ä¢ Flexible load is considered shapeable/shiftable as long as its total daily \ncompute (CPU) demand is preserved \n‚Ä¢ The system needs to consider that, while running a job, the virtual capacity \ncurve (VCC) might drop. Hence, this job should not start in the first place. \n‚Ä¢ They forecast VCC for the next day\n24\n\n\nVirtual Cluster Capacity (VCC)\n‚Ä¢ Aims at reducing the peak load at carbon intensive hours but in total it should allow for the \nsome amount of daily computation!']","['<1-hop>\n\nShuffle \nüîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them.\n‚Ä¢ If you run 30 executions for version A and another batch for version B:\n‚Ä¢ External conditions that change over time will have a diÔ¨Äerent bias in \nthe 2 versions (e.g., room temperature changes).\n‚Ä¢ If you shuÔ¨Ñe, you reduce this risk.\n11', '<2-hop>\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio)\n‚Ä¢ Dynamic Retry Delay\n‚Ä¢ Push Over Poll\n‚Ä¢ Reduce Size\n‚Ä¢ Cache\n‚Ä¢ Avoid Graphics and Animations\n20', '<1-hop>\n\nShuffle \nüîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them.\n‚Ä¢ If you run 30 executions for version A and another batch for version B:\n‚Ä¢ External conditions that change over time will have a diÔ¨Äerent bias in \nthe 2 versions (e.g., room temperature changes).\n‚Ä¢ If you shuÔ¨Ñe, you reduce this risk.\n11', '<2-hop>\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio)\n‚Ä¢ Dynamic Retry Delay\n‚Ä¢ Push Over Poll\n‚Ä¢ Reduce Size\n‚Ä¢ Cache\n‚Ä¢ Avoid Graphics and Animations\n20', '<1-hop>\n\nShuffle \nüîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them.\n‚Ä¢ If you run 30 executions for version A and another batch for version B:\n‚Ä¢ External conditions that change over time will have a diÔ¨Äerent bias in \nthe 2 versions (e.g., room temperature changes).\n‚Ä¢ If you shuÔ¨Ñe, you reduce this risk.\n11', '<2-hop>\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio)\n‚Ä¢ Dynamic Retry Delay\n‚Ä¢ Push Over Poll\n‚Ä¢ Reduce Size\n‚Ä¢ Cache\n‚Ä¢ Avoid Graphics and Animations\n20']","Shuffling reduces risk by minimizing the impact of external conditions that can change over time, such as room temperature, which might introduce bias into the results of different versions of an experiment. By shuffling the order of executions, you ensure that these external factors are more evenly distributed across all versions, thus reducing the risk of skewed results (Source: Shuffle üîÄ).

EcoAndroid reduces size by implementing strategies such as dynamic retry delay, push over poll, and caching, which help to optimize the app's operations and reduce unnecessary resource usage, thereby reducing the overall size and energy consumption of the app (Source: EcoAndroid).",Shuffling reduce risk by controlling external factors like room temperature changes. EcoAndroid reduce size by using features like caching and avoiding graphics and animations.,,1.0,0.875,0.33,0.16666666638888888,0.9304180701708167
How shuffling reduce risk when compare to EcoAndroid reduce size?,"['Rest ‚è∏\n‚Ä¢ It is common practice to do a pause/sleep between executions/\nmeasurements. \n‚Ä¢ Prevent tail energy consumption from previous measurements. ? \n‚Ä¢ Prevent collateral tasks of previous measurement from affecting the next \nmeasurement. \n‚Ä¢ There is no golden rule but one minute should be enough. It can be more or \nless depending on your hardware or the duration of your energy test.\n9\n\nt\nP\nTail Energy Consumption\n\nShuffle üîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them. \n‚Ä¢ If you run 30 executions for version A and another batch for version B: \n‚Ä¢ External conditions that change over time will have a different bias in \nthe 2 versions (e.g., room temperature changes). \n‚Ä¢ If you shuffle, you reduce this risk.\n11\n\nKeep it cool üå°\n‚Ä¢ Always make sure there is a stable room temperature. \n‚Ä¢ Tricky because, some times, experiments may have to run over a few days. \n‚Ä¢ If you cannot control room temperature: collect temperature data and filter \nout measurements where the room temperature is clearly deviating.\n12\n\nAutomate Executions ü§ñ\n‚Ä¢ (Already mentioned in the previous classes) \n‚Ä¢ One cannot run 30 shuffled experiments per version without automation‚Ä¶\n13\n\nData analysis\n14\n\n1. Exploratory Analysis\n‚Ä¢ Plot the data and inspect outliers or \nunexpected biases. \n‚Ä¢ Violin+box plots are usually handy. (?) \n‚Ä¢ It‚Äôs a nice way of combining the 30 \nexperiments, and of showing \ndescriptive statistics. (?) \n‚Ä¢ Shows the shape of the distribution \nof the data.\n15\n\n1. Exploratory Analysis (II)\n‚Ä¢ Data should be Normal. Unless there‚Äôs a \ngood reason. \n‚Ä¢ E.g., somewhere amongst the 30 executions, \nthere might be 1 or 2 that failed to finish due \nto some unexpected error. \n‚Ä¢ (It happens and that‚Äôs ok!)‚Äì consequently, \nthe execution is shorter and spends less \nenergy ‚Äì falsely appearing as more \nenergy efficient. \n‚Ä¢ If data is not Normal there might be some \nissues affecting the measurements that \nmight be ruining results. It is important to \ninvestigate this.\n16\n\nEnergy data is not normal. Why?', '‚Ä¢ Some users noticed that K-9 mail was spending more energy than usual. üôâ \n‚Ä¢ A user that was having issues with a personal mail server  noticed that K-9 \nmail was the one of the most energy-greedy apps. IMAP IDLE protocol for real-time \nnotifications. \n‚Ä¢ When a connection is not possible, the app automatically retries later. \n‚Ä¢ https://github.com/k9mail/k-9/commit/\n86f3b28f79509d1a4d613eb39f60603e08579ea3\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio) \n‚Ä¢ Dynamic Retry Delay \n‚Ä¢ Push Over Poll \n‚Ä¢ Reduce Size \n‚Ä¢ Cache \n‚Ä¢ Avoid Graphics and Animations\n20\n\nCarbon-Aware Computing for \nDatacenters \nhttps://sites.google.com/view/energy-efficiency-languages\n21\nAna Radovanovic ÃÅ, Ross Koningstein, Ian Schneider, Bokan \nChen, Alexandre Duarte, Binz Roy, Diyue Xiao, Maya \nHaridasan, Patrick Hung, Nick Care, Saurav Talukdar, Eric \nMullen, Kendal Smith, MariEllen Cottman, and Walfredo Cirne \n\n\n‚Ä¢ Google‚Äôs Carbon-Intelligent Computing System (CICS) \n‚Ä¢ Main idea: use carbon-intensity data to shift datacenter jobs in time \n‚Ä¢ Typically, job schedulers use a metric of cluster capacity to schedule a job in \na particular cluster. \n‚Ä¢ CICS overrides this metric with the virtual capacity curve (VCC) that \nfactors in Carbon intensity \n‚Ä¢ When a new job comes in, the scheduler estimates its CPU load and power \nusage and assigns it to a cluster if the VCC is not exceeded.\n23\n\n‚Ä¢ Jobs are divided between flexible and inflexible. \n‚Ä¢ Flexible load is considered shapeable/shiftable as long as its total daily \ncompute (CPU) demand is preserved \n‚Ä¢ The system needs to consider that, while running a job, the virtual capacity \ncurve (VCC) might drop. Hence, this job should not start in the first place. \n‚Ä¢ They forecast VCC for the next day\n24\n\n\nVirtual Cluster Capacity (VCC)\n‚Ä¢ Aims at reducing the peak load at carbon intensive hours but in total it should allow for the \nsome amount of daily computation!']","['<1-hop>\n\nShuffle \nüîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them.\n‚Ä¢ If you run 30 executions for version A and another batch for version B:\n‚Ä¢ External conditions that change over time will have a diÔ¨Äerent bias in \nthe 2 versions (e.g., room temperature changes).\n‚Ä¢ If you shuÔ¨Ñe, you reduce this risk.\n11', '<2-hop>\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio)\n‚Ä¢ Dynamic Retry Delay\n‚Ä¢ Push Over Poll\n‚Ä¢ Reduce Size\n‚Ä¢ Cache\n‚Ä¢ Avoid Graphics and Animations\n20']","Shuffling reduces risk by minimizing the impact of external conditions that change over time, such as room temperature, which can introduce bias in energy consumption measurements when comparing different versions of software. By shuffling the order of executions, you ensure that these external factors affect both versions more evenly, thus reducing the risk of biased results.

On the other hand, EcoAndroid's approach to reducing size is focused on optimizing the app itself to consume less energy. This involves techniques like dynamic retry delay, push over poll, and caching, which directly aim to make the app more energy-efficient.

In summary, shuffling is a method to ensure fair comparison by controlling external variables, while reducing size in EcoAndroid is a direct optimization strategy to lower energy consumption.",Shuffling reduce risk by balance external factor like room temperature change while EcoAndroid reduce size by optimize resource use.,0.0,0.5,0.7777777777777778,0.36,0.3333333322222222,0.9342609130453754
How shuffling reduce risk when reduce size in software engineering?,"['Rest ‚è∏\n‚Ä¢ It is common practice to do a pause/sleep between executions/\nmeasurements. \n‚Ä¢ Prevent tail energy consumption from previous measurements. ? \n‚Ä¢ Prevent collateral tasks of previous measurement from affecting the next \nmeasurement. \n‚Ä¢ There is no golden rule but one minute should be enough. It can be more or \nless depending on your hardware or the duration of your energy test.\n9\n\nt\nP\nTail Energy Consumption\n\nShuffle üîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them. \n‚Ä¢ If you run 30 executions for version A and another batch for version B: \n‚Ä¢ External conditions that change over time will have a different bias in \nthe 2 versions (e.g., room temperature changes). \n‚Ä¢ If you shuffle, you reduce this risk.\n11\n\nKeep it cool üå°\n‚Ä¢ Always make sure there is a stable room temperature. \n‚Ä¢ Tricky because, some times, experiments may have to run over a few days. \n‚Ä¢ If you cannot control room temperature: collect temperature data and filter \nout measurements where the room temperature is clearly deviating.\n12\n\nAutomate Executions ü§ñ\n‚Ä¢ (Already mentioned in the previous classes) \n‚Ä¢ One cannot run 30 shuffled experiments per version without automation‚Ä¶\n13\n\nData analysis\n14\n\n1. Exploratory Analysis\n‚Ä¢ Plot the data and inspect outliers or \nunexpected biases. \n‚Ä¢ Violin+box plots are usually handy. (?) \n‚Ä¢ It‚Äôs a nice way of combining the 30 \nexperiments, and of showing \ndescriptive statistics. (?) \n‚Ä¢ Shows the shape of the distribution \nof the data.\n15\n\n1. Exploratory Analysis (II)\n‚Ä¢ Data should be Normal. Unless there‚Äôs a \ngood reason. \n‚Ä¢ E.g., somewhere amongst the 30 executions, \nthere might be 1 or 2 that failed to finish due \nto some unexpected error. \n‚Ä¢ (It happens and that‚Äôs ok!)‚Äì consequently, \nthe execution is shorter and spends less \nenergy ‚Äì falsely appearing as more \nenergy efficient. \n‚Ä¢ If data is not Normal there might be some \nissues affecting the measurements that \nmight be ruining results. It is important to \ninvestigate this.\n16\n\nEnergy data is not normal. Why?', '‚Ä¢ Opt for low-power hardware (e.g., Nvidia Jetson boards) \n‚Ä¢ Or GPUs that provide energy metrics (e.g., NVIDIA GPUs via the nvidia-smi tool) \n‚Ä¢ Report energy/carbon metrics (e.g., embed in MLFlow?) \n‚Ä¢ Use pre-trained models (Transfer Learning) \n‚Ä¢ Preprocess dataset to reduce size. \n‚Ä¢ Improve parameter-tuning strategy.\n11\n\nReporting energy/carbon footprint\n‚Ä¢ We need benchmarks. \n‚Ä¢ AllenAI leaderboard\u2028\nhttps://leaderboard.allenai.org \n‚Ä¢ No carbon metrics, yet \n‚Ä¢ Report comparable proxies for energy \nconsumption. \n‚Ä¢ ‚ö† Learning algorithms behave in a non-\ndeterministic \n‚Ä¢ ‚ö† Different data-points lead to different \nenergy consumption\n12\n\nReporting energy/carbon footprint\n‚Ä¢ Reporting measured energy consumption \n‚Ä¢ + Accurate \n‚Ä¢ + Easy to map to carbon emissions \n‚Ä¢ - Hard to measure \n‚Ä¢ - Low replicability \n‚Ä¢ Reporting time / estimation based on time & hardware \n‚Ä¢ + Easy to measure \n‚Ä¢ + Correlates with energy consumption in most cases. \n‚Ä¢ -  Difficult to compare with measurements from other setups \n‚Ä¢ E.g., floating point operations (FPOs) (?) \n‚Ä¢ + comparable across different setups \n‚Ä¢ + cheap \n‚Ä¢ - does not factor in memory energy consumption \n‚Ä¢ - does not reflect carbon emissions\n13\n\nData-centric AI\n\nData-centric AI\n‚Ä¢ Emerging discipline that deals with systematically engineering data to build AI \nsystems. \n‚Ä¢ Shift from improving the training strategy to improving the data. \n‚Ä¢ It is better to have small but reliable datasets than large but noisy \ndatasets. \n‚Ä¢ => Improve data collection, data labelling, and data preprocessing. \n‚Ä¢ More about data-centric AI by Andrew Ng:\u2028\nhttps://www.youtube.com/watch?v=06-AZXmwHjo\n15\n\n\nGreen Data-centric AI\n‚Ä¢ How do different ML algorithms compare \nin terms of energy consumption? \n‚Ä¢ How does number of rows relate to the \nenergy consumption of ML models? \n‚Ä¢ How does number of features relate to \nthe energy consumption of ML models? \n‚Ä¢ What is the impact of reducing data in the \nperformance of the model? \n‚Ä¢ Method -> results -> discussion\n17\n\nMethod\n‚Ä¢ Single object of study: natural language model to detect spam messages.']","['<1-hop>\n\nShuffle \nüîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them.\n‚Ä¢ If you run 30 executions for version A and another batch for version B:\n‚Ä¢ External conditions that change over time will have a diÔ¨Äerent bias in \nthe 2 versions (e.g., room temperature changes).\n‚Ä¢ If you shuÔ¨Ñe, you reduce this risk.\n11', '<2-hop>\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio)\n‚Ä¢ Dynamic Retry Delay\n‚Ä¢ Push Over Poll\n‚Ä¢ Reduce Size\n‚Ä¢ Cache\n‚Ä¢ Avoid Graphics and Animations\n20', '<1-hop>\n\nShuffle \nüîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them.\n‚Ä¢ If you run 30 executions for version A and another batch for version B:\n‚Ä¢ External conditions that change over time will have a diÔ¨Äerent bias in \nthe 2 versions (e.g., room temperature changes).\n‚Ä¢ If you shuÔ¨Ñe, you reduce this risk.\n11', '<2-hop>\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio)\n‚Ä¢ Dynamic Retry Delay\n‚Ä¢ Push Over Poll\n‚Ä¢ Reduce Size\n‚Ä¢ Cache\n‚Ä¢ Avoid Graphics and Animations\n20']","Shuffling reduces risk in software engineering experiments by minimizing the bias introduced by external conditions that change over time. For example, if you run multiple executions for different versions of a software, external factors like room temperature can vary and affect the results. By shuffling the order of these executions, you reduce the likelihood that these external factors will consistently bias one version over another, leading to more reliable and unbiased results.","Shuffling reduce risk by controlling external factors like room temperature changes, which help in reducing size in software engineering.",0.0,0.0,1.0,0.75,0.0,0.929020175600165
How spiking neural networks relate to McCulloch-Pitts model?,"[""Neuromorphic computing\nCS4575\nSustainable Software Engineering\n05.03.2025\nNergis T√∂men\n\nIntroduction\nComputer Vision Lab\nBiomorphic Intelligence Lab\nBiomedical Intervention Optimisation Lab\nNergis\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing\n\nHow many of you are familiar \nwith neural networks?\n\nSimple model of an artificial neuron\nhttps://medium.com/@cprasenjit32/perceptron-a-simple-yet-mighty-machine-learning-algorithm-9ff6b7d86a71\n\nWhat is a neural network?\nhttps://www.tibco.com/reference-center/what-is-a-neural-network\n\nWhy is it called a 'neural network'?\nhttps://www.tibco.com/reference-center/what-is-a-neural-network\n\nWhat is a neural network?\nWhy is it called a 'neural network'?\nMcCulloch-Pitts neuron [1, 2] (1943)\nWarren Sturgis McCulloch\n(Neurophysiologist)\nWalter Pitts\n(Logician)\n\nHow do biological neurons work?\nhttps://commons.wikimedia.org/wiki/File:Coincidence_detection_in_dendrites_of_pyramidal_neurons.gif\n'Input current' travels down the dendrites (top),\nget integrated (summed!) in the cell body\nwhich generates an 'output current' (bottom)\nwhich is chemically transmitted to the dendrites of \nother neurons.\n\nSimplified picture\nReal neuron\nArtificial neuron\nhttps://vajiramandravi.com/quest-upsc-notes/artificial-neural-network/\n\nWhat is a neural network?\nMcCulloch-Pitts neuron [1, 2]\n1940s: How do biological neurons compute basic \nlogic functions? (e.g. logic gates)\nNote: Ref. [3] gives a nice brief history on the ideas which lead to the \nMcCulloch-Pitts neuron.\n\nWhat is a neural network?"", 'How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \n(not publicly available) doi:10.1037/h0042519\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience.']","[""<1-hop>\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant"", '<2-hop>\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \n(not publicly available) doi:10.1037/h0042519\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568', ""<1-hop>\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant"", '<2-hop>\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \n(not publicly available) doi:10.1037/h0042519\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568', ""<1-hop>\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant"", '<2-hop>\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \n(not publicly available) doi:10.1037/h0042519\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568']","The McCulloch-Pitts model, developed in the 1940s, is one of the earliest models of artificial neurons, designed to compute basic logic functions. It represents neurons as simple binary threshold units that output a signal if the sum of their weighted inputs exceeds a certain threshold.

Spiking neural networks (SNNs), on the other hand, are a more advanced and biologically realistic model of neural networks. They incorporate the concept of time into the neural processing, where neurons communicate by sending discrete spikes at particular points in time, rather than continuous values. This allows SNNs to capture the temporal dynamics of biological neural systems more accurately.

While the McCulloch-Pitts model laid the groundwork for understanding how neurons could perform logical operations, spiking neural networks extend this by modeling the timing of spikes, which is crucial for understanding more complex neural processes. Thus, SNNs can be seen as an evolution of the ideas introduced by the McCulloch-Pitts model, incorporating more biological realism.","Spiking neural networks relate to the McCulloch-Pitts model by building upon the foundational concepts of neural computation, where the McCulloch-Pitts model introduced the idea of binary neuron states, which is extended in spiking networks to model more complex information processing through spike timing and patterns.",0.49999999995,1.0,1.0,0.96,0.0,0.9311693773866484
How spiking neural networks used in encoding strategies?,"[""ANN: Perceptron, threshold activation function:\n\nHow to model spiking neurons?\nANN: Perceptron, threshold activation function:\n\nHow to model spiking neurons?\nSpiking neural network (SNN): The 'input current' Œµ(t) is integrated over time.\nspike\n\nHow to model spiking neurons?\nEquivalence to perceptron: Computation at least as complex as a perceptron.\n\nNon-leaky integrate-and-fire (IF) neuron\nThe temporal profile of the input current Œµ(t) can be chosen differently, for different computations.\n\nQuestions?\n\nComputation with spiking neurons\nCoincidence detection\n\nComputation with spiking neurons\nCoincidence detection\nx, y ‚àà {0, 1}n\nExample: n = 2\ninput = \nx1\nx2\ny1\ny2\n= \n0\n1\n1\n1\noutput? \n\nCoincidence detection\nComputation with spiking neurons\n\nCoincidence detection\nCan be trivially computed with a single spiking neuron! Requires at least n/log(n+1) hidden \nunits for a perceptron (proof in [7]).\nComputation with spiking neurons\n\nCoincidence detection\nCan be trivially computed with a single spiking neuron! Requires at least n/log(n+1) hidden \nunits for a perceptron (proof in [7]).\nBrains are energy efficient: \n1.\nHigh temporal resolution (more computation with less neurons)\nComputation with spiking neurons\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant\n\nFiring rates\nClassical view of the brain:\n- Each neuron is selective for one specific \nfeature in the input.\n- Higher firing rate (spikes per unit time) for \n'selected' feature.\nAdapted from Hubel & Wiesel, 1959\n\nFiring rates\nClassical view of the brain:\n- Each neuron is selective for one specific \nfeature in the input.\n- Higher firing rate (spikes per unit time) for \n'selected' feature."", ""- Higher firing rate (spikes per unit time) for \n'selected' feature.\nAdapted from Hubel & Wiesel, 1959\n\nFiring rates\nClassical view of the brain:\n- Each neuron is selective for one specific \nfeature in the input.\n- Higher firing rate (spikes per unit time) for \n'selected' feature.\n- Link to modern ANNs: The scalar output of \nan artificial neuron is interpreted as the firing \nrate.\nAdapted from Hubel & Wiesel, 1959\n\nFiring rates\nClassical view of the brain:\n- Each neuron is selective for one specific \nfeature in the input.\n- Higher firing rate (spikes per unit time) for \n'selected' feature.\n- Link to modern ANNs: The scalar output of \nan artificial neuron is interpreted as the firing \nrate.\nAdapted from Hubel & Wiesel, 1959\nBut rate coding is inefficient and slow‚Ä¶\n(i.e. each neuron needs to fire many spikes to get good precision)\nboth in vivo and in silico.\n\nDifferent encoding strategies with spiking neurons [8]\n7 neurons\n7 time bins\n\nDifferent encoding strategies with spiking neurons\n7 neurons\n7 time bins\nn\n6\n(in the general \ncase a \nnumber \nbetween 0-7)\n\nDifferent encoding strategies with spiking neurons\n7 neurons\n7 time bins\nn\nTotal spike \ncount can \nencode 3 bits.\n\nDifferent encoding strategies with spiking neurons\n7 neurons\n7 time bins\nIndividual rates \ncan encode 7 \nbits.\n\nDifferent encoding strategies with spiking neurons\n7 neurons\n7 time bins\nLatency can \nencode ~3*7 or \n~19 bits.\n\nDifferent encoding strategies with spiking neurons\n7 neurons\n7 time bins\nRank order can \nencode ~12 bits.\n\nDifferent encoding strategies with spiking neurons\n\nDifferent encoding strategies with spiking neurons\nUsing latency or spatio-temporal codes\nour encoding is faster and more spike-efficient (sparser)!\n\nDifferent encoding strategies with spiking neurons\nUsing latency or spatio-temporal codes\nour encoding is faster and more spike-efficient (sparser)!\nQuestions?\n\nNeuromorphic computing\nWhat is the advantage for applications?\n-\nLess spikes = less energy consumption in specialized neuromorphic hardware\n(e.g.""]","[""<1-hop>\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant"", '<2-hop>\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \n(not publicly available) doi:10.1037/h0042519\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568']","Spiking neural networks (SNNs) use various encoding strategies to efficiently represent information. These strategies include:

1. **Firing Rates**: Each neuron is selective for a specific feature, and a higher firing rate (spikes per unit time) indicates the presence of that feature. However, this method is considered inefficient and slow because it requires many spikes to achieve good precision.

2. **Total Spike Count**: This method can encode information by counting the total number of spikes, which can represent multiple bits of information.

3. **Individual Rates**: By considering the firing rates of individual neurons, more bits of information can be encoded.

4. **Latency**: The timing of spikes (latency) can encode a significant amount of information, making it a fast and efficient encoding strategy.

5. **Rank Order**: The order in which neurons fire can also encode information, allowing for a compact representation.

Using latency or spatio-temporal codes, SNNs achieve faster and more spike-efficient encoding, which is beneficial for reducing energy consumption in neuromorphic computing applications.",Spiking neural networks use single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0) to encode information about 'features' in a large network with many spikes. This approach is supported by foundational works such as McCulloch and Pitts' logical calculus of nervous activity and later developments in spiking neuron models.,0.0,0.5,1.0,0.0,0.0,0.9438028448304304
What are the benefits of neuromorphic computing in the context of green software practices?,"[""Neuromorphic computing\nCS4575\nSustainable Software Engineering\n05.03.2025\nNergis T√∂men\n\nIntroduction\nComputer Vision Lab\nBiomorphic Intelligence Lab\nBiomedical Intervention Optimisation Lab\nNergis\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing\n\nHow many of you are familiar \nwith neural networks?\n\nSimple model of an artificial neuron\nhttps://medium.com/@cprasenjit32/perceptron-a-simple-yet-mighty-machine-learning-algorithm-9ff6b7d86a71\n\nWhat is a neural network?\nhttps://www.tibco.com/reference-center/what-is-a-neural-network\n\nWhy is it called a 'neural network'?\nhttps://www.tibco.com/reference-center/what-is-a-neural-network\n\nWhat is a neural network?\nWhy is it called a 'neural network'?\nMcCulloch-Pitts neuron [1, 2] (1943)\nWarren Sturgis McCulloch\n(Neurophysiologist)\nWalter Pitts\n(Logician)\n\nHow do biological neurons work?\nhttps://commons.wikimedia.org/wiki/File:Coincidence_detection_in_dendrites_of_pyramidal_neurons.gif\n'Input current' travels down the dendrites (top),\nget integrated (summed!) in the cell body\nwhich generates an 'output current' (bottom)\nwhich is chemically transmitted to the dendrites of \nother neurons.\n\nSimplified picture\nReal neuron\nArtificial neuron\nhttps://vajiramandravi.com/quest-upsc-notes/artificial-neural-network/\n\nWhat is a neural network?\nMcCulloch-Pitts neuron [1, 2]\n1940s: How do biological neurons compute basic \nlogic functions? (e.g. logic gates)\nNote: Ref. [3] gives a nice brief history on the ideas which lead to the \nMcCulloch-Pitts neuron.\n\nWhat is a neural network?"", 'McCulloch-Pitts neuron [1, 2]\n1940s: How do biological neurons compute basic \nlogic functions? (e.g. logic gates)\nNote: Ref. [3] gives a nice brief history on the ideas which lead to the \nMcCulloch-Pitts neuron.\n\nWhat is a neural network?\n1950s: How are neurons organized to perform \nsensory perception?\n\nWhat is a neural network?\n1950s: How are neurons organized to perform \nsensory perception?\nThe first ""neural network"": Perceptron (1958). [4]\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\nFrank Rosenblatt (Psychologist)\nwith a Mark I Perceptron computer in 1960\n\nWhat is a neural network?\n1950s: How are neurons organized to perform \nsensory perception?\nThe first ""neural network"": Perceptron (1958). [4]\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\nFrank Rosenblatt (Psychologist)\nwith a Mark I Perceptron computer in 1960\nPower-efficient\n\nNeuromorphic computing\nWhy neuromorphic computing?\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\n\nNeuromorphic computing\nWhy neuromorphic computing?\n‚ÄòBiological inspiration‚Äô for artificial neural networks (ANNs) is not a new idea.\nEmulation (as opposed to simulation) of neural networks in hardware is not a new idea.\nQuestion: What can we gain from increasing biological realism in existing neural networks?\n\nPower-efficiency at scale\nModern, deep neural networks*\nare trained using GPUs.\n* It is estimated that ChatGPT was trained on \n10,000-20,000 GPUs and that it will require\n30,000 GPUs to keep running stably in the future.\n* It is estimated that ChatGPT has 10-20 billion \nparameters.']","['<1-hop>\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing', '<2-hop>\n\nReading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.', '<1-hop>\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing', '<2-hop>\n\nReading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.', '<1-hop>\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing', '<2-hop>\n\nReading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.']","Neuromorphic computing offers benefits in the context of green software practices primarily through its power-efficiency at scale. Neuromorphic systems use physical artificial neurons to perform computations, which can be more energy-efficient compared to traditional computing systems, especially those using GPUs for training modern, deep neural networks. This efficiency can lead to reduced energy consumption and lower carbon footprints, aligning with the goals of sustainable software engineering.","Neuromorphic computing offers several benefits in the context of green software practices. It is inspired by the structure and function of the human brain, making it highly energy-efficient compared to traditional computing methods. This efficiency is particularly relevant for sustainable software development, as it reduces the environmental impact of computing systems. Additionally, neuromorphic systems can process information in a way that mimics biological neural networks, which can lead to more efficient and sustainable computing solutions. These aspects make neuromorphic computing a promising approach for developers looking to implement green software practices.",0.49999999995,1.0,1.0,0.57,0.1111111109876543,0.9742565367564061
What are the challenges in creating a dataset of government-developed OS software?,"['Study test generation energy consumption\n‚Ä¢ Automatic test generation mainly focuses on making strong test suites \n‚Ä¢ Do different techniques and configurations impact the energy consumption \nduring generation? \n‚Ä¢ Preferably focus on non-LLM test generation methods (EvoSuite, Pyguin, \nDSpot)\n\nB3. Detailed energy profiling of build pipelines\n‚Ä¢ Automatic builds have become a cornerstone of quality assurance. But how \nmuch energy do they even consume? \n‚Ä¢ Create a tool that reports on the energy consumed during the (different stages \nof the) whole build (compile, build, test, package, ‚Ä¶) \n‚Ä¢ Should be integrated with build system(s), making setup for developers easy \n‚Ä¢ For local setup (to enable true energy measurements)\n\nB4. Energy profiling of static analysis tools\n‚Ä¢ What is the energy consumption of a ""typical run"" for a few OSS projects? \n‚Ä¢ Does the type of analysis matter? Are certain analysis more expensive? Does \nthe number of rules that are activated in a static analysis tool important for the \nenergy consumption? \n‚Ä¢ Differences between static analysis tools [lower priority]\n\nB5. Tool supporting SusAF workshop / process\n‚Ä¢ Lead engineers through process & questions \n‚Ä¢ Interface to create & document the two diagrams \n‚Ä¢ (!) Should be easy to start using & set up \n‚Ä¢ You may also create a simplified version / \u2028\nyour favorite sustainability framework\nEnvironmental\nEconomic\nTechnical\nIndividual\nSocial\nImmediate\nEnabling\nStructural\nAirbnb\ngreater \nearnings\nincrease \nin rents\ngentrification\ngreater racial \ndisparities\nrent \nrooms\n5\n1\n3\n4\n2\n \n \n \n \n \n \nVery \nunlikely \nVery \nlikely \n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise \n‚Ä¢ But studying government software is difficult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers \n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation? \n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!\n\nB7.', '‚Ä¢ Deadline April 4.\n6\n\nStrategy\n‚Ä¢ Week 0 \n‚Ä¢ Decide project idea (today) \n‚Ä¢ Define steering meeting schedule \n‚Ä¢ Create working document of the \narticle: Problem statement and solution \nproposal! \n‚Ä¢ Define and assign tasks for each week. \n‚Ä¢ Week 1 \n‚Ä¢ Implementation \n‚Ä¢ Agreements with supervisor. \n‚Ä¢ Week 2 \n‚Ä¢ Implementation \n‚Ä¢ Week 3 \n‚Ä¢ Implementation, Full draft of article, \ndissemination. \n‚Ä¢ Week 4 \n‚Ä¢ Final refinements \n‚Ä¢ Prepare presentation\n7\n\nProject ideas\n‚Ä¢ A1. Prototype cross-machine comparable benchmarks \n‚Ä¢ A2. Add energy metrics to LMstudio/Ollama \n‚Ä¢ A3. Visualizations built-in with EnergiBridge \n‚Ä¢ A4. Service-based version of EnergiBridge\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption \n‚Ä¢ B3. Energy profiling of static analysis tools \n‚Ä¢ B4. Detailed energy profiling of build pipelines \n‚Ä¢ B5. Tool supporting SusAF workshop / process \n‚Ä¢ B6. Dataset of government-developed OS software \n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability\n\nProject ideas\n‚Ä¢ C1. Compare energy consumption of docker images for ML workloads. \n‚Ä¢ C2. Create a plugin to visualize Hugging Face carbon emissions in detail. \n‚Ä¢ C3. Plugin for ChatGPT (footprint per chat window) \n‚Ä¢ C4. NutriScore for software libraries. \n‚Ä¢ C5. Add energy-awareness to existing software \n‚Ä¢ C6. Green Shift Left \n‚Ä¢ C7. Education for Sustainable SE\n\nA1. Prototype cross-machine comparable benchmarks\n‚Ä¢ Energy-usage comparisons require running both baseline + software on the \nsame machine ‚Üí limits how extensive our experiments can be \n‚Ä¢ Research community is in need of benchmarks that make energy \nmeasurements comparable even if executed on different machines \n‚Ä¢ Focus on a single task or model (i.e. computing vision, classification)\n\nA2.']","['<1-hop>\n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise\n‚Ä¢ But studying government software is diÔ¨Écult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation?\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!', '<2-hop>\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption\n‚Ä¢ B3. Energy proÔ¨Åling of static analysis tools\n‚Ä¢ B4. Detailed energy proÔ¨Åling of build pipelines\n‚Ä¢ B5. Tool supporting SusAF workshop / process\n‚Ä¢ B6. Dataset of government-developed OS software\n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability', '<1-hop>\n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise\n‚Ä¢ But studying government software is diÔ¨Écult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation?\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!', '<2-hop>\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption\n‚Ä¢ B3. Energy proÔ¨Åling of static analysis tools\n‚Ä¢ B4. Detailed energy proÔ¨Åling of build pipelines\n‚Ä¢ B5. Tool supporting SusAF workshop / process\n‚Ä¢ B6. Dataset of government-developed OS software\n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability', '<1-hop>\n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise\n‚Ä¢ But studying government software is diÔ¨Écult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation?\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!', '<2-hop>\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption\n‚Ä¢ B3. Energy proÔ¨Åling of static analysis tools\n‚Ä¢ B4. Detailed energy proÔ¨Åling of build pipelines\n‚Ä¢ B5. Tool supporting SusAF workshop / process\n‚Ä¢ B6. Dataset of government-developed OS software\n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability']","The challenges in creating a dataset of government-developed open-source software include:

1. **Lack of Incentive to Make Popular**: There is often little motivation for governments to promote their software, leading to a lack of visibility and awareness.

2. **Language Barriers**: Government software may be developed in various languages, making it difficult to compile a comprehensive dataset that is accessible and understandable to a wider audience.

3. **Understanding the State of Software**: It is challenging to gather data that provides insights into whether the software is buildable, has an open development history, and includes requirements documentation.

These challenges make it difficult to study and compile a comprehensive dataset of government-developed open-source software.","Creating a dataset of government-developed OS software faces challenges such as a lack of incentive to make the software popular and language barriers, which hinder comprehensive understanding of the software's buildability, open development history, and requirements documentation.",0.9999999999,1.0,0.8888888888888888,1.0,0.33333333277777777,0.9696515751694866
"What are the practical applications of neuromorphic computing, and how does its biological inspiration influence its implementation in modern computing systems?","['McCulloch-Pitts neuron [1, 2]\n1940s: How do biological neurons compute basic \nlogic functions? (e.g. logic gates)\nNote: Ref. [3] gives a nice brief history on the ideas which lead to the \nMcCulloch-Pitts neuron.\n\nWhat is a neural network?\n1950s: How are neurons organized to perform \nsensory perception?\n\nWhat is a neural network?\n1950s: How are neurons organized to perform \nsensory perception?\nThe first ""neural network"": Perceptron (1958). [4]\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\nFrank Rosenblatt (Psychologist)\nwith a Mark I Perceptron computer in 1960\n\nWhat is a neural network?\n1950s: How are neurons organized to perform \nsensory perception?\nThe first ""neural network"": Perceptron (1958). [4]\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\nFrank Rosenblatt (Psychologist)\nwith a Mark I Perceptron computer in 1960\nPower-efficient\n\nNeuromorphic computing\nWhy neuromorphic computing?\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\n\nNeuromorphic computing\nWhy neuromorphic computing?\n‚ÄòBiological inspiration‚Äô for artificial neural networks (ANNs) is not a new idea.\nEmulation (as opposed to simulation) of neural networks in hardware is not a new idea.\nQuestion: What can we gain from increasing biological realism in existing neural networks?\n\nPower-efficiency at scale\nModern, deep neural networks*\nare trained using GPUs.\n* It is estimated that ChatGPT was trained on \n10,000-20,000 GPUs and that it will require\n30,000 GPUs to keep running stably in the future.\n* It is estimated that ChatGPT has 10-20 billion \nparameters.', ""Neuromorphic computing\nCS4575\nSustainable Software Engineering\n05.03.2025\nNergis T√∂men\n\nIntroduction\nComputer Vision Lab\nBiomorphic Intelligence Lab\nBiomedical Intervention Optimisation Lab\nNergis\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing\n\nHow many of you are familiar \nwith neural networks?\n\nSimple model of an artificial neuron\nhttps://medium.com/@cprasenjit32/perceptron-a-simple-yet-mighty-machine-learning-algorithm-9ff6b7d86a71\n\nWhat is a neural network?\nhttps://www.tibco.com/reference-center/what-is-a-neural-network\n\nWhy is it called a 'neural network'?\nhttps://www.tibco.com/reference-center/what-is-a-neural-network\n\nWhat is a neural network?\nWhy is it called a 'neural network'?\nMcCulloch-Pitts neuron [1, 2] (1943)\nWarren Sturgis McCulloch\n(Neurophysiologist)\nWalter Pitts\n(Logician)\n\nHow do biological neurons work?\nhttps://commons.wikimedia.org/wiki/File:Coincidence_detection_in_dendrites_of_pyramidal_neurons.gif\n'Input current' travels down the dendrites (top),\nget integrated (summed!) in the cell body\nwhich generates an 'output current' (bottom)\nwhich is chemically transmitted to the dendrites of \nother neurons.\n\nSimplified picture\nReal neuron\nArtificial neuron\nhttps://vajiramandravi.com/quest-upsc-notes/artificial-neural-network/\n\nWhat is a neural network?\nMcCulloch-Pitts neuron [1, 2]\n1940s: How do biological neurons compute basic \nlogic functions? (e.g. logic gates)\nNote: Ref. [3] gives a nice brief history on the ideas which lead to the \nMcCulloch-Pitts neuron.\n\nWhat is a neural network?""]","['<1-hop>\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing', '<2-hop>\n\nReading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.', '<1-hop>\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing', '<2-hop>\n\nReading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.']","Neuromorphic computing is inspired by the structure and function of the human brain, and it involves using physical artificial neurons to perform computations. This approach offers several practical applications and advantages:

1. **Power Efficiency**: Neuromorphic computing systems are designed to be power-efficient, which is particularly beneficial for large-scale computations. This efficiency is crucial for applications like deep neural networks, which require significant computational resources.

2. **Real-Time Processing**: Due to their architecture, neuromorphic systems can process information in real-time, making them suitable for applications that require immediate responses, such as autonomous vehicles and robotics.

3. **Sensory Perception**: Neuromorphic computing can enhance sensory perception tasks, such as image and speech recognition, by mimicking the way biological systems process sensory information.

4. **Scalability**: The emulation of neural networks in hardware allows for scalable solutions that can handle complex tasks more efficiently than traditional computing systems.

The biological inspiration behind neuromorphic computing influences its implementation by encouraging the development of systems that mimic the parallel and distributed nature of the brain's neural networks. This leads to computing systems that are not only more efficient but also capable of handling complex, dynamic tasks in a manner similar to biological organisms.","Neuromorphic computing, inspired by the human brain, offers practical applications such as event-based vision systems and efficient processing of sensory data. Its biological inspiration influences its implementation through the use of spiking neural networks and physical artificial neurons, enabling more energy-efficient and brain-like computation methods.",0.9999999999,,0.7333333333333333,0.57,0.33333333277777777,0.9544250285082487
"What are the practical applications of neuromorphic computing, and how does its biological inspiration influence its implementation?","['McCulloch-Pitts neuron [1, 2]\n1940s: How do biological neurons compute basic \nlogic functions? (e.g. logic gates)\nNote: Ref. [3] gives a nice brief history on the ideas which lead to the \nMcCulloch-Pitts neuron.\n\nWhat is a neural network?\n1950s: How are neurons organized to perform \nsensory perception?\n\nWhat is a neural network?\n1950s: How are neurons organized to perform \nsensory perception?\nThe first ""neural network"": Perceptron (1958). [4]\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\nFrank Rosenblatt (Psychologist)\nwith a Mark I Perceptron computer in 1960\n\nWhat is a neural network?\n1950s: How are neurons organized to perform \nsensory perception?\nThe first ""neural network"": Perceptron (1958). [4]\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\nFrank Rosenblatt (Psychologist)\nwith a Mark I Perceptron computer in 1960\nPower-efficient\n\nNeuromorphic computing\nWhy neuromorphic computing?\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\n\nNeuromorphic computing\nWhy neuromorphic computing?\n‚ÄòBiological inspiration‚Äô for artificial neural networks (ANNs) is not a new idea.\nEmulation (as opposed to simulation) of neural networks in hardware is not a new idea.\nQuestion: What can we gain from increasing biological realism in existing neural networks?\n\nPower-efficiency at scale\nModern, deep neural networks*\nare trained using GPUs.\n* It is estimated that ChatGPT was trained on \n10,000-20,000 GPUs and that it will require\n30,000 GPUs to keep running stably in the future.\n* It is estimated that ChatGPT has 10-20 billion \nparameters.', ""Neuromorphic computing\nCS4575\nSustainable Software Engineering\n05.03.2025\nNergis T√∂men\n\nIntroduction\nComputer Vision Lab\nBiomorphic Intelligence Lab\nBiomedical Intervention Optimisation Lab\nNergis\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing\n\nHow many of you are familiar \nwith neural networks?\n\nSimple model of an artificial neuron\nhttps://medium.com/@cprasenjit32/perceptron-a-simple-yet-mighty-machine-learning-algorithm-9ff6b7d86a71\n\nWhat is a neural network?\nhttps://www.tibco.com/reference-center/what-is-a-neural-network\n\nWhy is it called a 'neural network'?\nhttps://www.tibco.com/reference-center/what-is-a-neural-network\n\nWhat is a neural network?\nWhy is it called a 'neural network'?\nMcCulloch-Pitts neuron [1, 2] (1943)\nWarren Sturgis McCulloch\n(Neurophysiologist)\nWalter Pitts\n(Logician)\n\nHow do biological neurons work?\nhttps://commons.wikimedia.org/wiki/File:Coincidence_detection_in_dendrites_of_pyramidal_neurons.gif\n'Input current' travels down the dendrites (top),\nget integrated (summed!) in the cell body\nwhich generates an 'output current' (bottom)\nwhich is chemically transmitted to the dendrites of \nother neurons.\n\nSimplified picture\nReal neuron\nArtificial neuron\nhttps://vajiramandravi.com/quest-upsc-notes/artificial-neural-network/\n\nWhat is a neural network?\nMcCulloch-Pitts neuron [1, 2]\n1940s: How do biological neurons compute basic \nlogic functions? (e.g. logic gates)\nNote: Ref. [3] gives a nice brief history on the ideas which lead to the \nMcCulloch-Pitts neuron.\n\nWhat is a neural network?""]","['<1-hop>\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing', '<2-hop>\n\nReading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.']","The practical applications of neuromorphic computing include areas such as computer vision, robotics, and biomedical intervention optimization. Neuromorphic computing is particularly useful in scenarios where power efficiency is crucial, as it aims to emulate the brain's structure and function, which is highly efficient in processing information.

The biological inspiration for neuromorphic computing influences its implementation by using physical artificial neurons to perform computations, mimicking the way biological neurons process information. This approach allows for more efficient and scalable computing systems, as it leverages the brain's ability to perform complex tasks with minimal energy consumption. This emulation of neural networks in hardware is not a new idea, but it continues to offer potential for advancements in creating more efficient and powerful computing systems.","Neuromorphic computing, inspired by the human brain, offers practical applications through its ability to process information in a manner similar to biological neurons. This biological inspiration influences its implementation by enabling the development of systems that can efficiently handle tasks such as pattern recognition and adaptive learning, as detailed in resources like 'Computing with spiking neuron networks' and discussions on the convergence of deep learning with biological systems.",0.0,0.3333333333333333,0.5555555555555556,0.64,0.37499999953124996,0.9893234461241739
What are the practical applications of neuromorphic systems that leverage biological inspiration and advanced training methods for efficient computation?,"['McCulloch-Pitts neuron [1, 2]\n1940s: How do biological neurons compute basic \nlogic functions? (e.g. logic gates)\nNote: Ref. [3] gives a nice brief history on the ideas which lead to the \nMcCulloch-Pitts neuron.\n\nWhat is a neural network?\n1950s: How are neurons organized to perform \nsensory perception?\n\nWhat is a neural network?\n1950s: How are neurons organized to perform \nsensory perception?\nThe first ""neural network"": Perceptron (1958). [4]\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\nFrank Rosenblatt (Psychologist)\nwith a Mark I Perceptron computer in 1960\n\nWhat is a neural network?\n1950s: How are neurons organized to perform \nsensory perception?\nThe first ""neural network"": Perceptron (1958). [4]\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\nFrank Rosenblatt (Psychologist)\nwith a Mark I Perceptron computer in 1960\nPower-efficient\n\nNeuromorphic computing\nWhy neuromorphic computing?\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\n\nNeuromorphic computing\nWhy neuromorphic computing?\n‚ÄòBiological inspiration‚Äô for artificial neural networks (ANNs) is not a new idea.\nEmulation (as opposed to simulation) of neural networks in hardware is not a new idea.\nQuestion: What can we gain from increasing biological realism in existing neural networks?\n\nPower-efficiency at scale\nModern, deep neural networks*\nare trained using GPUs.\n* It is estimated that ChatGPT was trained on \n10,000-20,000 GPUs and that it will require\n30,000 GPUs to keep running stably in the future.\n* It is estimated that ChatGPT has 10-20 billion \nparameters.', ""Neuromorphic computing\nCS4575\nSustainable Software Engineering\n05.03.2025\nNergis T√∂men\n\nIntroduction\nComputer Vision Lab\nBiomorphic Intelligence Lab\nBiomedical Intervention Optimisation Lab\nNergis\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing\n\nHow many of you are familiar \nwith neural networks?\n\nSimple model of an artificial neuron\nhttps://medium.com/@cprasenjit32/perceptron-a-simple-yet-mighty-machine-learning-algorithm-9ff6b7d86a71\n\nWhat is a neural network?\nhttps://www.tibco.com/reference-center/what-is-a-neural-network\n\nWhy is it called a 'neural network'?\nhttps://www.tibco.com/reference-center/what-is-a-neural-network\n\nWhat is a neural network?\nWhy is it called a 'neural network'?\nMcCulloch-Pitts neuron [1, 2] (1943)\nWarren Sturgis McCulloch\n(Neurophysiologist)\nWalter Pitts\n(Logician)\n\nHow do biological neurons work?\nhttps://commons.wikimedia.org/wiki/File:Coincidence_detection_in_dendrites_of_pyramidal_neurons.gif\n'Input current' travels down the dendrites (top),\nget integrated (summed!) in the cell body\nwhich generates an 'output current' (bottom)\nwhich is chemically transmitted to the dendrites of \nother neurons.\n\nSimplified picture\nReal neuron\nArtificial neuron\nhttps://vajiramandravi.com/quest-upsc-notes/artificial-neural-network/\n\nWhat is a neural network?\nMcCulloch-Pitts neuron [1, 2]\n1940s: How do biological neurons compute basic \nlogic functions? (e.g. logic gates)\nNote: Ref. [3] gives a nice brief history on the ideas which lead to the \nMcCulloch-Pitts neuron.\n\nWhat is a neural network?""]","['<1-hop>\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing', '<2-hop>\n\nReading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.', '<1-hop>\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing', '<2-hop>\n\nReading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.', '<1-hop>\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing', '<2-hop>\n\nReading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.']","The practical applications of neuromorphic systems, which leverage biological inspiration and advanced training methods for efficient computation, include:

1. **Power-Efficient Computing**: Neuromorphic systems are designed to mimic the brain's efficiency, making them highly power-efficient, especially at scale. This is particularly beneficial for applications requiring extensive computations, such as deep learning models.

2. **Real-Time Processing**: Due to their efficiency and speed, neuromorphic systems are well-suited for real-time processing tasks, such as those needed in autonomous vehicles and robotics.

3. **Sensory Perception**: These systems can be used for advanced sensory perception tasks, similar to how biological neurons are organized for sensory processing. This includes applications in computer vision and auditory processing.

4. **Adaptive Control Systems**: Neuromorphic systems can be used in adaptive control systems that require learning and adaptation in dynamic environments, such as in smart grid management or adaptive traffic control.

5. **Biomedical Applications**: They can be applied in biomedical fields for tasks like brain-machine interfaces and neural prosthetics, where efficient and real-time processing of neural signals is crucial.

These applications benefit from the neuromorphic approach's ability to perform computations in a manner similar to the human brain, offering advantages in efficiency and speed over traditional computing methods.","Neuromorphic systems, inspired by the human brain, have practical applications such as event-based vision, which is detailed in the reading materials. These systems use advanced training methods like surrogate gradient learning to optimize spiking neural networks, enabling efficient computation and real-world applications.",0.0,0.0,0.2631578947368421,0.35,0.0,0.9546676040223273
"What is the biological basis of neuromorphic computing, and how does it differ from conventional neural networks?","['McCulloch-Pitts neuron [1, 2]\n1940s: How do biological neurons compute basic \nlogic functions? (e.g. logic gates)\nNote: Ref. [3] gives a nice brief history on the ideas which lead to the \nMcCulloch-Pitts neuron.\n\nWhat is a neural network?\n1950s: How are neurons organized to perform \nsensory perception?\n\nWhat is a neural network?\n1950s: How are neurons organized to perform \nsensory perception?\nThe first ""neural network"": Perceptron (1958). [4]\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\nFrank Rosenblatt (Psychologist)\nwith a Mark I Perceptron computer in 1960\n\nWhat is a neural network?\n1950s: How are neurons organized to perform \nsensory perception?\nThe first ""neural network"": Perceptron (1958). [4]\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\nFrank Rosenblatt (Psychologist)\nwith a Mark I Perceptron computer in 1960\nPower-efficient\n\nNeuromorphic computing\nWhy neuromorphic computing?\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\n\nNeuromorphic computing\nWhy neuromorphic computing?\n‚ÄòBiological inspiration‚Äô for artificial neural networks (ANNs) is not a new idea.\nEmulation (as opposed to simulation) of neural networks in hardware is not a new idea.\nQuestion: What can we gain from increasing biological realism in existing neural networks?\n\nPower-efficiency at scale\nModern, deep neural networks*\nare trained using GPUs.\n* It is estimated that ChatGPT was trained on \n10,000-20,000 GPUs and that it will require\n30,000 GPUs to keep running stably in the future.\n* It is estimated that ChatGPT has 10-20 billion \nparameters.', ""Neuromorphic computing\nCS4575\nSustainable Software Engineering\n05.03.2025\nNergis T√∂men\n\nIntroduction\nComputer Vision Lab\nBiomorphic Intelligence Lab\nBiomedical Intervention Optimisation Lab\nNergis\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing\n\nHow many of you are familiar \nwith neural networks?\n\nSimple model of an artificial neuron\nhttps://medium.com/@cprasenjit32/perceptron-a-simple-yet-mighty-machine-learning-algorithm-9ff6b7d86a71\n\nWhat is a neural network?\nhttps://www.tibco.com/reference-center/what-is-a-neural-network\n\nWhy is it called a 'neural network'?\nhttps://www.tibco.com/reference-center/what-is-a-neural-network\n\nWhat is a neural network?\nWhy is it called a 'neural network'?\nMcCulloch-Pitts neuron [1, 2] (1943)\nWarren Sturgis McCulloch\n(Neurophysiologist)\nWalter Pitts\n(Logician)\n\nHow do biological neurons work?\nhttps://commons.wikimedia.org/wiki/File:Coincidence_detection_in_dendrites_of_pyramidal_neurons.gif\n'Input current' travels down the dendrites (top),\nget integrated (summed!) in the cell body\nwhich generates an 'output current' (bottom)\nwhich is chemically transmitted to the dendrites of \nother neurons.\n\nSimplified picture\nReal neuron\nArtificial neuron\nhttps://vajiramandravi.com/quest-upsc-notes/artificial-neural-network/\n\nWhat is a neural network?\nMcCulloch-Pitts neuron [1, 2]\n1940s: How do biological neurons compute basic \nlogic functions? (e.g. logic gates)\nNote: Ref. [3] gives a nice brief history on the ideas which lead to the \nMcCulloch-Pitts neuron.\n\nWhat is a neural network?""]","['<1-hop>\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing', '<2-hop>\n\nReading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.']","The biological basis of neuromorphic computing is its inspiration from the structure and function of the human brain. Neuromorphic computing involves using physical artificial neurons to perform computations, emulating the way biological neurons process information. This approach aims to mimic the brain's efficiency and adaptability.

In contrast, conventional neural networks, such as those used in deep learning, are typically implemented in software and run on general-purpose hardware like GPUs. These networks are inspired by the brain but do not emulate its physical structure. They are often less power-efficient compared to neuromorphic systems, which aim to achieve power-efficiency at scale by closely replicating the brain's architecture and processes.

In summary, neuromorphic computing seeks to emulate the brain's physical and functional characteristics in hardware, while conventional neural networks are software-based models inspired by the brain's information processing capabilities.","Neuromorphic computing is based on the biological principles of the human brain, utilizing physical artificial neurons to perform computations. Unlike conventional neural networks, which rely on traditional computing architectures, neuromorphic systems are designed to mimic the brain's structure and function, enabling more efficient and biologically inspired processing.",0.99999999995,0.6666666666666666,0.8181818181818182,0.94,0.2857142853061225,0.9849766818157953
What is the difference between spiking neural networks and spiking neuron networks?,"[""ANN: Perceptron, threshold activation function:\n\nHow to model spiking neurons?\nANN: Perceptron, threshold activation function:\n\nHow to model spiking neurons?\nSpiking neural network (SNN): The 'input current' Œµ(t) is integrated over time.\nspike\n\nHow to model spiking neurons?\nEquivalence to perceptron: Computation at least as complex as a perceptron.\n\nNon-leaky integrate-and-fire (IF) neuron\nThe temporal profile of the input current Œµ(t) can be chosen differently, for different computations.\n\nQuestions?\n\nComputation with spiking neurons\nCoincidence detection\n\nComputation with spiking neurons\nCoincidence detection\nx, y ‚àà {0, 1}n\nExample: n = 2\ninput = \nx1\nx2\ny1\ny2\n= \n0\n1\n1\n1\noutput? \n\nCoincidence detection\nComputation with spiking neurons\n\nCoincidence detection\nCan be trivially computed with a single spiking neuron! Requires at least n/log(n+1) hidden \nunits for a perceptron (proof in [7]).\nComputation with spiking neurons\n\nCoincidence detection\nCan be trivially computed with a single spiking neuron! Requires at least n/log(n+1) hidden \nunits for a perceptron (proof in [7]).\nBrains are energy efficient: \n1.\nHigh temporal resolution (more computation with less neurons)\nComputation with spiking neurons\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant\n\nFiring rates\nClassical view of the brain:\n- Each neuron is selective for one specific \nfeature in the input.\n- Higher firing rate (spikes per unit time) for \n'selected' feature.\nAdapted from Hubel & Wiesel, 1959\n\nFiring rates\nClassical view of the brain:\n- Each neuron is selective for one specific \nfeature in the input.\n- Higher firing rate (spikes per unit time) for \n'selected' feature."", 'Reading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020.']","[""<1-hop>\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant"", '<2-hop>\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \n(not publicly available) doi:10.1037/h0042519\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568', ""<1-hop>\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant"", '<2-hop>\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \n(not publicly available) doi:10.1037/h0042519\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568']","The sources provided do not explicitly differentiate between ""spiking neural networks"" and ""spiking neuron networks."" However, based on general understanding, these terms are often used interchangeably to describe networks that use spiking neurons as their fundamental units. Both refer to a type of artificial neural network that mimics the way biological neurons communicate through discrete spikes or action potentials. If there is a specific context or distinction you are referring to, it might not be covered in the provided sources.","Spiking neural networks (SNNs) are a type of neural network model that processes information using spikes, similar to biological neurons. Spiking neuron networks refer to the individual components within these networks, focusing on how each neuron processes and communicates information through spikes.",0.0,0.25,0.5714285714285714,0.57,0.0,0.0
What is the foundational concepts of spiking neural networks and how they are used in encoding strategies?,"[""- Higher firing rate (spikes per unit time) for \n'selected' feature.\nAdapted from Hubel & Wiesel, 1959\n\nFiring rates\nClassical view of the brain:\n- Each neuron is selective for one specific \nfeature in the input.\n- Higher firing rate (spikes per unit time) for \n'selected' feature.\n- Link to modern ANNs: The scalar output of \nan artificial neuron is interpreted as the firing \nrate.\nAdapted from Hubel & Wiesel, 1959\n\nFiring rates\nClassical view of the brain:\n- Each neuron is selective for one specific \nfeature in the input.\n- Higher firing rate (spikes per unit time) for \n'selected' feature.\n- Link to modern ANNs: The scalar output of \nan artificial neuron is interpreted as the firing \nrate.\nAdapted from Hubel & Wiesel, 1959\nBut rate coding is inefficient and slow‚Ä¶\n(i.e. each neuron needs to fire many spikes to get good precision)\nboth in vivo and in silico.\n\nDifferent encoding strategies with spiking neurons [8]\n7 neurons\n7 time bins\n\nDifferent encoding strategies with spiking neurons\n7 neurons\n7 time bins\nn\n6\n(in the general \ncase a \nnumber \nbetween 0-7)\n\nDifferent encoding strategies with spiking neurons\n7 neurons\n7 time bins\nn\nTotal spike \ncount can \nencode 3 bits.\n\nDifferent encoding strategies with spiking neurons\n7 neurons\n7 time bins\nIndividual rates \ncan encode 7 \nbits.\n\nDifferent encoding strategies with spiking neurons\n7 neurons\n7 time bins\nLatency can \nencode ~3*7 or \n~19 bits.\n\nDifferent encoding strategies with spiking neurons\n7 neurons\n7 time bins\nRank order can \nencode ~12 bits.\n\nDifferent encoding strategies with spiking neurons\n\nDifferent encoding strategies with spiking neurons\nUsing latency or spatio-temporal codes\nour encoding is faster and more spike-efficient (sparser)!\n\nDifferent encoding strategies with spiking neurons\nUsing latency or spatio-temporal codes\nour encoding is faster and more spike-efficient (sparser)!\nQuestions?\n\nNeuromorphic computing\nWhat is the advantage for applications?\n-\nLess spikes = less energy consumption in specialized neuromorphic hardware\n(e.g."", ""ANN: Perceptron, threshold activation function:\n\nHow to model spiking neurons?\nANN: Perceptron, threshold activation function:\n\nHow to model spiking neurons?\nSpiking neural network (SNN): The 'input current' Œµ(t) is integrated over time.\nspike\n\nHow to model spiking neurons?\nEquivalence to perceptron: Computation at least as complex as a perceptron.\n\nNon-leaky integrate-and-fire (IF) neuron\nThe temporal profile of the input current Œµ(t) can be chosen differently, for different computations.\n\nQuestions?\n\nComputation with spiking neurons\nCoincidence detection\n\nComputation with spiking neurons\nCoincidence detection\nx, y ‚àà {0, 1}n\nExample: n = 2\ninput = \nx1\nx2\ny1\ny2\n= \n0\n1\n1\n1\noutput? \n\nCoincidence detection\nComputation with spiking neurons\n\nCoincidence detection\nCan be trivially computed with a single spiking neuron! Requires at least n/log(n+1) hidden \nunits for a perceptron (proof in [7]).\nComputation with spiking neurons\n\nCoincidence detection\nCan be trivially computed with a single spiking neuron! Requires at least n/log(n+1) hidden \nunits for a perceptron (proof in [7]).\nBrains are energy efficient: \n1.\nHigh temporal resolution (more computation with less neurons)\nComputation with spiking neurons\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant\n\nFiring rates\nClassical view of the brain:\n- Each neuron is selective for one specific \nfeature in the input.\n- Higher firing rate (spikes per unit time) for \n'selected' feature.\nAdapted from Hubel & Wiesel, 1959\n\nFiring rates\nClassical view of the brain:\n- Each neuron is selective for one specific \nfeature in the input.\n- Higher firing rate (spikes per unit time) for \n'selected' feature.""]","[""<1-hop>\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant"", '<2-hop>\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \n(not publicly available) doi:10.1037/h0042519\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568', ""<1-hop>\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant"", '<2-hop>\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \n(not publicly available) doi:10.1037/h0042519\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568', ""<1-hop>\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant"", '<2-hop>\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \n(not publicly available) doi:10.1037/h0042519\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568', ""<1-hop>\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant"", '<2-hop>\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \n(not publicly available) doi:10.1037/h0042519\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568']","The foundational concept of spiking neural networks (SNNs) is that they model neurons as spiking units, where the 'input current' is integrated over time, leading to a spike when a threshold is reached. This is similar to the perceptron model but involves temporal dynamics.

In terms of encoding strategies, SNNs use different methods to encode information with spikes:

1. **Rate Coding**: This classical view involves neurons firing at higher rates for selected features. However, it is considered inefficient and slow as it requires many spikes for good precision.

2. **Latency Coding**: This method encodes information based on the timing of spikes, which can be more efficient and faster than rate coding.

3. **Spatio-Temporal Coding**: This involves using both spatial and temporal patterns of spikes to encode information, making it more spike-efficient and faster.

4. **Rank Order Coding**: This strategy encodes information based on the order in which neurons fire, allowing for a compact representation of information.

Overall, these encoding strategies in SNNs aim to achieve high temporal resolution and energy efficiency, allowing for more computation with fewer neurons and less energy consumption, especially in specialized neuromorphic hardware.","Spiking neural networks use spikes to encode information, with foundational concepts including the work of McCulloch and Pitts on logical calculus of nervous activity, and later developments in spiking neuron models.",0.0,0.0,1.0,0.22,0.0,0.9490565936383991
What is the project idea about government-developed OS software?,"['Study test generation energy consumption\n‚Ä¢ Automatic test generation mainly focuses on making strong test suites \n‚Ä¢ Do different techniques and configurations impact the energy consumption \nduring generation? \n‚Ä¢ Preferably focus on non-LLM test generation methods (EvoSuite, Pyguin, \nDSpot)\n\nB3. Detailed energy profiling of build pipelines\n‚Ä¢ Automatic builds have become a cornerstone of quality assurance. But how \nmuch energy do they even consume? \n‚Ä¢ Create a tool that reports on the energy consumed during the (different stages \nof the) whole build (compile, build, test, package, ‚Ä¶) \n‚Ä¢ Should be integrated with build system(s), making setup for developers easy \n‚Ä¢ For local setup (to enable true energy measurements)\n\nB4. Energy profiling of static analysis tools\n‚Ä¢ What is the energy consumption of a ""typical run"" for a few OSS projects? \n‚Ä¢ Does the type of analysis matter? Are certain analysis more expensive? Does \nthe number of rules that are activated in a static analysis tool important for the \nenergy consumption? \n‚Ä¢ Differences between static analysis tools [lower priority]\n\nB5. Tool supporting SusAF workshop / process\n‚Ä¢ Lead engineers through process & questions \n‚Ä¢ Interface to create & document the two diagrams \n‚Ä¢ (!) Should be easy to start using & set up \n‚Ä¢ You may also create a simplified version / \u2028\nyour favorite sustainability framework\nEnvironmental\nEconomic\nTechnical\nIndividual\nSocial\nImmediate\nEnabling\nStructural\nAirbnb\ngreater \nearnings\nincrease \nin rents\ngentrification\ngreater racial \ndisparities\nrent \nrooms\n5\n1\n3\n4\n2\n \n \n \n \n \n \nVery \nunlikely \nVery \nlikely \n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise \n‚Ä¢ But studying government software is difficult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers \n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation? \n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!\n\nB7.', '‚Ä¢ Deadline April 4.\n6\n\nStrategy\n‚Ä¢ Week 0 \n‚Ä¢ Decide project idea (today) \n‚Ä¢ Define steering meeting schedule \n‚Ä¢ Create working document of the \narticle: Problem statement and solution \nproposal! \n‚Ä¢ Define and assign tasks for each week. \n‚Ä¢ Week 1 \n‚Ä¢ Implementation \n‚Ä¢ Agreements with supervisor. \n‚Ä¢ Week 2 \n‚Ä¢ Implementation \n‚Ä¢ Week 3 \n‚Ä¢ Implementation, Full draft of article, \ndissemination. \n‚Ä¢ Week 4 \n‚Ä¢ Final refinements \n‚Ä¢ Prepare presentation\n7\n\nProject ideas\n‚Ä¢ A1. Prototype cross-machine comparable benchmarks \n‚Ä¢ A2. Add energy metrics to LMstudio/Ollama \n‚Ä¢ A3. Visualizations built-in with EnergiBridge \n‚Ä¢ A4. Service-based version of EnergiBridge\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption \n‚Ä¢ B3. Energy profiling of static analysis tools \n‚Ä¢ B4. Detailed energy profiling of build pipelines \n‚Ä¢ B5. Tool supporting SusAF workshop / process \n‚Ä¢ B6. Dataset of government-developed OS software \n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability\n\nProject ideas\n‚Ä¢ C1. Compare energy consumption of docker images for ML workloads. \n‚Ä¢ C2. Create a plugin to visualize Hugging Face carbon emissions in detail. \n‚Ä¢ C3. Plugin for ChatGPT (footprint per chat window) \n‚Ä¢ C4. NutriScore for software libraries. \n‚Ä¢ C5. Add energy-awareness to existing software \n‚Ä¢ C6. Green Shift Left \n‚Ä¢ C7. Education for Sustainable SE\n\nA1. Prototype cross-machine comparable benchmarks\n‚Ä¢ Energy-usage comparisons require running both baseline + software on the \nsame machine ‚Üí limits how extensive our experiments can be \n‚Ä¢ Research community is in need of benchmarks that make energy \nmeasurements comparable even if executed on different machines \n‚Ä¢ Focus on a single task or model (i.e. computing vision, classification)\n\nA2.']","['<1-hop>\n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise\n‚Ä¢ But studying government software is diÔ¨Écult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation?\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!', '<2-hop>\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption\n‚Ä¢ B3. Energy proÔ¨Åling of static analysis tools\n‚Ä¢ B4. Detailed energy proÔ¨Åling of build pipelines\n‚Ä¢ B5. Tool supporting SusAF workshop / process\n‚Ä¢ B6. Dataset of government-developed OS software\n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability']","The project idea about government-developed OS software involves creating a comprehensive dataset of open-source software developed and used by governments to support society. The dataset should include information to understand the state of the software, such as whether it is buildable, its open development history, and requirements documentation. The project could start with the Netherlands (NL) but would benefit from including other countries as well. The challenge lies in the lack of incentive to make such software popular and potential language barriers.","The project idea involves creating a comprehensive dataset of government-developed OS software to understand its state, including buildability, open development history, and requirements documentation. This addresses challenges like lack of incentives and language barriers.",0.99999999995,1.0,1.0,0.82,,0.9999999999999997
What is the project idea related to creating a dataset of goverment-developed OS software?,"['‚Ä¢ Deadline April 4.\n6\n\nStrategy\n‚Ä¢ Week 0 \n‚Ä¢ Decide project idea (today) \n‚Ä¢ Define steering meeting schedule \n‚Ä¢ Create working document of the \narticle: Problem statement and solution \nproposal! \n‚Ä¢ Define and assign tasks for each week. \n‚Ä¢ Week 1 \n‚Ä¢ Implementation \n‚Ä¢ Agreements with supervisor. \n‚Ä¢ Week 2 \n‚Ä¢ Implementation \n‚Ä¢ Week 3 \n‚Ä¢ Implementation, Full draft of article, \ndissemination. \n‚Ä¢ Week 4 \n‚Ä¢ Final refinements \n‚Ä¢ Prepare presentation\n7\n\nProject ideas\n‚Ä¢ A1. Prototype cross-machine comparable benchmarks \n‚Ä¢ A2. Add energy metrics to LMstudio/Ollama \n‚Ä¢ A3. Visualizations built-in with EnergiBridge \n‚Ä¢ A4. Service-based version of EnergiBridge\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption \n‚Ä¢ B3. Energy profiling of static analysis tools \n‚Ä¢ B4. Detailed energy profiling of build pipelines \n‚Ä¢ B5. Tool supporting SusAF workshop / process \n‚Ä¢ B6. Dataset of government-developed OS software \n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability\n\nProject ideas\n‚Ä¢ C1. Compare energy consumption of docker images for ML workloads. \n‚Ä¢ C2. Create a plugin to visualize Hugging Face carbon emissions in detail. \n‚Ä¢ C3. Plugin for ChatGPT (footprint per chat window) \n‚Ä¢ C4. NutriScore for software libraries. \n‚Ä¢ C5. Add energy-awareness to existing software \n‚Ä¢ C6. Green Shift Left \n‚Ä¢ C7. Education for Sustainable SE\n\nA1. Prototype cross-machine comparable benchmarks\n‚Ä¢ Energy-usage comparisons require running both baseline + software on the \nsame machine ‚Üí limits how extensive our experiments can be \n‚Ä¢ Research community is in need of benchmarks that make energy \nmeasurements comparable even if executed on different machines \n‚Ä¢ Focus on a single task or model (i.e. computing vision, classification)\n\nA2.', 'Study test generation energy consumption\n‚Ä¢ Automatic test generation mainly focuses on making strong test suites \n‚Ä¢ Do different techniques and configurations impact the energy consumption \nduring generation? \n‚Ä¢ Preferably focus on non-LLM test generation methods (EvoSuite, Pyguin, \nDSpot)\n\nB3. Detailed energy profiling of build pipelines\n‚Ä¢ Automatic builds have become a cornerstone of quality assurance. But how \nmuch energy do they even consume? \n‚Ä¢ Create a tool that reports on the energy consumed during the (different stages \nof the) whole build (compile, build, test, package, ‚Ä¶) \n‚Ä¢ Should be integrated with build system(s), making setup for developers easy \n‚Ä¢ For local setup (to enable true energy measurements)\n\nB4. Energy profiling of static analysis tools\n‚Ä¢ What is the energy consumption of a ""typical run"" for a few OSS projects? \n‚Ä¢ Does the type of analysis matter? Are certain analysis more expensive? Does \nthe number of rules that are activated in a static analysis tool important for the \nenergy consumption? \n‚Ä¢ Differences between static analysis tools [lower priority]\n\nB5. Tool supporting SusAF workshop / process\n‚Ä¢ Lead engineers through process & questions \n‚Ä¢ Interface to create & document the two diagrams \n‚Ä¢ (!) Should be easy to start using & set up \n‚Ä¢ You may also create a simplified version / \u2028\nyour favorite sustainability framework\nEnvironmental\nEconomic\nTechnical\nIndividual\nSocial\nImmediate\nEnabling\nStructural\nAirbnb\ngreater \nearnings\nincrease \nin rents\ngentrification\ngreater racial \ndisparities\nrent \nrooms\n5\n1\n3\n4\n2\n \n \n \n \n \n \nVery \nunlikely \nVery \nlikely \n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise \n‚Ä¢ But studying government software is difficult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers \n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation? \n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!\n\nB7.']","['<1-hop>\n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise\n‚Ä¢ But studying government software is diÔ¨Écult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation?\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!', '<2-hop>\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption\n‚Ä¢ B3. Energy proÔ¨Åling of static analysis tools\n‚Ä¢ B4. Detailed energy proÔ¨Åling of build pipelines\n‚Ä¢ B5. Tool supporting SusAF workshop / process\n‚Ä¢ B6. Dataset of government-developed OS software\n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability', '<1-hop>\n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise\n‚Ä¢ But studying government software is diÔ¨Écult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation?\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!', '<2-hop>\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption\n‚Ä¢ B3. Energy proÔ¨Åling of static analysis tools\n‚Ä¢ B4. Detailed energy proÔ¨Åling of build pipelines\n‚Ä¢ B5. Tool supporting SusAF workshop / process\n‚Ä¢ B6. Dataset of government-developed OS software\n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability', '<1-hop>\n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise\n‚Ä¢ But studying government software is diÔ¨Écult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation?\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!', '<2-hop>\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption\n‚Ä¢ B3. Energy proÔ¨Åling of static analysis tools\n‚Ä¢ B4. Detailed energy proÔ¨Åling of build pipelines\n‚Ä¢ B5. Tool supporting SusAF workshop / process\n‚Ä¢ B6. Dataset of government-developed OS software\n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability', '<1-hop>\n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise\n‚Ä¢ But studying government software is diÔ¨Écult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation?\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!', '<2-hop>\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption\n‚Ä¢ B3. Energy proÔ¨Åling of static analysis tools\n‚Ä¢ B4. Detailed energy proÔ¨Åling of build pipelines\n‚Ä¢ B5. Tool supporting SusAF workshop / process\n‚Ä¢ B6. Dataset of government-developed OS software\n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability', '<1-hop>\n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise\n‚Ä¢ But studying government software is diÔ¨Écult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation?\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!', '<2-hop>\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption\n‚Ä¢ B3. Energy proÔ¨Åling of static analysis tools\n‚Ä¢ B4. Detailed energy proÔ¨Åling of build pipelines\n‚Ä¢ B5. Tool supporting SusAF workshop / process\n‚Ä¢ B6. Dataset of government-developed OS software\n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability']","The project idea related to creating a dataset of government-developed OS software involves compiling a comprehensive dataset that includes data to understand the state of such software. This includes determining if the software is buildable, its open development history, and requirements documentation. The project acknowledges the challenges in studying government software due to a lack of incentive to make it popular and language barriers. It suggests starting with the Netherlands (NL) but encourages including other countries as well.","The project idea is to create a dataset of government-developed OS software, which would help in understanding the state of such software, including whether it is buildable, has open development history, and has requirements documentation.",0.99999999995,1.0,1.0,0.75,0.0,0.9980923627914131
What is the project idea related to creating a dataset of government-developed OS software?,"['Study test generation energy consumption\n‚Ä¢ Automatic test generation mainly focuses on making strong test suites \n‚Ä¢ Do different techniques and configurations impact the energy consumption \nduring generation? \n‚Ä¢ Preferably focus on non-LLM test generation methods (EvoSuite, Pyguin, \nDSpot)\n\nB3. Detailed energy profiling of build pipelines\n‚Ä¢ Automatic builds have become a cornerstone of quality assurance. But how \nmuch energy do they even consume? \n‚Ä¢ Create a tool that reports on the energy consumed during the (different stages \nof the) whole build (compile, build, test, package, ‚Ä¶) \n‚Ä¢ Should be integrated with build system(s), making setup for developers easy \n‚Ä¢ For local setup (to enable true energy measurements)\n\nB4. Energy profiling of static analysis tools\n‚Ä¢ What is the energy consumption of a ""typical run"" for a few OSS projects? \n‚Ä¢ Does the type of analysis matter? Are certain analysis more expensive? Does \nthe number of rules that are activated in a static analysis tool important for the \nenergy consumption? \n‚Ä¢ Differences between static analysis tools [lower priority]\n\nB5. Tool supporting SusAF workshop / process\n‚Ä¢ Lead engineers through process & questions \n‚Ä¢ Interface to create & document the two diagrams \n‚Ä¢ (!) Should be easy to start using & set up \n‚Ä¢ You may also create a simplified version / \u2028\nyour favorite sustainability framework\nEnvironmental\nEconomic\nTechnical\nIndividual\nSocial\nImmediate\nEnabling\nStructural\nAirbnb\ngreater \nearnings\nincrease \nin rents\ngentrification\ngreater racial \ndisparities\nrent \nrooms\n5\n1\n3\n4\n2\n \n \n \n \n \n \nVery \nunlikely \nVery \nlikely \n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise \n‚Ä¢ But studying government software is difficult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers \n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation? \n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!\n\nB7.', '‚Ä¢ Deadline April 4.\n6\n\nStrategy\n‚Ä¢ Week 0 \n‚Ä¢ Decide project idea (today) \n‚Ä¢ Define steering meeting schedule \n‚Ä¢ Create working document of the \narticle: Problem statement and solution \nproposal! \n‚Ä¢ Define and assign tasks for each week. \n‚Ä¢ Week 1 \n‚Ä¢ Implementation \n‚Ä¢ Agreements with supervisor. \n‚Ä¢ Week 2 \n‚Ä¢ Implementation \n‚Ä¢ Week 3 \n‚Ä¢ Implementation, Full draft of article, \ndissemination. \n‚Ä¢ Week 4 \n‚Ä¢ Final refinements \n‚Ä¢ Prepare presentation\n7\n\nProject ideas\n‚Ä¢ A1. Prototype cross-machine comparable benchmarks \n‚Ä¢ A2. Add energy metrics to LMstudio/Ollama \n‚Ä¢ A3. Visualizations built-in with EnergiBridge \n‚Ä¢ A4. Service-based version of EnergiBridge\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption \n‚Ä¢ B3. Energy profiling of static analysis tools \n‚Ä¢ B4. Detailed energy profiling of build pipelines \n‚Ä¢ B5. Tool supporting SusAF workshop / process \n‚Ä¢ B6. Dataset of government-developed OS software \n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability\n\nProject ideas\n‚Ä¢ C1. Compare energy consumption of docker images for ML workloads. \n‚Ä¢ C2. Create a plugin to visualize Hugging Face carbon emissions in detail. \n‚Ä¢ C3. Plugin for ChatGPT (footprint per chat window) \n‚Ä¢ C4. NutriScore for software libraries. \n‚Ä¢ C5. Add energy-awareness to existing software \n‚Ä¢ C6. Green Shift Left \n‚Ä¢ C7. Education for Sustainable SE\n\nA1. Prototype cross-machine comparable benchmarks\n‚Ä¢ Energy-usage comparisons require running both baseline + software on the \nsame machine ‚Üí limits how extensive our experiments can be \n‚Ä¢ Research community is in need of benchmarks that make energy \nmeasurements comparable even if executed on different machines \n‚Ä¢ Focus on a single task or model (i.e. computing vision, classification)\n\nA2.']","['<1-hop>\n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise\n‚Ä¢ But studying government software is diÔ¨Écult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation?\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!', '<2-hop>\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption\n‚Ä¢ B3. Energy proÔ¨Åling of static analysis tools\n‚Ä¢ B4. Detailed energy proÔ¨Åling of build pipelines\n‚Ä¢ B5. Tool supporting SusAF workshop / process\n‚Ä¢ B6. Dataset of government-developed OS software\n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability']","The project idea related to creating a dataset of government-developed OS software involves compiling a comprehensive dataset that includes data to understand the state of such software. This includes information on whether the software is buildable, its open development history, and requirements documentation. The project acknowledges the challenges in studying government software due to a lack of incentive to make it popular and language barriers. It suggests starting with the Netherlands (NL) but appreciates the inclusion of other countries.","The project idea is to create a comprehensive dataset of government-developed OS software to understand the state of such software, including its buildability, open development history, and requirements documentation. This addresses challenges like the lack of incentive to make software popular and language barriers.",0.99999999995,1.0,1.0,0.86,0.6666666655555555,1.0000000000000004
How EcoAndroid reduce risk by reduce size?,"['‚Ä¢ When a connection is not possible, the app automatically retries later. \n‚Ä¢ https://github.com/k9mail/k-9/commit/\n86f3b28f79509d1a4d613eb39f60603e08579ea3\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio) \n‚Ä¢ Dynamic Retry Delay \n‚Ä¢ Push Over Poll \n‚Ä¢ Reduce Size \n‚Ä¢ Cache \n‚Ä¢ Avoid Graphics and Animations\n20\n\nCarbon-Aware Computing for \nDatacenters \nhttps://sites.google.com/view/energy-efficiency-languages\n21\nAna Radovanovic ÃÅ,', '*/\n6028 \nchanges\n\nThematic Analysis\n1. Familiarization with data \n2. Generating initial labels \n3. Reviewing themes\n4. Defining and naming themes\n\n‚Ä¢ Energy Pattern: design pattern to improve energy efficiency.. \n‚Ä¢ 22 energy patterns. \n‚Ä¢ Each pattern is described by Context, Solution, Example, References from \nliterature, and Occurences (links to code changes from git repositories).\n8\n\nhttps://tqrg.github.io/energy-patterns\n\nDark UI Colors \nProvide a dark UI color theme to \nsave battery on devices with \nAMOLED screens.\n‚Ä¢ Context: [‚Ä¶] Apps that require heavy usage of screen can \nhave a substantial negative impact on battery life. \n‚Ä¢ Solution: Provide a UI theme with dark background colors. [‚Ä¶]\n‚Ä¢ Example: In a reading app, provide a theme with a dark \nbackground using light colors to display text. [‚Ä¶] \n10\n\nDark UI Colors \nProvide a dark UI color theme to \nsave battery on devices with \nAMOLED screens.\n‚Ä¢ Context: [‚Ä¶] Apps that require heavy usage of screen can \nhave a substantial negative impact on battery life. \n‚Ä¢ Solution: Provide a UI theme with dark background colors. [‚Ä¶]\n‚Ä¢ Example: In a reading app, provide a theme with a dark \nbackground using light colors to display text. [‚Ä¶] \n11\n\nDynamic Retry Delay\n‚Ä¢ Context: [‚Ä¶] In a mobile app, when a given resource is \nunavailable, the app will unnecessarily try to connect the resource \nfor a number of times, leading to unnecessary power consumption. \n‚Ä¢ Solution: Increase retry interval after each failed connection. [‚Ä¶]\n‚Ä¢ Example: Consider a mobile app that provides a news feed and \nthe app is not able to reach the server to collect updates. [‚Ä¶] use \nthe Fibonacci series to increase the time between attempts.\nWhenever an attempt to access a \nresource fails, increase the time \ninterval before retrying.\n12\n\nBatch Operations \n‚Ä¢ Context: Executing operations separately leads to extraneous \ntail energy consumptions  \n‚Ä¢ Solution: Bundle multiple operations in a single one. [‚Ä¶]\n‚Ä¢ Example: Use system provided APIs to schedule background \ntasks. These APIs, guarantee that device will exit sleep mode \nonly when there is a reasonable amount of work to do or when a \ngiven task is urgent. [‚Ä¶]\n13\n\nAvoid Extraneous Graphics and \nAnimations  \n‚Ä¢ Context: Mobile apps that feature impressive graphics \nand animations.', 'Green Architectural Tactics for ML-Enabled \nSystem\n38\nICSE-SEIS 2024\n\nArchitectural tactics\n39\n\nData-centric\n40\n‚Ä¢ Reduce data size \n‚Ä¢ Sampling \n‚Ä¢ Dimensionality reduction \n‚Ä¢ Quantization\n\nAlgorithm Design\n41\n‚Ä¢ Carefully select your algorithm \n‚Ä¢ You don‚Äôt need the fanciest \ntechniques\n\nModel Optimization\n42\n‚Ä¢ Add energy to training parameters \n‚Ä¢ Reduce FLOPs \n‚Ä¢ Pruning,']","['<1-hop>\n\nShuffle \nüîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them.\n‚Ä¢ If you run 30 executions for version A and another batch for version B:\n‚Ä¢ External conditions that change over time will have a diÔ¨Äerent bias in \nthe 2 versions (e.g., room temperature changes).\n‚Ä¢ If you shuÔ¨Ñe, you reduce this risk.\n11', '<2-hop>\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio)\n‚Ä¢ Dynamic Retry Delay\n‚Ä¢ Push Over Poll\n‚Ä¢ Reduce Size\n‚Ä¢ Cache\n‚Ä¢ Avoid Graphics and Animations\n20', '<1-hop>\n\nShuffle \nüîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them.\n‚Ä¢ If you run 30 executions for version A and another batch for version B:\n‚Ä¢ External conditions that change over time will have a diÔ¨Äerent bias in \nthe 2 versions (e.g., room temperature changes).\n‚Ä¢ If you shuÔ¨Ñe, you reduce this risk.\n11', '<2-hop>\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio)\n‚Ä¢ Dynamic Retry Delay\n‚Ä¢ Push Over Poll\n‚Ä¢ Reduce Size\n‚Ä¢ Cache\n‚Ä¢ Avoid Graphics and Animations\n20']","EcoAndroid reduces risk by reducing size through techniques such as caching and avoiding graphics and animations. By minimizing the size of data and resources used, the app can operate more efficiently, which can lead to lower energy consumption and improved performance. This approach helps in mitigating risks associated with excessive resource usage and potential performance bottlenecks.",EcoAndroid reduce risk by using Reduce Size feature which help minimize energy consumption and reduce impact of external factors like temperature changes.,0.0,0.5,0.14285714285714285,0.67,0.249999999375,0.9484229489049844
How can static code analysis in data science be used to improve the energy efficiency of data centers and contribute to sustainable software engineering?,"['Energy profiling of static analysis tools\n‚Ä¢ What is the energy consumption of a ""typical run"" for a few OSS projects? \n‚Ä¢ Does the type of analysis matter? Are certain analysis more expensive? Does \nthe number of rules that are activated in a static analysis tool important for the \nenergy consumption? \n‚Ä¢ Differences between static analysis tools [lower priority]\n\nB5.', '‚Ä¢ => Improve data collection, data labelling, and data preprocessing. \n‚Ä¢ More about data-centric AI by Andrew Ng:\u2028\nhttps://www.youtube.com/watch?v=06-AZXmwHjo\n15\n\n\nGreen Data-centric AI\n‚Ä¢ How do different ML algorithms compare \nin terms of energy consumption? \n‚Ä¢ How does number of rows relate to the \nenergy consumption of ML models? \n‚Ä¢ How does number of features relate to \nthe energy consumption of ML models? \n‚Ä¢ What is the impact of reducing data in the \nperformance of the model?', '19\n(?)\n\nResults: energy consumption of algorithms\n\nResults: energy vs data shape\n\nResults: performance vs data shape\n\nDiscussion\n‚Ä¢ Other data properties should be investigated. \n‚Ä¢ E.g., data types \n‚Ä¢ Reporting energy data is essential. It can lead to different model selection \nwithout hindering model performance. \n‚Ä¢ There is a big opportunity in Model and Data Simplification.\n23\n\nData/Model Simplification\n‚Ä¢ (?) \n‚Ä¢ Data selection \n‚Ä¢ Data quantisation. Posit? \n‚Ä¢ Data distillation \n‚Ä¢ Coreset extraction (?)']","['<1-hop>\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy eÔ¨Éciency using static code analysis.\n‚Ä¢ We don‚Äôt need an accurate value.\n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.\n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27', '<2-hop>\n\nWhy?\n‚Ä¢ Throughout your career you might:\n‚Ä¢ Design/maintain/contract data centers\n‚Ä¢ Set up operations/devops\n‚Ä¢ Develop AI for IoT devices\n‚Ä¢ Be the next CEO/CTO of a software company\n‚Ä¢ Sustainability can be your main role:\n‚Ä¢ Green Software Developer\n‚Ä¢ Sustainability Consultant\n‚Ä¢ Green Advocate \n‚Ä¢ Founder of a Green Tech startup (B2B?)\n28', '<1-hop>\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy eÔ¨Éciency using static code analysis.\n‚Ä¢ We don‚Äôt need an accurate value.\n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.\n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27', '<2-hop>\n\nWhy?\n‚Ä¢ Throughout your career you might:\n‚Ä¢ Design/maintain/contract data centers\n‚Ä¢ Set up operations/devops\n‚Ä¢ Develop AI for IoT devices\n‚Ä¢ Be the next CEO/CTO of a software company\n‚Ä¢ Sustainability can be your main role:\n‚Ä¢ Green Software Developer\n‚Ä¢ Sustainability Consultant\n‚Ä¢ Green Advocate \n‚Ä¢ Founder of a Green Tech startup (B2B?)\n28', '<1-hop>\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy eÔ¨Éciency using static code analysis.\n‚Ä¢ We don‚Äôt need an accurate value.\n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.\n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27', '<2-hop>\n\nWhy?\n‚Ä¢ Throughout your career you might:\n‚Ä¢ Design/maintain/contract data centers\n‚Ä¢ Set up operations/devops\n‚Ä¢ Develop AI for IoT devices\n‚Ä¢ Be the next CEO/CTO of a software company\n‚Ä¢ Sustainability can be your main role:\n‚Ä¢ Green Software Developer\n‚Ä¢ Sustainability Consultant\n‚Ä¢ Green Advocate \n‚Ä¢ Founder of a Green Tech startup (B2B?)\n28', '<1-hop>\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy eÔ¨Éciency using static code analysis.\n‚Ä¢ We don‚Äôt need an accurate value.\n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.\n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27', '<2-hop>\n\nWhy?\n‚Ä¢ Throughout your career you might:\n‚Ä¢ Design/maintain/contract data centers\n‚Ä¢ Set up operations/devops\n‚Ä¢ Develop AI for IoT devices\n‚Ä¢ Be the next CEO/CTO of a software company\n‚Ä¢ Sustainability can be your main role:\n‚Ä¢ Green Software Developer\n‚Ä¢ Sustainability Consultant\n‚Ä¢ Green Advocate \n‚Ä¢ Founder of a Green Tech startup (B2B?)\n28']","Static code analysis in data science can improve the energy efficiency of data centers and contribute to sustainable software engineering in several ways:

1. **Optimizing Code for Efficiency**: Static analysis tools can identify inefficient code patterns that consume more energy. By optimizing these patterns, developers can reduce the energy consumption of software applications.

2. **Reducing Redundant Computations**: Static analysis can detect redundant computations or unnecessary data processing steps, allowing developers to streamline code execution and reduce energy usage.

3. **Improving Resource Management**: By analyzing code, static analysis tools can suggest better resource management practices, such as efficient memory usage and optimal data storage solutions, which can lead to lower energy consumption.

4. **Identifying Energy-Intensive Operations**: Static analysis can highlight operations that are particularly energy-intensive, enabling developers to refactor or replace them with more energy-efficient alternatives.

5. **Guiding Data-Centric Improvements**: As mentioned in the sources, improving data collection, labeling, and preprocessing can contribute to energy efficiency. Static analysis can help ensure that data handling in software is optimized for minimal energy use.

By incorporating static code analysis into the software development lifecycle, data centers can achieve more energy-efficient operations, aligning with the goals of sustainable software engineering.","Static code analysis in data science can be used to estimate energy efficiency by identifying potential energy hotspots in the code. This helps in reviewing and optimizing the code to reduce energy consumption. By applying this approach, developers can contribute to the design and maintenance of more energy-efficient data centers, aligning with sustainable software engineering practices.",0.0,1.0,1.0,0.67,0.0,0.996656445430904
How can static code analysis in data science contribute to the development of more sustainable data centers?,"['Debugging Energy with \nDocker Images\n\nUnveiling the Energy Vampires \nA methodology for debugging Software \nEnergy Consumption\n ‚úÖ ICSE 2025\n\nData Centers and Docker\n‚Ä¢ Containers are the most popular way to deploy apps into the cloud \n‚Ä¢ Base image is an important choice when building an image \n‚Ä¢ Criteria \n‚Ä¢ Linux distribution and binaries \n‚Ä¢ Image size \n‚Ä¢ Energy?', '‚Ä¢ Libraries for stats? ML? Web Dev? Cloud?\n\nC5. Add energy-awareness to existing software\n26\n‚Ä¢ Streamlit, Notebooks, JSFiddle, \nPyScript, zsh, etc. \n‚Ä¢\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy efficiency using static code analysis. \n‚Ä¢ We don‚Äôt need an accurate value. \n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.', '19\n(?)\n\nResults: energy consumption of algorithms\n\nResults: energy vs data shape\n\nResults: performance vs data shape\n\nDiscussion\n‚Ä¢ Other data properties should be investigated. \n‚Ä¢ E.g., data types \n‚Ä¢ Reporting energy data is essential. It can lead to different model selection \nwithout hindering model performance. \n‚Ä¢ There is a big opportunity in Model and Data Simplification.\n23\n\nData/Model Simplification\n‚Ä¢ (?) \n‚Ä¢ Data selection \n‚Ä¢ Data quantisation. Posit? \n‚Ä¢ Data distillation \n‚Ä¢ Coreset extraction (?)']","['<1-hop>\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy eÔ¨Éciency using static code analysis.\n‚Ä¢ We don‚Äôt need an accurate value.\n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.\n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27', '<2-hop>\n\nWhy?\n‚Ä¢ Throughout your career you might:\n‚Ä¢ Design/maintain/contract data centers\n‚Ä¢ Set up operations/devops\n‚Ä¢ Develop AI for IoT devices\n‚Ä¢ Be the next CEO/CTO of a software company\n‚Ä¢ Sustainability can be your main role:\n‚Ä¢ Green Software Developer\n‚Ä¢ Sustainability Consultant\n‚Ä¢ Green Advocate \n‚Ä¢ Founder of a Green Tech startup (B2B?)\n28']","Static code analysis can contribute to the development of more sustainable data centers by estimating energy efficiency. This process helps identify which parts of the code are more likely to introduce energy hotspots. By reviewing and optimizing these areas, developers can reduce the energy consumption of their applications, leading to more energy-efficient software deployments in data centers. This approach aligns with the ""Green Shift Left"" methodology, which emphasizes the importance of considering energy efficiency early in the software development process.","Static code analysis in data science can contribute to the development of more sustainable data centers by estimating energy efficiency and identifying potential energy hotspots within the code. This approach allows developers to focus on reviewing code segments that are more likely to introduce inefficiencies, thereby optimizing resource usage. By integrating such practices, especially in domains like data science, developers can help create more sustainable solutions, which aligns with broader career goals in sustainability, such as designing or maintaining energy-efficient data centers.",0.49999999995,0.6666666666666666,1.0,0.57,0.0,0.9846241457649475
How can static code analysis in data science projects help in designing more sustainablility-focused data centers?,"['‚Ä¢ Libraries for stats? ML? Web Dev? Cloud?\n\nC5. Add energy-awareness to existing software\n26\n‚Ä¢ Streamlit, Notebooks, JSFiddle, \nPyScript, zsh, etc. \n‚Ä¢\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy efficiency using static code analysis. \n‚Ä¢ We don‚Äôt need an accurate value. \n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.', 'Green Architectural Tactics for ML-Enabled \nSystem\n38\nICSE-SEIS 2024\n\nArchitectural tactics\n39\n\nData-centric\n40\n‚Ä¢ Reduce data size \n‚Ä¢ Sampling \n‚Ä¢ Dimensionality reduction \n‚Ä¢ Quantization\n\nAlgorithm Design\n41\n‚Ä¢ Carefully select your algorithm \n‚Ä¢ You don‚Äôt need the fanciest \ntechniques\n\nModel Optimization\n42\n‚Ä¢ Add energy to training parameters \n‚Ä¢ Reduce FLOPs \n‚Ä¢ Pruning,', '‚Ä¢ Energy/Power is more useful at the software usecase level. \n‚Ä¢ Carbon is more useful at the infrastructure level (e.g., datacenter) or at the \nproject level (e.g., the impact of developing a full software project). \n‚Ä¢ Choose your metrics wisely ;)\n26\n\n‚Ä¢ Carbon emissions ‚úÖ \n‚Ä¢ How do we go from energy consumption to carbon consumption?\n27\n\nCarbon intensity\n‚Ä¢ How much carbon is emitted per kWh of electricity consumed. \n‚Ä¢ The common unit: \n ü§∑ \n‚Ä¢ E.g.,  gas-based power plants emit less carbon than coal-based plants.']","['<1-hop>\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy eÔ¨Éciency using static code analysis.\n‚Ä¢ We don‚Äôt need an accurate value.\n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.\n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27', '<2-hop>\n\nWhy?\n‚Ä¢ Throughout your career you might:\n‚Ä¢ Design/maintain/contract data centers\n‚Ä¢ Set up operations/devops\n‚Ä¢ Develop AI for IoT devices\n‚Ä¢ Be the next CEO/CTO of a software company\n‚Ä¢ Sustainability can be your main role:\n‚Ä¢ Green Software Developer\n‚Ä¢ Sustainability Consultant\n‚Ä¢ Green Advocate \n‚Ä¢ Founder of a Green Tech startup (B2B?)\n28', '<1-hop>\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy eÔ¨Éciency using static code analysis.\n‚Ä¢ We don‚Äôt need an accurate value.\n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.\n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27', '<2-hop>\n\nWhy?\n‚Ä¢ Throughout your career you might:\n‚Ä¢ Design/maintain/contract data centers\n‚Ä¢ Set up operations/devops\n‚Ä¢ Develop AI for IoT devices\n‚Ä¢ Be the next CEO/CTO of a software company\n‚Ä¢ Sustainability can be your main role:\n‚Ä¢ Green Software Developer\n‚Ä¢ Sustainability Consultant\n‚Ä¢ Green Advocate \n‚Ä¢ Founder of a Green Tech startup (B2B?)\n28', '<1-hop>\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy eÔ¨Éciency using static code analysis.\n‚Ä¢ We don‚Äôt need an accurate value.\n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.\n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27', '<2-hop>\n\nWhy?\n‚Ä¢ Throughout your career you might:\n‚Ä¢ Design/maintain/contract data centers\n‚Ä¢ Set up operations/devops\n‚Ä¢ Develop AI for IoT devices\n‚Ä¢ Be the next CEO/CTO of a software company\n‚Ä¢ Sustainability can be your main role:\n‚Ä¢ Green Software Developer\n‚Ä¢ Sustainability Consultant\n‚Ä¢ Green Advocate \n‚Ä¢ Founder of a Green Tech startup (B2B?)\n28']","Static code analysis in data science projects can help in designing more sustainability-focused data centers by identifying parts of the code that are likely to introduce energy hotspots. By estimating energy efficiency through static code analysis, developers can pinpoint inefficient code segments that may lead to higher energy consumption. This allows for targeted optimization efforts, reducing the overall energy demand of software applications. Consequently, this can lead to more efficient use of resources in data centers, contributing to their sustainability by lowering energy consumption and, indirectly, carbon emissions.","Static code analysis in data science projects can help in designing more sustainablility-focused data centers by identifying energy hotspots in the code. This allows developers to review and optimize code that may contribute to higher energy consumption, thereby supporting the development of more efficient and sustainable data centers.",0.9999999999,1.0,,1.0,0.0,0.9683760004857153
How does the use of static code analysis in data science projects contribute to the design and optimization of more sustanable data centers?,"['‚Ä¢ Libraries for stats? ML? Web Dev? Cloud?\n\nC5. Add energy-awareness to existing software\n26\n‚Ä¢ Streamlit, Notebooks, JSFiddle, \nPyScript, zsh, etc. \n‚Ä¢\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy efficiency using static code analysis. \n‚Ä¢ We don‚Äôt need an accurate value. \n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.', '‚Ä¢ DeepSeek-V3 claims ‚Äúonly‚Äù 2.78M GPU hours \n‚Ä¢ Bloom by Huggingface reports 25 tons, 51 when considering embodied \nand operational carbon footprint. (176billion params)\n9\n\nRed AI\nAccuracy: 0.999999999\nGreen AI\n‚Ä¢ Energy \n‚Ä¢ Time \n‚Ä¢ Reproducibility \n‚Ä¢ Reusage\n\nHow can we adopt Green AI\n‚Ä¢ Check whether AI is needed. \n‚Ä¢ Select green datacenters. \n‚Ä¢ Run on low carbon intensity hours. \n‚Ä¢ Opt for GPU-optimised solutions (?)', 'Energy profiling of static analysis tools\n‚Ä¢ What is the energy consumption of a ""typical run"" for a few OSS projects? \n‚Ä¢ Does the type of analysis matter? Are certain analysis more expensive? Does \nthe number of rules that are activated in a static analysis tool important for the \nenergy consumption? \n‚Ä¢ Differences between static analysis tools [lower priority]\n\nB5.']","['<1-hop>\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy eÔ¨Éciency using static code analysis.\n‚Ä¢ We don‚Äôt need an accurate value.\n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.\n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27', '<2-hop>\n\nWhy?\n‚Ä¢ Throughout your career you might:\n‚Ä¢ Design/maintain/contract data centers\n‚Ä¢ Set up operations/devops\n‚Ä¢ Develop AI for IoT devices\n‚Ä¢ Be the next CEO/CTO of a software company\n‚Ä¢ Sustainability can be your main role:\n‚Ä¢ Green Software Developer\n‚Ä¢ Sustainability Consultant\n‚Ä¢ Green Advocate \n‚Ä¢ Founder of a Green Tech startup (B2B?)\n28', '<1-hop>\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy eÔ¨Éciency using static code analysis.\n‚Ä¢ We don‚Äôt need an accurate value.\n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.\n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27', '<2-hop>\n\nWhy?\n‚Ä¢ Throughout your career you might:\n‚Ä¢ Design/maintain/contract data centers\n‚Ä¢ Set up operations/devops\n‚Ä¢ Develop AI for IoT devices\n‚Ä¢ Be the next CEO/CTO of a software company\n‚Ä¢ Sustainability can be your main role:\n‚Ä¢ Green Software Developer\n‚Ä¢ Sustainability Consultant\n‚Ä¢ Green Advocate \n‚Ä¢ Founder of a Green Tech startup (B2B?)\n28']","The use of static code analysis in data science projects can contribute to the design and optimization of more sustainable data centers by identifying energy hotspots in the code. By estimating energy efficiency through static code analysis, developers can pinpoint which parts of the code are likely to consume more energy and should be reviewed more attentively. This process doesn't require precise energy values but helps in identifying areas that could be optimized to reduce energy consumption. Consequently, optimizing these areas can lead to more efficient use of resources in data centers, thereby contributing to sustainability efforts.","The use of static code analysis in data science projects contributes to the design and optimization of more sustainable data centers by identifying energy hotspots within the code. This process allows developers to focus on reviewing and optimizing sections of code that are more likely to introduce energy inefficiencies. By doing so, it supports the broader goal of creating more energy-efficient systems, which is crucial for the sustainable operation of data centers. This approach aligns with the growing need for green software development practices, where professionals can play roles such as green software developers or sustainability consultants, ensuring that energy efficiency is a key consideration throughout the software lifecycle.",0.9999999999,0.75,1.0,0.75,0.09090909082644627,0.9801163369424023
How reduce risk and reduce size in software engineering?,"['Green Architectural Tactics for ML-Enabled \nSystem\n38\nICSE-SEIS 2024\n\nArchitectural tactics\n39\n\nData-centric\n40\n‚Ä¢ Reduce data size \n‚Ä¢ Sampling \n‚Ä¢ Dimensionality reduction \n‚Ä¢ Quantization\n\nAlgorithm Design\n41\n‚Ä¢ Carefully select your algorithm \n‚Ä¢ You don‚Äôt need the fanciest \ntechniques\n\nModel Optimization\n42\n‚Ä¢ Add energy to training parameters \n‚Ä¢ Reduce FLOPs \n‚Ä¢ Pruning, sparsity \n‚Ä¢  Take advantage of existing models\n\nModel Training\n43\n‚Ä¢ Quantization\n‚Ä¢ SAVE TRAINING PROGRESS\n\nModel Deployment\n44\n‚Ä¢ Distributed deployment \n‚Ä¢ Energy efficient hardware and \nconfigurations\n\nModel Management\n45\n‚Ä¢ Reuse the model as much as possible \n\nRethinking the Architecture: Spiking Neural Networks\n46\n\nRethinking the Architecture: Spiking Neural Networks\n47\n\nSELF Lab\n48\n\nrecap\n\n\nLu√≠s Cruz \nL.Cruz@tudelft.nl \n10. Project 2\nSustainable Software Engineering\u2028\nCS4575\nSustainableSE 2025\nCarolin Brandt \nC.E.Brandt@tudelft.nl \nEnrique Barba Roque \nE.BarbaRoque@tudelft.nl\n\n1. Goal/assignment \n2. Deliverables \n3. Strategy \n4. Ideas\n\nAssignment\n‚Ä¢ Goal: Solve a Sustainable Software Engineering problem. \n‚Ä¢ Identify 1 problem that should be fixed to help enabling sustainability in \nthe software engineering industry/community. \n‚Ä¢ Propose a solution. A tool, framework, guidelines, etc. \n‚Ä¢ Implementation. \n‚Ä¢ Validation. (Depending on the idea) \n‚Ä¢ Dissemination/social impact. (Solution should be open source, welcome \ncontributors, post on social media? Tool website? Available in a package \nmanager?)\n3\n\nDeliverables\n‚Ä¢ Paper-like article. (Min 4 pages, max 10) \n‚Ä¢ Online git repo with open source codebase and/or replication package. \n‚Ä¢ Presentation: 5 min + 5min Q&A\n4\n\nArticle\n‚Ä¢ Different projects will have different expectations -> Make agreements with \nyour coach. \n‚Ä¢ Some projects are more technical and some projects more theoretical. \n‚Ä¢ Common requirements: \n‚Ä¢ Motivation, formulation of the problem being addressed, etc. \n‚Ä¢ Description of the solution.', 'Energy Efficiency vs Code \nQuality\n\nMeasuring Maintainability\n‚Ä¢ According to ISO/IEC 25010, Maintainability is ‚Äúthe degree of \neffectiveness and efficiency with which a software product or \nsystem can be modified to improve it, correct it or adapt it to \nchanges in environment, and in requirements‚Äù \n‚Ä¢ We use the code analysis tool Better Code Hub to assess \nmaintainability \n‚Ä¢ Better Code Hub maps the ISO/IEC 25010 standard on \nmaintainability into a set of guidelines derived from static analysis\n46\n\nMaintainability of Energy Changes\n‚Ä¢ What is the impact of making energy-oriented code changes on \nthe maintainability of mobile apps? \nMaintainability \nDifference \nvE-2\nvE-1\nvE\nEnergy \nCommit\nvE+1\nM(vE-1)\nM(vE)\nParent \nCommit\n‚àÜM\n47\n\nThreshold Marks\n48\n\nBetter Code Hub\nMaintainability\nCombine\ndatasets\nEnergy\nCommits\nBaseline\nCommits\nBao et al. \n(2015)\nMoura et al. \n(2016)\nCruz et al. \n(2018)\nCruz et al. \n(2019)\nEnergy Code Changes \nDataset\n539 commits\u2028\nfrom 306 mobile apps\n539 baseline commits\u2028\nfrom 306 mobile apps\n49\n\nImpact of energy changes on \nmaintainability\n50\n\nWhich energy \npatterns are more \nlikely to affect \nmaintainability?\n51\n\nTypical maintainability issue I\nhttps://github.com/einmalfel/PodListen/commit/2ed5a65\n4 changed files with 28 additions and 0 deletions.\n‚Ä¶\n‚Ä¶\n52\n\nTypical maintainability issue II\nhttps://github.com/mozilla/MozStumbler/commit/6ea0268\n5 changed files with 66 additions and 14 deletions.\n53\n\n54', 'Carolin Brandt \nC.E.Brandt@tudelft.nl \nLu√≠s Cruz \nL.Cruz@tudelft.nl \n1. Intro Class\nSustainable Software Engineering\u2028\nCS4575\nSustainableSE 2025\nEnrique Barba Roque \nE.BarbaRoque@tudelft.nl\n\n1. Intro to Sustainable SE \n2. Intro to the course\n2\n\nof the electricity consumed worldwide \nby 2040 will stem from ICT\n14%\n\n4\nhttps://xkcd.com/1007/\n\nBuzz words\n‚Ä¢ Eco-friendly \n‚Ä¢ Climate change, action, adaption \n‚Ä¢ Energy efficiency \n‚Ä¢ Environmental-responsible \n‚Ä¢ Carbon-neutral; Climate-neutral; Net zero \n‚Ä¢ Carbon-offsetting \n‚Ä¢ Carbon-free \n‚Ä¢ Clean technology \n‚Ä¢ E-waste\n5\n\nhttps://www.menti.com/uns9d89kzn\nWhat is Sustainable \nSoftware Engineering?\n?\n6\n\nSustainable Software \nEngineering is‚Ä¶\n7\n‚Ä¶the discipline that studies the process of creating software systems that are able \nto create value in the long term without hindering its surrounding environment.\n\n8\nEconomical\nSocial\nTechnical\nIndividual\nEnvironmental\nSustainable\nSoftware\nEngineering\n‚≠ê\nTechnical\u2028\n‚öô\nEconomical\u2028\nüí∞\nSocial\u2028\nüë©üíºüë®üíºüë©üíºüë©üíº\nIndividual\u2028\nüë©üíª\nEnvironmental\u2028\nüå±\nSustainable\u2028\nSoftware \nEngineering\n\nEconomical\n‚Ä¢ Focused on assets, capital and added value\u2028\n(wealth creation, prosperity, profitability, capital \ninvestment, income, etc.) \n‚Ä¢ Nr of customers  \n‚Ä¢ Man-day-rate estimate \n‚Ä¢ Next round of funding \n‚Ä¢ Meet requirements in the contract\n9\n\nTechnical\n‚Ä¢ Longevity of information, systems, and infrastructure and their \nadequate evolution with changing surrounding conditions. \n‚Ä¢ Examples: \n‚Ä¢ Technical Debt \n‚Ä¢ Does it scale? \n‚Ä¢ Software testing \n‚Ä¢ Bus-factor \n‚Ä¢ Data integrity \n‚Ä¢ Innovation \n‚Ä¢ ‚Ä¶\n10\n\nIndividual\n‚Ä¢ Well-being of the individuals in an organisation.\u2028\nNote that it also includes how well individuals interact \nwith each other within the org.']","['<1-hop>\n\nShuffle \nüîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them.\n‚Ä¢ If you run 30 executions for version A and another batch for version B:\n‚Ä¢ External conditions that change over time will have a diÔ¨Äerent bias in \nthe 2 versions (e.g., room temperature changes).\n‚Ä¢ If you shuÔ¨Ñe, you reduce this risk.\n11', '<2-hop>\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio)\n‚Ä¢ Dynamic Retry Delay\n‚Ä¢ Push Over Poll\n‚Ä¢ Reduce Size\n‚Ä¢ Cache\n‚Ä¢ Avoid Graphics and Animations\n20', '<1-hop>\n\nShuffle \nüîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them.\n‚Ä¢ If you run 30 executions for version A and another batch for version B:\n‚Ä¢ External conditions that change over time will have a diÔ¨Äerent bias in \nthe 2 versions (e.g., room temperature changes).\n‚Ä¢ If you shuÔ¨Ñe, you reduce this risk.\n11', '<2-hop>\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio)\n‚Ä¢ Dynamic Retry Delay\n‚Ä¢ Push Over Poll\n‚Ä¢ Reduce Size\n‚Ä¢ Cache\n‚Ä¢ Avoid Graphics and Animations\n20']","To reduce risk and reduce size in software engineering, you can employ several strategies:

1. **Reduce Data Size**: Implement data-centric tactics such as sampling, dimensionality reduction, and quantization to minimize the amount of data processed and stored.

2. **Algorithm Design**: Carefully select algorithms that are efficient and effective without being unnecessarily complex. Avoid using the most complex techniques if simpler ones suffice.

3. **Model Optimization**: Optimize models by reducing the number of floating-point operations (FLOPs), using pruning and sparsity techniques, and leveraging existing models to avoid redundant work.

4. **Model Training**: Use quantization and save training progress to prevent unnecessary re-computation and reduce the computational load.

5. **Model Deployment**: Deploy models in a distributed manner and use energy-efficient hardware configurations to minimize resource usage.

By implementing these tactics, you can effectively reduce both the risk and size of software systems, leading to more sustainable and efficient software engineering practices.","To reduce risk, shuffling executions helps control external factors like temperature changes. To reduce size, EcoAndroid uses features like dynamic retry delay and push over poll.",0.0,0.0,0.8666666666666667,0.17,0.0,0.9808039774417124
How shuffling reduce risk and EcoAndroid reduce size?,"['‚Ä¢ When a connection is not possible, the app automatically retries later. \n‚Ä¢ https://github.com/k9mail/k-9/commit/\n86f3b28f79509d1a4d613eb39f60603e08579ea3\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio) \n‚Ä¢ Dynamic Retry Delay \n‚Ä¢ Push Over Poll \n‚Ä¢ Reduce Size \n‚Ä¢ Cache \n‚Ä¢ Avoid Graphics and Animations\n20\n\nCarbon-Aware Computing for \nDatacenters \nhttps://sites.google.com/view/energy-efficiency-languages\n21\nAna Radovanovic ÃÅ,', '*/\n6028 \nchanges\n\nThematic Analysis\n1. Familiarization with data \n2. Generating initial labels \n3. Reviewing themes\n4. Defining and naming themes\n\n‚Ä¢ Energy Pattern: design pattern to improve energy efficiency.. \n‚Ä¢ 22 energy patterns. \n‚Ä¢ Each pattern is described by Context, Solution, Example, References from \nliterature, and Occurences (links to code changes from git repositories).\n8\n\nhttps://tqrg.github.io/energy-patterns\n\nDark UI Colors \nProvide a dark UI color theme to \nsave battery on devices with \nAMOLED screens.\n‚Ä¢ Context: [‚Ä¶] Apps that require heavy usage of screen can \nhave a substantial negative impact on battery life. \n‚Ä¢ Solution: Provide a UI theme with dark background colors. [‚Ä¶]\n‚Ä¢ Example: In a reading app, provide a theme with a dark \nbackground using light colors to display text. [‚Ä¶] \n10\n\nDark UI Colors \nProvide a dark UI color theme to \nsave battery on devices with \nAMOLED screens.\n‚Ä¢ Context: [‚Ä¶] Apps that require heavy usage of screen can \nhave a substantial negative impact on battery life. \n‚Ä¢ Solution: Provide a UI theme with dark background colors. [‚Ä¶]\n‚Ä¢ Example: In a reading app, provide a theme with a dark \nbackground using light colors to display text. [‚Ä¶] \n11\n\nDynamic Retry Delay\n‚Ä¢ Context: [‚Ä¶] In a mobile app, when a given resource is \nunavailable, the app will unnecessarily try to connect the resource \nfor a number of times, leading to unnecessary power consumption. \n‚Ä¢ Solution: Increase retry interval after each failed connection. [‚Ä¶]\n‚Ä¢ Example: Consider a mobile app that provides a news feed and \nthe app is not able to reach the server to collect updates. [‚Ä¶] use \nthe Fibonacci series to increase the time between attempts.\nWhenever an attempt to access a \nresource fails, increase the time \ninterval before retrying.\n12\n\nBatch Operations \n‚Ä¢ Context: Executing operations separately leads to extraneous \ntail energy consumptions  \n‚Ä¢ Solution: Bundle multiple operations in a single one. [‚Ä¶]\n‚Ä¢ Example: Use system provided APIs to schedule background \ntasks. These APIs, guarantee that device will exit sleep mode \nonly when there is a reasonable amount of work to do or when a \ngiven task is urgent. [‚Ä¶]\n13\n\nAvoid Extraneous Graphics and \nAnimations  \n‚Ä¢ Context: Mobile apps that feature impressive graphics \nand animations.', '19\n(?)\n\nResults: energy consumption of algorithms\n\nResults: energy vs data shape\n\nResults: performance vs data shape\n\nDiscussion\n‚Ä¢ Other data properties should be investigated. \n‚Ä¢ E.g., data types \n‚Ä¢ Reporting energy data is essential. It can lead to different model selection \nwithout hindering model performance. \n‚Ä¢ There is a big opportunity in Model and Data Simplification.\n23\n\nData/Model Simplification\n‚Ä¢ (?) \n‚Ä¢ Data selection \n‚Ä¢ Data quantisation. Posit? \n‚Ä¢ Data distillation \n‚Ä¢ Coreset extraction (?)']","['<1-hop>\n\nShuffle \nüîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them.\n‚Ä¢ If you run 30 executions for version A and another batch for version B:\n‚Ä¢ External conditions that change over time will have a diÔ¨Äerent bias in \nthe 2 versions (e.g., room temperature changes).\n‚Ä¢ If you shuÔ¨Ñe, you reduce this risk.\n11', '<2-hop>\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio)\n‚Ä¢ Dynamic Retry Delay\n‚Ä¢ Push Over Poll\n‚Ä¢ Reduce Size\n‚Ä¢ Cache\n‚Ä¢ Avoid Graphics and Animations\n20', '<1-hop>\n\nShuffle \nüîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them.\n‚Ä¢ If you run 30 executions for version A and another batch for version B:\n‚Ä¢ External conditions that change over time will have a diÔ¨Äerent bias in \nthe 2 versions (e.g., room temperature changes).\n‚Ä¢ If you shuÔ¨Ñe, you reduce this risk.\n11', '<2-hop>\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio)\n‚Ä¢ Dynamic Retry Delay\n‚Ä¢ Push Over Poll\n‚Ä¢ Reduce Size\n‚Ä¢ Cache\n‚Ä¢ Avoid Graphics and Animations\n20', '<1-hop>\n\nShuffle \nüîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them.\n‚Ä¢ If you run 30 executions for version A and another batch for version B:\n‚Ä¢ External conditions that change over time will have a diÔ¨Äerent bias in \nthe 2 versions (e.g., room temperature changes).\n‚Ä¢ If you shuÔ¨Ñe, you reduce this risk.\n11', '<2-hop>\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio)\n‚Ä¢ Dynamic Retry Delay\n‚Ä¢ Push Over Poll\n‚Ä¢ Reduce Size\n‚Ä¢ Cache\n‚Ä¢ Avoid Graphics and Animations\n20']","The sources provided do not specifically mention how shuffling reduces risk or how EcoAndroid reduces size. However, based on general knowledge:

1. **Shuffling to Reduce Risk**: In the context of data processing or machine learning, shuffling data can help reduce the risk of overfitting by ensuring that the model does not learn the order of the data, which might contain patterns not representative of the general data distribution.

2. **EcoAndroid Reducing Size**: EcoAndroid likely reduces size by optimizing the app's code and resources, possibly by avoiding unnecessary graphics and animations, caching data efficiently, and using other techniques to minimize the app's footprint on the device. This can lead to reduced energy consumption and better performance on mobile devices.",Shuffling reduce risk by controlling external factors like room temperature changes. EcoAndroid reduce size by using features like caching and avoiding graphics and animations.,0.0,0.5,0.6,0.0,0.16666666638888888,0.0
How shuffling reduce risk when compare to EcoAndroid reduce size?,"['‚Ä¢ When a connection is not possible, the app automatically retries later. \n‚Ä¢ https://github.com/k9mail/k-9/commit/\n86f3b28f79509d1a4d613eb39f60603e08579ea3\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio) \n‚Ä¢ Dynamic Retry Delay \n‚Ä¢ Push Over Poll \n‚Ä¢ Reduce Size \n‚Ä¢ Cache \n‚Ä¢ Avoid Graphics and Animations\n20\n\nCarbon-Aware Computing for \nDatacenters \nhttps://sites.google.com/view/energy-efficiency-languages\n21\nAna Radovanovic ÃÅ,', 'Green Architectural Tactics for ML-Enabled \nSystem\n38\nICSE-SEIS 2024\n\nArchitectural tactics\n39\n\nData-centric\n40\n‚Ä¢ Reduce data size \n‚Ä¢ Sampling \n‚Ä¢ Dimensionality reduction \n‚Ä¢ Quantization\n\nAlgorithm Design\n41\n‚Ä¢ Carefully select your algorithm \n‚Ä¢ You don‚Äôt need the fanciest \ntechniques\n\nModel Optimization\n42\n‚Ä¢ Add energy to training parameters \n‚Ä¢ Reduce FLOPs \n‚Ä¢ Pruning,', '[‚Ä¶] \n‚Ä¢ Solution: Study the importance of graphics and \nanimations to the user experience and reduce them when \napplicable. [‚Ä¶]\n‚Ä¢ Example: Resort to low frame rates for animations when \npossible. \nDespite being important to improve user experience, graphics \nand animations are battery intensive and should be used with \nmoderation.  \n14\n\nEnergy Patterns are \nmore Frequent\nin Android Apps\n\nExample case: Nextcloud\nFOSS\n\nExample case: Nextcloud\n‚Ä¢ Users complain that sometimes they go on a trip and  Nextcloud drains their \nbattery. Users consider uninstalling the app when battery life is essential. \n‚Ä¢ File sync can be energy-greedy. Send large files to the server, long 3G/4G data connections. \n‚Ä¢ It is mostly used for backup. No real-time collaboration is needed. \n‚Ä¢ Energy requirements vary depending on context and user. Some days you really \nneed all the battery you can get. \n‚Ä¢ https://github.com/nextcloud/android/commit/\n8bc432027e0d33e8043cf40192203203a40ca29c\nSolutions?\n17\n\nExample case: K-9 mail\n18\n\nExample case: K-9 mail\n19\nSolutions?\n‚Ä¢ Some users noticed that K-9 mail was spending more energy than usual. üôâ \n‚Ä¢ A user that was having issues with a personal mail server  noticed that K-9 \nmail was the one of the most energy-greedy apps. IMAP IDLE protocol for real-time \nnotifications. \n‚Ä¢ When a connection is not possible, the app automatically retries later.']","['<1-hop>\n\nShuffle \nüîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them.\n‚Ä¢ If you run 30 executions for version A and another batch for version B:\n‚Ä¢ External conditions that change over time will have a diÔ¨Äerent bias in \nthe 2 versions (e.g., room temperature changes).\n‚Ä¢ If you shuÔ¨Ñe, you reduce this risk.\n11', '<2-hop>\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio)\n‚Ä¢ Dynamic Retry Delay\n‚Ä¢ Push Over Poll\n‚Ä¢ Reduce Size\n‚Ä¢ Cache\n‚Ä¢ Avoid Graphics and Animations\n20']","The provided sources do not mention ""shuffling"" in the context of reducing risk, nor do they provide a direct comparison between shuffling and EcoAndroid's tactic of reducing size. However, in general terms, shuffling data can help in reducing risk by ensuring that data is not processed or stored in a predictable order, which can enhance security and privacy. On the other hand, EcoAndroid's tactic of reducing size focuses on minimizing resource usage, such as memory and processing power, which can lead to improved energy efficiency and performance. Both tactics aim to optimize different aspects of system performance and security.",Shuffling reduce risk by balance external factor like room temperature change while EcoAndroid reduce size by optimize resource use.,0.0,0.5,0.6666666666666666,0.29,0.249999999375,0.0
How shuffling reduce risk when reduce size in software engineering?,"['‚Ä¢ If you run 30 executions for version A and another batch for version B: \n‚Ä¢ External conditions that change over time will have a different bias in \nthe 2 versions (e.g., room temperature changes). \n‚Ä¢ If you shuffle, you reduce this risk.\n11\n\nKeep it cool üå°\n‚Ä¢ Always make sure there is a stable room temperature. \n‚Ä¢ Tricky because, some times, experiments may have to run over a few days. \n‚Ä¢ If you cannot control room temperature: collect temperature data and filter \nout measurements where the room temperature is clearly deviating.', 'Green Architectural Tactics for ML-Enabled \nSystem\n38\nICSE-SEIS 2024\n\nArchitectural tactics\n39\n\nData-centric\n40\n‚Ä¢ Reduce data size \n‚Ä¢ Sampling \n‚Ä¢ Dimensionality reduction \n‚Ä¢ Quantization\n\nAlgorithm Design\n41\n‚Ä¢ Carefully select your algorithm \n‚Ä¢ You don‚Äôt need the fanciest \ntechniques\n\nModel Optimization\n42\n‚Ä¢ Add energy to training parameters \n‚Ä¢ Reduce FLOPs \n‚Ä¢ Pruning, sparsity \n‚Ä¢  Take advantage of existing models\n\nModel Training\n43\n‚Ä¢ Quantization\n‚Ä¢ SAVE TRAINING PROGRESS\n\nModel Deployment\n44\n‚Ä¢ Distributed deployment \n‚Ä¢ Energy efficient hardware and \nconfigurations\n\nModel Management\n45\n‚Ä¢ Reuse the model as much as possible \n\nRethinking the Architecture: Spiking Neural Networks\n46\n\nRethinking the Architecture: Spiking Neural Networks\n47\n\nSELF Lab\n48\n\nrecap\n\n\nLu√≠s Cruz \nL.Cruz@tudelft.nl \n10. Project 2\nSustainable Software Engineering\u2028\nCS4575\nSustainableSE 2025\nCarolin Brandt \nC.E.Brandt@tudelft.nl \nEnrique Barba Roque \nE.BarbaRoque@tudelft.nl\n\n1. Goal/assignment \n2. Deliverables \n3. Strategy \n4. Ideas\n\nAssignment\n‚Ä¢ Goal: Solve a Sustainable Software Engineering problem. \n‚Ä¢ Identify 1 problem that should be fixed to help enabling sustainability in \nthe software engineering industry/community. \n‚Ä¢ Propose a solution. A tool, framework, guidelines, etc. \n‚Ä¢ Implementation. \n‚Ä¢ Validation. (Depending on the idea) \n‚Ä¢ Dissemination/social impact. (Solution should be open source, welcome \ncontributors, post on social media? Tool website? Available in a package \nmanager?)\n3\n\nDeliverables\n‚Ä¢ Paper-like article. (Min 4 pages, max 10) \n‚Ä¢ Online git repo with open source codebase and/or replication package. \n‚Ä¢ Presentation: 5 min + 5min Q&A\n4\n\nArticle\n‚Ä¢ Different projects will have different expectations -> Make agreements with \nyour coach. \n‚Ä¢ Some projects are more technical and some projects more theoretical. \n‚Ä¢ Common requirements: \n‚Ä¢ Motivation, formulation of the problem being addressed, etc. \n‚Ä¢ Description of the solution.', '‚Ä¢ What is the impact of reducing data in the \nperformance of the model? \n‚Ä¢ Method -> results -> discussion\n17\n\nMethod\n‚Ä¢ Single object of study: natural language model to detect spam messages. \n‚Ä¢ 6 machine learning algorithms: SVM, Decision Tree, KNN, Random Forrest, \nAdaBoost, Bagging Classifier. \n‚Ä¢ Reduce the number of rows. 10%, 20%, .., 100% \n‚Ä¢ Stratified random sampling (?) \n‚Ä¢ Reduce the number of features.']","['<1-hop>\n\nShuffle \nüîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them.\n‚Ä¢ If you run 30 executions for version A and another batch for version B:\n‚Ä¢ External conditions that change over time will have a diÔ¨Äerent bias in \nthe 2 versions (e.g., room temperature changes).\n‚Ä¢ If you shuÔ¨Ñe, you reduce this risk.\n11', '<2-hop>\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio)\n‚Ä¢ Dynamic Retry Delay\n‚Ä¢ Push Over Poll\n‚Ä¢ Reduce Size\n‚Ä¢ Cache\n‚Ä¢ Avoid Graphics and Animations\n20', '<1-hop>\n\nShuffle \nüîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them.\n‚Ä¢ If you run 30 executions for version A and another batch for version B:\n‚Ä¢ External conditions that change over time will have a diÔ¨Äerent bias in \nthe 2 versions (e.g., room temperature changes).\n‚Ä¢ If you shuÔ¨Ñe, you reduce this risk.\n11', '<2-hop>\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio)\n‚Ä¢ Dynamic Retry Delay\n‚Ä¢ Push Over Poll\n‚Ä¢ Reduce Size\n‚Ä¢ Cache\n‚Ä¢ Avoid Graphics and Animations\n20']","Shuffling reduces risk by minimizing the impact of external conditions that may change over time, such as room temperature, which can introduce bias in different versions of an experiment. By shuffling, you ensure that these external factors are evenly distributed across all versions, thereby reducing the risk of biased results when reducing data size in software engineering experiments.","Shuffling reduce risk by controlling external factors like room temperature changes, which help in reducing size in software engineering.",0.0,0.0,0.6,0.67,0.0,0.9544273024077174
How spiking neural networks relate to McCulloch-Pitts model?,"['References\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947.', 'Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012).', 'https://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997.']","[""<1-hop>\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant"", '<2-hop>\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \n(not publicly available) doi:10.1037/h0042519\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568', ""<1-hop>\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant"", '<2-hop>\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \n(not publicly available) doi:10.1037/h0042519\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568', ""<1-hop>\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant"", '<2-hop>\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \n(not publicly available) doi:10.1037/h0042519\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568']","Spiking neural networks (SNNs) and the McCulloch-Pitts model both represent approaches to modeling neural activity, but they differ significantly in their complexity and biological realism.

The McCulloch-Pitts model, introduced in 1943, is a simplified mathematical model of a neuron that uses binary threshold units to simulate neural activity. It operates on the principle that neurons either fire or do not fire based on whether the weighted sum of their inputs exceeds a certain threshold (Source 1).

Spiking neural networks, on the other hand, are considered the third generation of neural network models and aim to more closely mimic the temporal dynamics of biological neurons. SNNs incorporate the concept of time into their operation, where neurons communicate by sending discrete spikes at particular points in time. This allows SNNs to capture the timing of spikes, which is crucial for understanding many neural processes (Source 8).

In summary, while the McCulloch-Pitts model provides a foundational framework for understanding neural computation, spiking neural networks offer a more detailed and biologically plausible representation by incorporating the temporal aspect of neural signaling.","Spiking neural networks relate to the McCulloch-Pitts model by building upon the foundational concepts of neural computation, where the McCulloch-Pitts model introduced the idea of binary neuron states, which is extended in spiking networks to model more complex information processing through spike timing and patterns.",0.0,1.0,0.8666666666666667,0.92,0.0,0.9386147745268785
How spiking neural networks used in encoding strategies?,"[""‚Ä¶ with energy costs reaching 200M USD!\n\nPower-efficiency at scale\nYour brain runs on:\n\nPower-efficiency at scale\nYour brain runs on:\nHigh estimate ~3000 kcal a day\n   ‚âà145 Watts\n* Human brain has ~600 trillion synapses \n(‚âàparameters).\n\nPower-efficiency at scale\nYour brain runs on:\nHigh estimate ~3000 kcal a day\n   ‚âà145 Watts\n* Human brain has ~600 trillion synapses \n(‚âàparameters).\nOversimplification\nThere are also multiple other advantages‚Ä¶\n\nHuman vs. computer computation\n- Fast real-time decision making, e.g. sports, e-sports\n- Adaptive, e.g. context-aware and employs selective attention\n- Energy efficient: Close to 100 billion neurons in the brain\n- Robust, for example to changes in illumination or obstructions in object tracking\n\nHuman vs. computer computation\nBrains are energy efficient: Why?\n1.\nHigh temporal resolution (more computation with less neurons)\n2.\nSparse encoding\n\nHuman vs. computer computation\nQuestions?\nBrains are energy efficient: Why?\n1.\nHigh temporal resolution (more computation with less neurons)\n2.\nSparse encoding\n\nHow do biological neurons communicate?\nAnalogy to artificial neural networks\nReal neuron\nArtificial neuron\nCurrent\n\nHow do biological neurons communicate?\nHow does the electrical activity propagate?\n?\nCurrent\n\nHow do biological neurons work?\ntime\nelectrode\nhttps://tinmard.github.io/spike-sorting-animation.html\nQuick electrical pulses trigger chemical signals for the next neuron ‚Üí Spikes\n\nHow do biological neurons work?\nQuick electrical pulses trigger chemical signals for the next neuron ‚Üí Spikes\nhttps://tinmard.github.io/spike-sorting-animation.html\ntime\nelectrode\nFrom CS perspective:\nSparse binary \nencoding\n\nBiologically realistic spiking neuron models\nBiologically realistic neuron models have \na new dimension: Time!\nSpiking neural networks (SNNs):\nThe input x  (t  ) to each neuron is summed \n(integrated) over time.\nscalar\nfunction of \ntime\n(t)\n(t)\nhttps://www.mdpi.com/2076-3425/12/7/863\n\nHow to model spiking neurons?\nANN: Perceptron, threshold activation function:\n\nHow to model spiking neurons?\nANN: Perceptron, threshold activation function:\n\nHow to model spiking neurons?\nSpiking neural network (SNN): The 'input current' Œµ(t) is integrated over time.\nspike\n\nHow to model spiking neurons?\nEquivalence to perceptron: Computation at least as complex as a perceptron.\n\nNon-leaky integrate-and-fire (IF) neuron\nThe temporal profile of the input current Œµ(t) can be chosen differently, for different computations.\n\nQuestions?\n\nComputation with spiking neurons\nCoincidence detection\n\nComputation with spiking neurons\nCoincidence detection\nx, y ‚àà {0, 1}n\nExample: n = 2\ninput = \nx1\nx2\ny1\ny2\n= \n0\n1\n1\n1\noutput? \n\nCoincidence detection\nComputation with spiking neurons\n\nCoincidence detection\nCan be trivially computed with a single spiking neuron! Requires at least n/log(n+1) hidden \nunits for a perceptron (proof in [7]).\nComputation with spiking neurons\n\nCoincidence detection\nCan be trivially computed with a single spiking neuron! Requires at least n/log(n+1) hidden \nunits for a perceptron (proof in [7]).\nBrains are energy efficient: \n1.\nHigh temporal resolution (more computation with less neurons)\nComputation with spiking neurons\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant\n\nFiring rates\nClassical view of the brain:\n- Each neuron is selective for one specific \nfeature in the input.\n- Higher firing rate (spikes per unit time) for \n'selected' feature.\nAdapted from Hubel & Wiesel, 1959\n\nFiring rates\nClassical view of the brain:\n- Each neuron is selective for one specific \nfeature in the input.\n- Higher firing rate (spikes per unit time) for \n'selected' feature.\n- Link to modern ANNs: The scalar output of \nan artificial neuron is interpreted as the firing \nrate.\nAdapted from Hubel & Wiesel, 1959\n\nFiring rates\nClassical view of the brain:\n- Each neuron is selective for one specific \nfeature in the input.\n- Higher firing rate (spikes per unit time) for \n'selected' feature.\n- Link to modern ANNs: The scalar output of \nan artificial neuron is interpreted as the firing \nrate.\nAdapted from Hubel & Wiesel, 1959\nBut rate coding is inefficient and slow‚Ä¶\n(i.e. each neuron needs to fire many spikes to get good precision)\nboth in vivo and in silico.\n\nDifferent encoding strategies with spiking neurons [8]\n7 neurons\n7 time bins\n\nDifferent encoding strategies with spiking neurons\n7 neurons\n7 time bins\nn\n6\n(in the general \ncase a \nnumber \nbetween 0-7)\n\nDifferent encoding strategies with spiking neurons\n7 neurons\n7 time bins\nn\nTotal spike \ncount can \nencode 3 bits.\n\nDifferent encoding strategies with spiking neurons\n7 neurons\n7 time bins\nIndividual rates \ncan encode 7 \nbits.\n\nDifferent encoding strategies with spiking neurons\n7 neurons\n7 time bins\nLatency can \nencode ~3*7 or \n~19 bits.\n\nDifferent encoding strategies with spiking neurons\n7 neurons\n7 time bins\nRank order can \nencode ~12 bits.\n\nDifferent encoding strategies with spiking neurons\n\nDifferent encoding strategies with spiking neurons\nUsing latency or spatio-temporal codes\nour encoding is faster and more spike-efficient (sparser)!\n\nDifferent encoding strategies with spiking neurons\nUsing latency or spatio-temporal codes\nour encoding is faster and more spike-efficient (sparser)!\nQuestions?\n\nNeuromorphic computing\nWhat is the advantage for applications?\n-\nLess spikes = less energy consumption in specialized neuromorphic hardware\n(e.g. Intel Loihi [12])\nBrains are energy efficient: \n2. Sparse encoding\n\nMultiply-accumulate (MAC) operations:\nNormal neuron: Multiplies input with \nweights, then adds.\nSpiking neuron: Consider binary input (e.g. input currents are piecewise \nconstant and assume values {0,1}). There is no multiplication, only addition.\n\nAssume one multiplier and one adder circuit uses M and A energy respectively with AÔπ§M\n(e.g., for a 45nm CMOS process, standard energy usage is A = 0.9 pJ and M = 3.7 pJ).\nNormal neuron: nin x nout multiplications,\n(nin‚Äì 1) x nout additions\nSpiking neuron: 0 multiplications, (nactive‚Äì 1) x nout \nadditions, with nactive ‚â§ nin\nEnergy consumption:\nEnormal = M nin nout + A (nin‚Äì 1) nout = 17.5 pJ\nEnergy consumption:\nEspiking = A (nactive‚Äì 1) nout = 2.7 pJ\nMultiply-accumulate (MAC) operations:\n\nAssume one multiplier and one adder circuit uses M and A energy respectively with AÔπ§M\n(e.g., for a 45nm CMOS process, standard energy usage is A = 0.9 pJ and M = 3.7 pJ).\nNormal neuron: nin x nout multiplications,\n(nin‚Äì 1) x nout additions\nSpiking neuron: 0 multiplications, (nactive‚Äì 1) x nout \nadditions, with nactive ‚â§ nin\nEnergy consumption:\nEnormal = M nin nout + A (nin‚Äì 1) nout = 17.5 pJ\nEnergy consumption:\nEspiking = A (nactive‚Äì 1) nout = 2.7 pJ\nMultiply-accumulate (MAC) operations:\nSNN challenge: how to \ncompute with the least \namount of spikes!\n\nOften, we observe a \nsparsity (energy)-\ntask accuracy trade-off\n(Left: results for image \nclassification)\nSNN challenge: how to \ncompute with the least \namount of spikes!\nhttps://arxiv.org/pdf/2409.08290\n\nIn practice, energy \nconsumption computations \nare complex. \nNeed to take into account\n- memory access,\n- addressing,\n- auxiliary operations,\nin addition to MACs.\nEstimated energy consumption for 3 different datasets (CIFAR10, GSC, NCARS; image, sound \nand video classification respectively). FNN‚Äôs are conventional feed-forward neural networks.\nIn this example: SNNs are 6 to 8 times more energy efficient than FNNs.\nhttps://arxiv.org/pdf/2210.13107\nComputing energy consumption\n\nIn practice, energy \nconsumption computations \nare complex. \nNeed to take into account\n- memory access,\n- addressing,\n- auxiliary operations,\nin addition to MACs.\nEstimated energy consumption for 3 different datasets (CIFAR10, GSC, NCARS; image, sound \nand video classification respectively). FNN‚Äôs are conventional feed-forward neural networks."", 'Often, we observe a \nsparsity (energy)-\ntask accuracy trade-off\n(Left: results for image \nclassification)\nSNN challenge: how to \ncompute with the least \namount of spikes!\nhttps://arxiv.org/pdf/2409.08290\n\nIn practice, energy \nconsumption computations \nare complex. \nNeed to take into account\n- memory access,\n- addressing,\n- auxiliary operations,\nin addition to MACs.\nEstimated energy consumption for 3 different datasets (CIFAR10, GSC, NCARS; image, sound \nand video classification respectively).', 'Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945.']","[""<1-hop>\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant"", '<2-hop>\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \n(not publicly available) doi:10.1037/h0042519\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568']","Spiking neural networks (SNNs) use various encoding strategies to efficiently process information. These strategies include:

1. **Latency Encoding**: The timing of spikes is used to encode information. This method can encode a significant amount of data quickly and efficiently, as it relies on the precise timing of spikes rather than the rate of firing.

2. **Rate Encoding**: This classical view involves each neuron being selective for a specific feature, with the firing rate (spikes per unit time) representing the intensity of that feature. However, this method is considered inefficient and slow because it requires many spikes to achieve good precision.

3. **Rank Order Encoding**: This strategy uses the order in which neurons fire to encode information, which can be more efficient than rate encoding.

4. **Sparse Encoding**: SNNs often use sparse encoding, where fewer spikes are used to represent information, leading to reduced energy consumption. This is particularly advantageous in neuromorphic hardware, where less energy is consumed with fewer spikes.

These encoding strategies allow SNNs to be more energy-efficient and faster in processing information compared to traditional neural networks.",Spiking neural networks use single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0) to encode information about 'features' in a large network with many spikes. This approach is supported by foundational works such as McCulloch and Pitts' logical calculus of nervous activity and later developments in spiking neuron models.,0.0,0.5,1.0,0.29,,0.9524510480717829
What are the benefits of neuromorphic computing in the context of green software practices?,"['Questions?\n\nNeuromorphic computing\nWhat is the advantage for applications?\n-\nLess spikes = less energy consumption in specialized neuromorphic hardware\n(e.g. Intel Loihi [12])\nBrains are energy efficient: \n2. Sparse encoding\n\nMultiply-accumulate (MAC) operations:\nNormal neuron: Multiplies input with \nweights, then adds.\nSpiking neuron: Consider binary input (e.g. input currents are piecewise \nconstant and assume values {0,1}). There is no multiplication, only addition.', 'Oversimplification\nThere are also multiple other advantages‚Ä¶\n\nHuman vs. computer computation\n- Fast real-time decision making, e.g. sports, e-sports\n- Adaptive, e.g. context-aware and employs selective attention\n- Energy efficient: Close to 100 billion neurons in the brain\n- Robust, for example to changes in illumination or obstructions in object tracking\n\nHuman vs. computer computation\nBrains are energy efficient: Why?\n1.\nHigh temporal resolution (more computation with less neurons)\n2.\nSparse encoding\n\nHuman vs. computer computation\nQuestions?\nBrains are energy efficient: Why?', 'Browser plugin?\n24\nCO2\n\nC4. NutriScore for software libraries\n25\n‚Ä¢ NutriScore labels are not perfect but they are a good starting point! \n‚Ä¢ What if we could do the same thing for the energy efficiency of software. \n‚Ä¢ (Also open to individual or social sustainability) \n‚Ä¢ This work can be scoped in particular domains/ecossystems/use cases. \n‚Ä¢ Libraries for stats? ML? Web Dev? Cloud?\n\nC5. Add energy-awareness to existing software\n26\n‚Ä¢ Streamlit, Notebooks, JSFiddle, \nPyScript, zsh, etc. \n‚Ä¢\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy efficiency using static code analysis. \n‚Ä¢ We don‚Äôt need an accurate value. \n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention. \n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27\n\nC7 - Education\n‚Ä¢ Educational game for Software \nSustainability practices \n‚Ä¢ Purpose: use within software teams to \ndiscuss or learn about different sustainable \nIT practices: at the organisation level, \nsoftware, etc.\n28\nhttps://github.com/OttoKaaij/Ticket-To-Sustainability/?tab=readme-ov-file\n\nProject ideas (old)\n‚Ä¢ Plugin from EnergiBridge (GUI, report generator, python library, etc.) \n‚Ä¢ Plugin for ChatGPT (carbon emissions per chat window) \n‚Ä¢ Seamless measurements for AI libraries \n‚Ä¢ Energy patterns for Green AI \n‚Ä¢ Sustainable SW dev gamification \n‚Ä¢ Sustainability auditor for AI projects \n‚Ä¢ Energy Profiling of screen colour filter tools (or display settings) \n‚Ä¢ ‚Ä¶ you can also propose yours!\n\nhttps://edu.nl/64gpk\nedu.nl/64gpk\n\n\nNeuromorphic computing\nCS4575\nSustainable Software Engineering\n05.03.2025\nNergis T√∂men\n\nIntroduction\nComputer Vision Lab\nBiomorphic Intelligence Lab\nBiomedical Intervention Optimisation Lab\nNergis\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.']","['<1-hop>\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing', '<2-hop>\n\nReading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.', '<1-hop>\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing', '<2-hop>\n\nReading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.', '<1-hop>\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing', '<2-hop>\n\nReading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.']","Neuromorphic computing offers several benefits in the context of green software practices:

1. **Energy Efficiency**: Neuromorphic computing is inspired by the human brain, which is highly energy efficient. It uses less energy due to sparse encoding and the nature of spiking neurons, which only perform addition instead of multiply-accumulate operations. This results in less energy consumption, especially in specialized neuromorphic hardware like Intel's Loihi.

2. **Real-time Decision Making**: Neuromorphic systems can make fast real-time decisions, which is beneficial for applications requiring quick responses, such as sports or e-sports, while maintaining energy efficiency.

3. **Adaptive and Robust**: These systems are adaptive and robust, similar to the human brain, allowing them to handle changes in conditions like illumination or obstructions in object tracking without significant energy overhead.

Overall, neuromorphic computing aligns well with green software practices by reducing energy consumption and improving computational efficiency.","Neuromorphic computing offers several benefits in the context of green software practices. It is inspired by the structure and function of the human brain, making it highly energy-efficient compared to traditional computing methods. This efficiency is particularly relevant for sustainable software development, as it reduces the environmental impact of computing systems. Additionally, neuromorphic systems can process information in a way that mimics biological neural networks, which can lead to more efficient and sustainable computing solutions. These aspects make neuromorphic computing a promising approach for developers looking to implement green software practices.",0.9999999999,0.4,0.9166666666666666,0.67,0.12499999984374999,1.0000000000000009
What are the challenges in creating a dataset of government-developed OS software?,"['Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise \n‚Ä¢ But studying government software is difficult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers \n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation? \n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!\n\nB7.', '(2016)\nCruz et al. \n(2018)\nCruz et al. \n(2019)\nEnergy Code Changes \nDataset\n539 commits\u2028\nfrom 306 mobile apps\n539 baseline commits\u2028\nfrom 306 mobile apps\n49\n\nImpact of energy changes on \nmaintainability\n50\n\nWhich energy \npatterns are more \nlikely to affect \nmaintainability?\n51\n\nTypical maintainability issue I\nhttps://github.com/einmalfel/PodListen/commit/2ed5a65\n4 changed files with 28 additions and 0 deletions.', 'This is time consuming and requires \nexpertise. \n‚Ä¢ How can we reuse these efforts?\n4\n\nEnergy Patterns for Mobile \nApps\nhttps://tqrg.github.io/energy-patterns/\n\nMethodology\n5. Catalog of Energy Patterns\n22 \npatterns\nF-droid\nCurated Lists\n1. App Collection\n1783 \napps\n3. Manual Refinement of Subjects of \nInterest\n1563 \nchanges\n4. Thematic Analysis\n431 \nreusable \nchanges\n2. Collect Changes With Potential Interest\n/.*(energy|power|battery).']","['<1-hop>\n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise\n‚Ä¢ But studying government software is diÔ¨Écult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation?\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!', '<2-hop>\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption\n‚Ä¢ B3. Energy proÔ¨Åling of static analysis tools\n‚Ä¢ B4. Detailed energy proÔ¨Åling of build pipelines\n‚Ä¢ B5. Tool supporting SusAF workshop / process\n‚Ä¢ B6. Dataset of government-developed OS software\n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability', '<1-hop>\n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise\n‚Ä¢ But studying government software is diÔ¨Écult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation?\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!', '<2-hop>\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption\n‚Ä¢ B3. Energy proÔ¨Åling of static analysis tools\n‚Ä¢ B4. Detailed energy proÔ¨Åling of build pipelines\n‚Ä¢ B5. Tool supporting SusAF workshop / process\n‚Ä¢ B6. Dataset of government-developed OS software\n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability', '<1-hop>\n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise\n‚Ä¢ But studying government software is diÔ¨Écult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation?\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!', '<2-hop>\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption\n‚Ä¢ B3. Energy proÔ¨Åling of static analysis tools\n‚Ä¢ B4. Detailed energy proÔ¨Åling of build pipelines\n‚Ä¢ B5. Tool supporting SusAF workshop / process\n‚Ä¢ B6. Dataset of government-developed OS software\n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability']","The challenges in creating a dataset of government-developed OS software include:

1. **Lack of Incentive to Make Software Popular**: There is often little motivation for governments to promote their software widely, which can lead to difficulties in discovering and cataloging these projects.

2. **Language Barriers**: Government software may be developed in various languages, making it challenging to compile and understand the software across different regions.

3. **Difficulty in Understanding the State of Software**: It is challenging to determine whether the software is buildable, has an open development history, or includes requirements documentation.

These factors make it difficult to study and create a comprehensive dataset of government-developed software.","Creating a dataset of government-developed OS software faces challenges such as a lack of incentive to make the software popular and language barriers, which hinder comprehensive understanding of the software's buildability, open development history, and requirements documentation.",0.9999999999,1.0,0.7272727272727273,1.0,0.249999999375,0.9999999999999997
"What are the practical applications of neuromorphic computing, and how does its biological inspiration influence its implementation in modern computing systems?","['Questions?\n\nNeuromorphic computing\nWhat is the advantage for applications?\n-\nLess spikes = less energy consumption in specialized neuromorphic hardware\n(e.g. Intel Loihi [12])\nBrains are energy efficient: \n2. Sparse encoding\n\nMultiply-accumulate (MAC) operations:\nNormal neuron: Multiplies input with \nweights, then adds.\nSpiking neuron: Consider binary input (e.g. input currents are piecewise \nconstant and assume values {0,1}). There is no multiplication, only addition.', 'A neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing\n\nHow many of you are familiar \nwith neural networks?\n\nSimple model of an artificial neuron\nhttps://medium.com/@cprasenjit32/perceptron-a-simple-yet-mighty-machine-learning-algorithm-9ff6b7d86a71\n\nWhat is a neural network?\nhttps://www.tibco.com/reference-center/what-is-a-neural-network\n\nWhy is it called a \'neural network\'?\nhttps://www.tibco.com/reference-center/what-is-a-neural-network\n\nWhat is a neural network?\nWhy is it called a \'neural network\'?\nMcCulloch-Pitts neuron [1, 2] (1943)\nWarren Sturgis McCulloch\n(Neurophysiologist)\nWalter Pitts\n(Logician)\n\nHow do biological neurons work?\nhttps://commons.wikimedia.org/wiki/File:Coincidence_detection_in_dendrites_of_pyramidal_neurons.gif\n\'Input current\' travels down the dendrites (top),\nget integrated (summed!) in the cell body\nwhich generates an \'output current\' (bottom)\nwhich is chemically transmitted to the dendrites of \nother neurons.\n\nSimplified picture\nReal neuron\nArtificial neuron\nhttps://vajiramandravi.com/quest-upsc-notes/artificial-neural-network/\n\nWhat is a neural network?\nMcCulloch-Pitts neuron [1, 2]\n1940s: How do biological neurons compute basic \nlogic functions? (e.g. logic gates)\nNote: Ref. [3] gives a nice brief history on the ideas which lead to the \nMcCulloch-Pitts neuron.\n\nWhat is a neural network?\n1950s: How are neurons organized to perform \nsensory perception?\n\nWhat is a neural network?\n1950s: How are neurons organized to perform \nsensory perception?\nThe first ""neural network"": Perceptron (1958).', 'https://edu.nl/64gpk\nedu.nl/64gpk\n\n\nNeuromorphic computing\nCS4575\nSustainable Software Engineering\n05.03.2025\nNergis T√∂men\n\nIntroduction\nComputer Vision Lab\nBiomorphic Intelligence Lab\nBiomedical Intervention Optimisation Lab\nNergis\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.']","['<1-hop>\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing', '<2-hop>\n\nReading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.', '<1-hop>\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing', '<2-hop>\n\nReading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.']","Neuromorphic computing is inspired by the structure and function of the human brain, and it uses physical artificial neurons to perform computations. This approach offers several advantages for practical applications, particularly in areas where energy efficiency and processing speed are critical.

1. **Energy Efficiency**: Neuromorphic systems, such as Intel's Loihi chip, consume less energy because they use spiking neurons that perform operations with fewer spikes, leading to reduced energy consumption. This is particularly beneficial for applications that require continuous processing with minimal power usage.

2. **Sparse Encoding**: Neuromorphic systems use sparse encoding, which mimics the brain's way of processing information. This allows for efficient data representation and processing, making it suitable for applications like real-time data analysis and sensory processing.

3. **Efficient Computation**: Unlike traditional neurons that perform multiply-accumulate (MAC) operations, spiking neurons in neuromorphic systems only perform addition, which simplifies computations and reduces the computational load.

These characteristics make neuromorphic computing particularly suitable for applications in computer vision, sensory perception, and other areas where mimicking the brain's efficiency and processing capabilities can lead to significant improvements in performance and energy savings.","Neuromorphic computing, inspired by the human brain, offers practical applications such as event-based vision systems and efficient processing of sensory data. Its biological inspiration influences its implementation through the use of spiking neural networks and physical artificial neurons, enabling more energy-efficient and brain-like computation methods.",0.0,0.5,0.7142857142857143,0.6,0.1111111109876543,0.886272890966556
"What are the practical applications of neuromorphic computing, and how does its biological inspiration influence its implementation?","['Questions?\n\nNeuromorphic computing\nWhat is the advantage for applications?\n-\nLess spikes = less energy consumption in specialized neuromorphic hardware\n(e.g. Intel Loihi [12])\nBrains are energy efficient: \n2. Sparse encoding\n\nMultiply-accumulate (MAC) operations:\nNormal neuron: Multiplies input with \nweights, then adds.\nSpiking neuron: Consider binary input (e.g. input currents are piecewise \nconstant and assume values {0,1}). There is no multiplication, only addition.', 'The first ""neural network"": Perceptron (1958). [4]\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\nFrank Rosenblatt (Psychologist)\nwith a Mark I Perceptron computer in 1960\nPower-efficient\n\nNeuromorphic computing\nWhy neuromorphic computing?\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.', 'Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \n(not publicly available) doi:10.1037/h0042519\n5) Tappert CC.']","['<1-hop>\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing', '<2-hop>\n\nReading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.']","Neuromorphic computing is inspired by the structure and function of the human brain, which influences its implementation by using physical artificial neurons to perform computations. This approach offers several advantages for practical applications:

1. **Energy Efficiency**: Neuromorphic systems, like the human brain, are highly energy-efficient. They consume less energy, especially in specialized neuromorphic hardware, because they use sparse encoding and fewer spikes, which reduces energy consumption (e.g., Intel Loihi).

2. **Efficient Computation**: Unlike traditional neurons that perform multiply-accumulate (MAC) operations, spiking neurons in neuromorphic systems use binary input and only perform addition, which simplifies computations and reduces power usage.

3. **Event-Based Vision**: Neuromorphic computing is particularly useful in vision systems, such as event cameras, which mimic the way biological systems process visual information. These systems can efficiently handle dynamic scenes and reduce data redundancy by only recording changes in the visual field.

Overall, the biological inspiration of neuromorphic computing leads to systems that are more efficient in terms of energy and computation, making them suitable for applications in areas like robotics, sensory processing, and real-time data analysis.","Neuromorphic computing, inspired by the human brain, offers practical applications through its ability to process information in a manner similar to biological neurons. This biological inspiration influences its implementation by enabling the development of systems that can efficiently handle tasks such as pattern recognition and adaptive learning, as detailed in resources like 'Computing with spiking neuron networks' and discussions on the convergence of deep learning with biological systems.",0.0,0.6666666666666666,0.7333333333333333,0.29,0.14285714265306124,0.9435087801651508
What are the practical applications of neuromorphic systems that leverage biological inspiration and advanced training methods for efficient computation?,"['Questions?\n\nNeuromorphic computing\nWhat is the advantage for applications?\n-\nLess spikes = less energy consumption in specialized neuromorphic hardware\n(e.g. Intel Loihi [12])\nBrains are energy efficient: \n2. Sparse encoding\n\nMultiply-accumulate (MAC) operations:\nNormal neuron: Multiplies input with \nweights, then adds.\nSpiking neuron: Consider binary input (e.g. input currents are piecewise \nconstant and assume values {0,1}). There is no multiplication, only addition.', 'FNN‚Äôs are conventional feed-forward neural networks.\nIn this example: SNNs are 6 to 8 times more energy efficient than FNNs.\nComputing energy consumption\nQuestions?\n\nReading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020.', 'Oversimplification\nThere are also multiple other advantages‚Ä¶\n\nHuman vs. computer computation\n- Fast real-time decision making, e.g. sports, e-sports\n- Adaptive, e.g. context-aware and employs selective attention\n- Energy efficient: Close to 100 billion neurons in the brain\n- Robust, for example to changes in illumination or obstructions in object tracking\n\nHuman vs. computer computation\nBrains are energy efficient: Why?\n1.\nHigh temporal resolution (more computation with less neurons)\n2.\nSparse encoding\n\nHuman vs. computer computation\nQuestions?\nBrains are energy efficient: Why?']","['<1-hop>\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing', '<2-hop>\n\nReading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.', '<1-hop>\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing', '<2-hop>\n\nReading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.', '<1-hop>\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing', '<2-hop>\n\nReading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.']","Neuromorphic systems, inspired by biological processes and advanced training methods, have several practical applications due to their efficient computation capabilities. These include:

1. **Energy Efficiency**: Neuromorphic systems, such as those using spiking neural networks (SNNs), are significantly more energy-efficient than conventional feed-forward neural networks (FNNs). This makes them suitable for applications where power consumption is a critical factor.

2. **Real-Time Decision Making**: They are capable of fast real-time decision making, which is beneficial in applications like sports and e-sports, where quick responses are crucial.

3. **Adaptive Systems**: Neuromorphic systems can be context-aware and employ selective attention, making them useful in adaptive applications that require dynamic responses to changing environments.

4. **Robustness**: These systems are robust to changes, such as variations in illumination or obstructions in object tracking, making them ideal for vision and tracking applications.

5. **Sparse Encoding**: By leveraging sparse encoding, neuromorphic systems can perform high temporal resolution computations with fewer neurons, which is advantageous in applications requiring efficient data processing.

Overall, neuromorphic systems are well-suited for applications that require efficient, adaptive, and robust computation with low energy consumption.","Neuromorphic systems, inspired by the human brain, have practical applications such as event-based vision, which is detailed in the reading materials. These systems use advanced training methods like surrogate gradient learning to optimize spiking neural networks, enabling efficient computation and real-world applications.",0.49999999995,1.0,0.875,0.29,0.12499999984374999,0.9609441315216459
"What is the biological basis of neuromorphic computing, and how does it differ from conventional neural networks?","['https://edu.nl/64gpk\nedu.nl/64gpk\n\n\nNeuromorphic computing\nCS4575\nSustainable Software Engineering\n05.03.2025\nNergis T√∂men\n\nIntroduction\nComputer Vision Lab\nBiomorphic Intelligence Lab\nBiomedical Intervention Optimisation Lab\nNergis\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.', ""Computation with spiking neurons\n\nCoincidence detection\nCan be trivially computed with a single spiking neuron! Requires at least n/log(n+1) hidden \nunits for a perceptron (proof in [7]).\nBrains are energy efficient: \n1.\nHigh temporal resolution (more computation with less neurons)\nComputation with spiking neurons\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?"", 'Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021.']","['<1-hop>\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing', '<2-hop>\n\nReading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.']","Neuromorphic computing is inspired by the structure and function of the human brain. It involves using physical artificial neurons to perform computations, mimicking the way biological neurons operate. This approach is based on biology, as it seeks to replicate the brain's energy efficiency and high temporal resolution, allowing for more computation with fewer neurons.

In contrast, conventional neural networks, while also inspired by the brain, typically use mathematical models to simulate neuron behavior and are not necessarily designed to mimic the brain's physical structure or energy efficiency. Neuromorphic computing often involves spiking neurons, which encode information using spikes (binary signals), whereas conventional neural networks generally use continuous values for neuron outputs.","Neuromorphic computing is based on the biological principles of the human brain, utilizing physical artificial neurons to perform computations. Unlike conventional neural networks, which rely on traditional computing architectures, neuromorphic systems are designed to mimic the brain's structure and function, enabling more efficient and biologically inspired processing.",0.8333333332916666,0.5,0.5714285714285714,0.77,0.16666666638888888,0.9354184907309843
What is the difference between spiking neural networks and spiking neuron networks?,"['Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012).', '9 pJ and M = 3.7 pJ).\nNormal neuron: nin x nout multiplications,\n(nin‚Äì 1) x nout additions\nSpiking neuron: 0 multiplications, (nactive‚Äì 1) x nout \nadditions, with nactive ‚â§ nin\nEnergy consumption:\nEnormal = M nin nout + A (nin‚Äì 1) nout = 17.5 pJ\nEnergy consumption:\nEspiking = A (nactive‚Äì 1) nout = 2.7 pJ\nMultiply-accumulate (MAC) operations:\nSNN challenge: how to \ncompute with the least \namount of spikes!', ""‚Ä¶ with energy costs reaching 200M USD!\n\nPower-efficiency at scale\nYour brain runs on:\n\nPower-efficiency at scale\nYour brain runs on:\nHigh estimate ~3000 kcal a day\n   ‚âà145 Watts\n* Human brain has ~600 trillion synapses \n(‚âàparameters).\n\nPower-efficiency at scale\nYour brain runs on:\nHigh estimate ~3000 kcal a day\n   ‚âà145 Watts\n* Human brain has ~600 trillion synapses \n(‚âàparameters).\nOversimplification\nThere are also multiple other advantages‚Ä¶\n\nHuman vs. computer computation\n- Fast real-time decision making, e.g. sports, e-sports\n- Adaptive, e.g. context-aware and employs selective attention\n- Energy efficient: Close to 100 billion neurons in the brain\n- Robust, for example to changes in illumination or obstructions in object tracking\n\nHuman vs. computer computation\nBrains are energy efficient: Why?\n1.\nHigh temporal resolution (more computation with less neurons)\n2.\nSparse encoding\n\nHuman vs. computer computation\nQuestions?\nBrains are energy efficient: Why?\n1.\nHigh temporal resolution (more computation with less neurons)\n2.\nSparse encoding\n\nHow do biological neurons communicate?\nAnalogy to artificial neural networks\nReal neuron\nArtificial neuron\nCurrent\n\nHow do biological neurons communicate?\nHow does the electrical activity propagate?\n?\nCurrent\n\nHow do biological neurons work?\ntime\nelectrode\nhttps://tinmard.github.io/spike-sorting-animation.html\nQuick electrical pulses trigger chemical signals for the next neuron ‚Üí Spikes\n\nHow do biological neurons work?\nQuick electrical pulses trigger chemical signals for the next neuron ‚Üí Spikes\nhttps://tinmard.github.io/spike-sorting-animation.html\ntime\nelectrode\nFrom CS perspective:\nSparse binary \nencoding\n\nBiologically realistic spiking neuron models\nBiologically realistic neuron models have \na new dimension: Time!\nSpiking neural networks (SNNs):\nThe input x  (t  ) to each neuron is summed \n(integrated) over time.\nscalar\nfunction of \ntime\n(t)\n(t)\nhttps://www.mdpi.com/2076-3425/12/7/863\n\nHow to model spiking neurons?\nANN: Perceptron, threshold activation function:\n\nHow to model spiking neurons?\nANN: Perceptron, threshold activation function:\n\nHow to model spiking neurons?\nSpiking neural network (SNN): The 'input current' Œµ(t) is integrated over time.\nspike\n\nHow to model spiking neurons?\nEquivalence to perceptron: Computation at least as complex as a perceptron.\n\nNon-leaky integrate-and-fire (IF) neuron\nThe temporal profile of the input current Œµ(t) can be chosen differently, for different computations.\n\nQuestions?\n\nComputation with spiking neurons\nCoincidence detection\n\nComputation with spiking neurons\nCoincidence detection\nx, y ‚àà {0, 1}n\nExample: n = 2\ninput = \nx1\nx2\ny1\ny2\n= \n0\n1\n1\n1\noutput? \n\nCoincidence detection\nComputation with spiking neurons\n\nCoincidence detection\nCan be trivially computed with a single spiking neuron! Requires at least n/log(n+1) hidden \nunits for a perceptron (proof in [7]).\nComputation with spiking neurons\n\nCoincidence detection\nCan be trivially computed with a single spiking neuron! Requires at least n/log(n+1) hidden \nunits for a perceptron (proof in [7]).\nBrains are energy efficient: \n1.\nHigh temporal resolution (more computation with less neurons)\nComputation with spiking neurons\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant\n\nFiring rates\nClassical view of the brain:\n- Each neuron is selective for one specific \nfeature in the input.\n- Higher firing rate (spikes per unit time) for \n'selected' feature.\nAdapted from Hubel & Wiesel, 1959\n\nFiring rates\nClassical view of the brain:\n- Each neuron is selective for one specific \nfeature in the input.\n- Higher firing rate (spikes per unit time) for \n'selected' feature.\n- Link to modern ANNs: The scalar output of \nan artificial neuron is interpreted as the firing \nrate.\nAdapted from Hubel & Wiesel, 1959\n\nFiring rates\nClassical view of the brain:\n- Each neuron is selective for one specific \nfeature in the input.\n- Higher firing rate (spikes per unit time) for \n'selected' feature.\n- Link to modern ANNs: The scalar output of \nan artificial neuron is interpreted as the firing \nrate.\nAdapted from Hubel & Wiesel, 1959\nBut rate coding is inefficient and slow‚Ä¶\n(i.e. each neuron needs to fire many spikes to get good precision)\nboth in vivo and in silico.\n\nDifferent encoding strategies with spiking neurons [8]\n7 neurons\n7 time bins\n\nDifferent encoding strategies with spiking neurons\n7 neurons\n7 time bins\nn\n6\n(in the general \ncase a \nnumber \nbetween 0-7)\n\nDifferent encoding strategies with spiking neurons\n7 neurons\n7 time bins\nn\nTotal spike \ncount can \nencode 3 bits.\n\nDifferent encoding strategies with spiking neurons\n7 neurons\n7 time bins\nIndividual rates \ncan encode 7 \nbits.\n\nDifferent encoding strategies with spiking neurons\n7 neurons\n7 time bins\nLatency can \nencode ~3*7 or \n~19 bits.\n\nDifferent encoding strategies with spiking neurons\n7 neurons\n7 time bins\nRank order can \nencode ~12 bits.\n\nDifferent encoding strategies with spiking neurons\n\nDifferent encoding strategies with spiking neurons\nUsing latency or spatio-temporal codes\nour encoding is faster and more spike-efficient (sparser)!\n\nDifferent encoding strategies with spiking neurons\nUsing latency or spatio-temporal codes\nour encoding is faster and more spike-efficient (sparser)!\nQuestions?\n\nNeuromorphic computing\nWhat is the advantage for applications?\n-\nLess spikes = less energy consumption in specialized neuromorphic hardware\n(e.g. Intel Loihi [12])\nBrains are energy efficient: \n2. Sparse encoding\n\nMultiply-accumulate (MAC) operations:\nNormal neuron: Multiplies input with \nweights, then adds.\nSpiking neuron: Consider binary input (e.g. input currents are piecewise \nconstant and assume values {0,1}). There is no multiplication, only addition.\n\nAssume one multiplier and one adder circuit uses M and A energy respectively with AÔπ§M\n(e.g., for a 45nm CMOS process, standard energy usage is A = 0.9 pJ and M = 3.7 pJ).\nNormal neuron: nin x nout multiplications,\n(nin‚Äì 1) x nout additions\nSpiking neuron: 0 multiplications, (nactive‚Äì 1) x nout \nadditions, with nactive ‚â§ nin\nEnergy consumption:\nEnormal = M nin nout + A (nin‚Äì 1) nout = 17.5 pJ\nEnergy consumption:\nEspiking = A (nactive‚Äì 1) nout = 2.7 pJ\nMultiply-accumulate (MAC) operations:\n\nAssume one multiplier and one adder circuit uses M and A energy respectively with AÔπ§M\n(e.g., for a 45nm CMOS process, standard energy usage is A = 0.9 pJ and M = 3.7 pJ).\nNormal neuron: nin x nout multiplications,\n(nin‚Äì 1) x nout additions\nSpiking neuron: 0 multiplications, (nactive‚Äì 1) x nout \nadditions, with nactive ‚â§ nin\nEnergy consumption:\nEnormal = M nin nout + A (nin‚Äì 1) nout = 17.5 pJ\nEnergy consumption:\nEspiking = A (nactive‚Äì 1) nout = 2.7 pJ\nMultiply-accumulate (MAC) operations:\nSNN challenge: how to \ncompute with the least \namount of spikes!\n\nOften, we observe a \nsparsity (energy)-\ntask accuracy trade-off\n(Left: results for image \nclassification)\nSNN challenge: how to \ncompute with the least \namount of spikes!\nhttps://arxiv.org/pdf/2409.08290\n\nIn practice, energy \nconsumption computations \nare complex. \nNeed to take into account\n- memory access,\n- addressing,\n- auxiliary operations,\nin addition to MACs.\nEstimated energy consumption for 3 different datasets (CIFAR10, GSC, NCARS; image, sound \nand video classification respectively). FNN‚Äôs are conventional feed-forward neural networks.\nIn this example: SNNs are 6 to 8 times more energy efficient than FNNs.\nhttps://arxiv.org/pdf/2210.13107\nComputing energy consumption\n\nIn practice, energy \nconsumption computations \nare complex. \nNeed to take into account\n- memory access,\n- addressing,\n- auxiliary operations,\nin addition to MACs.\nEstimated energy consumption for 3 different datasets (CIFAR10, GSC, NCARS; image, sound \nand video classification respectively). FNN‚Äôs are conventional feed-forward neural networks.""]","[""<1-hop>\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant"", '<2-hop>\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \n(not publicly available) doi:10.1037/h0042519\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568', ""<1-hop>\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant"", '<2-hop>\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \n(not publicly available) doi:10.1037/h0042519\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568']","The terms ""spiking neural networks"" (SNNs) and ""spiking neuron networks"" are often used interchangeably to refer to the same concept. Both describe a type of artificial neural network that more closely mimics the way biological neurons communicate through spikes or discrete events over time. These networks use spiking neurons, which integrate input over time and fire spikes when a certain threshold is reached, as opposed to traditional artificial neural networks that use continuous activation functions.

The key characteristics of SNNs include the integration of input over time, sparse encoding, and the use of spikes for communication, which can lead to more energy-efficient computations compared to traditional neural networks. They are particularly noted for their potential in neuromorphic computing, where less energy consumption is achieved through fewer spikes and sparse encoding strategies.","Spiking neural networks (SNNs) are a type of neural network model that processes information using spikes, similar to biological neurons. Spiking neuron networks refer to the individual components within these networks, focusing on how each neuron processes and communicates information through spikes.",0.0,,0.8181818181818182,0.6,0.9999999900000002,0.9040739947914259
What is the foundational concepts of spiking neural networks and how they are used in encoding strategies?,"[""‚Ä¶ with energy costs reaching 200M USD!\n\nPower-efficiency at scale\nYour brain runs on:\n\nPower-efficiency at scale\nYour brain runs on:\nHigh estimate ~3000 kcal a day\n   ‚âà145 Watts\n* Human brain has ~600 trillion synapses \n(‚âàparameters).\n\nPower-efficiency at scale\nYour brain runs on:\nHigh estimate ~3000 kcal a day\n   ‚âà145 Watts\n* Human brain has ~600 trillion synapses \n(‚âàparameters).\nOversimplification\nThere are also multiple other advantages‚Ä¶\n\nHuman vs. computer computation\n- Fast real-time decision making, e.g. sports, e-sports\n- Adaptive, e.g. context-aware and employs selective attention\n- Energy efficient: Close to 100 billion neurons in the brain\n- Robust, for example to changes in illumination or obstructions in object tracking\n\nHuman vs. computer computation\nBrains are energy efficient: Why?\n1.\nHigh temporal resolution (more computation with less neurons)\n2.\nSparse encoding\n\nHuman vs. computer computation\nQuestions?\nBrains are energy efficient: Why?\n1.\nHigh temporal resolution (more computation with less neurons)\n2.\nSparse encoding\n\nHow do biological neurons communicate?\nAnalogy to artificial neural networks\nReal neuron\nArtificial neuron\nCurrent\n\nHow do biological neurons communicate?\nHow does the electrical activity propagate?\n?\nCurrent\n\nHow do biological neurons work?\ntime\nelectrode\nhttps://tinmard.github.io/spike-sorting-animation.html\nQuick electrical pulses trigger chemical signals for the next neuron ‚Üí Spikes\n\nHow do biological neurons work?\nQuick electrical pulses trigger chemical signals for the next neuron ‚Üí Spikes\nhttps://tinmard.github.io/spike-sorting-animation.html\ntime\nelectrode\nFrom CS perspective:\nSparse binary \nencoding\n\nBiologically realistic spiking neuron models\nBiologically realistic neuron models have \na new dimension: Time!\nSpiking neural networks (SNNs):\nThe input x  (t  ) to each neuron is summed \n(integrated) over time.\nscalar\nfunction of \ntime\n(t)\n(t)\nhttps://www.mdpi.com/2076-3425/12/7/863\n\nHow to model spiking neurons?\nANN: Perceptron, threshold activation function:\n\nHow to model spiking neurons?\nANN: Perceptron, threshold activation function:\n\nHow to model spiking neurons?\nSpiking neural network (SNN): The 'input current' Œµ(t) is integrated over time.\nspike\n\nHow to model spiking neurons?\nEquivalence to perceptron: Computation at least as complex as a perceptron.\n\nNon-leaky integrate-and-fire (IF) neuron\nThe temporal profile of the input current Œµ(t) can be chosen differently, for different computations.\n\nQuestions?\n\nComputation with spiking neurons\nCoincidence detection\n\nComputation with spiking neurons\nCoincidence detection\nx, y ‚àà {0, 1}n\nExample: n = 2\ninput = \nx1\nx2\ny1\ny2\n= \n0\n1\n1\n1\noutput? \n\nCoincidence detection\nComputation with spiking neurons\n\nCoincidence detection\nCan be trivially computed with a single spiking neuron! Requires at least n/log(n+1) hidden \nunits for a perceptron (proof in [7]).\nComputation with spiking neurons\n\nCoincidence detection\nCan be trivially computed with a single spiking neuron! Requires at least n/log(n+1) hidden \nunits for a perceptron (proof in [7]).\nBrains are energy efficient: \n1.\nHigh temporal resolution (more computation with less neurons)\nComputation with spiking neurons\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant\n\nFiring rates\nClassical view of the brain:\n- Each neuron is selective for one specific \nfeature in the input.\n- Higher firing rate (spikes per unit time) for \n'selected' feature.\nAdapted from Hubel & Wiesel, 1959\n\nFiring rates\nClassical view of the brain:\n- Each neuron is selective for one specific \nfeature in the input.\n- Higher firing rate (spikes per unit time) for \n'selected' feature.\n- Link to modern ANNs: The scalar output of \nan artificial neuron is interpreted as the firing \nrate.\nAdapted from Hubel & Wiesel, 1959\n\nFiring rates\nClassical view of the brain:\n- Each neuron is selective for one specific \nfeature in the input.\n- Higher firing rate (spikes per unit time) for \n'selected' feature.\n- Link to modern ANNs: The scalar output of \nan artificial neuron is interpreted as the firing \nrate.\nAdapted from Hubel & Wiesel, 1959\nBut rate coding is inefficient and slow‚Ä¶\n(i.e. each neuron needs to fire many spikes to get good precision)\nboth in vivo and in silico.\n\nDifferent encoding strategies with spiking neurons [8]\n7 neurons\n7 time bins\n\nDifferent encoding strategies with spiking neurons\n7 neurons\n7 time bins\nn\n6\n(in the general \ncase a \nnumber \nbetween 0-7)\n\nDifferent encoding strategies with spiking neurons\n7 neurons\n7 time bins\nn\nTotal spike \ncount can \nencode 3 bits.\n\nDifferent encoding strategies with spiking neurons\n7 neurons\n7 time bins\nIndividual rates \ncan encode 7 \nbits.\n\nDifferent encoding strategies with spiking neurons\n7 neurons\n7 time bins\nLatency can \nencode ~3*7 or \n~19 bits.\n\nDifferent encoding strategies with spiking neurons\n7 neurons\n7 time bins\nRank order can \nencode ~12 bits.\n\nDifferent encoding strategies with spiking neurons\n\nDifferent encoding strategies with spiking neurons\nUsing latency or spatio-temporal codes\nour encoding is faster and more spike-efficient (sparser)!\n\nDifferent encoding strategies with spiking neurons\nUsing latency or spatio-temporal codes\nour encoding is faster and more spike-efficient (sparser)!\nQuestions?\n\nNeuromorphic computing\nWhat is the advantage for applications?\n-\nLess spikes = less energy consumption in specialized neuromorphic hardware\n(e.g. Intel Loihi [12])\nBrains are energy efficient: \n2. Sparse encoding\n\nMultiply-accumulate (MAC) operations:\nNormal neuron: Multiplies input with \nweights, then adds.\nSpiking neuron: Consider binary input (e.g. input currents are piecewise \nconstant and assume values {0,1}). There is no multiplication, only addition.\n\nAssume one multiplier and one adder circuit uses M and A energy respectively with AÔπ§M\n(e.g., for a 45nm CMOS process, standard energy usage is A = 0.9 pJ and M = 3.7 pJ).\nNormal neuron: nin x nout multiplications,\n(nin‚Äì 1) x nout additions\nSpiking neuron: 0 multiplications, (nactive‚Äì 1) x nout \nadditions, with nactive ‚â§ nin\nEnergy consumption:\nEnormal = M nin nout + A (nin‚Äì 1) nout = 17.5 pJ\nEnergy consumption:\nEspiking = A (nactive‚Äì 1) nout = 2.7 pJ\nMultiply-accumulate (MAC) operations:\n\nAssume one multiplier and one adder circuit uses M and A energy respectively with AÔπ§M\n(e.g., for a 45nm CMOS process, standard energy usage is A = 0.9 pJ and M = 3.7 pJ).\nNormal neuron: nin x nout multiplications,\n(nin‚Äì 1) x nout additions\nSpiking neuron: 0 multiplications, (nactive‚Äì 1) x nout \nadditions, with nactive ‚â§ nin\nEnergy consumption:\nEnormal = M nin nout + A (nin‚Äì 1) nout = 17.5 pJ\nEnergy consumption:\nEspiking = A (nactive‚Äì 1) nout = 2.7 pJ\nMultiply-accumulate (MAC) operations:\nSNN challenge: how to \ncompute with the least \namount of spikes!\n\nOften, we observe a \nsparsity (energy)-\ntask accuracy trade-off\n(Left: results for image \nclassification)\nSNN challenge: how to \ncompute with the least \namount of spikes!\nhttps://arxiv.org/pdf/2409.08290\n\nIn practice, energy \nconsumption computations \nare complex. \nNeed to take into account\n- memory access,\n- addressing,\n- auxiliary operations,\nin addition to MACs.\nEstimated energy consumption for 3 different datasets (CIFAR10, GSC, NCARS; image, sound \nand video classification respectively). FNN‚Äôs are conventional feed-forward neural networks.\nIn this example: SNNs are 6 to 8 times more energy efficient than FNNs.\nhttps://arxiv.org/pdf/2210.13107\nComputing energy consumption\n\nIn practice, energy \nconsumption computations \nare complex. \nNeed to take into account\n- memory access,\n- addressing,\n- auxiliary operations,\nin addition to MACs.\nEstimated energy consumption for 3 different datasets (CIFAR10, GSC, NCARS; image, sound \nand video classification respectively). FNN‚Äôs are conventional feed-forward neural networks."", 'Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945.']","[""<1-hop>\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant"", '<2-hop>\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \n(not publicly available) doi:10.1037/h0042519\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568', ""<1-hop>\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant"", '<2-hop>\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \n(not publicly available) doi:10.1037/h0042519\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568', ""<1-hop>\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant"", '<2-hop>\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \n(not publicly available) doi:10.1037/h0042519\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568', ""<1-hop>\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant"", '<2-hop>\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \n(not publicly available) doi:10.1037/h0042519\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568']","Spiking Neural Networks (SNNs) are a type of neural network that mimic the way biological neurons communicate. The foundational concept of SNNs involves the use of spikes, or quick electrical pulses, to transmit information. Unlike traditional artificial neural networks (ANNs) that use continuous values, SNNs use discrete events (spikes) to represent and process information over time.

Key foundational concepts of SNNs include:

1. **Temporal Dynamics**: SNNs incorporate the dimension of time, where the input to each neuron is integrated over time. This allows for the modeling of temporal patterns and dynamics similar to biological neurons.

2. **Sparse Encoding**: SNNs use sparse encoding strategies, which means fewer spikes are used to represent information. This leads to energy efficiency, as less energy is consumed in processing fewer spikes.

3. **Coincidence Detection**: SNNs can perform computations such as coincidence detection, which can be efficiently computed with a single spiking neuron.

In terms of encoding strategies, SNNs utilize various methods to encode information:

- **Firing Rates**: Each neuron is selective for specific features, and the firing rate (spikes per unit time) increases for selected features. However, this method can be inefficient and slow.

- **Latency and Spatio-Temporal Codes**: These methods use the timing of spikes to encode information, which is faster and more spike-efficient compared to rate coding.

- **Rank Order and Total Spike Count**: These strategies involve encoding information based on the order of spikes or the total number of spikes, allowing for efficient information representation.

Overall, SNNs are designed to be more energy-efficient and capable of processing temporal information effectively, making them suitable for applications in neuromorphic computing.","Spiking neural networks use spikes to encode information, with foundational concepts including the work of McCulloch and Pitts on logical calculus of nervous activity, and later developments in spiking neuron models.",0.0,0.0,1.0,0.29,,0.9412788113698402
What is the project idea about government-developed OS software?,"['Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise \n‚Ä¢ But studying government software is difficult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers \n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation? \n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!\n\nB7.', '‚Ä¢ Description of the solution. \n‚Ä¢ Validation of the solution (if applicable -> discuss with coach) \n‚Ä¢ Discussion of the solution. (Including limitations)\n5\n\nStrategy\n‚Ä¢ Starting next week, there are no lectures  \n‚Ä¢ Steering meetings from week 5 till week 9 (either online or in person).  \n‚Ä¢ 1 steering meeting per week. (4+1 sprints) \n‚Ä¢ Every week, you need to plan different tasks and assignments. \n‚Ä¢ Deadline April 4.\n6\n\nStrategy\n‚Ä¢ Week 0 \n‚Ä¢ Decide project idea (today) \n‚Ä¢ Define steering meeting schedule \n‚Ä¢ Create working document of the \narticle: Problem statement and solution \nproposal! \n‚Ä¢ Define and assign tasks for each week. \n‚Ä¢ Week 1 \n‚Ä¢ Implementation \n‚Ä¢ Agreements with supervisor. \n‚Ä¢ Week 2 \n‚Ä¢ Implementation \n‚Ä¢ Week 3 \n‚Ä¢ Implementation, Full draft of article, \ndissemination. \n‚Ä¢ Week 4 \n‚Ä¢ Final refinements \n‚Ä¢ Prepare presentation\n7\n\nProject ideas\n‚Ä¢ A1. Prototype cross-machine comparable benchmarks \n‚Ä¢ A2. Add energy metrics to LMstudio/Ollama \n‚Ä¢ A3. Visualizations built-in with EnergiBridge \n‚Ä¢ A4. Service-based version of EnergiBridge\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption \n‚Ä¢ B3. Energy profiling of static analysis tools \n‚Ä¢ B4. Detailed energy profiling of build pipelines \n‚Ä¢ B5. Tool supporting SusAF workshop / process \n‚Ä¢ B6. Dataset of government-developed OS software \n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability\n\nProject ideas\n‚Ä¢ C1. Compare energy consumption of docker images for ML workloads. \n‚Ä¢ C2. Create a plugin to visualize Hugging Face carbon emissions in detail. \n‚Ä¢ C3. Plugin for ChatGPT (footprint per chat window) \n‚Ä¢ C4. NutriScore for software libraries. \n‚Ä¢ C5. Add energy-awareness to existing software \n‚Ä¢ C6. Green Shift Left \n‚Ä¢ C7. Education for Sustainable SE\n\nA1.']","['<1-hop>\n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise\n‚Ä¢ But studying government software is diÔ¨Écult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation?\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!', '<2-hop>\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption\n‚Ä¢ B3. Energy proÔ¨Åling of static analysis tools\n‚Ä¢ B4. Detailed energy proÔ¨Åling of build pipelines\n‚Ä¢ B5. Tool supporting SusAF workshop / process\n‚Ä¢ B6. Dataset of government-developed OS software\n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability']","The project idea about government-developed OS software involves creating a comprehensive dataset of software developed and used by governments to support society. The focus is on open-source development and policies, which are on the rise. The project aims to include data that helps understand the state of this software, such as whether it is buildable, has an open development history, and includes requirements documentation. The initiative could start with the Netherlands (NL), but contributions from other countries are also appreciated. The project addresses challenges like the lack of incentive to make such software popular and language barriers.","The project idea involves creating a comprehensive dataset of government-developed OS software to understand its state, including buildability, open development history, and requirements documentation. This addresses challenges like lack of incentives and language barriers.",0.99999999995,1.0,0.8461538461538461,0.57,0.0,0.9999999999999997
What is the project idea related to creating a dataset of goverment-developed OS software?,"['Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise \n‚Ä¢ But studying government software is difficult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers \n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation? \n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!\n\nB7.', 'Ideas\n\nAssignment\n‚Ä¢ Goal: Solve a Sustainable Software Engineering problem. \n‚Ä¢ Identify 1 problem that should be fixed to help enabling sustainability in \nthe software engineering industry/community. \n‚Ä¢ Propose a solution. A tool, framework, guidelines, etc. \n‚Ä¢ Implementation. \n‚Ä¢ Validation. (Depending on the idea) \n‚Ä¢ Dissemination/social impact. (Solution should be open source, welcome \ncontributors, post on social media? Tool website? Available in a package \nmanager?)\n3\n\nDeliverables\n‚Ä¢ Paper-like article.']","['<1-hop>\n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise\n‚Ä¢ But studying government software is diÔ¨Écult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation?\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!', '<2-hop>\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption\n‚Ä¢ B3. Energy proÔ¨Åling of static analysis tools\n‚Ä¢ B4. Detailed energy proÔ¨Åling of build pipelines\n‚Ä¢ B5. Tool supporting SusAF workshop / process\n‚Ä¢ B6. Dataset of government-developed OS software\n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability', '<1-hop>\n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise\n‚Ä¢ But studying government software is diÔ¨Écult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation?\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!', '<2-hop>\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption\n‚Ä¢ B3. Energy proÔ¨Åling of static analysis tools\n‚Ä¢ B4. Detailed energy proÔ¨Åling of build pipelines\n‚Ä¢ B5. Tool supporting SusAF workshop / process\n‚Ä¢ B6. Dataset of government-developed OS software\n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability', '<1-hop>\n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise\n‚Ä¢ But studying government software is diÔ¨Écult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation?\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!', '<2-hop>\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption\n‚Ä¢ B3. Energy proÔ¨Åling of static analysis tools\n‚Ä¢ B4. Detailed energy proÔ¨Åling of build pipelines\n‚Ä¢ B5. Tool supporting SusAF workshop / process\n‚Ä¢ B6. Dataset of government-developed OS software\n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability', '<1-hop>\n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise\n‚Ä¢ But studying government software is diÔ¨Écult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation?\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!', '<2-hop>\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption\n‚Ä¢ B3. Energy proÔ¨Åling of static analysis tools\n‚Ä¢ B4. Detailed energy proÔ¨Åling of build pipelines\n‚Ä¢ B5. Tool supporting SusAF workshop / process\n‚Ä¢ B6. Dataset of government-developed OS software\n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability', '<1-hop>\n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise\n‚Ä¢ But studying government software is diÔ¨Écult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation?\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!', '<2-hop>\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption\n‚Ä¢ B3. Energy proÔ¨Åling of static analysis tools\n‚Ä¢ B4. Detailed energy proÔ¨Åling of build pipelines\n‚Ä¢ B5. Tool supporting SusAF workshop / process\n‚Ä¢ B6. Dataset of government-developed OS software\n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability']","The project idea involves creating a comprehensive dataset of government-developed open-source software. This dataset would include data necessary to understand the state of the software, such as whether it is buildable, has an open development history, and includes requirements documentation. The project acknowledges the challenges in studying government software due to a lack of incentive to make it popular and language barriers. It suggests starting with the Netherlands but welcomes the inclusion of data from other countries.","The project idea is to create a dataset of government-developed OS software, which would help in understanding the state of such software, including whether it is buildable, has open development history, and has requirements documentation.",0.9999999999,1.0,0.7,0.67,0.0,0.9368846304674229
What is the project idea related to creating a dataset of government-developed OS software?,"['Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise \n‚Ä¢ But studying government software is difficult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers \n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation? \n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!\n\nB7.', 'Ideas\n\nAssignment\n‚Ä¢ Goal: Solve a Sustainable Software Engineering problem. \n‚Ä¢ Identify 1 problem that should be fixed to help enabling sustainability in \nthe software engineering industry/community. \n‚Ä¢ Propose a solution. A tool, framework, guidelines, etc. \n‚Ä¢ Implementation. \n‚Ä¢ Validation. (Depending on the idea) \n‚Ä¢ Dissemination/social impact. (Solution should be open source, welcome \ncontributors, post on social media? Tool website? Available in a package \nmanager?)\n3\n\nDeliverables\n‚Ä¢ Paper-like article.', 'Browser plugin?\n24\nCO2\n\nC4. NutriScore for software libraries\n25\n‚Ä¢ NutriScore labels are not perfect but they are a good starting point! \n‚Ä¢ What if we could do the same thing for the energy efficiency of software. \n‚Ä¢ (Also open to individual or social sustainability) \n‚Ä¢ This work can be scoped in particular domains/ecossystems/use cases. \n‚Ä¢ Libraries for stats? ML? Web Dev? Cloud?\n\nC5. Add energy-awareness to existing software\n26\n‚Ä¢ Streamlit, Notebooks, JSFiddle, \nPyScript, zsh, etc. \n‚Ä¢\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy efficiency using static code analysis. \n‚Ä¢ We don‚Äôt need an accurate value. \n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention. \n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27\n\nC7 - Education\n‚Ä¢ Educational game for Software \nSustainability practices \n‚Ä¢ Purpose: use within software teams to \ndiscuss or learn about different sustainable \nIT practices: at the organisation level, \nsoftware, etc.\n28\nhttps://github.com/OttoKaaij/Ticket-To-Sustainability/?tab=readme-ov-file\n\nProject ideas (old)\n‚Ä¢ Plugin from EnergiBridge (GUI, report generator, python library, etc.) \n‚Ä¢ Plugin for ChatGPT (carbon emissions per chat window) \n‚Ä¢ Seamless measurements for AI libraries \n‚Ä¢ Energy patterns for Green AI \n‚Ä¢ Sustainable SW dev gamification \n‚Ä¢ Sustainability auditor for AI projects \n‚Ä¢ Energy Profiling of screen colour filter tools (or display settings) \n‚Ä¢ ‚Ä¶ you can also propose yours!\n\nhttps://edu.nl/64gpk\nedu.nl/64gpk\n\n\nNeuromorphic computing\nCS4575\nSustainable Software Engineering\n05.03.2025\nNergis T√∂men\n\nIntroduction\nComputer Vision Lab\nBiomorphic Intelligence Lab\nBiomedical Intervention Optimisation Lab\nNergis\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.']","['<1-hop>\n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise\n‚Ä¢ But studying government software is diÔ¨Écult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation?\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!', '<2-hop>\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption\n‚Ä¢ B3. Energy proÔ¨Åling of static analysis tools\n‚Ä¢ B4. Detailed energy proÔ¨Åling of build pipelines\n‚Ä¢ B5. Tool supporting SusAF workshop / process\n‚Ä¢ B6. Dataset of government-developed OS software\n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability']","The project idea related to creating a dataset of government-developed OS software involves compiling a comprehensive dataset that includes data to understand the state of such software. This would involve determining if the software is buildable, has an open development history, and includes requirements documentation. The project could start with the Netherlands (NL) but would benefit from including data from other countries as well. The challenge in studying government software is due to the lack of incentive to make it popular and language barriers.","The project idea is to create a comprehensive dataset of government-developed OS software to understand the state of such software, including its buildability, open development history, and requirements documentation. This addresses challenges like the lack of incentive to make software popular and language barriers.",0.9999999999,1.0,1.0,0.89,0.16666666638888888,0.9898905009465272
