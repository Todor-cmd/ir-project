user_input,retrieved_contexts,reference_contexts,response,reference,context_precision,context_recall,faithfulness,factual_correctness(mode=f1),context_entity_recall,answer_relevancy
How EcoAndroid reduce risk by reduce size?,"['‚Ä¢ Software consumers have started to worry about the climate impact \nof their behaviour as users. \n‚Ä¢ Being environmentally sustainable is now an important competitive \nfactor \n‚Ä¢ Marketing teams are already using all eco-friendly labels. Technical \nteams are not there yet, though. \n‚Ä¢ It‚Äôs easier said than done!\n$\n16\n\nGreen Washing\n‚Ä¢ Deceptively use marketing techniques to \nclaim being eco-friendly. \n‚Ä¢ Opting for green-coloured designs. \n‚Ä¢ Red/orange is usually perceived as \ntasty. \n‚Ä¢ Green is perceived as eco-friendly. \n‚Ä¢ The VW case. (?)\n17\n\nThe VW scandal\nGreenwashing\n‚Ä¢ Used software to cheat on vehicle emissions \ntests. \n‚Ä¢ The vehicle‚Äôs software could detect whether they \nwere being tested, changing the performance \naccordingly to improve results. \n‚Ä¢ Affected 11M cars worldwide, 8M in Europe.\n18\n\nHow can we drive sustainability \nin the SE industry?\n\nGreen Procurement\n‚Ä¢ Customers decide on providers that share their values \n‚Ä¢ This is currently the main trigger reason why organisations \nworry about Sustainability and Green Software. \n‚Ä¢ Examples of green procurement: \n‚Ä¢ Customers that only buy green services/products \n‚Ä¢ Companies that only use green providers \n‚Ä¢ Developers that only work for green companies \n‚Ä¢ Green procurement makes environmental sustainability \nessential for economical sustainability.\n20\n\nSustainability via compliance\n‚Ä¢ EU wants to be carbon neutral by 2030 \n‚Ä¢ This also affects the ICT sector. Estimated to impact \n14% of the global carbon footprint by 2040. \n‚Ä¢ Some initiatives are already being negotiated. \n‚Ä¢ Extending the smartphone lifetime to 7 years. \n‚Ä¢ Right-to-repair movement. https://repair.eu \n‚Ä¢ Making IT services relying on clean energy more \naccessible (e.g., less taxes).\n21\n\nSoftware for Sustainability \n‚Ä¢ We are not covering it in this course.\n\nCarbon-free giants\n‚Ä¢ Google, Microsoft, Meta/Facebook want to be carbon free by 2030 \n‚Ä¢ Carbon free is different from carbon neutral \n‚Ä¢ Green IT experts are needed to meet these goals\n23\n\n\nRebound effect*\n‚Ä¢ Energy consumption decreases ‚Üì‚Üì but demand also increases ‚Üë‚Üë. \n‚Ä¢ *a.k.a. Jevons Paradox in economics; Downs‚ÄìThomson paradox in\xa0mobility.', '[‚Ä¶]\n13\n\nAvoid Extraneous Graphics and \nAnimations  \n‚Ä¢ Context: Mobile apps that feature impressive graphics \nand animations. [‚Ä¶] \n‚Ä¢ Solution: Study the importance of graphics and \nanimations to the user experience and reduce them when \napplicable. [‚Ä¶]\n‚Ä¢ Example: Resort to low frame rates for animations when \npossible. \nDespite being important to improve user experience, graphics \nand animations are battery intensive and should be used with \nmoderation.  \n14\n\nEnergy Patterns are \nmore Frequent\nin Android Apps\n\nExample case: Nextcloud\nFOSS\n\nExample case: Nextcloud\n‚Ä¢ Users complain that sometimes they go on a trip and  Nextcloud drains their \nbattery. Users consider uninstalling the app when battery life is essential. \n‚Ä¢ File sync can be energy-greedy. Send large files to the server, long 3G/4G data connections. \n‚Ä¢ It is mostly used for backup. No real-time collaboration is needed. \n‚Ä¢ Energy requirements vary depending on context and user. Some days you really \nneed all the battery you can get. \n‚Ä¢ https://github.com/nextcloud/android/commit/\n8bc432027e0d33e8043cf40192203203a40ca29c\nSolutions?\n17\n\nExample case: K-9 mail\n18\n\nExample case: K-9 mail\n19\nSolutions?\n‚Ä¢ Some users noticed that K-9 mail was spending more energy than usual. üôâ \n‚Ä¢ A user that was having issues with a personal mail server  noticed that K-9 \nmail was the one of the most energy-greedy apps. IMAP IDLE protocol for real-time \nnotifications. \n‚Ä¢ When a connection is not possible, the app automatically retries later.', '‚Ä¢ Some users noticed that K-9 mail was spending more energy than usual. üôâ \n‚Ä¢ A user that was having issues with a personal mail server  noticed that K-9 \nmail was the one of the most energy-greedy apps. IMAP IDLE protocol for real-time \nnotifications. \n‚Ä¢ When a connection is not possible, the app automatically retries later. \n‚Ä¢ https://github.com/k9mail/k-9/commit/\n86f3b28f79509d1a4d613eb39f60603e08579ea3\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio) \n‚Ä¢ Dynamic Retry Delay \n‚Ä¢ Push Over Poll \n‚Ä¢ Reduce Size \n‚Ä¢ Cache \n‚Ä¢ Avoid Graphics and Animations\n20\n\nCarbon-Aware Computing for \nDatacenters \nhttps://sites.google.com/view/energy-efficiency-languages\n21\nAna Radovanovic ÃÅ, Ross Koningstein, Ian Schneider, Bokan \nChen, Alexandre Duarte, Binz Roy, Diyue Xiao, Maya \nHaridasan, Patrick Hung, Nick Care, Saurav Talukdar, Eric \nMullen, Kendal Smith, MariEllen Cottman, and Walfredo Cirne \n\n\n‚Ä¢ Google‚Äôs Carbon-Intelligent Computing System (CICS) \n‚Ä¢ Main idea: use carbon-intensity data to shift datacenter jobs in time \n‚Ä¢ Typically, job schedulers use a metric of cluster capacity to schedule a job in \na particular cluster. \n‚Ä¢ CICS overrides this metric with the virtual capacity curve (VCC) that \nfactors in Carbon intensity \n‚Ä¢ When a new job comes in, the scheduler estimates its CPU load and power \nusage and assigns it to a cluster if the VCC is not exceeded.\n23\n\n‚Ä¢ Jobs are divided between flexible and inflexible. \n‚Ä¢ Flexible load is considered shapeable/shiftable as long as its total daily \ncompute (CPU) demand is preserved \n‚Ä¢ The system needs to consider that, while running a job, the virtual capacity \ncurve (VCC) might drop. Hence, this job should not start in the first place. \n‚Ä¢ They forecast VCC for the next day\n24\n\n\nVirtual Cluster Capacity (VCC)\n‚Ä¢ Aims at reducing the peak load at carbon intensive hours but in total it should allow for the \nsome amount of daily computation!']","['<1-hop>\n\nShuffle \nüîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them.\n‚Ä¢ If you run 30 executions for version A and another batch for version B:\n‚Ä¢ External conditions that change over time will have a diÔ¨Äerent bias in \nthe 2 versions (e.g., room temperature changes).\n‚Ä¢ If you shuÔ¨Ñe, you reduce this risk.\n11', '<2-hop>\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio)\n‚Ä¢ Dynamic Retry Delay\n‚Ä¢ Push Over Poll\n‚Ä¢ Reduce Size\n‚Ä¢ Cache\n‚Ä¢ Avoid Graphics and Animations\n20', '<1-hop>\n\nShuffle \nüîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them.\n‚Ä¢ If you run 30 executions for version A and another batch for version B:\n‚Ä¢ External conditions that change over time will have a diÔ¨Äerent bias in \nthe 2 versions (e.g., room temperature changes).\n‚Ä¢ If you shuÔ¨Ñe, you reduce this risk.\n11', '<2-hop>\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio)\n‚Ä¢ Dynamic Retry Delay\n‚Ä¢ Push Over Poll\n‚Ä¢ Reduce Size\n‚Ä¢ Cache\n‚Ä¢ Avoid Graphics and Animations\n20']","EcoAndroid reduces risk by reducing size through optimizing the application to consume less energy and resources. By minimizing the size of the app, it can decrease the energy consumption required for data processing and storage, which in turn reduces the environmental impact and operational costs associated with running the app. This approach aligns with the broader goal of making software more sustainable and efficient.",EcoAndroid reduce risk by using Reduce Size feature which help minimize energy consumption and reduce impact of external factors like temperature changes.,0.0,0.0,0.5,0.5,0.249999999375,0.9452558384693622
How can static code analysis in data science be used to improve the energy efficiency of data centers and contribute to sustainable software engineering?,"['‚Ä¢\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy efficiency using static code analysis. \n‚Ä¢ We don‚Äôt need an accurate value. \n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention. \n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27\n\nC7 - Education\n‚Ä¢ Educational game for Software \nSustainability practices \n‚Ä¢ Purpose: use within software teams to \ndiscuss or learn about different sustainable \nIT practices: at the organisation level, \nsoftware, etc.\n28\nhttps://github.com/OttoKaaij/Ticket-To-Sustainability/?tab=readme-ov-file\n\nProject ideas (old)\n‚Ä¢ Plugin from EnergiBridge (GUI, report generator, python library, etc.) \n‚Ä¢ Plugin for ChatGPT (carbon emissions per chat window) \n‚Ä¢ Seamless measurements for AI libraries \n‚Ä¢ Energy patterns for Green AI \n‚Ä¢ Sustainable SW dev gamification \n‚Ä¢ Sustainability auditor for AI projects \n‚Ä¢ Energy Profiling of screen colour filter tools (or display settings) \n‚Ä¢ ‚Ä¶ you can also propose yours!\n\nhttps://edu.nl/64gpk\nedu.nl/64gpk', 'Revisiting Research Questions\n‚Ä¢ Can we compare the energy efficiency of software languages?  \n‚Ä¢ Is the faster language always the most energy efficient? \n‚Ä¢ How does memory usage relate to energy consumption?  \n‚Ä¢ Can we automatically decide what is the best programming language considering \nenergy, time, and memory usage?  \n‚Ä¢ How do the results of our energy consumption analysis of programming \nlanguages gathered from rigorous performance benchmarking solutions \ncompare to results of average day-to-day solutions?  \n‚Ä¢ What would happen if we cherry picked the tasks?\u2028\n44\n\n\nLu√≠s Cruz \nL.Cruz@tudelft.nl \n3. Scientific Guide for Reliable \nEnergy Experiments\nSustainable Software Engineering\u2028\nCS4575\nSustainableSE 2025\nCarolin Brandt \nC.E.Brandt@tudelft.nl \nEnrique Barba Roque \nE.BarbaRoque@tudelft.nl', 'data to understand state of software: \nbuildable?, open dev. history?, requirements documentation? \n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!\n\nB7. Queue - but better for the student / TA society\n‚Ä¢ Requirements analysis regarding social and individual sustainability effects \nof Queue \n‚Ä¢ Other EIP / TUD used software also possible: e.g., Answers EWI \n‚Ä¢ Non-technical project ‚Üí proper process (workshops? Interviews?) & rich \ndescription of outcomes focus of grading\nhttps://eip.pages.ewi.tudelft.nl/eip-website/queue.html\n\nC1. Compare energy consumption of docker images for \nML workloads.\n‚Ä¢ Similar to what we have seen in the lectures but for ML-specific workloads. \n‚Ä¢ We can reuse existing experiment replication packages.\n22\n\nC2. Plugin to visualize Hugging Face carbon emissions.\n‚Ä¢ https://huggingface.co/blog/leaderboard-emissions-\nanalysis \n‚Ä¢\nYoo, Taewon, et al. ""Visualizing the Carbon Intensity of Machine Learning Inference for Image Analysis on TensorFlow Hub.""\n\nC3. Plugin for ChatGPT\n‚Ä¢ Users seldom know how much carbon they are emitting when they interact \nwith chat GPT. \n‚Ä¢ Let‚Äôs make it transparent to the users. Browser plugin?\n24\nCO2\n\nC4. NutriScore for software libraries\n25\n‚Ä¢ NutriScore labels are not perfect but they are a good starting point! \n‚Ä¢ What if we could do the same thing for the energy efficiency of software. \n‚Ä¢ (Also open to individual or social sustainability) \n‚Ä¢ This work can be scoped in particular domains/ecossystems/use cases. \n‚Ä¢ Libraries for stats? ML? Web Dev? Cloud?\n\nC5. Add energy-awareness to existing software\n26\n‚Ä¢ Streamlit, Notebooks, JSFiddle, \nPyScript, zsh, etc. \n‚Ä¢\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy efficiency using static code analysis. \n‚Ä¢ We don‚Äôt need an accurate value. \n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention. \n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)']","['<1-hop>\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy eÔ¨Éciency using static code analysis.\n‚Ä¢ We don‚Äôt need an accurate value.\n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.\n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27', '<2-hop>\n\nWhy?\n‚Ä¢ Throughout your career you might:\n‚Ä¢ Design/maintain/contract data centers\n‚Ä¢ Set up operations/devops\n‚Ä¢ Develop AI for IoT devices\n‚Ä¢ Be the next CEO/CTO of a software company\n‚Ä¢ Sustainability can be your main role:\n‚Ä¢ Green Software Developer\n‚Ä¢ Sustainability Consultant\n‚Ä¢ Green Advocate \n‚Ä¢ Founder of a Green Tech startup (B2B?)\n28', '<1-hop>\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy eÔ¨Éciency using static code analysis.\n‚Ä¢ We don‚Äôt need an accurate value.\n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.\n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27', '<2-hop>\n\nWhy?\n‚Ä¢ Throughout your career you might:\n‚Ä¢ Design/maintain/contract data centers\n‚Ä¢ Set up operations/devops\n‚Ä¢ Develop AI for IoT devices\n‚Ä¢ Be the next CEO/CTO of a software company\n‚Ä¢ Sustainability can be your main role:\n‚Ä¢ Green Software Developer\n‚Ä¢ Sustainability Consultant\n‚Ä¢ Green Advocate \n‚Ä¢ Founder of a Green Tech startup (B2B?)\n28', '<1-hop>\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy eÔ¨Éciency using static code analysis.\n‚Ä¢ We don‚Äôt need an accurate value.\n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.\n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27', '<2-hop>\n\nWhy?\n‚Ä¢ Throughout your career you might:\n‚Ä¢ Design/maintain/contract data centers\n‚Ä¢ Set up operations/devops\n‚Ä¢ Develop AI for IoT devices\n‚Ä¢ Be the next CEO/CTO of a software company\n‚Ä¢ Sustainability can be your main role:\n‚Ä¢ Green Software Developer\n‚Ä¢ Sustainability Consultant\n‚Ä¢ Green Advocate \n‚Ä¢ Founder of a Green Tech startup (B2B?)\n28', '<1-hop>\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy eÔ¨Éciency using static code analysis.\n‚Ä¢ We don‚Äôt need an accurate value.\n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.\n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27', '<2-hop>\n\nWhy?\n‚Ä¢ Throughout your career you might:\n‚Ä¢ Design/maintain/contract data centers\n‚Ä¢ Set up operations/devops\n‚Ä¢ Develop AI for IoT devices\n‚Ä¢ Be the next CEO/CTO of a software company\n‚Ä¢ Sustainability can be your main role:\n‚Ä¢ Green Software Developer\n‚Ä¢ Sustainability Consultant\n‚Ä¢ Green Advocate \n‚Ä¢ Founder of a Green Tech startup (B2B?)\n28']","Static code analysis in data science can be used to improve the energy efficiency of data centers by identifying code that is likely to introduce energy hotspots. By estimating energy efficiency through static code analysis, developers can pinpoint which parts of the codebase require more attention and optimization. This proactive approach allows for targeted improvements that can reduce energy consumption, thereby contributing to sustainable software engineering. While the analysis does not need to provide an accurate value, it helps in highlighting potential inefficiencies that, when addressed, can lead to significant energy savings in data centers. This method can be scoped specifically to data science domains, allowing for tailored optimizations that align with the specific computational demands of data science workloads.","Static code analysis in data science can be used to estimate energy efficiency by identifying potential energy hotspots in the code. This helps in reviewing and optimizing the code to reduce energy consumption. By applying this approach, developers can contribute to the design and maintenance of more energy-efficient data centers, aligning with sustainable software engineering practices.",0.8333333332916666,0.6666666666666666,0.8,0.89,0.37499999953124996,0.9790472276579353
How can static code analysis in data science contribute to the development of more sustainable data centers?,"['‚Ä¢\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy efficiency using static code analysis. \n‚Ä¢ We don‚Äôt need an accurate value. \n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention. \n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27\n\nC7 - Education\n‚Ä¢ Educational game for Software \nSustainability practices \n‚Ä¢ Purpose: use within software teams to \ndiscuss or learn about different sustainable \nIT practices: at the organisation level, \nsoftware, etc.\n28\nhttps://github.com/OttoKaaij/Ticket-To-Sustainability/?tab=readme-ov-file\n\nProject ideas (old)\n‚Ä¢ Plugin from EnergiBridge (GUI, report generator, python library, etc.) \n‚Ä¢ Plugin for ChatGPT (carbon emissions per chat window) \n‚Ä¢ Seamless measurements for AI libraries \n‚Ä¢ Energy patterns for Green AI \n‚Ä¢ Sustainable SW dev gamification \n‚Ä¢ Sustainability auditor for AI projects \n‚Ä¢ Energy Profiling of screen colour filter tools (or display settings) \n‚Ä¢ ‚Ä¶ you can also propose yours!\n\nhttps://edu.nl/64gpk\nedu.nl/64gpk', 'data to understand state of software: \nbuildable?, open dev. history?, requirements documentation? \n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!\n\nB7. Queue - but better for the student / TA society\n‚Ä¢ Requirements analysis regarding social and individual sustainability effects \nof Queue \n‚Ä¢ Other EIP / TUD used software also possible: e.g., Answers EWI \n‚Ä¢ Non-technical project ‚Üí proper process (workshops? Interviews?) & rich \ndescription of outcomes focus of grading\nhttps://eip.pages.ewi.tudelft.nl/eip-website/queue.html\n\nC1. Compare energy consumption of docker images for \nML workloads.\n‚Ä¢ Similar to what we have seen in the lectures but for ML-specific workloads. \n‚Ä¢ We can reuse existing experiment replication packages.\n22\n\nC2. Plugin to visualize Hugging Face carbon emissions.\n‚Ä¢ https://huggingface.co/blog/leaderboard-emissions-\nanalysis \n‚Ä¢\nYoo, Taewon, et al. ""Visualizing the Carbon Intensity of Machine Learning Inference for Image Analysis on TensorFlow Hub.""\n\nC3. Plugin for ChatGPT\n‚Ä¢ Users seldom know how much carbon they are emitting when they interact \nwith chat GPT. \n‚Ä¢ Let‚Äôs make it transparent to the users. Browser plugin?\n24\nCO2\n\nC4. NutriScore for software libraries\n25\n‚Ä¢ NutriScore labels are not perfect but they are a good starting point! \n‚Ä¢ What if we could do the same thing for the energy efficiency of software. \n‚Ä¢ (Also open to individual or social sustainability) \n‚Ä¢ This work can be scoped in particular domains/ecossystems/use cases. \n‚Ä¢ Libraries for stats? ML? Web Dev? Cloud?\n\nC5. Add energy-awareness to existing software\n26\n‚Ä¢ Streamlit, Notebooks, JSFiddle, \nPyScript, zsh, etc. \n‚Ä¢\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy efficiency using static code analysis. \n‚Ä¢ We don‚Äôt need an accurate value. \n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention. \n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)', 'Green Data-centric AI\n‚Ä¢ How do different ML algorithms compare \nin terms of energy consumption? \n‚Ä¢ How does number of rows relate to the \nenergy consumption of ML models? \n‚Ä¢ How does number of features relate to \nthe energy consumption of ML models? \n‚Ä¢ What is the impact of reducing data in the \nperformance of the model? \n‚Ä¢ Method -> results -> discussion\n17\n\nMethod\n‚Ä¢ Single object of study: natural language model to detect spam messages. \n‚Ä¢ 6 machine learning algorithms: SVM, Decision Tree, KNN, Random Forrest, \nAdaBoost, Bagging Classifier. \n‚Ä¢ Reduce the number of rows. 10%, 20%, .., 100% \n‚Ä¢ Stratified random sampling (?) \n‚Ä¢ Reduce the number of features. 10%, 20%, .., 100% \n‚Ä¢ Feature importance metric based on the Chi-Square Test (Chi2) \n‚Ä¢ Estimate energy consumption using a RAPL-based tool. (?)\n18\n\n‚Ä¢ Repeat 30 times \n‚Ä¢ Fix random seeds \n‚Ä¢ ‚Ä¶ \n‚Ä¢ Data was not Normal => tailed Normal distribution.\n19\n(?)\n\nResults: energy consumption of algorithms\n\nResults: energy vs data shape\n\nResults: performance vs data shape\n\nDiscussion\n‚Ä¢ Other data properties should be investigated. \n‚Ä¢ E.g., data types \n‚Ä¢ Reporting energy data is essential. It can lead to different model selection \nwithout hindering model performance. \n‚Ä¢ There is a big opportunity in Model and Data Simplification.\n23\n\nData/Model Simplification\n‚Ä¢ (?) \n‚Ä¢ Data selection \n‚Ä¢ Data quantisation. Posit? \n‚Ä¢ Data distillation \n‚Ä¢ Coreset extraction (?) \n‚Ä¢ Model distillation \n‚Ä¢ Model quantisation \n‚Ä¢ Model pruning \n‚Ä¢ ‚Ä¶\n24\n\nPosit vs Float\nMore about this: https://spectrum.ieee.org/floating-point-numbers-posits-processor\nBetter for DL use cases\n\nHow can we tune \nlearning \nparameters \nefficiently?\n\nHyper parameter tuning\n‚Ä¢ When training an ML model, there are several parameters that need to be \ntuned. \n‚Ä¢ E.g., in SVM we have the Regularization parameter C, the kernel function, \nthe degree of the kernel function, and depending on the case, many other. \n‚Ä¢ The common approach revolves around grid search. The user provides a \nsequence of possible values for each parameter and the pipeline runs all \npossible combinations.']","['<1-hop>\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy eÔ¨Éciency using static code analysis.\n‚Ä¢ We don‚Äôt need an accurate value.\n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.\n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27', '<2-hop>\n\nWhy?\n‚Ä¢ Throughout your career you might:\n‚Ä¢ Design/maintain/contract data centers\n‚Ä¢ Set up operations/devops\n‚Ä¢ Develop AI for IoT devices\n‚Ä¢ Be the next CEO/CTO of a software company\n‚Ä¢ Sustainability can be your main role:\n‚Ä¢ Green Software Developer\n‚Ä¢ Sustainability Consultant\n‚Ä¢ Green Advocate \n‚Ä¢ Founder of a Green Tech startup (B2B?)\n28']","Static code analysis in data science can contribute to the development of more sustainable data centers by estimating energy efficiency and identifying potential energy hotspots in the code. By analyzing the code without executing it, developers can pinpoint which parts of the code are likely to consume more energy and therefore should be reviewed with more attention. This proactive approach allows for optimizations that can reduce energy consumption, leading to more efficient use of resources in data centers. This process can be scoped to specific domains, such as data science, to tailor the analysis to the particular needs and characteristics of the field.","Static code analysis in data science can contribute to the development of more sustainable data centers by estimating energy efficiency and identifying potential energy hotspots within the code. This approach allows developers to focus on reviewing code segments that are more likely to introduce inefficiencies, thereby optimizing resource usage. By integrating such practices, especially in domains like data science, developers can help create more sustainable solutions, which aligns with broader career goals in sustainability, such as designing or maintaining energy-efficient data centers.",0.99999999995,1.0,1.0,0.82,0.0,0.9896122324858414
How can static code analysis in data science projects help in designing more sustainablility-focused data centers?,"['‚Ä¢\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy efficiency using static code analysis. \n‚Ä¢ We don‚Äôt need an accurate value. \n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention. \n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27\n\nC7 - Education\n‚Ä¢ Educational game for Software \nSustainability practices \n‚Ä¢ Purpose: use within software teams to \ndiscuss or learn about different sustainable \nIT practices: at the organisation level, \nsoftware, etc.\n28\nhttps://github.com/OttoKaaij/Ticket-To-Sustainability/?tab=readme-ov-file\n\nProject ideas (old)\n‚Ä¢ Plugin from EnergiBridge (GUI, report generator, python library, etc.) \n‚Ä¢ Plugin for ChatGPT (carbon emissions per chat window) \n‚Ä¢ Seamless measurements for AI libraries \n‚Ä¢ Energy patterns for Green AI \n‚Ä¢ Sustainable SW dev gamification \n‚Ä¢ Sustainability auditor for AI projects \n‚Ä¢ Energy Profiling of screen colour filter tools (or display settings) \n‚Ä¢ ‚Ä¶ you can also propose yours!\n\nhttps://edu.nl/64gpk\nedu.nl/64gpk', 'data to understand state of software: \nbuildable?, open dev. history?, requirements documentation? \n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!\n\nB7. Queue - but better for the student / TA society\n‚Ä¢ Requirements analysis regarding social and individual sustainability effects \nof Queue \n‚Ä¢ Other EIP / TUD used software also possible: e.g., Answers EWI \n‚Ä¢ Non-technical project ‚Üí proper process (workshops? Interviews?) & rich \ndescription of outcomes focus of grading\nhttps://eip.pages.ewi.tudelft.nl/eip-website/queue.html\n\nC1. Compare energy consumption of docker images for \nML workloads.\n‚Ä¢ Similar to what we have seen in the lectures but for ML-specific workloads. \n‚Ä¢ We can reuse existing experiment replication packages.\n22\n\nC2. Plugin to visualize Hugging Face carbon emissions.\n‚Ä¢ https://huggingface.co/blog/leaderboard-emissions-\nanalysis \n‚Ä¢\nYoo, Taewon, et al. ""Visualizing the Carbon Intensity of Machine Learning Inference for Image Analysis on TensorFlow Hub.""\n\nC3. Plugin for ChatGPT\n‚Ä¢ Users seldom know how much carbon they are emitting when they interact \nwith chat GPT. \n‚Ä¢ Let‚Äôs make it transparent to the users. Browser plugin?\n24\nCO2\n\nC4. NutriScore for software libraries\n25\n‚Ä¢ NutriScore labels are not perfect but they are a good starting point! \n‚Ä¢ What if we could do the same thing for the energy efficiency of software. \n‚Ä¢ (Also open to individual or social sustainability) \n‚Ä¢ This work can be scoped in particular domains/ecossystems/use cases. \n‚Ä¢ Libraries for stats? ML? Web Dev? Cloud?\n\nC5. Add energy-awareness to existing software\n26\n‚Ä¢ Streamlit, Notebooks, JSFiddle, \nPyScript, zsh, etc. \n‚Ä¢\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy efficiency using static code analysis. \n‚Ä¢ We don‚Äôt need an accurate value. \n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention. \n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)', 'Revisiting Research Questions\n‚Ä¢ Can we compare the energy efficiency of software languages?  \n‚Ä¢ Is the faster language always the most energy efficient? \n‚Ä¢ How does memory usage relate to energy consumption?  \n‚Ä¢ Can we automatically decide what is the best programming language considering \nenergy, time, and memory usage?  \n‚Ä¢ How do the results of our energy consumption analysis of programming \nlanguages gathered from rigorous performance benchmarking solutions \ncompare to results of average day-to-day solutions?  \n‚Ä¢ What would happen if we cherry picked the tasks?\u2028\n44\n\n\nLu√≠s Cruz \nL.Cruz@tudelft.nl \n3. Scientific Guide for Reliable \nEnergy Experiments\nSustainable Software Engineering\u2028\nCS4575\nSustainableSE 2025\nCarolin Brandt \nC.E.Brandt@tudelft.nl \nEnrique Barba Roque \nE.BarbaRoque@tudelft.nl']","['<1-hop>\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy eÔ¨Éciency using static code analysis.\n‚Ä¢ We don‚Äôt need an accurate value.\n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.\n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27', '<2-hop>\n\nWhy?\n‚Ä¢ Throughout your career you might:\n‚Ä¢ Design/maintain/contract data centers\n‚Ä¢ Set up operations/devops\n‚Ä¢ Develop AI for IoT devices\n‚Ä¢ Be the next CEO/CTO of a software company\n‚Ä¢ Sustainability can be your main role:\n‚Ä¢ Green Software Developer\n‚Ä¢ Sustainability Consultant\n‚Ä¢ Green Advocate \n‚Ä¢ Founder of a Green Tech startup (B2B?)\n28', '<1-hop>\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy eÔ¨Éciency using static code analysis.\n‚Ä¢ We don‚Äôt need an accurate value.\n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.\n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27', '<2-hop>\n\nWhy?\n‚Ä¢ Throughout your career you might:\n‚Ä¢ Design/maintain/contract data centers\n‚Ä¢ Set up operations/devops\n‚Ä¢ Develop AI for IoT devices\n‚Ä¢ Be the next CEO/CTO of a software company\n‚Ä¢ Sustainability can be your main role:\n‚Ä¢ Green Software Developer\n‚Ä¢ Sustainability Consultant\n‚Ä¢ Green Advocate \n‚Ä¢ Founder of a Green Tech startup (B2B?)\n28', '<1-hop>\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy eÔ¨Éciency using static code analysis.\n‚Ä¢ We don‚Äôt need an accurate value.\n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.\n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27', '<2-hop>\n\nWhy?\n‚Ä¢ Throughout your career you might:\n‚Ä¢ Design/maintain/contract data centers\n‚Ä¢ Set up operations/devops\n‚Ä¢ Develop AI for IoT devices\n‚Ä¢ Be the next CEO/CTO of a software company\n‚Ä¢ Sustainability can be your main role:\n‚Ä¢ Green Software Developer\n‚Ä¢ Sustainability Consultant\n‚Ä¢ Green Advocate \n‚Ä¢ Founder of a Green Tech startup (B2B?)\n28']","Static code analysis in data science projects can help in designing more sustainability-focused data centers by estimating energy efficiency. Although it doesn't provide an accurate value, it identifies which parts of the code are more likely to introduce energy hotspots. By focusing on these areas, developers can optimize code to reduce energy consumption, which in turn can lead to more energy-efficient data centers. This approach allows for targeted improvements that can contribute to the overall sustainability of data center operations. (Source: C6 - Green Shift Left)","Static code analysis in data science projects can help in designing more sustainablility-focused data centers by identifying energy hotspots in the code. This allows developers to review and optimize code that may contribute to higher energy consumption, thereby supporting the development of more efficient and sustainable data centers.",0.99999999995,1.0,0.5,0.86,0.0,0.9506109264845971
How does the use of static code analysis in data science projects contribute to the design and optimization of more sustanable data centers?,"['‚Ä¢\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy efficiency using static code analysis. \n‚Ä¢ We don‚Äôt need an accurate value. \n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention. \n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27\n\nC7 - Education\n‚Ä¢ Educational game for Software \nSustainability practices \n‚Ä¢ Purpose: use within software teams to \ndiscuss or learn about different sustainable \nIT practices: at the organisation level, \nsoftware, etc.\n28\nhttps://github.com/OttoKaaij/Ticket-To-Sustainability/?tab=readme-ov-file\n\nProject ideas (old)\n‚Ä¢ Plugin from EnergiBridge (GUI, report generator, python library, etc.) \n‚Ä¢ Plugin for ChatGPT (carbon emissions per chat window) \n‚Ä¢ Seamless measurements for AI libraries \n‚Ä¢ Energy patterns for Green AI \n‚Ä¢ Sustainable SW dev gamification \n‚Ä¢ Sustainability auditor for AI projects \n‚Ä¢ Energy Profiling of screen colour filter tools (or display settings) \n‚Ä¢ ‚Ä¶ you can also propose yours!\n\nhttps://edu.nl/64gpk\nedu.nl/64gpk', 'data to understand state of software: \nbuildable?, open dev. history?, requirements documentation? \n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!\n\nB7. Queue - but better for the student / TA society\n‚Ä¢ Requirements analysis regarding social and individual sustainability effects \nof Queue \n‚Ä¢ Other EIP / TUD used software also possible: e.g., Answers EWI \n‚Ä¢ Non-technical project ‚Üí proper process (workshops? Interviews?) & rich \ndescription of outcomes focus of grading\nhttps://eip.pages.ewi.tudelft.nl/eip-website/queue.html\n\nC1. Compare energy consumption of docker images for \nML workloads.\n‚Ä¢ Similar to what we have seen in the lectures but for ML-specific workloads. \n‚Ä¢ We can reuse existing experiment replication packages.\n22\n\nC2. Plugin to visualize Hugging Face carbon emissions.\n‚Ä¢ https://huggingface.co/blog/leaderboard-emissions-\nanalysis \n‚Ä¢\nYoo, Taewon, et al. ""Visualizing the Carbon Intensity of Machine Learning Inference for Image Analysis on TensorFlow Hub.""\n\nC3. Plugin for ChatGPT\n‚Ä¢ Users seldom know how much carbon they are emitting when they interact \nwith chat GPT. \n‚Ä¢ Let‚Äôs make it transparent to the users. Browser plugin?\n24\nCO2\n\nC4. NutriScore for software libraries\n25\n‚Ä¢ NutriScore labels are not perfect but they are a good starting point! \n‚Ä¢ What if we could do the same thing for the energy efficiency of software. \n‚Ä¢ (Also open to individual or social sustainability) \n‚Ä¢ This work can be scoped in particular domains/ecossystems/use cases. \n‚Ä¢ Libraries for stats? ML? Web Dev? Cloud?\n\nC5. Add energy-awareness to existing software\n26\n‚Ä¢ Streamlit, Notebooks, JSFiddle, \nPyScript, zsh, etc. \n‚Ä¢\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy efficiency using static code analysis. \n‚Ä¢ We don‚Äôt need an accurate value. \n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention. \n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)', 'Revisiting Research Questions\n‚Ä¢ Can we compare the energy efficiency of software languages?  \n‚Ä¢ Is the faster language always the most energy efficient? \n‚Ä¢ How does memory usage relate to energy consumption?  \n‚Ä¢ Can we automatically decide what is the best programming language considering \nenergy, time, and memory usage?  \n‚Ä¢ How do the results of our energy consumption analysis of programming \nlanguages gathered from rigorous performance benchmarking solutions \ncompare to results of average day-to-day solutions?  \n‚Ä¢ What would happen if we cherry picked the tasks?\u2028\n44\n\n\nLu√≠s Cruz \nL.Cruz@tudelft.nl \n3. Scientific Guide for Reliable \nEnergy Experiments\nSustainable Software Engineering\u2028\nCS4575\nSustainableSE 2025\nCarolin Brandt \nC.E.Brandt@tudelft.nl \nEnrique Barba Roque \nE.BarbaRoque@tudelft.nl']","['<1-hop>\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy eÔ¨Éciency using static code analysis.\n‚Ä¢ We don‚Äôt need an accurate value.\n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.\n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27', '<2-hop>\n\nWhy?\n‚Ä¢ Throughout your career you might:\n‚Ä¢ Design/maintain/contract data centers\n‚Ä¢ Set up operations/devops\n‚Ä¢ Develop AI for IoT devices\n‚Ä¢ Be the next CEO/CTO of a software company\n‚Ä¢ Sustainability can be your main role:\n‚Ä¢ Green Software Developer\n‚Ä¢ Sustainability Consultant\n‚Ä¢ Green Advocate \n‚Ä¢ Founder of a Green Tech startup (B2B?)\n28', '<1-hop>\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy eÔ¨Éciency using static code analysis.\n‚Ä¢ We don‚Äôt need an accurate value.\n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.\n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27', '<2-hop>\n\nWhy?\n‚Ä¢ Throughout your career you might:\n‚Ä¢ Design/maintain/contract data centers\n‚Ä¢ Set up operations/devops\n‚Ä¢ Develop AI for IoT devices\n‚Ä¢ Be the next CEO/CTO of a software company\n‚Ä¢ Sustainability can be your main role:\n‚Ä¢ Green Software Developer\n‚Ä¢ Sustainability Consultant\n‚Ä¢ Green Advocate \n‚Ä¢ Founder of a Green Tech startup (B2B?)\n28']","The use of static code analysis in data science projects can contribute to the design and optimization of more sustainable data centers by estimating energy efficiency. Although it does not provide an accurate value, static code analysis helps identify which parts of the code are more likely to introduce energy hotspots. By focusing on these areas, developers can optimize the code to reduce energy consumption, which in turn can lead to more efficient use of resources in data centers. This approach can be scoped to specific domains, such as data science, to ensure targeted improvements in energy efficiency. (Source: C6 - Green Shift Left)","The use of static code analysis in data science projects contributes to the design and optimization of more sustainable data centers by identifying energy hotspots within the code. This process allows developers to focus on reviewing and optimizing sections of code that are more likely to introduce energy inefficiencies. By doing so, it supports the broader goal of creating more energy-efficient systems, which is crucial for the sustainable operation of data centers. This approach aligns with the growing need for green software development practices, where professionals can play roles such as green software developers or sustainability consultants, ensuring that energy efficiency is a key consideration throughout the software lifecycle.",0.99999999995,0.75,0.7142857142857143,0.67,0.0,0.9690165824224825
How reduce risk and reduce size in software engineering?,"['Lu√≠s Cruz \nL.Cruz@tudelft.nl \n10. Project 2\nSustainable Software Engineering\u2028\nCS4575\nSustainableSE 2025\nCarolin Brandt \nC.E.Brandt@tudelft.nl \nEnrique Barba Roque \nE.BarbaRoque@tudelft.nl\n\n1. Goal/assignment \n2. Deliverables \n3. Strategy \n4. Ideas\n\nAssignment\n‚Ä¢ Goal: Solve a Sustainable Software Engineering problem. \n‚Ä¢ Identify 1 problem that should be fixed to help enabling sustainability in \nthe software engineering industry/community. \n‚Ä¢ Propose a solution. A tool, framework, guidelines, etc. \n‚Ä¢ Implementation. \n‚Ä¢ Validation. (Depending on the idea) \n‚Ä¢ Dissemination/social impact. (Solution should be open source, welcome \ncontributors, post on social media? Tool website? Available in a package \nmanager?)\n3\n\nDeliverables\n‚Ä¢ Paper-like article. (Min 4 pages, max 10) \n‚Ä¢ Online git repo with open source codebase and/or replication package. \n‚Ä¢ Presentation: 5 min + 5min Q&A\n4\n\nArticle\n‚Ä¢ Different projects will have different expectations -> Make agreements with \nyour coach. \n‚Ä¢ Some projects are more technical and some projects more theoretical. \n‚Ä¢ Common requirements: \n‚Ä¢ Motivation, formulation of the problem being addressed, etc. \n‚Ä¢ Description of the solution. \n‚Ä¢ Validation of the solution (if applicable -> discuss with coach) \n‚Ä¢ Discussion of the solution. (Including limitations)\n5\n\nStrategy\n‚Ä¢ Starting next week, there are no lectures  \n‚Ä¢ Steering meetings from week 5 till week 9 (either online or in person).  \n‚Ä¢ 1 steering meeting per week. (4+1 sprints) \n‚Ä¢ Every week, you need to plan different tasks and assignments. \n‚Ä¢ Deadline April 4.\n6\n\nStrategy\n‚Ä¢ Week 0 \n‚Ä¢ Decide project idea (today) \n‚Ä¢ Define steering meeting schedule \n‚Ä¢ Create working document of the \narticle: Problem statement and solution \nproposal! \n‚Ä¢ Define and assign tasks for each week. \n‚Ä¢ Week 1 \n‚Ä¢ Implementation \n‚Ä¢ Agreements with supervisor. \n‚Ä¢ Week 2 \n‚Ä¢ Implementation \n‚Ä¢ Week 3 \n‚Ä¢ Implementation, Full draft of article, \ndissemination.', 'data to understand state of software: \nbuildable?, open dev. history?, requirements documentation? \n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!\n\nB7. Queue - but better for the student / TA society\n‚Ä¢ Requirements analysis regarding social and individual sustainability effects \nof Queue \n‚Ä¢ Other EIP / TUD used software also possible: e.g., Answers EWI \n‚Ä¢ Non-technical project ‚Üí proper process (workshops? Interviews?) & rich \ndescription of outcomes focus of grading\nhttps://eip.pages.ewi.tudelft.nl/eip-website/queue.html\n\nC1. Compare energy consumption of docker images for \nML workloads.\n‚Ä¢ Similar to what we have seen in the lectures but for ML-specific workloads. \n‚Ä¢ We can reuse existing experiment replication packages.\n22\n\nC2. Plugin to visualize Hugging Face carbon emissions.\n‚Ä¢ https://huggingface.co/blog/leaderboard-emissions-\nanalysis \n‚Ä¢\nYoo, Taewon, et al. ""Visualizing the Carbon Intensity of Machine Learning Inference for Image Analysis on TensorFlow Hub.""\n\nC3. Plugin for ChatGPT\n‚Ä¢ Users seldom know how much carbon they are emitting when they interact \nwith chat GPT. \n‚Ä¢ Let‚Äôs make it transparent to the users. Browser plugin?\n24\nCO2\n\nC4. NutriScore for software libraries\n25\n‚Ä¢ NutriScore labels are not perfect but they are a good starting point! \n‚Ä¢ What if we could do the same thing for the energy efficiency of software. \n‚Ä¢ (Also open to individual or social sustainability) \n‚Ä¢ This work can be scoped in particular domains/ecossystems/use cases. \n‚Ä¢ Libraries for stats? ML? Web Dev? Cloud?\n\nC5. Add energy-awareness to existing software\n26\n‚Ä¢ Streamlit, Notebooks, JSFiddle, \nPyScript, zsh, etc. \n‚Ä¢\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy efficiency using static code analysis. \n‚Ä¢ We don‚Äôt need an accurate value. \n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention. \n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)', 'Revisiting Research Questions\n‚Ä¢ Can we compare the energy efficiency of software languages?  \n‚Ä¢ Is the faster language always the most energy efficient? \n‚Ä¢ How does memory usage relate to energy consumption?  \n‚Ä¢ Can we automatically decide what is the best programming language considering \nenergy, time, and memory usage?  \n‚Ä¢ How do the results of our energy consumption analysis of programming \nlanguages gathered from rigorous performance benchmarking solutions \ncompare to results of average day-to-day solutions?  \n‚Ä¢ What would happen if we cherry picked the tasks?\u2028\n44\n\n\nLu√≠s Cruz \nL.Cruz@tudelft.nl \n3. Scientific Guide for Reliable \nEnergy Experiments\nSustainable Software Engineering\u2028\nCS4575\nSustainableSE 2025\nCarolin Brandt \nC.E.Brandt@tudelft.nl \nEnrique Barba Roque \nE.BarbaRoque@tudelft.nl']","['<1-hop>\n\nShuffle \nüîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them.\n‚Ä¢ If you run 30 executions for version A and another batch for version B:\n‚Ä¢ External conditions that change over time will have a diÔ¨Äerent bias in \nthe 2 versions (e.g., room temperature changes).\n‚Ä¢ If you shuÔ¨Ñe, you reduce this risk.\n11', '<2-hop>\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio)\n‚Ä¢ Dynamic Retry Delay\n‚Ä¢ Push Over Poll\n‚Ä¢ Reduce Size\n‚Ä¢ Cache\n‚Ä¢ Avoid Graphics and Animations\n20', '<1-hop>\n\nShuffle \nüîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them.\n‚Ä¢ If you run 30 executions for version A and another batch for version B:\n‚Ä¢ External conditions that change over time will have a diÔ¨Äerent bias in \nthe 2 versions (e.g., room temperature changes).\n‚Ä¢ If you shuÔ¨Ñe, you reduce this risk.\n11', '<2-hop>\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio)\n‚Ä¢ Dynamic Retry Delay\n‚Ä¢ Push Over Poll\n‚Ä¢ Reduce Size\n‚Ä¢ Cache\n‚Ä¢ Avoid Graphics and Animations\n20']","The provided sources do not directly address the question of reducing risk and size in software engineering. However, based on general software engineering principles, here are some strategies that can be applied:

1. **Modular Design**: Break down the software into smaller, manageable modules. This reduces complexity and makes it easier to manage changes and identify issues.

2. **Code Refactoring**: Regularly refactor code to improve its structure and reduce size without changing its functionality. This can help in maintaining a clean codebase and reducing technical debt.

3. **Automated Testing**: Implement automated testing to quickly identify and fix bugs, reducing the risk of defects in the software.

4. **Version Control**: Use version control systems to manage changes and track the history of the codebase, which helps in mitigating risks associated with changes.

5. **Static Code Analysis**: Use tools for static code analysis to identify potential issues in the code early in the development process.

6. **Continuous Integration/Continuous Deployment (CI/CD)**: Implement CI/CD pipelines to automate the process of testing and deploying code, reducing the risk of human error.

7. **Documentation**: Maintain thorough documentation to ensure that the software is understandable and maintainable by different team members.

These strategies can help in reducing both the risk and size of software projects, leading to more sustainable and efficient software engineering practices.","To reduce risk, shuffling executions helps control external factors like temperature changes. To reduce size, EcoAndroid uses features like dynamic retry delay and push over poll.",0.0,1.0,0.0,0.15,0.0,0.9805639151252591
How shuffling reduce risk and EcoAndroid reduce size?,"['[‚Ä¶]\n13\n\nAvoid Extraneous Graphics and \nAnimations  \n‚Ä¢ Context: Mobile apps that feature impressive graphics \nand animations. [‚Ä¶] \n‚Ä¢ Solution: Study the importance of graphics and \nanimations to the user experience and reduce them when \napplicable. [‚Ä¶]\n‚Ä¢ Example: Resort to low frame rates for animations when \npossible. \nDespite being important to improve user experience, graphics \nand animations are battery intensive and should be used with \nmoderation.  \n14\n\nEnergy Patterns are \nmore Frequent\nin Android Apps\n\nExample case: Nextcloud\nFOSS\n\nExample case: Nextcloud\n‚Ä¢ Users complain that sometimes they go on a trip and  Nextcloud drains their \nbattery. Users consider uninstalling the app when battery life is essential. \n‚Ä¢ File sync can be energy-greedy. Send large files to the server, long 3G/4G data connections. \n‚Ä¢ It is mostly used for backup. No real-time collaboration is needed. \n‚Ä¢ Energy requirements vary depending on context and user. Some days you really \nneed all the battery you can get. \n‚Ä¢ https://github.com/nextcloud/android/commit/\n8bc432027e0d33e8043cf40192203203a40ca29c\nSolutions?\n17\n\nExample case: K-9 mail\n18\n\nExample case: K-9 mail\n19\nSolutions?\n‚Ä¢ Some users noticed that K-9 mail was spending more energy than usual. üôâ \n‚Ä¢ A user that was having issues with a personal mail server  noticed that K-9 \nmail was the one of the most energy-greedy apps. IMAP IDLE protocol for real-time \nnotifications. \n‚Ä¢ When a connection is not possible, the app automatically retries later.', '‚Ä¢\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy efficiency using static code analysis. \n‚Ä¢ We don‚Äôt need an accurate value. \n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention. \n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27\n\nC7 - Education\n‚Ä¢ Educational game for Software \nSustainability practices \n‚Ä¢ Purpose: use within software teams to \ndiscuss or learn about different sustainable \nIT practices: at the organisation level, \nsoftware, etc.\n28\nhttps://github.com/OttoKaaij/Ticket-To-Sustainability/?tab=readme-ov-file\n\nProject ideas (old)\n‚Ä¢ Plugin from EnergiBridge (GUI, report generator, python library, etc.) \n‚Ä¢ Plugin for ChatGPT (carbon emissions per chat window) \n‚Ä¢ Seamless measurements for AI libraries \n‚Ä¢ Energy patterns for Green AI \n‚Ä¢ Sustainable SW dev gamification \n‚Ä¢ Sustainability auditor for AI projects \n‚Ä¢ Energy Profiling of screen colour filter tools (or display settings) \n‚Ä¢ ‚Ä¶ you can also propose yours!\n\nhttps://edu.nl/64gpk\nedu.nl/64gpk', '‚Ä¢ Some users noticed that K-9 mail was spending more energy than usual. üôâ \n‚Ä¢ A user that was having issues with a personal mail server  noticed that K-9 \nmail was the one of the most energy-greedy apps. IMAP IDLE protocol for real-time \nnotifications. \n‚Ä¢ When a connection is not possible, the app automatically retries later. \n‚Ä¢ https://github.com/k9mail/k-9/commit/\n86f3b28f79509d1a4d613eb39f60603e08579ea3\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio) \n‚Ä¢ Dynamic Retry Delay \n‚Ä¢ Push Over Poll \n‚Ä¢ Reduce Size \n‚Ä¢ Cache \n‚Ä¢ Avoid Graphics and Animations\n20\n\nCarbon-Aware Computing for \nDatacenters \nhttps://sites.google.com/view/energy-efficiency-languages\n21\nAna Radovanovic ÃÅ, Ross Koningstein, Ian Schneider, Bokan \nChen, Alexandre Duarte, Binz Roy, Diyue Xiao, Maya \nHaridasan, Patrick Hung, Nick Care, Saurav Talukdar, Eric \nMullen, Kendal Smith, MariEllen Cottman, and Walfredo Cirne \n\n\n‚Ä¢ Google‚Äôs Carbon-Intelligent Computing System (CICS) \n‚Ä¢ Main idea: use carbon-intensity data to shift datacenter jobs in time \n‚Ä¢ Typically, job schedulers use a metric of cluster capacity to schedule a job in \na particular cluster. \n‚Ä¢ CICS overrides this metric with the virtual capacity curve (VCC) that \nfactors in Carbon intensity \n‚Ä¢ When a new job comes in, the scheduler estimates its CPU load and power \nusage and assigns it to a cluster if the VCC is not exceeded.\n23\n\n‚Ä¢ Jobs are divided between flexible and inflexible. \n‚Ä¢ Flexible load is considered shapeable/shiftable as long as its total daily \ncompute (CPU) demand is preserved \n‚Ä¢ The system needs to consider that, while running a job, the virtual capacity \ncurve (VCC) might drop. Hence, this job should not start in the first place. \n‚Ä¢ They forecast VCC for the next day\n24\n\n\nVirtual Cluster Capacity (VCC)\n‚Ä¢ Aims at reducing the peak load at carbon intensive hours but in total it should allow for the \nsome amount of daily computation!']","['<1-hop>\n\nShuffle \nüîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them.\n‚Ä¢ If you run 30 executions for version A and another batch for version B:\n‚Ä¢ External conditions that change over time will have a diÔ¨Äerent bias in \nthe 2 versions (e.g., room temperature changes).\n‚Ä¢ If you shuÔ¨Ñe, you reduce this risk.\n11', '<2-hop>\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio)\n‚Ä¢ Dynamic Retry Delay\n‚Ä¢ Push Over Poll\n‚Ä¢ Reduce Size\n‚Ä¢ Cache\n‚Ä¢ Avoid Graphics and Animations\n20', '<1-hop>\n\nShuffle \nüîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them.\n‚Ä¢ If you run 30 executions for version A and another batch for version B:\n‚Ä¢ External conditions that change over time will have a diÔ¨Äerent bias in \nthe 2 versions (e.g., room temperature changes).\n‚Ä¢ If you shuÔ¨Ñe, you reduce this risk.\n11', '<2-hop>\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio)\n‚Ä¢ Dynamic Retry Delay\n‚Ä¢ Push Over Poll\n‚Ä¢ Reduce Size\n‚Ä¢ Cache\n‚Ä¢ Avoid Graphics and Animations\n20', '<1-hop>\n\nShuffle \nüîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them.\n‚Ä¢ If you run 30 executions for version A and another batch for version B:\n‚Ä¢ External conditions that change over time will have a diÔ¨Äerent bias in \nthe 2 versions (e.g., room temperature changes).\n‚Ä¢ If you shuÔ¨Ñe, you reduce this risk.\n11', '<2-hop>\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio)\n‚Ä¢ Dynamic Retry Delay\n‚Ä¢ Push Over Poll\n‚Ä¢ Reduce Size\n‚Ä¢ Cache\n‚Ä¢ Avoid Graphics and Animations\n20']","The sources provided do not specifically mention ""shuffling"" in the context of reducing risk. However, in general, shuffling can reduce risk by randomizing the order of operations or data, which can help prevent patterns that might lead to vulnerabilities or inefficiencies.

Regarding EcoAndroid, the source mentions ""Reduce Size"" as one of the strategies. While the specific details on how EcoAndroid achieves size reduction are not provided, generally, reducing size in an application can involve optimizing code, removing unnecessary resources, and compressing assets, which can lead to lower energy consumption and improved performance.",Shuffling reduce risk by controlling external factors like room temperature changes. EcoAndroid reduce size by using features like caching and avoiding graphics and animations.,0.0,0.5,0.42857142857142855,0.25,0.16666666638888888,0.0
How shuffling reduce risk when compare to EcoAndroid reduce size?,"['[‚Ä¶]\n13\n\nAvoid Extraneous Graphics and \nAnimations  \n‚Ä¢ Context: Mobile apps that feature impressive graphics \nand animations. [‚Ä¶] \n‚Ä¢ Solution: Study the importance of graphics and \nanimations to the user experience and reduce them when \napplicable. [‚Ä¶]\n‚Ä¢ Example: Resort to low frame rates for animations when \npossible. \nDespite being important to improve user experience, graphics \nand animations are battery intensive and should be used with \nmoderation.  \n14\n\nEnergy Patterns are \nmore Frequent\nin Android Apps\n\nExample case: Nextcloud\nFOSS\n\nExample case: Nextcloud\n‚Ä¢ Users complain that sometimes they go on a trip and  Nextcloud drains their \nbattery. Users consider uninstalling the app when battery life is essential. \n‚Ä¢ File sync can be energy-greedy. Send large files to the server, long 3G/4G data connections. \n‚Ä¢ It is mostly used for backup. No real-time collaboration is needed. \n‚Ä¢ Energy requirements vary depending on context and user. Some days you really \nneed all the battery you can get. \n‚Ä¢ https://github.com/nextcloud/android/commit/\n8bc432027e0d33e8043cf40192203203a40ca29c\nSolutions?\n17\n\nExample case: K-9 mail\n18\n\nExample case: K-9 mail\n19\nSolutions?\n‚Ä¢ Some users noticed that K-9 mail was spending more energy than usual. üôâ \n‚Ä¢ A user that was having issues with a personal mail server  noticed that K-9 \nmail was the one of the most energy-greedy apps. IMAP IDLE protocol for real-time \nnotifications. \n‚Ä¢ When a connection is not possible, the app automatically retries later.', '‚Ä¢ Some users noticed that K-9 mail was spending more energy than usual. üôâ \n‚Ä¢ A user that was having issues with a personal mail server  noticed that K-9 \nmail was the one of the most energy-greedy apps. IMAP IDLE protocol for real-time \nnotifications. \n‚Ä¢ When a connection is not possible, the app automatically retries later. \n‚Ä¢ https://github.com/k9mail/k-9/commit/\n86f3b28f79509d1a4d613eb39f60603e08579ea3\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio) \n‚Ä¢ Dynamic Retry Delay \n‚Ä¢ Push Over Poll \n‚Ä¢ Reduce Size \n‚Ä¢ Cache \n‚Ä¢ Avoid Graphics and Animations\n20\n\nCarbon-Aware Computing for \nDatacenters \nhttps://sites.google.com/view/energy-efficiency-languages\n21\nAna Radovanovic ÃÅ, Ross Koningstein, Ian Schneider, Bokan \nChen, Alexandre Duarte, Binz Roy, Diyue Xiao, Maya \nHaridasan, Patrick Hung, Nick Care, Saurav Talukdar, Eric \nMullen, Kendal Smith, MariEllen Cottman, and Walfredo Cirne \n\n\n‚Ä¢ Google‚Äôs Carbon-Intelligent Computing System (CICS) \n‚Ä¢ Main idea: use carbon-intensity data to shift datacenter jobs in time \n‚Ä¢ Typically, job schedulers use a metric of cluster capacity to schedule a job in \na particular cluster. \n‚Ä¢ CICS overrides this metric with the virtual capacity curve (VCC) that \nfactors in Carbon intensity \n‚Ä¢ When a new job comes in, the scheduler estimates its CPU load and power \nusage and assigns it to a cluster if the VCC is not exceeded.\n23\n\n‚Ä¢ Jobs are divided between flexible and inflexible. \n‚Ä¢ Flexible load is considered shapeable/shiftable as long as its total daily \ncompute (CPU) demand is preserved \n‚Ä¢ The system needs to consider that, while running a job, the virtual capacity \ncurve (VCC) might drop. Hence, this job should not start in the first place. \n‚Ä¢ They forecast VCC for the next day\n24\n\n\nVirtual Cluster Capacity (VCC)\n‚Ä¢ Aims at reducing the peak load at carbon intensive hours but in total it should allow for the \nsome amount of daily computation!', 'Green Data-centric AI\n‚Ä¢ How do different ML algorithms compare \nin terms of energy consumption? \n‚Ä¢ How does number of rows relate to the \nenergy consumption of ML models? \n‚Ä¢ How does number of features relate to \nthe energy consumption of ML models? \n‚Ä¢ What is the impact of reducing data in the \nperformance of the model? \n‚Ä¢ Method -> results -> discussion\n17\n\nMethod\n‚Ä¢ Single object of study: natural language model to detect spam messages. \n‚Ä¢ 6 machine learning algorithms: SVM, Decision Tree, KNN, Random Forrest, \nAdaBoost, Bagging Classifier. \n‚Ä¢ Reduce the number of rows. 10%, 20%, .., 100% \n‚Ä¢ Stratified random sampling (?) \n‚Ä¢ Reduce the number of features. 10%, 20%, .., 100% \n‚Ä¢ Feature importance metric based on the Chi-Square Test (Chi2) \n‚Ä¢ Estimate energy consumption using a RAPL-based tool. (?)\n18\n\n‚Ä¢ Repeat 30 times \n‚Ä¢ Fix random seeds \n‚Ä¢ ‚Ä¶ \n‚Ä¢ Data was not Normal => tailed Normal distribution.\n19\n(?)\n\nResults: energy consumption of algorithms\n\nResults: energy vs data shape\n\nResults: performance vs data shape\n\nDiscussion\n‚Ä¢ Other data properties should be investigated. \n‚Ä¢ E.g., data types \n‚Ä¢ Reporting energy data is essential. It can lead to different model selection \nwithout hindering model performance. \n‚Ä¢ There is a big opportunity in Model and Data Simplification.\n23\n\nData/Model Simplification\n‚Ä¢ (?) \n‚Ä¢ Data selection \n‚Ä¢ Data quantisation. Posit? \n‚Ä¢ Data distillation \n‚Ä¢ Coreset extraction (?) \n‚Ä¢ Model distillation \n‚Ä¢ Model quantisation \n‚Ä¢ Model pruning \n‚Ä¢ ‚Ä¶\n24\n\nPosit vs Float\nMore about this: https://spectrum.ieee.org/floating-point-numbers-posits-processor\nBetter for DL use cases\n\nHow can we tune \nlearning \nparameters \nefficiently?\n\nHyper parameter tuning\n‚Ä¢ When training an ML model, there are several parameters that need to be \ntuned. \n‚Ä¢ E.g., in SVM we have the Regularization parameter C, the kernel function, \nthe degree of the kernel function, and depending on the case, many other. \n‚Ä¢ The common approach revolves around grid search. The user provides a \nsequence of possible values for each parameter and the pipeline runs all \npossible combinations.']","['<1-hop>\n\nShuffle \nüîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them.\n‚Ä¢ If you run 30 executions for version A and another batch for version B:\n‚Ä¢ External conditions that change over time will have a diÔ¨Äerent bias in \nthe 2 versions (e.g., room temperature changes).\n‚Ä¢ If you shuÔ¨Ñe, you reduce this risk.\n11', '<2-hop>\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio)\n‚Ä¢ Dynamic Retry Delay\n‚Ä¢ Push Over Poll\n‚Ä¢ Reduce Size\n‚Ä¢ Cache\n‚Ä¢ Avoid Graphics and Animations\n20']","The sources provided do not contain specific information about shuffling or how it reduces risk in comparison to EcoAndroid's ""reduce size"" strategy. However, I can provide a general explanation:

Shuffling in the context of data processing or machine learning typically refers to randomizing the order of data points to prevent any bias that might arise from the order of data. This can reduce the risk of overfitting to specific patterns in the data sequence.

On the other hand, EcoAndroid's ""reduce size"" strategy likely involves minimizing the size of data or resources used by an application to conserve energy and improve performance. This can reduce the risk of excessive energy consumption and improve the efficiency of the app.

Both strategies aim to optimize performance and efficiency, but they address different aspects: shuffling focuses on data integrity and model robustness, while reducing size focuses on resource efficiency and energy conservation.",Shuffling reduce risk by balance external factor like room temperature change while EcoAndroid reduce size by optimize resource use.,0.0,0.0,0.5,0.6,0.3333333322222222,0.9655420453238507
How shuffling reduce risk when reduce size in software engineering?,"['‚Ä¢\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy efficiency using static code analysis. \n‚Ä¢ We don‚Äôt need an accurate value. \n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention. \n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27\n\nC7 - Education\n‚Ä¢ Educational game for Software \nSustainability practices \n‚Ä¢ Purpose: use within software teams to \ndiscuss or learn about different sustainable \nIT practices: at the organisation level, \nsoftware, etc.\n28\nhttps://github.com/OttoKaaij/Ticket-To-Sustainability/?tab=readme-ov-file\n\nProject ideas (old)\n‚Ä¢ Plugin from EnergiBridge (GUI, report generator, python library, etc.) \n‚Ä¢ Plugin for ChatGPT (carbon emissions per chat window) \n‚Ä¢ Seamless measurements for AI libraries \n‚Ä¢ Energy patterns for Green AI \n‚Ä¢ Sustainable SW dev gamification \n‚Ä¢ Sustainability auditor for AI projects \n‚Ä¢ Energy Profiling of screen colour filter tools (or display settings) \n‚Ä¢ ‚Ä¶ you can also propose yours!\n\nhttps://edu.nl/64gpk\nedu.nl/64gpk', 'Rest ‚è∏\n‚Ä¢ It is common practice to do a pause/sleep between executions/\nmeasurements. \n‚Ä¢ Prevent tail energy consumption from previous measurements. ? \n‚Ä¢ Prevent collateral tasks of previous measurement from affecting the next \nmeasurement. \n‚Ä¢ There is no golden rule but one minute should be enough. It can be more or \nless depending on your hardware or the duration of your energy test.\n9\n\nt\nP\nTail Energy Consumption\n\nShuffle üîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them. \n‚Ä¢ If you run 30 executions for version A and another batch for version B: \n‚Ä¢ External conditions that change over time will have a different bias in \nthe 2 versions (e.g., room temperature changes). \n‚Ä¢ If you shuffle, you reduce this risk.\n11\n\nKeep it cool üå°\n‚Ä¢ Always make sure there is a stable room temperature. \n‚Ä¢ Tricky because, some times, experiments may have to run over a few days. \n‚Ä¢ If you cannot control room temperature: collect temperature data and filter \nout measurements where the room temperature is clearly deviating.\n12\n\nAutomate Executions ü§ñ\n‚Ä¢ (Already mentioned in the previous classes) \n‚Ä¢ One cannot run 30 shuffled experiments per version without automation‚Ä¶\n13\n\nData analysis\n14\n\n1. Exploratory Analysis\n‚Ä¢ Plot the data and inspect outliers or \nunexpected biases. \n‚Ä¢ Violin+box plots are usually handy. (?) \n‚Ä¢ It‚Äôs a nice way of combining the 30 \nexperiments, and of showing \ndescriptive statistics. (?) \n‚Ä¢ Shows the shape of the distribution \nof the data.\n15\n\n1. Exploratory Analysis (II)\n‚Ä¢ Data should be Normal. Unless there‚Äôs a \ngood reason. \n‚Ä¢ E.g., somewhere amongst the 30 executions, \nthere might be 1 or 2 that failed to finish due \nto some unexpected error. \n‚Ä¢ (It happens and that‚Äôs ok!)‚Äì consequently, \nthe execution is shorter and spends less \nenergy ‚Äì falsely appearing as more \nenergy efficient. \n‚Ä¢ If data is not Normal there might be some \nissues affecting the measurements that \nmight be ruining results. It is important to \ninvestigate this.\n16\n\nEnergy data is not normal. Why?', 'Revisiting Research Questions\n‚Ä¢ Can we compare the energy efficiency of software languages?  \n‚Ä¢ Is the faster language always the most energy efficient? \n‚Ä¢ How does memory usage relate to energy consumption?  \n‚Ä¢ Can we automatically decide what is the best programming language considering \nenergy, time, and memory usage?  \n‚Ä¢ How do the results of our energy consumption analysis of programming \nlanguages gathered from rigorous performance benchmarking solutions \ncompare to results of average day-to-day solutions?  \n‚Ä¢ What would happen if we cherry picked the tasks?\u2028\n44\n\n\nLu√≠s Cruz \nL.Cruz@tudelft.nl \n3. Scientific Guide for Reliable \nEnergy Experiments\nSustainable Software Engineering\u2028\nCS4575\nSustainableSE 2025\nCarolin Brandt \nC.E.Brandt@tudelft.nl \nEnrique Barba Roque \nE.BarbaRoque@tudelft.nl']","['<1-hop>\n\nShuffle \nüîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them.\n‚Ä¢ If you run 30 executions for version A and another batch for version B:\n‚Ä¢ External conditions that change over time will have a diÔ¨Äerent bias in \nthe 2 versions (e.g., room temperature changes).\n‚Ä¢ If you shuÔ¨Ñe, you reduce this risk.\n11', '<2-hop>\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio)\n‚Ä¢ Dynamic Retry Delay\n‚Ä¢ Push Over Poll\n‚Ä¢ Reduce Size\n‚Ä¢ Cache\n‚Ä¢ Avoid Graphics and Animations\n20', '<1-hop>\n\nShuffle \nüîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them.\n‚Ä¢ If you run 30 executions for version A and another batch for version B:\n‚Ä¢ External conditions that change over time will have a diÔ¨Äerent bias in \nthe 2 versions (e.g., room temperature changes).\n‚Ä¢ If you shuÔ¨Ñe, you reduce this risk.\n11', '<2-hop>\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio)\n‚Ä¢ Dynamic Retry Delay\n‚Ä¢ Push Over Poll\n‚Ä¢ Reduce Size\n‚Ä¢ Cache\n‚Ä¢ Avoid Graphics and Animations\n20']","Shuffling reduces risk in software engineering experiments by minimizing the impact of external conditions that can introduce bias. When you run multiple executions for different versions of software, external factors such as room temperature changes can affect the results. By shuffling the order of these executions, you reduce the risk that these external conditions will consistently bias one version over another, leading to more reliable and unbiased results.","Shuffling reduce risk by controlling external factors like room temperature changes, which help in reducing size in software engineering.",0.0,0.0,1.0,0.67,0.0,0.9551598280926026
How spiking neural networks relate to McCulloch-Pitts model?,"['McCulloch-Pitts neuron [1, 2]\n1940s: How do biological neurons compute basic \nlogic functions? (e.g. logic gates)\nNote: Ref. [3] gives a nice brief history on the ideas which lead to the \nMcCulloch-Pitts neuron.\n\nWhat is a neural network?\n1950s: How are neurons organized to perform \nsensory perception?\n\nWhat is a neural network?\n1950s: How are neurons organized to perform \nsensory perception?\nThe first ""neural network"": Perceptron (1958). [4]\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\nFrank Rosenblatt (Psychologist)\nwith a Mark I Perceptron computer in 1960\n\nWhat is a neural network?\n1950s: How are neurons organized to perform \nsensory perception?\nThe first ""neural network"": Perceptron (1958). [4]\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\nFrank Rosenblatt (Psychologist)\nwith a Mark I Perceptron computer in 1960\nPower-efficient\n\nNeuromorphic computing\nWhy neuromorphic computing?\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\n\nNeuromorphic computing\nWhy neuromorphic computing?\n‚ÄòBiological inspiration‚Äô for artificial neural networks (ANNs) is not a new idea.\nEmulation (as opposed to simulation) of neural networks in hardware is not a new idea.\nQuestion: What can we gain from increasing biological realism in existing neural networks?\n\nPower-efficiency at scale\nModern, deep neural networks*\nare trained using GPUs.\n* It is estimated that ChatGPT was trained on \n10,000-20,000 GPUs and that it will require\n30,000 GPUs to keep running stably in the future.\n* It is estimated that ChatGPT has 10-20 billion \nparameters.', 'Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002.', 'Neural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568']","[""<1-hop>\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant"", '<2-hop>\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \n(not publicly available) doi:10.1037/h0042519\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568', ""<1-hop>\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant"", '<2-hop>\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \n(not publicly available) doi:10.1037/h0042519\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568', ""<1-hop>\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant"", '<2-hop>\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \n(not publicly available) doi:10.1037/h0042519\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568']","The McCulloch-Pitts model, developed in the 1940s, is one of the earliest models of artificial neurons. It represents neurons as simple binary devices that compute basic logic functions, such as logic gates, based on weighted inputs and a threshold. This model laid the groundwork for understanding how biological neurons might perform computations.

Spiking neural networks (SNNs), on the other hand, are a more biologically realistic model of neural computation. They incorporate the concept of time into the firing of neurons, where neurons communicate by sending discrete spikes at particular times, rather than continuous signals. This allows SNNs to capture the temporal dynamics of neural activity more accurately than the McCulloch-Pitts model.

While the McCulloch-Pitts model provides a foundational understanding of neural computation in terms of logic functions, spiking neural networks extend this by incorporating temporal aspects, making them more aligned with how actual biological neurons operate. Both models contribute to the broader field of neural networks, with SNNs offering a more detailed emulation of biological processes.","Spiking neural networks relate to the McCulloch-Pitts model by building upon the foundational concepts of neural computation, where the McCulloch-Pitts model introduced the idea of binary neuron states, which is extended in spiking networks to model more complex information processing through spike timing and patterns.",0.0,0.6666666666666666,0.45454545454545453,0.93,0.0,0.9373263275700353
How spiking neural networks used in encoding strategies?,"['Different encoding strategies with spiking neurons\n\nDifferent encoding strategies with spiking neurons\nUsing latency or spatio-temporal codes\nour encoding is faster and more spike-efficient (sparser)!\n\nDifferent encoding strategies with spiking neurons\nUsing latency or spatio-temporal codes\nour encoding is faster and more spike-efficient (sparser)!\nQuestions?\n\nNeuromorphic computing\nWhat is the advantage for applications?\n-\nLess spikes = less energy consumption in specialized neuromorphic hardware\n(e.g. Intel Loihi [12])\nBrains are energy efficient: \n2. Sparse encoding\n\nMultiply-accumulate (MAC) operations:\nNormal neuron: Multiplies input with \nweights, then adds.\nSpiking neuron: Consider binary input (e.g. input currents are piecewise \nconstant and assume values {0,1}). There is no multiplication, only addition.\n\nAssume one multiplier and one adder circuit uses M and A energy respectively with AÔπ§M\n(e.g., for a 45nm CMOS process, standard energy usage is A = 0.9 pJ and M = 3.7 pJ).\nNormal neuron: nin x nout multiplications,\n(nin‚Äì 1) x nout additions\nSpiking neuron: 0 multiplications, (nactive‚Äì 1) x nout \nadditions, with nactive ‚â§ nin\nEnergy consumption:\nEnormal = M nin nout + A (nin‚Äì 1) nout = 17.5 pJ\nEnergy consumption:\nEspiking = A (nactive‚Äì 1) nout = 2.7 pJ\nMultiply-accumulate (MAC) operations:\n\nAssume one multiplier and one adder circuit uses M and A energy respectively with AÔπ§M\n(e.g., for a 45nm CMOS process, standard energy usage is A = 0.9 pJ and M = 3.7 pJ).', ""- Higher firing rate (spikes per unit time) for \n'selected' feature.\nAdapted from Hubel & Wiesel, 1959\n\nFiring rates\nClassical view of the brain:\n- Each neuron is selective for one specific \nfeature in the input.\n- Higher firing rate (spikes per unit time) for \n'selected' feature.\n- Link to modern ANNs: The scalar output of \nan artificial neuron is interpreted as the firing \nrate.\nAdapted from Hubel & Wiesel, 1959\n\nFiring rates\nClassical view of the brain:\n- Each neuron is selective for one specific \nfeature in the input.\n- Higher firing rate (spikes per unit time) for \n'selected' feature.\n- Link to modern ANNs: The scalar output of \nan artificial neuron is interpreted as the firing \nrate.\nAdapted from Hubel & Wiesel, 1959\nBut rate coding is inefficient and slow‚Ä¶\n(i.e. each neuron needs to fire many spikes to get good precision)\nboth in vivo and in silico.\n\nDifferent encoding strategies with spiking neurons [8]\n7 neurons\n7 time bins\n\nDifferent encoding strategies with spiking neurons\n7 neurons\n7 time bins\nn\n6\n(in the general \ncase a \nnumber \nbetween 0-7)\n\nDifferent encoding strategies with spiking neurons\n7 neurons\n7 time bins\nn\nTotal spike \ncount can \nencode 3 bits.\n\nDifferent encoding strategies with spiking neurons\n7 neurons\n7 time bins\nIndividual rates \ncan encode 7 \nbits.\n\nDifferent encoding strategies with spiking neurons\n7 neurons\n7 time bins\nLatency can \nencode ~3*7 or \n~19 bits.\n\nDifferent encoding strategies with spiking neurons\n7 neurons\n7 time bins\nRank order can \nencode ~12 bits.\n\nDifferent encoding strategies with spiking neurons\n\nDifferent encoding strategies with spiking neurons\nUsing latency or spatio-temporal codes\nour encoding is faster and more spike-efficient (sparser)!\n\nDifferent encoding strategies with spiking neurons\nUsing latency or spatio-temporal codes\nour encoding is faster and more spike-efficient (sparser)!\nQuestions?\n\nNeuromorphic computing\nWhat is the advantage for applications?\n-\nLess spikes = less energy consumption in specialized neuromorphic hardware\n(e.g."", 'Neural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568']","[""<1-hop>\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant"", '<2-hop>\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \n(not publicly available) doi:10.1037/h0042519\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568']","Spiking neural networks (SNNs) use different encoding strategies such as latency or spatio-temporal codes, which are faster and more spike-efficient (sparser) compared to traditional rate coding. These encoding strategies allow SNNs to use fewer spikes, leading to less energy consumption, especially in specialized neuromorphic hardware. This efficiency is achieved because spiking neurons do not require multiplications, only additions, which consume less energy. Additionally, spiking neurons can encode information in various ways, such as using total spike count, individual rates, latency, and rank order, each capable of encoding different amounts of bits. This makes SNNs more efficient for certain applications compared to traditional neural networks.",Spiking neural networks use single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0) to encode information about 'features' in a large network with many spikes. This approach is supported by foundational works such as McCulloch and Pitts' logical calculus of nervous activity and later developments in spiking neuron models.,0.0,0.0,1.0,0.0,0.0,0.8985056243354522
What are the benefits of neuromorphic computing in the context of green software practices?,"[""Neuromorphic computing\nCS4575\nSustainable Software Engineering\n05.03.2025\nNergis T√∂men\n\nIntroduction\nComputer Vision Lab\nBiomorphic Intelligence Lab\nBiomedical Intervention Optimisation Lab\nNergis\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing\n\nHow many of you are familiar \nwith neural networks?\n\nSimple model of an artificial neuron\nhttps://medium.com/@cprasenjit32/perceptron-a-simple-yet-mighty-machine-learning-algorithm-9ff6b7d86a71\n\nWhat is a neural network?\nhttps://www.tibco.com/reference-center/what-is-a-neural-network\n\nWhy is it called a 'neural network'?\nhttps://www.tibco.com/reference-center/what-is-a-neural-network\n\nWhat is a neural network?\nWhy is it called a 'neural network'?\nMcCulloch-Pitts neuron [1, 2] (1943)\nWarren Sturgis McCulloch\n(Neurophysiologist)\nWalter Pitts\n(Logician)\n\nHow do biological neurons work?\nhttps://commons.wikimedia.org/wiki/File:Coincidence_detection_in_dendrites_of_pyramidal_neurons.gif\n'Input current' travels down the dendrites (top),\nget integrated (summed!) in the cell body\nwhich generates an 'output current' (bottom)\nwhich is chemically transmitted to the dendrites of \nother neurons.\n\nSimplified picture\nReal neuron\nArtificial neuron\nhttps://vajiramandravi.com/quest-upsc-notes/artificial-neural-network/\n\nWhat is a neural network?\nMcCulloch-Pitts neuron [1, 2]\n1940s: How do biological neurons compute basic \nlogic functions? (e.g. logic gates)\nNote: Ref. [3] gives a nice brief history on the ideas which lead to the \nMcCulloch-Pitts neuron.\n\nWhat is a neural network?"", '8. Green AI\nSustainable Software Engineering\u2028\nCS4575\nSustainableSE 2025\nLu√≠s Cruz \nL.Cruz@tudelft.nl \nCarolin Brandt \nC.E.Brandt@tudelft.nl \nEnrique Barba Roque \nE.BarbaRoque@tudelft.nl\n\n- Overview of Green AI \n- Large language models \n- Green data-centric AI \n- Model simplification \n- Hyper parameter tuning \n- Mixture of Experts and DeepSeek \n- Green AI at Meta \n\nAI\n‚Ä¢ Artificial Intelligence (AI) is the branch of computer science that deals with \nautomating tasks that typically require human intelligence. \n‚Ä¢ In the past years AI has been widely applied across different domains.\u2028\nE.g., health care, transportation, finance. \n‚Ä¢ To deploy AI systems, we test them against benchmarks (or validation sets). \n‚Ä¢ The goal is to outperform the previous existing models. \n‚Ä¢ E.g., in Machine Learning we usually resort to accuracy metrics. The \nhighest the accuracy, the better the model.\n3\n\nSince 2012, the amount of computing used for AI \ntraining has been doubling every 6 months\n‚Ä¢ https://epoch.ai/blog/compute-trends\n4\n\n‚Ä¢ To create better AI systems we are currently adding \n‚Ä¢ More data \n‚Ä¢ More experiments \n‚Ä¢ Larger models\n5\n\nThe Equation of Red AI\nCost(R) ‚àùE¬∑D¬∑H\nCost of a single (E)xample\nSize of (D)ataset\nNumber of (H)yperparameters\nBy Schwartz et al. (2020)\n\nIssues of Red AI\n‚Ä¢ High costs (hardware, electricity, data access, etc.) \n‚Ä¢ Limited reproducibility.  \n‚Ä¢ Energy consumption. \n‚Ä¢ Carbon emissions. \n‚Ä¢ SMEs can hardly be competitive. \n‚Ä¢ Groundbreaking AI research is mostly done by tech giants.', '‚Ä¢ Software consumers have started to worry about the climate impact \nof their behaviour as users. \n‚Ä¢ Being environmentally sustainable is now an important competitive \nfactor \n‚Ä¢ Marketing teams are already using all eco-friendly labels. Technical \nteams are not there yet, though. \n‚Ä¢ It‚Äôs easier said than done!\n$\n16\n\nGreen Washing\n‚Ä¢ Deceptively use marketing techniques to \nclaim being eco-friendly. \n‚Ä¢ Opting for green-coloured designs. \n‚Ä¢ Red/orange is usually perceived as \ntasty. \n‚Ä¢ Green is perceived as eco-friendly. \n‚Ä¢ The VW case. (?)\n17\n\nThe VW scandal\nGreenwashing\n‚Ä¢ Used software to cheat on vehicle emissions \ntests. \n‚Ä¢ The vehicle‚Äôs software could detect whether they \nwere being tested, changing the performance \naccordingly to improve results. \n‚Ä¢ Affected 11M cars worldwide, 8M in Europe.\n18\n\nHow can we drive sustainability \nin the SE industry?\n\nGreen Procurement\n‚Ä¢ Customers decide on providers that share their values \n‚Ä¢ This is currently the main trigger reason why organisations \nworry about Sustainability and Green Software. \n‚Ä¢ Examples of green procurement: \n‚Ä¢ Customers that only buy green services/products \n‚Ä¢ Companies that only use green providers \n‚Ä¢ Developers that only work for green companies \n‚Ä¢ Green procurement makes environmental sustainability \nessential for economical sustainability.\n20\n\nSustainability via compliance\n‚Ä¢ EU wants to be carbon neutral by 2030 \n‚Ä¢ This also affects the ICT sector. Estimated to impact \n14% of the global carbon footprint by 2040. \n‚Ä¢ Some initiatives are already being negotiated. \n‚Ä¢ Extending the smartphone lifetime to 7 years. \n‚Ä¢ Right-to-repair movement. https://repair.eu \n‚Ä¢ Making IT services relying on clean energy more \naccessible (e.g., less taxes).\n21\n\nSoftware for Sustainability \n‚Ä¢ We are not covering it in this course.\n\nCarbon-free giants\n‚Ä¢ Google, Microsoft, Meta/Facebook want to be carbon free by 2030 \n‚Ä¢ Carbon free is different from carbon neutral \n‚Ä¢ Green IT experts are needed to meet these goals\n23\n\n\nRebound effect*\n‚Ä¢ Energy consumption decreases ‚Üì‚Üì but demand also increases ‚Üë‚Üë. \n‚Ä¢ *a.k.a. Jevons Paradox in economics; Downs‚ÄìThomson paradox in\xa0mobility.']","['<1-hop>\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing', '<2-hop>\n\nReading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.', '<1-hop>\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing', '<2-hop>\n\nReading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.', '<1-hop>\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing', '<2-hop>\n\nReading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.']","The sources provided do not explicitly discuss the benefits of neuromorphic computing in the context of green software practices. However, I can infer that neuromorphic computing, which is inspired by the structure and function of the human brain, could potentially offer energy efficiency benefits. This is because neuromorphic systems are designed to mimic the brain's ability to process information in a highly parallel and efficient manner, which could reduce the energy consumption associated with traditional computing methods. This aligns with the goals of green software practices, which aim to reduce energy consumption and carbon emissions. Therefore, neuromorphic computing could contribute to more sustainable and environmentally friendly computing solutions.","Neuromorphic computing offers several benefits in the context of green software practices. It is inspired by the structure and function of the human brain, making it highly energy-efficient compared to traditional computing methods. This efficiency is particularly relevant for sustainable software development, as it reduces the environmental impact of computing systems. Additionally, neuromorphic systems can process information in a way that mimics biological neural networks, which can lead to more efficient and sustainable computing solutions. These aspects make neuromorphic computing a promising approach for developers looking to implement green software practices.",0.0,0.6,0.5714285714285714,0.73,0.12499999984374999,0.0
What are the challenges in creating a dataset of government-developed OS software?,"['data to understand state of software: \nbuildable?, open dev. history?, requirements documentation? \n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!\n\nB7. Queue - but better for the student / TA society\n‚Ä¢ Requirements analysis regarding social and individual sustainability effects \nof Queue \n‚Ä¢ Other EIP / TUD used software also possible: e.g., Answers EWI \n‚Ä¢ Non-technical project ‚Üí proper process (workshops? Interviews?) & rich \ndescription of outcomes focus of grading\nhttps://eip.pages.ewi.tudelft.nl/eip-website/queue.html\n\nC1. Compare energy consumption of docker images for \nML workloads.\n‚Ä¢ Similar to what we have seen in the lectures but for ML-specific workloads. \n‚Ä¢ We can reuse existing experiment replication packages.\n22\n\nC2. Plugin to visualize Hugging Face carbon emissions.\n‚Ä¢ https://huggingface.co/blog/leaderboard-emissions-\nanalysis \n‚Ä¢\nYoo, Taewon, et al. ""Visualizing the Carbon Intensity of Machine Learning Inference for Image Analysis on TensorFlow Hub.""\n\nC3. Plugin for ChatGPT\n‚Ä¢ Users seldom know how much carbon they are emitting when they interact \nwith chat GPT. \n‚Ä¢ Let‚Äôs make it transparent to the users. Browser plugin?\n24\nCO2\n\nC4. NutriScore for software libraries\n25\n‚Ä¢ NutriScore labels are not perfect but they are a good starting point! \n‚Ä¢ What if we could do the same thing for the energy efficiency of software. \n‚Ä¢ (Also open to individual or social sustainability) \n‚Ä¢ This work can be scoped in particular domains/ecossystems/use cases. \n‚Ä¢ Libraries for stats? ML? Web Dev? Cloud?\n\nC5. Add energy-awareness to existing software\n26\n‚Ä¢ Streamlit, Notebooks, JSFiddle, \nPyScript, zsh, etc. \n‚Ä¢\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy efficiency using static code analysis. \n‚Ä¢ We don‚Äôt need an accurate value. \n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention. \n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)', '‚Ä¢ Software consumers have started to worry about the climate impact \nof their behaviour as users. \n‚Ä¢ Being environmentally sustainable is now an important competitive \nfactor \n‚Ä¢ Marketing teams are already using all eco-friendly labels. Technical \nteams are not there yet, though. \n‚Ä¢ It‚Äôs easier said than done!\n$\n16\n\nGreen Washing\n‚Ä¢ Deceptively use marketing techniques to \nclaim being eco-friendly. \n‚Ä¢ Opting for green-coloured designs. \n‚Ä¢ Red/orange is usually perceived as \ntasty. \n‚Ä¢ Green is perceived as eco-friendly. \n‚Ä¢ The VW case. (?)\n17\n\nThe VW scandal\nGreenwashing\n‚Ä¢ Used software to cheat on vehicle emissions \ntests. \n‚Ä¢ The vehicle‚Äôs software could detect whether they \nwere being tested, changing the performance \naccordingly to improve results. \n‚Ä¢ Affected 11M cars worldwide, 8M in Europe.\n18\n\nHow can we drive sustainability \nin the SE industry?\n\nGreen Procurement\n‚Ä¢ Customers decide on providers that share their values \n‚Ä¢ This is currently the main trigger reason why organisations \nworry about Sustainability and Green Software. \n‚Ä¢ Examples of green procurement: \n‚Ä¢ Customers that only buy green services/products \n‚Ä¢ Companies that only use green providers \n‚Ä¢ Developers that only work for green companies \n‚Ä¢ Green procurement makes environmental sustainability \nessential for economical sustainability.\n20\n\nSustainability via compliance\n‚Ä¢ EU wants to be carbon neutral by 2030 \n‚Ä¢ This also affects the ICT sector. Estimated to impact \n14% of the global carbon footprint by 2040. \n‚Ä¢ Some initiatives are already being negotiated. \n‚Ä¢ Extending the smartphone lifetime to 7 years. \n‚Ä¢ Right-to-repair movement. https://repair.eu \n‚Ä¢ Making IT services relying on clean energy more \naccessible (e.g., less taxes).\n21\n\nSoftware for Sustainability \n‚Ä¢ We are not covering it in this course.\n\nCarbon-free giants\n‚Ä¢ Google, Microsoft, Meta/Facebook want to be carbon free by 2030 \n‚Ä¢ Carbon free is different from carbon neutral \n‚Ä¢ Green IT experts are needed to meet these goals\n23\n\n\nRebound effect*\n‚Ä¢ Energy consumption decreases ‚Üì‚Üì but demand also increases ‚Üë‚Üë. \n‚Ä¢ *a.k.a. Jevons Paradox in economics; Downs‚ÄìThomson paradox in\xa0mobility.', 'Revisiting Research Questions\n‚Ä¢ Can we compare the energy efficiency of software languages?  \n‚Ä¢ Is the faster language always the most energy efficient? \n‚Ä¢ How does memory usage relate to energy consumption?  \n‚Ä¢ Can we automatically decide what is the best programming language considering \nenergy, time, and memory usage?  \n‚Ä¢ How do the results of our energy consumption analysis of programming \nlanguages gathered from rigorous performance benchmarking solutions \ncompare to results of average day-to-day solutions?  \n‚Ä¢ What would happen if we cherry picked the tasks?\u2028\n44\n\n\nLu√≠s Cruz \nL.Cruz@tudelft.nl \n3. Scientific Guide for Reliable \nEnergy Experiments\nSustainable Software Engineering\u2028\nCS4575\nSustainableSE 2025\nCarolin Brandt \nC.E.Brandt@tudelft.nl \nEnrique Barba Roque \nE.BarbaRoque@tudelft.nl']","['<1-hop>\n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise\n‚Ä¢ But studying government software is diÔ¨Écult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation?\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!', '<2-hop>\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption\n‚Ä¢ B3. Energy proÔ¨Åling of static analysis tools\n‚Ä¢ B4. Detailed energy proÔ¨Åling of build pipelines\n‚Ä¢ B5. Tool supporting SusAF workshop / process\n‚Ä¢ B6. Dataset of government-developed OS software\n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability', '<1-hop>\n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise\n‚Ä¢ But studying government software is diÔ¨Écult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation?\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!', '<2-hop>\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption\n‚Ä¢ B3. Energy proÔ¨Åling of static analysis tools\n‚Ä¢ B4. Detailed energy proÔ¨Åling of build pipelines\n‚Ä¢ B5. Tool supporting SusAF workshop / process\n‚Ä¢ B6. Dataset of government-developed OS software\n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability', '<1-hop>\n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise\n‚Ä¢ But studying government software is diÔ¨Écult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation?\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!', '<2-hop>\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption\n‚Ä¢ B3. Energy proÔ¨Åling of static analysis tools\n‚Ä¢ B4. Detailed energy proÔ¨Åling of build pipelines\n‚Ä¢ B5. Tool supporting SusAF workshop / process\n‚Ä¢ B6. Dataset of government-developed OS software\n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability']","The sources provided do not directly address the challenges in creating a dataset of government-developed open-source software. However, based on general knowledge, some potential challenges could include:

1. **Data Availability**: Government-developed software may not always be open or easily accessible due to security, privacy, or proprietary concerns.

2. **Standardization**: Different government bodies may use different standards and formats, making it difficult to compile a consistent dataset.

3. **Documentation**: There may be a lack of comprehensive documentation or metadata accompanying the software, which is crucial for understanding and categorizing the software effectively.

4. **Licensing Issues**: Understanding and verifying the open-source licenses under which the software is released can be complex.

5. **Language and Localization**: Software developed by governments in different countries may be in different languages, requiring translation and localization efforts.

6. **Version Control and History**: Accessing the full development history and version control information might be challenging if not properly maintained or shared.

These challenges require careful planning and collaboration with government entities to ensure a comprehensive and useful dataset.","Creating a dataset of government-developed OS software faces challenges such as a lack of incentive to make the software popular and language barriers, which hinder comprehensive understanding of the software's buildability, open development history, and requirements documentation.",0.0,0.0,0.0,0.57,,0.9656727799167242
"What are the practical applications of neuromorphic computing, and how does its biological inspiration influence its implementation in modern computing systems?","[""Neuromorphic computing\nCS4575\nSustainable Software Engineering\n05.03.2025\nNergis T√∂men\n\nIntroduction\nComputer Vision Lab\nBiomorphic Intelligence Lab\nBiomedical Intervention Optimisation Lab\nNergis\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing\n\nHow many of you are familiar \nwith neural networks?\n\nSimple model of an artificial neuron\nhttps://medium.com/@cprasenjit32/perceptron-a-simple-yet-mighty-machine-learning-algorithm-9ff6b7d86a71\n\nWhat is a neural network?\nhttps://www.tibco.com/reference-center/what-is-a-neural-network\n\nWhy is it called a 'neural network'?\nhttps://www.tibco.com/reference-center/what-is-a-neural-network\n\nWhat is a neural network?\nWhy is it called a 'neural network'?\nMcCulloch-Pitts neuron [1, 2] (1943)\nWarren Sturgis McCulloch\n(Neurophysiologist)\nWalter Pitts\n(Logician)\n\nHow do biological neurons work?\nhttps://commons.wikimedia.org/wiki/File:Coincidence_detection_in_dendrites_of_pyramidal_neurons.gif\n'Input current' travels down the dendrites (top),\nget integrated (summed!) in the cell body\nwhich generates an 'output current' (bottom)\nwhich is chemically transmitted to the dendrites of \nother neurons.\n\nSimplified picture\nReal neuron\nArtificial neuron\nhttps://vajiramandravi.com/quest-upsc-notes/artificial-neural-network/\n\nWhat is a neural network?\nMcCulloch-Pitts neuron [1, 2]\n1940s: How do biological neurons compute basic \nlogic functions? (e.g. logic gates)\nNote: Ref. [3] gives a nice brief history on the ideas which lead to the \nMcCulloch-Pitts neuron.\n\nWhat is a neural network?"", 'McCulloch-Pitts neuron [1, 2]\n1940s: How do biological neurons compute basic \nlogic functions? (e.g. logic gates)\nNote: Ref. [3] gives a nice brief history on the ideas which lead to the \nMcCulloch-Pitts neuron.\n\nWhat is a neural network?\n1950s: How are neurons organized to perform \nsensory perception?\n\nWhat is a neural network?\n1950s: How are neurons organized to perform \nsensory perception?\nThe first ""neural network"": Perceptron (1958). [4]\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\nFrank Rosenblatt (Psychologist)\nwith a Mark I Perceptron computer in 1960\n\nWhat is a neural network?\n1950s: How are neurons organized to perform \nsensory perception?\nThe first ""neural network"": Perceptron (1958). [4]\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\nFrank Rosenblatt (Psychologist)\nwith a Mark I Perceptron computer in 1960\nPower-efficient\n\nNeuromorphic computing\nWhy neuromorphic computing?\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\n\nNeuromorphic computing\nWhy neuromorphic computing?\n‚ÄòBiological inspiration‚Äô for artificial neural networks (ANNs) is not a new idea.\nEmulation (as opposed to simulation) of neural networks in hardware is not a new idea.\nQuestion: What can we gain from increasing biological realism in existing neural networks?\n\nPower-efficiency at scale\nModern, deep neural networks*\nare trained using GPUs.\n* It is estimated that ChatGPT was trained on \n10,000-20,000 GPUs and that it will require\n30,000 GPUs to keep running stably in the future.\n* It is estimated that ChatGPT has 10-20 billion \nparameters.', 'Reading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020.']","['<1-hop>\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing', '<2-hop>\n\nReading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.', '<1-hop>\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing', '<2-hop>\n\nReading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.']","Neuromorphic computing is inspired by the structure and function of the human brain, using physical artificial neurons to perform computations. This approach offers several practical applications and influences modern computing systems in various ways:

1. **Power Efficiency**: Neuromorphic computing is designed to be power-efficient, which is crucial for large-scale applications like deep neural networks. This efficiency is achieved by emulating the brain's ability to perform complex computations with minimal energy consumption.

2. **Real-time Processing**: Due to its architecture, neuromorphic computing can handle real-time data processing, making it suitable for applications in robotics, autonomous vehicles, and real-time sensory data analysis.

3. **Scalability**: Neuromorphic systems can scale efficiently, which is beneficial for handling large datasets and complex models, such as those used in artificial intelligence and machine learning.

4. **Biological Realism**: The biological inspiration behind neuromorphic computing allows for more natural and efficient processing of information, similar to how the human brain processes sensory inputs and makes decisions.

5. **Emulation of Neural Networks**: Neuromorphic computing emulates neural networks in hardware, which can lead to faster and more efficient computations compared to traditional software simulations.

Overall, the biological inspiration of neuromorphic computing influences its implementation by focusing on energy efficiency, real-time processing capabilities, and the ability to emulate complex neural processes in hardware.","Neuromorphic computing, inspired by the human brain, offers practical applications such as event-based vision systems and efficient processing of sensory data. Its biological inspiration influences its implementation through the use of spiking neural networks and physical artificial neurons, enabling more energy-efficient and brain-like computation methods.",0.8333333332916666,1.0,0.47058823529411764,0.67,0.33333333277777777,0.9600794602606534
"What are the practical applications of neuromorphic computing, and how does its biological inspiration influence its implementation?","[""Neuromorphic computing\nCS4575\nSustainable Software Engineering\n05.03.2025\nNergis T√∂men\n\nIntroduction\nComputer Vision Lab\nBiomorphic Intelligence Lab\nBiomedical Intervention Optimisation Lab\nNergis\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing\n\nHow many of you are familiar \nwith neural networks?\n\nSimple model of an artificial neuron\nhttps://medium.com/@cprasenjit32/perceptron-a-simple-yet-mighty-machine-learning-algorithm-9ff6b7d86a71\n\nWhat is a neural network?\nhttps://www.tibco.com/reference-center/what-is-a-neural-network\n\nWhy is it called a 'neural network'?\nhttps://www.tibco.com/reference-center/what-is-a-neural-network\n\nWhat is a neural network?\nWhy is it called a 'neural network'?\nMcCulloch-Pitts neuron [1, 2] (1943)\nWarren Sturgis McCulloch\n(Neurophysiologist)\nWalter Pitts\n(Logician)\n\nHow do biological neurons work?\nhttps://commons.wikimedia.org/wiki/File:Coincidence_detection_in_dendrites_of_pyramidal_neurons.gif\n'Input current' travels down the dendrites (top),\nget integrated (summed!) in the cell body\nwhich generates an 'output current' (bottom)\nwhich is chemically transmitted to the dendrites of \nother neurons.\n\nSimplified picture\nReal neuron\nArtificial neuron\nhttps://vajiramandravi.com/quest-upsc-notes/artificial-neural-network/\n\nWhat is a neural network?\nMcCulloch-Pitts neuron [1, 2]\n1940s: How do biological neurons compute basic \nlogic functions? (e.g. logic gates)\nNote: Ref. [3] gives a nice brief history on the ideas which lead to the \nMcCulloch-Pitts neuron.\n\nWhat is a neural network?"", 'McCulloch-Pitts neuron [1, 2]\n1940s: How do biological neurons compute basic \nlogic functions? (e.g. logic gates)\nNote: Ref. [3] gives a nice brief history on the ideas which lead to the \nMcCulloch-Pitts neuron.\n\nWhat is a neural network?\n1950s: How are neurons organized to perform \nsensory perception?\n\nWhat is a neural network?\n1950s: How are neurons organized to perform \nsensory perception?\nThe first ""neural network"": Perceptron (1958). [4]\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\nFrank Rosenblatt (Psychologist)\nwith a Mark I Perceptron computer in 1960\n\nWhat is a neural network?\n1950s: How are neurons organized to perform \nsensory perception?\nThe first ""neural network"": Perceptron (1958). [4]\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\nFrank Rosenblatt (Psychologist)\nwith a Mark I Perceptron computer in 1960\nPower-efficient\n\nNeuromorphic computing\nWhy neuromorphic computing?\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\n\nNeuromorphic computing\nWhy neuromorphic computing?\n‚ÄòBiological inspiration‚Äô for artificial neural networks (ANNs) is not a new idea.\nEmulation (as opposed to simulation) of neural networks in hardware is not a new idea.\nQuestion: What can we gain from increasing biological realism in existing neural networks?\n\nPower-efficiency at scale\nModern, deep neural networks*\nare trained using GPUs.\n* It is estimated that ChatGPT was trained on \n10,000-20,000 GPUs and that it will require\n30,000 GPUs to keep running stably in the future.\n* It is estimated that ChatGPT has 10-20 billion \nparameters.', 'Reading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020.']","['<1-hop>\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing', '<2-hop>\n\nReading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.']","Neuromorphic computing is inspired by the structure and function of the human brain, which influences its implementation by using physical artificial neurons to perform computations. This biological inspiration allows neuromorphic systems to emulate the brain's efficiency and adaptability, leading to potential practical applications in areas that require power-efficient and real-time processing.

Practical applications of neuromorphic computing include:

1. **Computer Vision**: Neuromorphic systems can process visual information efficiently, making them suitable for applications in autonomous vehicles and surveillance systems.

2. **Robotics**: The ability to process sensory information in real-time makes neuromorphic computing ideal for robotics, enabling more adaptive and responsive robotic systems.

3. **Biomedical Devices**: Neuromorphic chips can be used in biomedical devices for real-time monitoring and intervention, such as in prosthetics or brain-machine interfaces.

4. **Internet of Things (IoT)**: Due to their power efficiency, neuromorphic systems are well-suited for IoT devices that require low-power, real-time data processing.

The biological inspiration of neuromorphic computing influences its implementation by focusing on emulating the brain's neural networks in hardware, which can lead to increased power efficiency and scalability compared to traditional computing methods. This approach aims to achieve more biologically realistic neural network models that can perform complex tasks with lower energy consumption.","Neuromorphic computing, inspired by the human brain, offers practical applications through its ability to process information in a manner similar to biological neurons. This biological inspiration influences its implementation by enabling the development of systems that can efficiently handle tasks such as pattern recognition and adaptive learning, as detailed in resources like 'Computing with spiking neuron networks' and discussions on the convergence of deep learning with biological systems.",0.3333333333,1.0,0.19047619047619047,0.76,0.24999999968749997,0.9584292526250776
What are the practical applications of neuromorphic systems that leverage biological inspiration and advanced training methods for efficient computation?,"[""Neuromorphic computing\nCS4575\nSustainable Software Engineering\n05.03.2025\nNergis T√∂men\n\nIntroduction\nComputer Vision Lab\nBiomorphic Intelligence Lab\nBiomedical Intervention Optimisation Lab\nNergis\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing\n\nHow many of you are familiar \nwith neural networks?\n\nSimple model of an artificial neuron\nhttps://medium.com/@cprasenjit32/perceptron-a-simple-yet-mighty-machine-learning-algorithm-9ff6b7d86a71\n\nWhat is a neural network?\nhttps://www.tibco.com/reference-center/what-is-a-neural-network\n\nWhy is it called a 'neural network'?\nhttps://www.tibco.com/reference-center/what-is-a-neural-network\n\nWhat is a neural network?\nWhy is it called a 'neural network'?\nMcCulloch-Pitts neuron [1, 2] (1943)\nWarren Sturgis McCulloch\n(Neurophysiologist)\nWalter Pitts\n(Logician)\n\nHow do biological neurons work?\nhttps://commons.wikimedia.org/wiki/File:Coincidence_detection_in_dendrites_of_pyramidal_neurons.gif\n'Input current' travels down the dendrites (top),\nget integrated (summed!) in the cell body\nwhich generates an 'output current' (bottom)\nwhich is chemically transmitted to the dendrites of \nother neurons.\n\nSimplified picture\nReal neuron\nArtificial neuron\nhttps://vajiramandravi.com/quest-upsc-notes/artificial-neural-network/\n\nWhat is a neural network?\nMcCulloch-Pitts neuron [1, 2]\n1940s: How do biological neurons compute basic \nlogic functions? (e.g. logic gates)\nNote: Ref. [3] gives a nice brief history on the ideas which lead to the \nMcCulloch-Pitts neuron.\n\nWhat is a neural network?"", 'Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002.', 'Neural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568']","['<1-hop>\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing', '<2-hop>\n\nReading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.', '<1-hop>\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing', '<2-hop>\n\nReading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.', '<1-hop>\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing', '<2-hop>\n\nReading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.']","Neuromorphic systems, inspired by the structure and function of the human brain, have several practical applications. These include:

1. **Event-based Vision**: Neuromorphic systems are used in event cameras, which are beneficial for applications requiring high-speed and low-latency visual processing, such as autonomous vehicles and robotics. These cameras capture changes in a scene rather than static frames, mimicking the way biological vision systems work.

2. **Efficient Computation**: Neuromorphic computing is designed to perform computations more efficiently than traditional systems, particularly for tasks involving pattern recognition and sensory data processing. This efficiency is due to the parallel and distributed nature of neuromorphic architectures, which resemble neural networks in the brain.

3. **Spiking Neural Networks (SNNs)**: These networks are a type of artificial neural network that more closely mimic the way biological neurons communicate through spikes. They are used in applications that require real-time processing and low power consumption, such as mobile devices and edge computing.

4. **Biomedical Applications**: Neuromorphic systems can be used in biomedical intervention optimization, potentially improving the efficiency and effectiveness of medical treatments by modeling complex biological processes.

These applications leverage the biological inspiration of neuromorphic systems to achieve advanced training methods and efficient computation, offering advantages in speed, power consumption, and adaptability.","Neuromorphic systems, inspired by the human brain, have practical applications such as event-based vision, which is detailed in the reading materials. These systems use advanced training methods like surrogate gradient learning to optimize spiking neural networks, enabling efficient computation and real-world applications.",0.0,1.0,0.5,0.5,0.24999999968749997,0.9609441315216459
"What is the biological basis of neuromorphic computing, and how does it differ from conventional neural networks?","[""Neuromorphic computing\nCS4575\nSustainable Software Engineering\n05.03.2025\nNergis T√∂men\n\nIntroduction\nComputer Vision Lab\nBiomorphic Intelligence Lab\nBiomedical Intervention Optimisation Lab\nNergis\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing\n\nHow many of you are familiar \nwith neural networks?\n\nSimple model of an artificial neuron\nhttps://medium.com/@cprasenjit32/perceptron-a-simple-yet-mighty-machine-learning-algorithm-9ff6b7d86a71\n\nWhat is a neural network?\nhttps://www.tibco.com/reference-center/what-is-a-neural-network\n\nWhy is it called a 'neural network'?\nhttps://www.tibco.com/reference-center/what-is-a-neural-network\n\nWhat is a neural network?\nWhy is it called a 'neural network'?\nMcCulloch-Pitts neuron [1, 2] (1943)\nWarren Sturgis McCulloch\n(Neurophysiologist)\nWalter Pitts\n(Logician)\n\nHow do biological neurons work?\nhttps://commons.wikimedia.org/wiki/File:Coincidence_detection_in_dendrites_of_pyramidal_neurons.gif\n'Input current' travels down the dendrites (top),\nget integrated (summed!) in the cell body\nwhich generates an 'output current' (bottom)\nwhich is chemically transmitted to the dendrites of \nother neurons.\n\nSimplified picture\nReal neuron\nArtificial neuron\nhttps://vajiramandravi.com/quest-upsc-notes/artificial-neural-network/\n\nWhat is a neural network?\nMcCulloch-Pitts neuron [1, 2]\n1940s: How do biological neurons compute basic \nlogic functions? (e.g. logic gates)\nNote: Ref. [3] gives a nice brief history on the ideas which lead to the \nMcCulloch-Pitts neuron.\n\nWhat is a neural network?"", 'McCulloch-Pitts neuron [1, 2]\n1940s: How do biological neurons compute basic \nlogic functions? (e.g. logic gates)\nNote: Ref. [3] gives a nice brief history on the ideas which lead to the \nMcCulloch-Pitts neuron.\n\nWhat is a neural network?\n1950s: How are neurons organized to perform \nsensory perception?\n\nWhat is a neural network?\n1950s: How are neurons organized to perform \nsensory perception?\nThe first ""neural network"": Perceptron (1958). [4]\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\nFrank Rosenblatt (Psychologist)\nwith a Mark I Perceptron computer in 1960\n\nWhat is a neural network?\n1950s: How are neurons organized to perform \nsensory perception?\nThe first ""neural network"": Perceptron (1958). [4]\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\nFrank Rosenblatt (Psychologist)\nwith a Mark I Perceptron computer in 1960\nPower-efficient\n\nNeuromorphic computing\nWhy neuromorphic computing?\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\n\nNeuromorphic computing\nWhy neuromorphic computing?\n‚ÄòBiological inspiration‚Äô for artificial neural networks (ANNs) is not a new idea.\nEmulation (as opposed to simulation) of neural networks in hardware is not a new idea.\nQuestion: What can we gain from increasing biological realism in existing neural networks?\n\nPower-efficiency at scale\nModern, deep neural networks*\nare trained using GPUs.\n* It is estimated that ChatGPT was trained on \n10,000-20,000 GPUs and that it will require\n30,000 GPUs to keep running stably in the future.\n* It is estimated that ChatGPT has 10-20 billion \nparameters.', 'Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002.']","['<1-hop>\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing', '<2-hop>\n\nReading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.']","Neuromorphic computing is inspired by the structure and function of the human brain. It involves using physical artificial neurons to perform computations, emulating the way biological neurons work. This approach is distinct from conventional neural networks, which are typically implemented in software and run on general-purpose hardware like GPUs.

The biological basis of neuromorphic computing lies in its attempt to mimic the brain's architecture and processes more closely than conventional neural networks. While conventional neural networks are inspired by the brain, they often simplify or abstract away many biological details to focus on mathematical models that can be efficiently computed on traditional hardware.

In contrast, neuromorphic computing aims to increase biological realism by using hardware that emulates the brain's neural circuits. This can lead to power-efficient computation, as neuromorphic systems can potentially perform complex tasks with less energy compared to conventional systems that rely on power-hungry GPUs.","Neuromorphic computing is based on the biological principles of the human brain, utilizing physical artificial neurons to perform computations. Unlike conventional neural networks, which rely on traditional computing architectures, neuromorphic systems are designed to mimic the brain's structure and function, enabling more efficient and biologically inspired processing.",0.99999999995,1.0,0.9166666666666666,0.92,0.16666666638888888,0.9475118438101008
What is the difference between spiking neural networks and spiking neuron networks?,"['Neural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568', 'Different encoding strategies with spiking neurons\n\nDifferent encoding strategies with spiking neurons\nUsing latency or spatio-temporal codes\nour encoding is faster and more spike-efficient (sparser)!\n\nDifferent encoding strategies with spiking neurons\nUsing latency or spatio-temporal codes\nour encoding is faster and more spike-efficient (sparser)!\nQuestions?\n\nNeuromorphic computing\nWhat is the advantage for applications?\n-\nLess spikes = less energy consumption in specialized neuromorphic hardware\n(e.g. Intel Loihi [12])\nBrains are energy efficient: \n2. Sparse encoding\n\nMultiply-accumulate (MAC) operations:\nNormal neuron: Multiplies input with \nweights, then adds.\nSpiking neuron: Consider binary input (e.g. input currents are piecewise \nconstant and assume values {0,1}). There is no multiplication, only addition.\n\nAssume one multiplier and one adder circuit uses M and A energy respectively with AÔπ§M\n(e.g., for a 45nm CMOS process, standard energy usage is A = 0.9 pJ and M = 3.7 pJ).\nNormal neuron: nin x nout multiplications,\n(nin‚Äì 1) x nout additions\nSpiking neuron: 0 multiplications, (nactive‚Äì 1) x nout \nadditions, with nactive ‚â§ nin\nEnergy consumption:\nEnormal = M nin nout + A (nin‚Äì 1) nout = 17.5 pJ\nEnergy consumption:\nEspiking = A (nactive‚Äì 1) nout = 2.7 pJ\nMultiply-accumulate (MAC) operations:\n\nAssume one multiplier and one adder circuit uses M and A energy respectively with AÔπ§M\n(e.g., for a 45nm CMOS process, standard energy usage is A = 0.9 pJ and M = 3.7 pJ).', 'Reading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020.']","[""<1-hop>\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant"", '<2-hop>\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \n(not publicly available) doi:10.1037/h0042519\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568', ""<1-hop>\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant"", '<2-hop>\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \n(not publicly available) doi:10.1037/h0042519\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568']","The terms ""spiking neural networks"" (SNNs) and ""spiking neuron networks"" are often used interchangeably to refer to the same concept. Both describe a type of artificial neural network that more closely mimics the way biological neurons communicate, using discrete spikes or action potentials to transmit information. These networks leverage the timing of spikes to encode and process information, which can lead to more energy-efficient computations compared to traditional artificial neural networks.

In the context of the provided sources, there is no explicit distinction made between ""spiking neural networks"" and ""spiking neuron networks."" Both terms refer to networks that utilize spiking neurons to perform computations, often with the goal of achieving more biologically plausible and energy-efficient processing. If there is any difference, it would likely be in the context or preference of terminology rather than a fundamental difference in the concept.","Spiking neural networks (SNNs) are a type of neural network model that processes information using spikes, similar to biological neurons. Spiking neuron networks refer to the individual components within these networks, focusing on how each neuron processes and communicates information through spikes.",0.0,1.0,0.8333333333333334,0.43,0.0,0.9718582506279204
What is the foundational concepts of spiking neural networks and how they are used in encoding strategies?,"['Different encoding strategies with spiking neurons\n\nDifferent encoding strategies with spiking neurons\nUsing latency or spatio-temporal codes\nour encoding is faster and more spike-efficient (sparser)!\n\nDifferent encoding strategies with spiking neurons\nUsing latency or spatio-temporal codes\nour encoding is faster and more spike-efficient (sparser)!\nQuestions?\n\nNeuromorphic computing\nWhat is the advantage for applications?\n-\nLess spikes = less energy consumption in specialized neuromorphic hardware\n(e.g. Intel Loihi [12])\nBrains are energy efficient: \n2. Sparse encoding\n\nMultiply-accumulate (MAC) operations:\nNormal neuron: Multiplies input with \nweights, then adds.\nSpiking neuron: Consider binary input (e.g. input currents are piecewise \nconstant and assume values {0,1}). There is no multiplication, only addition.\n\nAssume one multiplier and one adder circuit uses M and A energy respectively with AÔπ§M\n(e.g., for a 45nm CMOS process, standard energy usage is A = 0.9 pJ and M = 3.7 pJ).\nNormal neuron: nin x nout multiplications,\n(nin‚Äì 1) x nout additions\nSpiking neuron: 0 multiplications, (nactive‚Äì 1) x nout \nadditions, with nactive ‚â§ nin\nEnergy consumption:\nEnormal = M nin nout + A (nin‚Äì 1) nout = 17.5 pJ\nEnergy consumption:\nEspiking = A (nactive‚Äì 1) nout = 2.7 pJ\nMultiply-accumulate (MAC) operations:\n\nAssume one multiplier and one adder circuit uses M and A energy respectively with AÔπ§M\n(e.g., for a 45nm CMOS process, standard energy usage is A = 0.9 pJ and M = 3.7 pJ).', 'Neural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568', 'Reading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020.']","[""<1-hop>\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant"", '<2-hop>\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \n(not publicly available) doi:10.1037/h0042519\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568', ""<1-hop>\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant"", '<2-hop>\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \n(not publicly available) doi:10.1037/h0042519\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568', ""<1-hop>\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant"", '<2-hop>\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \n(not publicly available) doi:10.1037/h0042519\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568', ""<1-hop>\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant"", '<2-hop>\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \n(not publicly available) doi:10.1037/h0042519\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568']","Spiking neural networks (SNNs) are a type of neural network that more closely mimic the way biological neurons communicate. The foundational concept of SNNs is that they use spikes, or discrete events, to transmit information, rather than continuous signals. This allows them to perform computations in a way that is more similar to the brain, potentially leading to more efficient processing.

In terms of encoding strategies, SNNs can use latency or spatio-temporal codes. These strategies are designed to be faster and more spike-efficient, meaning they use fewer spikes to encode information. This sparsity in spike usage leads to less energy consumption, which is particularly advantageous for applications in neuromorphic computing. Neuromorphic hardware, such as Intel's Loihi, benefits from this efficiency because it reduces the energy required for computation, making it more sustainable and scalable.

Overall, the use of spiking neurons in encoding strategies allows for more efficient and biologically plausible computation, leveraging the advantages of sparse and event-driven processing.","Spiking neural networks use spikes to encode information, with foundational concepts including the work of McCulloch and Pitts on logical calculus of nervous activity, and later developments in spiking neuron models.",0.0,0.6666666666666666,0.8181818181818182,0.17,0.0,0.9128742468478909
What is the project idea about government-developed OS software?,"['data to understand state of software: \nbuildable?, open dev. history?, requirements documentation? \n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!\n\nB7. Queue - but better for the student / TA society\n‚Ä¢ Requirements analysis regarding social and individual sustainability effects \nof Queue \n‚Ä¢ Other EIP / TUD used software also possible: e.g., Answers EWI \n‚Ä¢ Non-technical project ‚Üí proper process (workshops? Interviews?) & rich \ndescription of outcomes focus of grading\nhttps://eip.pages.ewi.tudelft.nl/eip-website/queue.html\n\nC1. Compare energy consumption of docker images for \nML workloads.\n‚Ä¢ Similar to what we have seen in the lectures but for ML-specific workloads. \n‚Ä¢ We can reuse existing experiment replication packages.\n22\n\nC2. Plugin to visualize Hugging Face carbon emissions.\n‚Ä¢ https://huggingface.co/blog/leaderboard-emissions-\nanalysis \n‚Ä¢\nYoo, Taewon, et al. ""Visualizing the Carbon Intensity of Machine Learning Inference for Image Analysis on TensorFlow Hub.""\n\nC3. Plugin for ChatGPT\n‚Ä¢ Users seldom know how much carbon they are emitting when they interact \nwith chat GPT. \n‚Ä¢ Let‚Äôs make it transparent to the users. Browser plugin?\n24\nCO2\n\nC4. NutriScore for software libraries\n25\n‚Ä¢ NutriScore labels are not perfect but they are a good starting point! \n‚Ä¢ What if we could do the same thing for the energy efficiency of software. \n‚Ä¢ (Also open to individual or social sustainability) \n‚Ä¢ This work can be scoped in particular domains/ecossystems/use cases. \n‚Ä¢ Libraries for stats? ML? Web Dev? Cloud?\n\nC5. Add energy-awareness to existing software\n26\n‚Ä¢ Streamlit, Notebooks, JSFiddle, \nPyScript, zsh, etc. \n‚Ä¢\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy efficiency using static code analysis. \n‚Ä¢ We don‚Äôt need an accurate value. \n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention. \n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)', 'Lu√≠s Cruz \nL.Cruz@tudelft.nl \n10. Project 2\nSustainable Software Engineering\u2028\nCS4575\nSustainableSE 2025\nCarolin Brandt \nC.E.Brandt@tudelft.nl \nEnrique Barba Roque \nE.BarbaRoque@tudelft.nl\n\n1. Goal/assignment \n2. Deliverables \n3. Strategy \n4. Ideas\n\nAssignment\n‚Ä¢ Goal: Solve a Sustainable Software Engineering problem. \n‚Ä¢ Identify 1 problem that should be fixed to help enabling sustainability in \nthe software engineering industry/community. \n‚Ä¢ Propose a solution. A tool, framework, guidelines, etc. \n‚Ä¢ Implementation. \n‚Ä¢ Validation. (Depending on the idea) \n‚Ä¢ Dissemination/social impact. (Solution should be open source, welcome \ncontributors, post on social media? Tool website? Available in a package \nmanager?)\n3\n\nDeliverables\n‚Ä¢ Paper-like article. (Min 4 pages, max 10) \n‚Ä¢ Online git repo with open source codebase and/or replication package. \n‚Ä¢ Presentation: 5 min + 5min Q&A\n4\n\nArticle\n‚Ä¢ Different projects will have different expectations -> Make agreements with \nyour coach. \n‚Ä¢ Some projects are more technical and some projects more theoretical. \n‚Ä¢ Common requirements: \n‚Ä¢ Motivation, formulation of the problem being addressed, etc. \n‚Ä¢ Description of the solution. \n‚Ä¢ Validation of the solution (if applicable -> discuss with coach) \n‚Ä¢ Discussion of the solution. (Including limitations)\n5\n\nStrategy\n‚Ä¢ Starting next week, there are no lectures  \n‚Ä¢ Steering meetings from week 5 till week 9 (either online or in person).  \n‚Ä¢ 1 steering meeting per week. (4+1 sprints) \n‚Ä¢ Every week, you need to plan different tasks and assignments. \n‚Ä¢ Deadline April 4.\n6\n\nStrategy\n‚Ä¢ Week 0 \n‚Ä¢ Decide project idea (today) \n‚Ä¢ Define steering meeting schedule \n‚Ä¢ Create working document of the \narticle: Problem statement and solution \nproposal! \n‚Ä¢ Define and assign tasks for each week. \n‚Ä¢ Week 1 \n‚Ä¢ Implementation \n‚Ä¢ Agreements with supervisor. \n‚Ä¢ Week 2 \n‚Ä¢ Implementation \n‚Ä¢ Week 3 \n‚Ä¢ Implementation, Full draft of article, \ndissemination.', 'Lu√≠s Cruz \nL.Cruz@tudelft.nl \n7. Green SE ‚Äì Research\nSustainable Software Engineering\u2028\nCS4575\nSustainableSE 2025\nCarolin Brandt \nC.E.Brandt@tudelft.nl \nEnrique Barba Roque \nE.BarbaRoque@tudelft.nl\n\n1. Energy patterns for mobile apps \n2. Carbon-aware datacenters \n3. Energy Regression Testing \n4. Debugging Energy with Docker images \n5. Energy Efficiency vs Code Quality \n\n‚Ä¢ While learning about these works, try to be critical about them and find their \npitfalls.\n3\n\n‚Ä¢ We have seen that measuring energy consumption is not trivial \n‚Ä¢ It is not practical considering that developers have other priorities above \nenergy efficiency \n‚Ä¢ At the same time, every now and then there are some efforts to improve \nenergy efficiency in some cases. This is time consuming and requires \nexpertise. \n‚Ä¢ How can we reuse these efforts?\n4\n\nEnergy Patterns for Mobile \nApps\nhttps://tqrg.github.io/energy-patterns/\n\nMethodology\n5. Catalog of Energy Patterns\n22 \npatterns\nF-droid\nCurated Lists\n1. App Collection\n1783 \napps\n3. Manual Refinement of Subjects of \nInterest\n1563 \nchanges\n4. Thematic Analysis\n431 \nreusable \nchanges\n2. Collect Changes With Potential Interest\n/.*(energy|power|battery).*/\n6028 \nchanges\n\nThematic Analysis\n1. Familiarization with data \n2. Generating initial labels \n3. Reviewing themes\n4. Defining and naming themes\n\n‚Ä¢ Energy Pattern: design pattern to improve energy efficiency.. \n‚Ä¢ 22 energy patterns. \n‚Ä¢ Each pattern is described by Context, Solution, Example, References from \nliterature, and Occurences (links to code changes from git repositories).\n8\n\nhttps://tqrg.github.io/energy-patterns\n\nDark UI Colors \nProvide a dark UI color theme to \nsave battery on devices with \nAMOLED screens.\n‚Ä¢ Context: [‚Ä¶] Apps that require heavy usage of screen can \nhave a substantial negative impact on battery life. \n‚Ä¢ Solution: Provide a UI theme with dark background colors.']","['<1-hop>\n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise\n‚Ä¢ But studying government software is diÔ¨Écult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation?\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!', '<2-hop>\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption\n‚Ä¢ B3. Energy proÔ¨Åling of static analysis tools\n‚Ä¢ B4. Detailed energy proÔ¨Åling of build pipelines\n‚Ä¢ B5. Tool supporting SusAF workshop / process\n‚Ä¢ B6. Dataset of government-developed OS software\n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability']","The provided sources do not mention a project idea specifically about government-developed OS software. However, if you are interested in sustainable software engineering projects, the sources discuss various ideas such as energy consumption comparison of docker images for ML workloads, plugins to visualize carbon emissions, and adding energy-awareness to existing software. If you have a specific interest in government-developed OS software, you might consider exploring how such software can be made more sustainable or energy-efficient.","The project idea involves creating a comprehensive dataset of government-developed OS software to understand its state, including buildability, open development history, and requirements documentation. This addresses challenges like lack of incentives and language barriers.",0.0,0.0,0.7142857142857143,0.0,0.0,0.0
What is the project idea related to creating a dataset of goverment-developed OS software?,"['data to understand state of software: \nbuildable?, open dev. history?, requirements documentation? \n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!\n\nB7. Queue - but better for the student / TA society\n‚Ä¢ Requirements analysis regarding social and individual sustainability effects \nof Queue \n‚Ä¢ Other EIP / TUD used software also possible: e.g., Answers EWI \n‚Ä¢ Non-technical project ‚Üí proper process (workshops? Interviews?) & rich \ndescription of outcomes focus of grading\nhttps://eip.pages.ewi.tudelft.nl/eip-website/queue.html\n\nC1. Compare energy consumption of docker images for \nML workloads.\n‚Ä¢ Similar to what we have seen in the lectures but for ML-specific workloads. \n‚Ä¢ We can reuse existing experiment replication packages.\n22\n\nC2. Plugin to visualize Hugging Face carbon emissions.\n‚Ä¢ https://huggingface.co/blog/leaderboard-emissions-\nanalysis \n‚Ä¢\nYoo, Taewon, et al. ""Visualizing the Carbon Intensity of Machine Learning Inference for Image Analysis on TensorFlow Hub.""\n\nC3. Plugin for ChatGPT\n‚Ä¢ Users seldom know how much carbon they are emitting when they interact \nwith chat GPT. \n‚Ä¢ Let‚Äôs make it transparent to the users. Browser plugin?\n24\nCO2\n\nC4. NutriScore for software libraries\n25\n‚Ä¢ NutriScore labels are not perfect but they are a good starting point! \n‚Ä¢ What if we could do the same thing for the energy efficiency of software. \n‚Ä¢ (Also open to individual or social sustainability) \n‚Ä¢ This work can be scoped in particular domains/ecossystems/use cases. \n‚Ä¢ Libraries for stats? ML? Web Dev? Cloud?\n\nC5. Add energy-awareness to existing software\n26\n‚Ä¢ Streamlit, Notebooks, JSFiddle, \nPyScript, zsh, etc. \n‚Ä¢\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy efficiency using static code analysis. \n‚Ä¢ We don‚Äôt need an accurate value. \n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention. \n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)', 'Lu√≠s Cruz \nL.Cruz@tudelft.nl \n10. Project 2\nSustainable Software Engineering\u2028\nCS4575\nSustainableSE 2025\nCarolin Brandt \nC.E.Brandt@tudelft.nl \nEnrique Barba Roque \nE.BarbaRoque@tudelft.nl\n\n1. Goal/assignment \n2. Deliverables \n3. Strategy \n4. Ideas\n\nAssignment\n‚Ä¢ Goal: Solve a Sustainable Software Engineering problem. \n‚Ä¢ Identify 1 problem that should be fixed to help enabling sustainability in \nthe software engineering industry/community. \n‚Ä¢ Propose a solution. A tool, framework, guidelines, etc. \n‚Ä¢ Implementation. \n‚Ä¢ Validation. (Depending on the idea) \n‚Ä¢ Dissemination/social impact. (Solution should be open source, welcome \ncontributors, post on social media? Tool website? Available in a package \nmanager?)\n3\n\nDeliverables\n‚Ä¢ Paper-like article. (Min 4 pages, max 10) \n‚Ä¢ Online git repo with open source codebase and/or replication package. \n‚Ä¢ Presentation: 5 min + 5min Q&A\n4\n\nArticle\n‚Ä¢ Different projects will have different expectations -> Make agreements with \nyour coach. \n‚Ä¢ Some projects are more technical and some projects more theoretical. \n‚Ä¢ Common requirements: \n‚Ä¢ Motivation, formulation of the problem being addressed, etc. \n‚Ä¢ Description of the solution. \n‚Ä¢ Validation of the solution (if applicable -> discuss with coach) \n‚Ä¢ Discussion of the solution. (Including limitations)\n5\n\nStrategy\n‚Ä¢ Starting next week, there are no lectures  \n‚Ä¢ Steering meetings from week 5 till week 9 (either online or in person).  \n‚Ä¢ 1 steering meeting per week. (4+1 sprints) \n‚Ä¢ Every week, you need to plan different tasks and assignments. \n‚Ä¢ Deadline April 4.\n6\n\nStrategy\n‚Ä¢ Week 0 \n‚Ä¢ Decide project idea (today) \n‚Ä¢ Define steering meeting schedule \n‚Ä¢ Create working document of the \narticle: Problem statement and solution \nproposal! \n‚Ä¢ Define and assign tasks for each week. \n‚Ä¢ Week 1 \n‚Ä¢ Implementation \n‚Ä¢ Agreements with supervisor. \n‚Ä¢ Week 2 \n‚Ä¢ Implementation \n‚Ä¢ Week 3 \n‚Ä¢ Implementation, Full draft of article, \ndissemination.', '‚Ä¢ Deadline April 4.\n6\n\nStrategy\n‚Ä¢ Week 0 \n‚Ä¢ Decide project idea (today) \n‚Ä¢ Define steering meeting schedule \n‚Ä¢ Create working document of the \narticle: Problem statement and solution \nproposal! \n‚Ä¢ Define and assign tasks for each week. \n‚Ä¢ Week 1 \n‚Ä¢ Implementation \n‚Ä¢ Agreements with supervisor. \n‚Ä¢ Week 2 \n‚Ä¢ Implementation \n‚Ä¢ Week 3 \n‚Ä¢ Implementation, Full draft of article, \ndissemination. \n‚Ä¢ Week 4 \n‚Ä¢ Final refinements \n‚Ä¢ Prepare presentation\n7\n\nProject ideas\n‚Ä¢ A1. Prototype cross-machine comparable benchmarks \n‚Ä¢ A2. Add energy metrics to LMstudio/Ollama \n‚Ä¢ A3. Visualizations built-in with EnergiBridge \n‚Ä¢ A4. Service-based version of EnergiBridge\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption \n‚Ä¢ B3. Energy profiling of static analysis tools \n‚Ä¢ B4. Detailed energy profiling of build pipelines \n‚Ä¢ B5. Tool supporting SusAF workshop / process \n‚Ä¢ B6. Dataset of government-developed OS software \n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability\n\nProject ideas\n‚Ä¢ C1. Compare energy consumption of docker images for ML workloads. \n‚Ä¢ C2. Create a plugin to visualize Hugging Face carbon emissions in detail. \n‚Ä¢ C3. Plugin for ChatGPT (footprint per chat window) \n‚Ä¢ C4. NutriScore for software libraries. \n‚Ä¢ C5. Add energy-awareness to existing software \n‚Ä¢ C6. Green Shift Left \n‚Ä¢ C7. Education for Sustainable SE\n\nA1. Prototype cross-machine comparable benchmarks\n‚Ä¢ Energy-usage comparisons require running both baseline + software on the \nsame machine ‚Üí limits how extensive our experiments can be \n‚Ä¢ Research community is in need of benchmarks that make energy \nmeasurements comparable even if executed on different machines \n‚Ä¢ Focus on a single task or model (i.e. computing vision, classification)\n\nA2.']","['<1-hop>\n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise\n‚Ä¢ But studying government software is diÔ¨Écult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation?\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!', '<2-hop>\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption\n‚Ä¢ B3. Energy proÔ¨Åling of static analysis tools\n‚Ä¢ B4. Detailed energy proÔ¨Åling of build pipelines\n‚Ä¢ B5. Tool supporting SusAF workshop / process\n‚Ä¢ B6. Dataset of government-developed OS software\n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability', '<1-hop>\n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise\n‚Ä¢ But studying government software is diÔ¨Écult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation?\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!', '<2-hop>\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption\n‚Ä¢ B3. Energy proÔ¨Åling of static analysis tools\n‚Ä¢ B4. Detailed energy proÔ¨Åling of build pipelines\n‚Ä¢ B5. Tool supporting SusAF workshop / process\n‚Ä¢ B6. Dataset of government-developed OS software\n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability', '<1-hop>\n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise\n‚Ä¢ But studying government software is diÔ¨Écult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation?\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!', '<2-hop>\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption\n‚Ä¢ B3. Energy proÔ¨Åling of static analysis tools\n‚Ä¢ B4. Detailed energy proÔ¨Åling of build pipelines\n‚Ä¢ B5. Tool supporting SusAF workshop / process\n‚Ä¢ B6. Dataset of government-developed OS software\n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability', '<1-hop>\n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise\n‚Ä¢ But studying government software is diÔ¨Écult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation?\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!', '<2-hop>\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption\n‚Ä¢ B3. Energy proÔ¨Åling of static analysis tools\n‚Ä¢ B4. Detailed energy proÔ¨Åling of build pipelines\n‚Ä¢ B5. Tool supporting SusAF workshop / process\n‚Ä¢ B6. Dataset of government-developed OS software\n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability', '<1-hop>\n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise\n‚Ä¢ But studying government software is diÔ¨Écult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation?\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!', '<2-hop>\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption\n‚Ä¢ B3. Energy proÔ¨Åling of static analysis tools\n‚Ä¢ B4. Detailed energy proÔ¨Åling of build pipelines\n‚Ä¢ B5. Tool supporting SusAF workshop / process\n‚Ä¢ B6. Dataset of government-developed OS software\n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability']",The project idea related to creating a dataset of government-developed OS software is labeled as B6. The focus of this project is to compile a dataset that includes open-source software developed by government entities. This project falls under the category of Quality Assurance & Testing and Social & Individual Sustainability.,"The project idea is to create a dataset of government-developed OS software, which would help in understanding the state of such software, including whether it is buildable, has open development history, and has requirements documentation.",0.8333333332916666,1.0,1.0,0.33,,0.9190513882459332
What is the project idea related to creating a dataset of government-developed OS software?,"['data to understand state of software: \nbuildable?, open dev. history?, requirements documentation? \n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!\n\nB7. Queue - but better for the student / TA society\n‚Ä¢ Requirements analysis regarding social and individual sustainability effects \nof Queue \n‚Ä¢ Other EIP / TUD used software also possible: e.g., Answers EWI \n‚Ä¢ Non-technical project ‚Üí proper process (workshops? Interviews?) & rich \ndescription of outcomes focus of grading\nhttps://eip.pages.ewi.tudelft.nl/eip-website/queue.html\n\nC1. Compare energy consumption of docker images for \nML workloads.\n‚Ä¢ Similar to what we have seen in the lectures but for ML-specific workloads. \n‚Ä¢ We can reuse existing experiment replication packages.\n22\n\nC2. Plugin to visualize Hugging Face carbon emissions.\n‚Ä¢ https://huggingface.co/blog/leaderboard-emissions-\nanalysis \n‚Ä¢\nYoo, Taewon, et al. ""Visualizing the Carbon Intensity of Machine Learning Inference for Image Analysis on TensorFlow Hub.""\n\nC3. Plugin for ChatGPT\n‚Ä¢ Users seldom know how much carbon they are emitting when they interact \nwith chat GPT. \n‚Ä¢ Let‚Äôs make it transparent to the users. Browser plugin?\n24\nCO2\n\nC4. NutriScore for software libraries\n25\n‚Ä¢ NutriScore labels are not perfect but they are a good starting point! \n‚Ä¢ What if we could do the same thing for the energy efficiency of software. \n‚Ä¢ (Also open to individual or social sustainability) \n‚Ä¢ This work can be scoped in particular domains/ecossystems/use cases. \n‚Ä¢ Libraries for stats? ML? Web Dev? Cloud?\n\nC5. Add energy-awareness to existing software\n26\n‚Ä¢ Streamlit, Notebooks, JSFiddle, \nPyScript, zsh, etc. \n‚Ä¢\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy efficiency using static code analysis. \n‚Ä¢ We don‚Äôt need an accurate value. \n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention. \n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)', '‚Ä¢ Deadline April 4.\n6\n\nStrategy\n‚Ä¢ Week 0 \n‚Ä¢ Decide project idea (today) \n‚Ä¢ Define steering meeting schedule \n‚Ä¢ Create working document of the \narticle: Problem statement and solution \nproposal! \n‚Ä¢ Define and assign tasks for each week. \n‚Ä¢ Week 1 \n‚Ä¢ Implementation \n‚Ä¢ Agreements with supervisor. \n‚Ä¢ Week 2 \n‚Ä¢ Implementation \n‚Ä¢ Week 3 \n‚Ä¢ Implementation, Full draft of article, \ndissemination. \n‚Ä¢ Week 4 \n‚Ä¢ Final refinements \n‚Ä¢ Prepare presentation\n7\n\nProject ideas\n‚Ä¢ A1. Prototype cross-machine comparable benchmarks \n‚Ä¢ A2. Add energy metrics to LMstudio/Ollama \n‚Ä¢ A3. Visualizations built-in with EnergiBridge \n‚Ä¢ A4. Service-based version of EnergiBridge\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption \n‚Ä¢ B3. Energy profiling of static analysis tools \n‚Ä¢ B4. Detailed energy profiling of build pipelines \n‚Ä¢ B5. Tool supporting SusAF workshop / process \n‚Ä¢ B6. Dataset of government-developed OS software \n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability\n\nProject ideas\n‚Ä¢ C1. Compare energy consumption of docker images for ML workloads. \n‚Ä¢ C2. Create a plugin to visualize Hugging Face carbon emissions in detail. \n‚Ä¢ C3. Plugin for ChatGPT (footprint per chat window) \n‚Ä¢ C4. NutriScore for software libraries. \n‚Ä¢ C5. Add energy-awareness to existing software \n‚Ä¢ C6. Green Shift Left \n‚Ä¢ C7. Education for Sustainable SE\n\nA1. Prototype cross-machine comparable benchmarks\n‚Ä¢ Energy-usage comparisons require running both baseline + software on the \nsame machine ‚Üí limits how extensive our experiments can be \n‚Ä¢ Research community is in need of benchmarks that make energy \nmeasurements comparable even if executed on different machines \n‚Ä¢ Focus on a single task or model (i.e. computing vision, classification)\n\nA2.', 'Lu√≠s Cruz \nL.Cruz@tudelft.nl \n10. Project 2\nSustainable Software Engineering\u2028\nCS4575\nSustainableSE 2025\nCarolin Brandt \nC.E.Brandt@tudelft.nl \nEnrique Barba Roque \nE.BarbaRoque@tudelft.nl\n\n1. Goal/assignment \n2. Deliverables \n3. Strategy \n4. Ideas\n\nAssignment\n‚Ä¢ Goal: Solve a Sustainable Software Engineering problem. \n‚Ä¢ Identify 1 problem that should be fixed to help enabling sustainability in \nthe software engineering industry/community. \n‚Ä¢ Propose a solution. A tool, framework, guidelines, etc. \n‚Ä¢ Implementation. \n‚Ä¢ Validation. (Depending on the idea) \n‚Ä¢ Dissemination/social impact. (Solution should be open source, welcome \ncontributors, post on social media? Tool website? Available in a package \nmanager?)\n3\n\nDeliverables\n‚Ä¢ Paper-like article. (Min 4 pages, max 10) \n‚Ä¢ Online git repo with open source codebase and/or replication package. \n‚Ä¢ Presentation: 5 min + 5min Q&A\n4\n\nArticle\n‚Ä¢ Different projects will have different expectations -> Make agreements with \nyour coach. \n‚Ä¢ Some projects are more technical and some projects more theoretical. \n‚Ä¢ Common requirements: \n‚Ä¢ Motivation, formulation of the problem being addressed, etc. \n‚Ä¢ Description of the solution. \n‚Ä¢ Validation of the solution (if applicable -> discuss with coach) \n‚Ä¢ Discussion of the solution. (Including limitations)\n5\n\nStrategy\n‚Ä¢ Starting next week, there are no lectures  \n‚Ä¢ Steering meetings from week 5 till week 9 (either online or in person).  \n‚Ä¢ 1 steering meeting per week. (4+1 sprints) \n‚Ä¢ Every week, you need to plan different tasks and assignments. \n‚Ä¢ Deadline April 4.\n6\n\nStrategy\n‚Ä¢ Week 0 \n‚Ä¢ Decide project idea (today) \n‚Ä¢ Define steering meeting schedule \n‚Ä¢ Create working document of the \narticle: Problem statement and solution \nproposal! \n‚Ä¢ Define and assign tasks for each week. \n‚Ä¢ Week 1 \n‚Ä¢ Implementation \n‚Ä¢ Agreements with supervisor. \n‚Ä¢ Week 2 \n‚Ä¢ Implementation \n‚Ä¢ Week 3 \n‚Ä¢ Implementation, Full draft of article, \ndissemination.']","['<1-hop>\n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise\n‚Ä¢ But studying government software is diÔ¨Écult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation?\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!', '<2-hop>\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption\n‚Ä¢ B3. Energy proÔ¨Åling of static analysis tools\n‚Ä¢ B4. Detailed energy proÔ¨Åling of build pipelines\n‚Ä¢ B5. Tool supporting SusAF workshop / process\n‚Ä¢ B6. Dataset of government-developed OS software\n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability']","The project idea related to creating a dataset of government-developed OS software is labeled as B6. This project involves compiling a dataset that includes open-source software developed by government entities. The focus is on understanding the state of such software, including aspects like whether it is buildable, has an open development history, and includes requirements documentation.","The project idea is to create a comprehensive dataset of government-developed OS software to understand the state of such software, including its buildability, open development history, and requirements documentation. This addresses challenges like the lack of incentive to make software popular and language barriers.",0.49999999995,0.5,1.0,0.57,,0.8323777535647436
How EcoAndroid reduce risk by reduce size?,"['‚Ä¢ Some users noticed that K-9 mail was spending more energy than usual. üôâ \n‚Ä¢ A user that was having issues with a personal mail server  noticed that K-9 \nmail was the one of the most energy-greedy apps. IMAP IDLE protocol for real-time \nnotifications. \n‚Ä¢ When a connection is not possible, the app automatically retries later. \n‚Ä¢ https://github.com/k9mail/k-9/commit/\n86f3b28f79509d1a4d613eb39f60603e08579ea3\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio) \n‚Ä¢ Dynamic Retry Delay \n‚Ä¢ Push Over Poll \n‚Ä¢ Reduce Size \n‚Ä¢ Cache \n‚Ä¢ Avoid Graphics and Animations\n20\n\nCarbon-Aware Computing for \nDatacenters \nhttps://sites.google.com/view/energy-efficiency-languages\n21\nAna Radovanovic ÃÅ, Ross Koningstein, Ian Schneider, Bokan \nChen, Alexandre Duarte, Binz Roy, Diyue Xiao, Maya \nHaridasan, Patrick Hung, Nick Care, Saurav Talukdar, Eric \nMullen, Kendal Smith, MariEllen Cottman, and Walfredo Cirne \n\n\n‚Ä¢ Google‚Äôs Carbon-Intelligent Computing System (CICS) \n‚Ä¢ Main idea: use carbon-intensity data to shift datacenter jobs in time \n‚Ä¢ Typically, job schedulers use a metric of cluster capacity to schedule a job in \na particular cluster. \n‚Ä¢ CICS overrides this metric with the virtual capacity curve (VCC) that \nfactors in Carbon intensity \n‚Ä¢ When a new job comes in, the scheduler estimates its CPU load and power \nusage and assigns it to a cluster if the VCC is not exceeded.\n23\n\n‚Ä¢ Jobs are divided between flexible and inflexible. \n‚Ä¢ Flexible load is considered shapeable/shiftable as long as its total daily \ncompute (CPU) demand is preserved \n‚Ä¢ The system needs to consider that, while running a job, the virtual capacity \ncurve (VCC) might drop. Hence, this job should not start in the first place. \n‚Ä¢ They forecast VCC for the next day\n24\n\n\nVirtual Cluster Capacity (VCC)\n‚Ä¢ Aims at reducing the peak load at carbon intensive hours but in total it should allow for the \nsome amount of daily computation!', '‚Ä¢ Opt for low-power hardware (e.g., Nvidia Jetson boards) \n‚Ä¢ Or GPUs that provide energy metrics (e.g., NVIDIA GPUs via the nvidia-smi tool) \n‚Ä¢ Report energy/carbon metrics (e.g., embed in MLFlow?) \n‚Ä¢ Use pre-trained models (Transfer Learning) \n‚Ä¢ Preprocess dataset to reduce size. \n‚Ä¢ Improve parameter-tuning strategy.\n11\n\nReporting energy/carbon footprint\n‚Ä¢ We need benchmarks. \n‚Ä¢ AllenAI leaderboard\u2028\nhttps://leaderboard.allenai.org \n‚Ä¢ No carbon metrics, yet \n‚Ä¢ Report comparable proxies for energy \nconsumption. \n‚Ä¢ ‚ö† Learning algorithms behave in a non-\ndeterministic \n‚Ä¢ ‚ö† Different data-points lead to different \nenergy consumption\n12\n\nReporting energy/carbon footprint\n‚Ä¢ Reporting measured energy consumption \n‚Ä¢ + Accurate \n‚Ä¢ + Easy to map to carbon emissions \n‚Ä¢ - Hard to measure \n‚Ä¢ - Low replicability \n‚Ä¢ Reporting time / estimation based on time & hardware \n‚Ä¢ + Easy to measure \n‚Ä¢ + Correlates with energy consumption in most cases. \n‚Ä¢ -  Difficult to compare with measurements from other setups \n‚Ä¢ E.g., floating point operations (FPOs) (?) \n‚Ä¢ + comparable across different setups \n‚Ä¢ + cheap \n‚Ä¢ - does not factor in memory energy consumption \n‚Ä¢ - does not reflect carbon emissions\n13\n\nData-centric AI\n\nData-centric AI\n‚Ä¢ Emerging discipline that deals with systematically engineering data to build AI \nsystems. \n‚Ä¢ Shift from improving the training strategy to improving the data. \n‚Ä¢ It is better to have small but reliable datasets than large but noisy \ndatasets. \n‚Ä¢ => Improve data collection, data labelling, and data preprocessing. \n‚Ä¢ More about data-centric AI by Andrew Ng:\u2028\nhttps://www.youtube.com/watch?v=06-AZXmwHjo\n15\n\n\nGreen Data-centric AI\n‚Ä¢ How do different ML algorithms compare \nin terms of energy consumption? \n‚Ä¢ How does number of rows relate to the \nenergy consumption of ML models? \n‚Ä¢ How does number of features relate to \nthe energy consumption of ML models? \n‚Ä¢ What is the impact of reducing data in the \nperformance of the model? \n‚Ä¢ Method -> results -> discussion\n17\n\nMethod\n‚Ä¢ Single object of study: natural language model to detect spam messages.']","['<1-hop>\n\nShuffle \nüîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them.\n‚Ä¢ If you run 30 executions for version A and another batch for version B:\n‚Ä¢ External conditions that change over time will have a diÔ¨Äerent bias in \nthe 2 versions (e.g., room temperature changes).\n‚Ä¢ If you shuÔ¨Ñe, you reduce this risk.\n11', '<2-hop>\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio)\n‚Ä¢ Dynamic Retry Delay\n‚Ä¢ Push Over Poll\n‚Ä¢ Reduce Size\n‚Ä¢ Cache\n‚Ä¢ Avoid Graphics and Animations\n20', '<1-hop>\n\nShuffle \nüîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them.\n‚Ä¢ If you run 30 executions for version A and another batch for version B:\n‚Ä¢ External conditions that change over time will have a diÔ¨Äerent bias in \nthe 2 versions (e.g., room temperature changes).\n‚Ä¢ If you shuÔ¨Ñe, you reduce this risk.\n11', '<2-hop>\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio)\n‚Ä¢ Dynamic Retry Delay\n‚Ä¢ Push Over Poll\n‚Ä¢ Reduce Size\n‚Ä¢ Cache\n‚Ä¢ Avoid Graphics and Animations\n20']","EcoAndroid reduces risk by reducing size through several strategies, such as implementing dynamic retry delays, using push over poll, caching, and avoiding graphics and animations. These strategies help in minimizing the app's resource consumption, which in turn reduces energy usage and the risk of excessive battery drain.",EcoAndroid reduce risk by using Reduce Size feature which help minimize energy consumption and reduce impact of external factors like temperature changes.,0.49999999995,0.5,1.0,0.75,0.249999999375,0.9454568779359086
How can static code analysis in data science be used to improve the energy efficiency of data centers and contribute to sustainable software engineering?,"['‚Ä¢\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy efficiency using static code analysis. \n‚Ä¢ We don‚Äôt need an accurate value. \n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention. \n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27\n\nC7 - Education\n‚Ä¢ Educational game for Software \nSustainability practices \n‚Ä¢ Purpose: use within software teams to \ndiscuss or learn about different sustainable \nIT practices: at the organisation level, \nsoftware, etc.\n28\nhttps://github.com/OttoKaaij/Ticket-To-Sustainability/?tab=readme-ov-file\n\nProject ideas (old)\n‚Ä¢ Plugin from EnergiBridge (GUI, report generator, python library, etc.) \n‚Ä¢ Plugin for ChatGPT (carbon emissions per chat window) \n‚Ä¢ Seamless measurements for AI libraries \n‚Ä¢ Energy patterns for Green AI \n‚Ä¢ Sustainable SW dev gamification \n‚Ä¢ Sustainability auditor for AI projects \n‚Ä¢ Energy Profiling of screen colour filter tools (or display settings) \n‚Ä¢ ‚Ä¶ you can also propose yours!\n\nhttps://edu.nl/64gpk\nedu.nl/64gpk', 'data to understand state of software: \nbuildable?, open dev. history?, requirements documentation? \n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!\n\nB7. Queue - but better for the student / TA society\n‚Ä¢ Requirements analysis regarding social and individual sustainability effects \nof Queue \n‚Ä¢ Other EIP / TUD used software also possible: e.g., Answers EWI \n‚Ä¢ Non-technical project ‚Üí proper process (workshops? Interviews?) & rich \ndescription of outcomes focus of grading\nhttps://eip.pages.ewi.tudelft.nl/eip-website/queue.html\n\nC1. Compare energy consumption of docker images for \nML workloads.\n‚Ä¢ Similar to what we have seen in the lectures but for ML-specific workloads. \n‚Ä¢ We can reuse existing experiment replication packages.\n22\n\nC2. Plugin to visualize Hugging Face carbon emissions.\n‚Ä¢ https://huggingface.co/blog/leaderboard-emissions-\nanalysis \n‚Ä¢\nYoo, Taewon, et al. ""Visualizing the Carbon Intensity of Machine Learning Inference for Image Analysis on TensorFlow Hub.""\n\nC3. Plugin for ChatGPT\n‚Ä¢ Users seldom know how much carbon they are emitting when they interact \nwith chat GPT. \n‚Ä¢ Let‚Äôs make it transparent to the users. Browser plugin?\n24\nCO2\n\nC4. NutriScore for software libraries\n25\n‚Ä¢ NutriScore labels are not perfect but they are a good starting point! \n‚Ä¢ What if we could do the same thing for the energy efficiency of software. \n‚Ä¢ (Also open to individual or social sustainability) \n‚Ä¢ This work can be scoped in particular domains/ecossystems/use cases. \n‚Ä¢ Libraries for stats? ML? Web Dev? Cloud?\n\nC5. Add energy-awareness to existing software\n26\n‚Ä¢ Streamlit, Notebooks, JSFiddle, \nPyScript, zsh, etc. \n‚Ä¢\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy efficiency using static code analysis. \n‚Ä¢ We don‚Äôt need an accurate value. \n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention. \n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)']","['<1-hop>\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy eÔ¨Éciency using static code analysis.\n‚Ä¢ We don‚Äôt need an accurate value.\n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.\n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27', '<2-hop>\n\nWhy?\n‚Ä¢ Throughout your career you might:\n‚Ä¢ Design/maintain/contract data centers\n‚Ä¢ Set up operations/devops\n‚Ä¢ Develop AI for IoT devices\n‚Ä¢ Be the next CEO/CTO of a software company\n‚Ä¢ Sustainability can be your main role:\n‚Ä¢ Green Software Developer\n‚Ä¢ Sustainability Consultant\n‚Ä¢ Green Advocate \n‚Ä¢ Founder of a Green Tech startup (B2B?)\n28', '<1-hop>\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy eÔ¨Éciency using static code analysis.\n‚Ä¢ We don‚Äôt need an accurate value.\n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.\n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27', '<2-hop>\n\nWhy?\n‚Ä¢ Throughout your career you might:\n‚Ä¢ Design/maintain/contract data centers\n‚Ä¢ Set up operations/devops\n‚Ä¢ Develop AI for IoT devices\n‚Ä¢ Be the next CEO/CTO of a software company\n‚Ä¢ Sustainability can be your main role:\n‚Ä¢ Green Software Developer\n‚Ä¢ Sustainability Consultant\n‚Ä¢ Green Advocate \n‚Ä¢ Founder of a Green Tech startup (B2B?)\n28', '<1-hop>\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy eÔ¨Éciency using static code analysis.\n‚Ä¢ We don‚Äôt need an accurate value.\n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.\n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27', '<2-hop>\n\nWhy?\n‚Ä¢ Throughout your career you might:\n‚Ä¢ Design/maintain/contract data centers\n‚Ä¢ Set up operations/devops\n‚Ä¢ Develop AI for IoT devices\n‚Ä¢ Be the next CEO/CTO of a software company\n‚Ä¢ Sustainability can be your main role:\n‚Ä¢ Green Software Developer\n‚Ä¢ Sustainability Consultant\n‚Ä¢ Green Advocate \n‚Ä¢ Founder of a Green Tech startup (B2B?)\n28', '<1-hop>\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy eÔ¨Éciency using static code analysis.\n‚Ä¢ We don‚Äôt need an accurate value.\n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.\n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27', '<2-hop>\n\nWhy?\n‚Ä¢ Throughout your career you might:\n‚Ä¢ Design/maintain/contract data centers\n‚Ä¢ Set up operations/devops\n‚Ä¢ Develop AI for IoT devices\n‚Ä¢ Be the next CEO/CTO of a software company\n‚Ä¢ Sustainability can be your main role:\n‚Ä¢ Green Software Developer\n‚Ä¢ Sustainability Consultant\n‚Ä¢ Green Advocate \n‚Ä¢ Founder of a Green Tech startup (B2B?)\n28']","Static code analysis in data science can be used to improve the energy efficiency of data centers by identifying code that is likely to introduce energy hotspots. This process involves estimating energy efficiency without needing an exact value, allowing developers to focus on reviewing and optimizing parts of the code that are more likely to consume excessive energy. By targeting these areas, developers can make informed decisions to refactor or optimize code, leading to more energy-efficient software. This approach contributes to sustainable software engineering by reducing the energy consumption of software applications, which in turn can lower the overall energy usage of data centers. This method can be scoped specifically to data science domains, ensuring that the analysis is relevant and effective for the specific types of workloads and computations typical in data science projects.","Static code analysis in data science can be used to estimate energy efficiency by identifying potential energy hotspots in the code. This helps in reviewing and optimizing the code to reduce energy consumption. By applying this approach, developers can contribute to the design and maintenance of more energy-efficient data centers, aligning with sustainable software engineering practices.",0.99999999995,0.6666666666666666,0.7142857142857143,0.89,0.24999999968749997,0.9719459797223058
How can static code analysis in data science contribute to the development of more sustainable data centers?,"['‚Ä¢\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy efficiency using static code analysis. \n‚Ä¢ We don‚Äôt need an accurate value. \n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention. \n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27\n\nC7 - Education\n‚Ä¢ Educational game for Software \nSustainability practices \n‚Ä¢ Purpose: use within software teams to \ndiscuss or learn about different sustainable \nIT practices: at the organisation level, \nsoftware, etc.\n28\nhttps://github.com/OttoKaaij/Ticket-To-Sustainability/?tab=readme-ov-file\n\nProject ideas (old)\n‚Ä¢ Plugin from EnergiBridge (GUI, report generator, python library, etc.) \n‚Ä¢ Plugin for ChatGPT (carbon emissions per chat window) \n‚Ä¢ Seamless measurements for AI libraries \n‚Ä¢ Energy patterns for Green AI \n‚Ä¢ Sustainable SW dev gamification \n‚Ä¢ Sustainability auditor for AI projects \n‚Ä¢ Energy Profiling of screen colour filter tools (or display settings) \n‚Ä¢ ‚Ä¶ you can also propose yours!\n\nhttps://edu.nl/64gpk\nedu.nl/64gpk', 'Carbon-free giants\n‚Ä¢ Google, Microsoft, Meta/Facebook want to be carbon free by 2030 \n‚Ä¢ Carbon free is different from carbon neutral \n‚Ä¢ Green IT experts are needed to meet these goals\n23\n\n\nRebound effect*\n‚Ä¢ Energy consumption decreases ‚Üì‚Üì but demand also increases ‚Üë‚Üë. \n‚Ä¢ *a.k.a. Jevons Paradox in economics; Downs‚ÄìThomson paradox in\xa0mobility.\nEnergy per prompt\nPrompts\n100\n80\n30\n38\nChat \nGPT\n‚ÄúEnergy-efficient‚Äù \nChat GPT\n0\n\nIs sustainability an\u2028\nethical issue?\n‚Ä¢ Climate change is more likely to affect the \npoorest countries. \n‚Ä¢ Less financial resources to adapt \n‚Ä¢ Climate-impact does not necessarily affect \npolluting countries. \n‚Ä¢ Poorest countries have contributed less to the \nclimate change. \n‚Ä¢ We need to figure out how to do more using \nless resources.\n26\n\nMorality ‚â† Moralising\n‚Ä¢ We should not use climate action as a \nshaming weapon \n‚Ä¢ Climate action should be agnostic of political \nviews, ideology, social status, etc. \n‚Ä¢ We need everyone to take action!\n27\n\nWhy?\n‚Ä¢ Throughout your career you might: \n‚Ä¢ Design/maintain/contract data centers \n‚Ä¢ Set up operations/devops \n‚Ä¢ Develop AI for IoT devices \n‚Ä¢ Be the next CEO/CTO of a software company \n‚Ä¢ Sustainability can be your main role: \n‚Ä¢ Green Software Developer \n‚Ä¢ Sustainability Consultant \n‚Ä¢ Green Advocate  \n‚Ä¢ Founder of a Green Tech startup (B2B?)\n28\n\nFormat of classes\n‚Ä¢ In-person. \n‚Ä¢ Collegerama recordings. \n‚Ä¢ Lectures and Labs. \n‚Ä¢ Guest lectures. \n‚Ä¢ Steering meetings (after week 5, new schedule)\n29\n\nFormat of classes\n‚Ä¢ There‚Äôs no exam in this course. It‚Äôs more important that we learn how to \ndiscuss this topic and come up with new ideas than learning all the theory. \nCritical thinking over checkboxes. \n‚Ä¢ Mix of content and discussion \n‚Ä¢ Ultimately, the lectures aim to give you food for thought and the necessary \nknowledge to excel in Project 2.']","['<1-hop>\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy eÔ¨Éciency using static code analysis.\n‚Ä¢ We don‚Äôt need an accurate value.\n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.\n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27', '<2-hop>\n\nWhy?\n‚Ä¢ Throughout your career you might:\n‚Ä¢ Design/maintain/contract data centers\n‚Ä¢ Set up operations/devops\n‚Ä¢ Develop AI for IoT devices\n‚Ä¢ Be the next CEO/CTO of a software company\n‚Ä¢ Sustainability can be your main role:\n‚Ä¢ Green Software Developer\n‚Ä¢ Sustainability Consultant\n‚Ä¢ Green Advocate \n‚Ä¢ Founder of a Green Tech startup (B2B?)\n28']","Static code analysis in data science can contribute to the development of more sustainable data centers by estimating energy efficiency. Although it doesn't provide an accurate value, it helps identify which parts of the code are more likely to introduce energy hotspots. By focusing on these areas, developers can optimize code to reduce energy consumption, thereby contributing to the overall sustainability of data centers. This approach allows for targeted improvements in energy efficiency, which is crucial for reducing the carbon footprint of data centers.","Static code analysis in data science can contribute to the development of more sustainable data centers by estimating energy efficiency and identifying potential energy hotspots within the code. This approach allows developers to focus on reviewing code segments that are more likely to introduce inefficiencies, thereby optimizing resource usage. By integrating such practices, especially in domains like data science, developers can help create more sustainable solutions, which aligns with broader career goals in sustainability, such as designing or maintaining energy-efficient data centers.",0.9999999999,1.0,0.625,0.86,0.2222222219753086,0.9772216761575173
How can static code analysis in data science projects help in designing more sustainablility-focused data centers?,"['data to understand state of software: \nbuildable?, open dev. history?, requirements documentation? \n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!\n\nB7. Queue - but better for the student / TA society\n‚Ä¢ Requirements analysis regarding social and individual sustainability effects \nof Queue \n‚Ä¢ Other EIP / TUD used software also possible: e.g., Answers EWI \n‚Ä¢ Non-technical project ‚Üí proper process (workshops? Interviews?) & rich \ndescription of outcomes focus of grading\nhttps://eip.pages.ewi.tudelft.nl/eip-website/queue.html\n\nC1. Compare energy consumption of docker images for \nML workloads.\n‚Ä¢ Similar to what we have seen in the lectures but for ML-specific workloads. \n‚Ä¢ We can reuse existing experiment replication packages.\n22\n\nC2. Plugin to visualize Hugging Face carbon emissions.\n‚Ä¢ https://huggingface.co/blog/leaderboard-emissions-\nanalysis \n‚Ä¢\nYoo, Taewon, et al. ""Visualizing the Carbon Intensity of Machine Learning Inference for Image Analysis on TensorFlow Hub.""\n\nC3. Plugin for ChatGPT\n‚Ä¢ Users seldom know how much carbon they are emitting when they interact \nwith chat GPT. \n‚Ä¢ Let‚Äôs make it transparent to the users. Browser plugin?\n24\nCO2\n\nC4. NutriScore for software libraries\n25\n‚Ä¢ NutriScore labels are not perfect but they are a good starting point! \n‚Ä¢ What if we could do the same thing for the energy efficiency of software. \n‚Ä¢ (Also open to individual or social sustainability) \n‚Ä¢ This work can be scoped in particular domains/ecossystems/use cases. \n‚Ä¢ Libraries for stats? ML? Web Dev? Cloud?\n\nC5. Add energy-awareness to existing software\n26\n‚Ä¢ Streamlit, Notebooks, JSFiddle, \nPyScript, zsh, etc. \n‚Ä¢\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy efficiency using static code analysis. \n‚Ä¢ We don‚Äôt need an accurate value. \n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention. \n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)', '‚Ä¢\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy efficiency using static code analysis. \n‚Ä¢ We don‚Äôt need an accurate value. \n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention. \n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27\n\nC7 - Education\n‚Ä¢ Educational game for Software \nSustainability practices \n‚Ä¢ Purpose: use within software teams to \ndiscuss or learn about different sustainable \nIT practices: at the organisation level, \nsoftware, etc.\n28\nhttps://github.com/OttoKaaij/Ticket-To-Sustainability/?tab=readme-ov-file\n\nProject ideas (old)\n‚Ä¢ Plugin from EnergiBridge (GUI, report generator, python library, etc.) \n‚Ä¢ Plugin for ChatGPT (carbon emissions per chat window) \n‚Ä¢ Seamless measurements for AI libraries \n‚Ä¢ Energy patterns for Green AI \n‚Ä¢ Sustainable SW dev gamification \n‚Ä¢ Sustainability auditor for AI projects \n‚Ä¢ Energy Profiling of screen colour filter tools (or display settings) \n‚Ä¢ ‚Ä¶ you can also propose yours!\n\nhttps://edu.nl/64gpk\nedu.nl/64gpk']","['<1-hop>\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy eÔ¨Éciency using static code analysis.\n‚Ä¢ We don‚Äôt need an accurate value.\n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.\n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27', '<2-hop>\n\nWhy?\n‚Ä¢ Throughout your career you might:\n‚Ä¢ Design/maintain/contract data centers\n‚Ä¢ Set up operations/devops\n‚Ä¢ Develop AI for IoT devices\n‚Ä¢ Be the next CEO/CTO of a software company\n‚Ä¢ Sustainability can be your main role:\n‚Ä¢ Green Software Developer\n‚Ä¢ Sustainability Consultant\n‚Ä¢ Green Advocate \n‚Ä¢ Founder of a Green Tech startup (B2B?)\n28', '<1-hop>\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy eÔ¨Éciency using static code analysis.\n‚Ä¢ We don‚Äôt need an accurate value.\n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.\n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27', '<2-hop>\n\nWhy?\n‚Ä¢ Throughout your career you might:\n‚Ä¢ Design/maintain/contract data centers\n‚Ä¢ Set up operations/devops\n‚Ä¢ Develop AI for IoT devices\n‚Ä¢ Be the next CEO/CTO of a software company\n‚Ä¢ Sustainability can be your main role:\n‚Ä¢ Green Software Developer\n‚Ä¢ Sustainability Consultant\n‚Ä¢ Green Advocate \n‚Ä¢ Founder of a Green Tech startup (B2B?)\n28', '<1-hop>\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy eÔ¨Éciency using static code analysis.\n‚Ä¢ We don‚Äôt need an accurate value.\n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.\n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27', '<2-hop>\n\nWhy?\n‚Ä¢ Throughout your career you might:\n‚Ä¢ Design/maintain/contract data centers\n‚Ä¢ Set up operations/devops\n‚Ä¢ Develop AI for IoT devices\n‚Ä¢ Be the next CEO/CTO of a software company\n‚Ä¢ Sustainability can be your main role:\n‚Ä¢ Green Software Developer\n‚Ä¢ Sustainability Consultant\n‚Ä¢ Green Advocate \n‚Ä¢ Founder of a Green Tech startup (B2B?)\n28']","Static code analysis in data science projects can help in designing more sustainability-focused data centers by identifying code that is likely to introduce energy hotspots. By analyzing the code statically, developers can estimate energy efficiency and pinpoint areas that may require optimization to reduce energy consumption. This proactive approach allows for more efficient use of resources, leading to reduced energy usage in data centers. By focusing on optimizing code for energy efficiency, data centers can operate more sustainably, minimizing their carbon footprint and overall environmental impact. This process can be scoped to particular domains such as data science, ensuring that the specific needs and characteristics of these projects are taken into account.","Static code analysis in data science projects can help in designing more sustainablility-focused data centers by identifying energy hotspots in the code. This allows developers to review and optimize code that may contribute to higher energy consumption, thereby supporting the development of more efficient and sustainable data centers.",0.99999999995,1.0,0.5555555555555556,1.0,0.0,0.9715101513908625
How does the use of static code analysis in data science projects contribute to the design and optimization of more sustanable data centers?,"['Carbon-free giants\n‚Ä¢ Google, Microsoft, Meta/Facebook want to be carbon free by 2030 \n‚Ä¢ Carbon free is different from carbon neutral \n‚Ä¢ Green IT experts are needed to meet these goals\n23\n\n\nRebound effect*\n‚Ä¢ Energy consumption decreases ‚Üì‚Üì but demand also increases ‚Üë‚Üë. \n‚Ä¢ *a.k.a. Jevons Paradox in economics; Downs‚ÄìThomson paradox in\xa0mobility.\nEnergy per prompt\nPrompts\n100\n80\n30\n38\nChat \nGPT\n‚ÄúEnergy-efficient‚Äù \nChat GPT\n0\n\nIs sustainability an\u2028\nethical issue?\n‚Ä¢ Climate change is more likely to affect the \npoorest countries. \n‚Ä¢ Less financial resources to adapt \n‚Ä¢ Climate-impact does not necessarily affect \npolluting countries. \n‚Ä¢ Poorest countries have contributed less to the \nclimate change. \n‚Ä¢ We need to figure out how to do more using \nless resources.\n26\n\nMorality ‚â† Moralising\n‚Ä¢ We should not use climate action as a \nshaming weapon \n‚Ä¢ Climate action should be agnostic of political \nviews, ideology, social status, etc. \n‚Ä¢ We need everyone to take action!\n27\n\nWhy?\n‚Ä¢ Throughout your career you might: \n‚Ä¢ Design/maintain/contract data centers \n‚Ä¢ Set up operations/devops \n‚Ä¢ Develop AI for IoT devices \n‚Ä¢ Be the next CEO/CTO of a software company \n‚Ä¢ Sustainability can be your main role: \n‚Ä¢ Green Software Developer \n‚Ä¢ Sustainability Consultant \n‚Ä¢ Green Advocate  \n‚Ä¢ Founder of a Green Tech startup (B2B?)\n28\n\nFormat of classes\n‚Ä¢ In-person. \n‚Ä¢ Collegerama recordings. \n‚Ä¢ Lectures and Labs. \n‚Ä¢ Guest lectures. \n‚Ä¢ Steering meetings (after week 5, new schedule)\n29\n\nFormat of classes\n‚Ä¢ There‚Äôs no exam in this course. It‚Äôs more important that we learn how to \ndiscuss this topic and come up with new ideas than learning all the theory. \nCritical thinking over checkboxes. \n‚Ä¢ Mix of content and discussion \n‚Ä¢ Ultimately, the lectures aim to give you food for thought and the necessary \nknowledge to excel in Project 2.', '‚Ä¢\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy efficiency using static code analysis. \n‚Ä¢ We don‚Äôt need an accurate value. \n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention. \n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27\n\nC7 - Education\n‚Ä¢ Educational game for Software \nSustainability practices \n‚Ä¢ Purpose: use within software teams to \ndiscuss or learn about different sustainable \nIT practices: at the organisation level, \nsoftware, etc.\n28\nhttps://github.com/OttoKaaij/Ticket-To-Sustainability/?tab=readme-ov-file\n\nProject ideas (old)\n‚Ä¢ Plugin from EnergiBridge (GUI, report generator, python library, etc.) \n‚Ä¢ Plugin for ChatGPT (carbon emissions per chat window) \n‚Ä¢ Seamless measurements for AI libraries \n‚Ä¢ Energy patterns for Green AI \n‚Ä¢ Sustainable SW dev gamification \n‚Ä¢ Sustainability auditor for AI projects \n‚Ä¢ Energy Profiling of screen colour filter tools (or display settings) \n‚Ä¢ ‚Ä¶ you can also propose yours!\n\nhttps://edu.nl/64gpk\nedu.nl/64gpk']","['<1-hop>\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy eÔ¨Éciency using static code analysis.\n‚Ä¢ We don‚Äôt need an accurate value.\n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.\n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27', '<2-hop>\n\nWhy?\n‚Ä¢ Throughout your career you might:\n‚Ä¢ Design/maintain/contract data centers\n‚Ä¢ Set up operations/devops\n‚Ä¢ Develop AI for IoT devices\n‚Ä¢ Be the next CEO/CTO of a software company\n‚Ä¢ Sustainability can be your main role:\n‚Ä¢ Green Software Developer\n‚Ä¢ Sustainability Consultant\n‚Ä¢ Green Advocate \n‚Ä¢ Founder of a Green Tech startup (B2B?)\n28', '<1-hop>\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy eÔ¨Éciency using static code analysis.\n‚Ä¢ We don‚Äôt need an accurate value.\n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.\n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27', '<2-hop>\n\nWhy?\n‚Ä¢ Throughout your career you might:\n‚Ä¢ Design/maintain/contract data centers\n‚Ä¢ Set up operations/devops\n‚Ä¢ Develop AI for IoT devices\n‚Ä¢ Be the next CEO/CTO of a software company\n‚Ä¢ Sustainability can be your main role:\n‚Ä¢ Green Software Developer\n‚Ä¢ Sustainability Consultant\n‚Ä¢ Green Advocate \n‚Ä¢ Founder of a Green Tech startup (B2B?)\n28']","The use of static code analysis in data science projects helps estimate energy efficiency by identifying code that is likely to introduce energy hotspots. By reviewing and optimizing such code, data centers can reduce energy consumption, contributing to more sustainable operations. This process allows for targeted improvements in energy efficiency without needing precise energy values, thus supporting the design and optimization of more sustainable data centers.","The use of static code analysis in data science projects contributes to the design and optimization of more sustainable data centers by identifying energy hotspots within the code. This process allows developers to focus on reviewing and optimizing sections of code that are more likely to introduce energy inefficiencies. By doing so, it supports the broader goal of creating more energy-efficient systems, which is crucial for the sustainable operation of data centers. This approach aligns with the growing need for green software development practices, where professionals can play roles such as green software developers or sustainability consultants, ensuring that energy efficiency is a key consideration throughout the software lifecycle.",0.49999999995,1.0,0.8333333333333334,0.44,0.0,0.9475599989728102
How reduce risk and reduce size in software engineering?,"['‚Ä¢ Opt for low-power hardware (e.g., Nvidia Jetson boards) \n‚Ä¢ Or GPUs that provide energy metrics (e.g., NVIDIA GPUs via the nvidia-smi tool) \n‚Ä¢ Report energy/carbon metrics (e.g., embed in MLFlow?) \n‚Ä¢ Use pre-trained models (Transfer Learning) \n‚Ä¢ Preprocess dataset to reduce size. \n‚Ä¢ Improve parameter-tuning strategy.\n11\n\nReporting energy/carbon footprint\n‚Ä¢ We need benchmarks. \n‚Ä¢ AllenAI leaderboard\u2028\nhttps://leaderboard.allenai.org \n‚Ä¢ No carbon metrics, yet \n‚Ä¢ Report comparable proxies for energy \nconsumption. \n‚Ä¢ ‚ö† Learning algorithms behave in a non-\ndeterministic \n‚Ä¢ ‚ö† Different data-points lead to different \nenergy consumption\n12\n\nReporting energy/carbon footprint\n‚Ä¢ Reporting measured energy consumption \n‚Ä¢ + Accurate \n‚Ä¢ + Easy to map to carbon emissions \n‚Ä¢ - Hard to measure \n‚Ä¢ - Low replicability \n‚Ä¢ Reporting time / estimation based on time & hardware \n‚Ä¢ + Easy to measure \n‚Ä¢ + Correlates with energy consumption in most cases. \n‚Ä¢ -  Difficult to compare with measurements from other setups \n‚Ä¢ E.g., floating point operations (FPOs) (?) \n‚Ä¢ + comparable across different setups \n‚Ä¢ + cheap \n‚Ä¢ - does not factor in memory energy consumption \n‚Ä¢ - does not reflect carbon emissions\n13\n\nData-centric AI\n\nData-centric AI\n‚Ä¢ Emerging discipline that deals with systematically engineering data to build AI \nsystems. \n‚Ä¢ Shift from improving the training strategy to improving the data. \n‚Ä¢ It is better to have small but reliable datasets than large but noisy \ndatasets. \n‚Ä¢ => Improve data collection, data labelling, and data preprocessing. \n‚Ä¢ More about data-centric AI by Andrew Ng:\u2028\nhttps://www.youtube.com/watch?v=06-AZXmwHjo\n15\n\n\nGreen Data-centric AI\n‚Ä¢ How do different ML algorithms compare \nin terms of energy consumption? \n‚Ä¢ How does number of rows relate to the \nenergy consumption of ML models? \n‚Ä¢ How does number of features relate to \nthe energy consumption of ML models? \n‚Ä¢ What is the impact of reducing data in the \nperformance of the model? \n‚Ä¢ Method -> results -> discussion\n17\n\nMethod\n‚Ä¢ Single object of study: natural language model to detect spam messages.', 'Rest ‚è∏\n‚Ä¢ It is common practice to do a pause/sleep between executions/\nmeasurements. \n‚Ä¢ Prevent tail energy consumption from previous measurements. ? \n‚Ä¢ Prevent collateral tasks of previous measurement from affecting the next \nmeasurement. \n‚Ä¢ There is no golden rule but one minute should be enough. It can be more or \nless depending on your hardware or the duration of your energy test.\n9\n\nt\nP\nTail Energy Consumption\n\nShuffle üîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them. \n‚Ä¢ If you run 30 executions for version A and another batch for version B: \n‚Ä¢ External conditions that change over time will have a different bias in \nthe 2 versions (e.g., room temperature changes). \n‚Ä¢ If you shuffle, you reduce this risk.\n11\n\nKeep it cool üå°\n‚Ä¢ Always make sure there is a stable room temperature. \n‚Ä¢ Tricky because, some times, experiments may have to run over a few days. \n‚Ä¢ If you cannot control room temperature: collect temperature data and filter \nout measurements where the room temperature is clearly deviating.\n12\n\nAutomate Executions ü§ñ\n‚Ä¢ (Already mentioned in the previous classes) \n‚Ä¢ One cannot run 30 shuffled experiments per version without automation‚Ä¶\n13\n\nData analysis\n14\n\n1. Exploratory Analysis\n‚Ä¢ Plot the data and inspect outliers or \nunexpected biases. \n‚Ä¢ Violin+box plots are usually handy. (?) \n‚Ä¢ It‚Äôs a nice way of combining the 30 \nexperiments, and of showing \ndescriptive statistics. (?) \n‚Ä¢ Shows the shape of the distribution \nof the data.\n15\n\n1. Exploratory Analysis (II)\n‚Ä¢ Data should be Normal. Unless there‚Äôs a \ngood reason. \n‚Ä¢ E.g., somewhere amongst the 30 executions, \nthere might be 1 or 2 that failed to finish due \nto some unexpected error. \n‚Ä¢ (It happens and that‚Äôs ok!)‚Äì consequently, \nthe execution is shorter and spends less \nenergy ‚Äì falsely appearing as more \nenergy efficient. \n‚Ä¢ If data is not Normal there might be some \nissues affecting the measurements that \nmight be ruining results. It is important to \ninvestigate this.\n16\n\nEnergy data is not normal. Why?']","['<1-hop>\n\nShuffle \nüîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them.\n‚Ä¢ If you run 30 executions for version A and another batch for version B:\n‚Ä¢ External conditions that change over time will have a diÔ¨Äerent bias in \nthe 2 versions (e.g., room temperature changes).\n‚Ä¢ If you shuÔ¨Ñe, you reduce this risk.\n11', '<2-hop>\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio)\n‚Ä¢ Dynamic Retry Delay\n‚Ä¢ Push Over Poll\n‚Ä¢ Reduce Size\n‚Ä¢ Cache\n‚Ä¢ Avoid Graphics and Animations\n20', '<1-hop>\n\nShuffle \nüîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them.\n‚Ä¢ If you run 30 executions for version A and another batch for version B:\n‚Ä¢ External conditions that change over time will have a diÔ¨Äerent bias in \nthe 2 versions (e.g., room temperature changes).\n‚Ä¢ If you shuÔ¨Ñe, you reduce this risk.\n11', '<2-hop>\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio)\n‚Ä¢ Dynamic Retry Delay\n‚Ä¢ Push Over Poll\n‚Ä¢ Reduce Size\n‚Ä¢ Cache\n‚Ä¢ Avoid Graphics and Animations\n20']","To reduce risk and reduce size in software engineering, consider the following strategies:

1. **Opt for Low-Power Hardware**: Use energy-efficient hardware like Nvidia Jetson boards or GPUs that provide energy metrics, which can help in reducing the energy footprint and potentially the size of the hardware setup.

2. **Use Pre-trained Models (Transfer Learning)**: This approach can reduce the size of the training dataset needed and the computational resources required, thereby minimizing risk and resource consumption.

3. **Preprocess Dataset to Reduce Size**: By preprocessing the dataset, you can eliminate unnecessary data, which reduces the size and complexity of the data, leading to more efficient processing and reduced risk of errors.

4. **Improve Parameter-Tuning Strategy**: Efficient parameter tuning can lead to better model performance with less computational overhead, reducing both risk and resource usage.

5. **Data-Centric AI**: Focus on improving data quality rather than just the training strategy. Reliable, smaller datasets are preferable to large, noisy ones, reducing the risk of errors and inefficiencies.

6. **Automate Executions**: Automation can help manage and reduce the risk of human error in repetitive tasks, ensuring consistency and efficiency.

7. **Shuffle and Control External Conditions**: Shuffling experiments and controlling external conditions like room temperature can help reduce biases and risks associated with environmental factors.

These strategies collectively help in managing risk and reducing the size and complexity of software engineering projects.","To reduce risk, shuffling executions helps control external factors like temperature changes. To reduce size, EcoAndroid uses features like dynamic retry delay and push over poll.",0.0,0.5,0.7647058823529411,0.36,0.0,0.980885315377629
How shuffling reduce risk and EcoAndroid reduce size?,"['Rest ‚è∏\n‚Ä¢ It is common practice to do a pause/sleep between executions/\nmeasurements. \n‚Ä¢ Prevent tail energy consumption from previous measurements. ? \n‚Ä¢ Prevent collateral tasks of previous measurement from affecting the next \nmeasurement. \n‚Ä¢ There is no golden rule but one minute should be enough. It can be more or \nless depending on your hardware or the duration of your energy test.\n9\n\nt\nP\nTail Energy Consumption\n\nShuffle üîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them. \n‚Ä¢ If you run 30 executions for version A and another batch for version B: \n‚Ä¢ External conditions that change over time will have a different bias in \nthe 2 versions (e.g., room temperature changes). \n‚Ä¢ If you shuffle, you reduce this risk.\n11\n\nKeep it cool üå°\n‚Ä¢ Always make sure there is a stable room temperature. \n‚Ä¢ Tricky because, some times, experiments may have to run over a few days. \n‚Ä¢ If you cannot control room temperature: collect temperature data and filter \nout measurements where the room temperature is clearly deviating.\n12\n\nAutomate Executions ü§ñ\n‚Ä¢ (Already mentioned in the previous classes) \n‚Ä¢ One cannot run 30 shuffled experiments per version without automation‚Ä¶\n13\n\nData analysis\n14\n\n1. Exploratory Analysis\n‚Ä¢ Plot the data and inspect outliers or \nunexpected biases. \n‚Ä¢ Violin+box plots are usually handy. (?) \n‚Ä¢ It‚Äôs a nice way of combining the 30 \nexperiments, and of showing \ndescriptive statistics. (?) \n‚Ä¢ Shows the shape of the distribution \nof the data.\n15\n\n1. Exploratory Analysis (II)\n‚Ä¢ Data should be Normal. Unless there‚Äôs a \ngood reason. \n‚Ä¢ E.g., somewhere amongst the 30 executions, \nthere might be 1 or 2 that failed to finish due \nto some unexpected error. \n‚Ä¢ (It happens and that‚Äôs ok!)‚Äì consequently, \nthe execution is shorter and spends less \nenergy ‚Äì falsely appearing as more \nenergy efficient. \n‚Ä¢ If data is not Normal there might be some \nissues affecting the measurements that \nmight be ruining results. It is important to \ninvestigate this.\n16\n\nEnergy data is not normal. Why?', '‚Ä¢ Some users noticed that K-9 mail was spending more energy than usual. üôâ \n‚Ä¢ A user that was having issues with a personal mail server  noticed that K-9 \nmail was the one of the most energy-greedy apps. IMAP IDLE protocol for real-time \nnotifications. \n‚Ä¢ When a connection is not possible, the app automatically retries later. \n‚Ä¢ https://github.com/k9mail/k-9/commit/\n86f3b28f79509d1a4d613eb39f60603e08579ea3\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio) \n‚Ä¢ Dynamic Retry Delay \n‚Ä¢ Push Over Poll \n‚Ä¢ Reduce Size \n‚Ä¢ Cache \n‚Ä¢ Avoid Graphics and Animations\n20\n\nCarbon-Aware Computing for \nDatacenters \nhttps://sites.google.com/view/energy-efficiency-languages\n21\nAna Radovanovic ÃÅ, Ross Koningstein, Ian Schneider, Bokan \nChen, Alexandre Duarte, Binz Roy, Diyue Xiao, Maya \nHaridasan, Patrick Hung, Nick Care, Saurav Talukdar, Eric \nMullen, Kendal Smith, MariEllen Cottman, and Walfredo Cirne \n\n\n‚Ä¢ Google‚Äôs Carbon-Intelligent Computing System (CICS) \n‚Ä¢ Main idea: use carbon-intensity data to shift datacenter jobs in time \n‚Ä¢ Typically, job schedulers use a metric of cluster capacity to schedule a job in \na particular cluster. \n‚Ä¢ CICS overrides this metric with the virtual capacity curve (VCC) that \nfactors in Carbon intensity \n‚Ä¢ When a new job comes in, the scheduler estimates its CPU load and power \nusage and assigns it to a cluster if the VCC is not exceeded.\n23\n\n‚Ä¢ Jobs are divided between flexible and inflexible. \n‚Ä¢ Flexible load is considered shapeable/shiftable as long as its total daily \ncompute (CPU) demand is preserved \n‚Ä¢ The system needs to consider that, while running a job, the virtual capacity \ncurve (VCC) might drop. Hence, this job should not start in the first place. \n‚Ä¢ They forecast VCC for the next day\n24\n\n\nVirtual Cluster Capacity (VCC)\n‚Ä¢ Aims at reducing the peak load at carbon intensive hours but in total it should allow for the \nsome amount of daily computation!']","['<1-hop>\n\nShuffle \nüîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them.\n‚Ä¢ If you run 30 executions for version A and another batch for version B:\n‚Ä¢ External conditions that change over time will have a diÔ¨Äerent bias in \nthe 2 versions (e.g., room temperature changes).\n‚Ä¢ If you shuÔ¨Ñe, you reduce this risk.\n11', '<2-hop>\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio)\n‚Ä¢ Dynamic Retry Delay\n‚Ä¢ Push Over Poll\n‚Ä¢ Reduce Size\n‚Ä¢ Cache\n‚Ä¢ Avoid Graphics and Animations\n20', '<1-hop>\n\nShuffle \nüîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them.\n‚Ä¢ If you run 30 executions for version A and another batch for version B:\n‚Ä¢ External conditions that change over time will have a diÔ¨Äerent bias in \nthe 2 versions (e.g., room temperature changes).\n‚Ä¢ If you shuÔ¨Ñe, you reduce this risk.\n11', '<2-hop>\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio)\n‚Ä¢ Dynamic Retry Delay\n‚Ä¢ Push Over Poll\n‚Ä¢ Reduce Size\n‚Ä¢ Cache\n‚Ä¢ Avoid Graphics and Animations\n20', '<1-hop>\n\nShuffle \nüîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them.\n‚Ä¢ If you run 30 executions for version A and another batch for version B:\n‚Ä¢ External conditions that change over time will have a diÔ¨Äerent bias in \nthe 2 versions (e.g., room temperature changes).\n‚Ä¢ If you shuÔ¨Ñe, you reduce this risk.\n11', '<2-hop>\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio)\n‚Ä¢ Dynamic Retry Delay\n‚Ä¢ Push Over Poll\n‚Ä¢ Reduce Size\n‚Ä¢ Cache\n‚Ä¢ Avoid Graphics and Animations\n20']","Shuffling reduces risk by minimizing the impact of external conditions that can change over time, such as room temperature, which might introduce bias into the results of different versions of an experiment. By shuffling the order of executions, you ensure that these external factors are more evenly distributed across all versions, thus reducing the risk of skewed results (Source: Shuffle üîÄ).

EcoAndroid reduces size by implementing strategies such as dynamic retry delay, push over poll, and caching, which help to optimize the app's operations and reduce unnecessary resource usage, thereby reducing the overall size and energy consumption of the app (Source: EcoAndroid).",Shuffling reduce risk by controlling external factors like room temperature changes. EcoAndroid reduce size by using features like caching and avoiding graphics and animations.,0.0,1.0,0.6363636363636364,0.33,0.16666666638888888,0.9795435762741264
How shuffling reduce risk when compare to EcoAndroid reduce size?,"['Rest ‚è∏\n‚Ä¢ It is common practice to do a pause/sleep between executions/\nmeasurements. \n‚Ä¢ Prevent tail energy consumption from previous measurements. ? \n‚Ä¢ Prevent collateral tasks of previous measurement from affecting the next \nmeasurement. \n‚Ä¢ There is no golden rule but one minute should be enough. It can be more or \nless depending on your hardware or the duration of your energy test.\n9\n\nt\nP\nTail Energy Consumption\n\nShuffle üîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them. \n‚Ä¢ If you run 30 executions for version A and another batch for version B: \n‚Ä¢ External conditions that change over time will have a different bias in \nthe 2 versions (e.g., room temperature changes). \n‚Ä¢ If you shuffle, you reduce this risk.\n11\n\nKeep it cool üå°\n‚Ä¢ Always make sure there is a stable room temperature. \n‚Ä¢ Tricky because, some times, experiments may have to run over a few days. \n‚Ä¢ If you cannot control room temperature: collect temperature data and filter \nout measurements where the room temperature is clearly deviating.\n12\n\nAutomate Executions ü§ñ\n‚Ä¢ (Already mentioned in the previous classes) \n‚Ä¢ One cannot run 30 shuffled experiments per version without automation‚Ä¶\n13\n\nData analysis\n14\n\n1. Exploratory Analysis\n‚Ä¢ Plot the data and inspect outliers or \nunexpected biases. \n‚Ä¢ Violin+box plots are usually handy. (?) \n‚Ä¢ It‚Äôs a nice way of combining the 30 \nexperiments, and of showing \ndescriptive statistics. (?) \n‚Ä¢ Shows the shape of the distribution \nof the data.\n15\n\n1. Exploratory Analysis (II)\n‚Ä¢ Data should be Normal. Unless there‚Äôs a \ngood reason. \n‚Ä¢ E.g., somewhere amongst the 30 executions, \nthere might be 1 or 2 that failed to finish due \nto some unexpected error. \n‚Ä¢ (It happens and that‚Äôs ok!)‚Äì consequently, \nthe execution is shorter and spends less \nenergy ‚Äì falsely appearing as more \nenergy efficient. \n‚Ä¢ If data is not Normal there might be some \nissues affecting the measurements that \nmight be ruining results. It is important to \ninvestigate this.\n16\n\nEnergy data is not normal. Why?', '‚Ä¢ Some users noticed that K-9 mail was spending more energy than usual. üôâ \n‚Ä¢ A user that was having issues with a personal mail server  noticed that K-9 \nmail was the one of the most energy-greedy apps. IMAP IDLE protocol for real-time \nnotifications. \n‚Ä¢ When a connection is not possible, the app automatically retries later. \n‚Ä¢ https://github.com/k9mail/k-9/commit/\n86f3b28f79509d1a4d613eb39f60603e08579ea3\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio) \n‚Ä¢ Dynamic Retry Delay \n‚Ä¢ Push Over Poll \n‚Ä¢ Reduce Size \n‚Ä¢ Cache \n‚Ä¢ Avoid Graphics and Animations\n20\n\nCarbon-Aware Computing for \nDatacenters \nhttps://sites.google.com/view/energy-efficiency-languages\n21\nAna Radovanovic ÃÅ, Ross Koningstein, Ian Schneider, Bokan \nChen, Alexandre Duarte, Binz Roy, Diyue Xiao, Maya \nHaridasan, Patrick Hung, Nick Care, Saurav Talukdar, Eric \nMullen, Kendal Smith, MariEllen Cottman, and Walfredo Cirne \n\n\n‚Ä¢ Google‚Äôs Carbon-Intelligent Computing System (CICS) \n‚Ä¢ Main idea: use carbon-intensity data to shift datacenter jobs in time \n‚Ä¢ Typically, job schedulers use a metric of cluster capacity to schedule a job in \na particular cluster. \n‚Ä¢ CICS overrides this metric with the virtual capacity curve (VCC) that \nfactors in Carbon intensity \n‚Ä¢ When a new job comes in, the scheduler estimates its CPU load and power \nusage and assigns it to a cluster if the VCC is not exceeded.\n23\n\n‚Ä¢ Jobs are divided between flexible and inflexible. \n‚Ä¢ Flexible load is considered shapeable/shiftable as long as its total daily \ncompute (CPU) demand is preserved \n‚Ä¢ The system needs to consider that, while running a job, the virtual capacity \ncurve (VCC) might drop. Hence, this job should not start in the first place. \n‚Ä¢ They forecast VCC for the next day\n24\n\n\nVirtual Cluster Capacity (VCC)\n‚Ä¢ Aims at reducing the peak load at carbon intensive hours but in total it should allow for the \nsome amount of daily computation!']","['<1-hop>\n\nShuffle \nüîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them.\n‚Ä¢ If you run 30 executions for version A and another batch for version B:\n‚Ä¢ External conditions that change over time will have a diÔ¨Äerent bias in \nthe 2 versions (e.g., room temperature changes).\n‚Ä¢ If you shuÔ¨Ñe, you reduce this risk.\n11', '<2-hop>\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio)\n‚Ä¢ Dynamic Retry Delay\n‚Ä¢ Push Over Poll\n‚Ä¢ Reduce Size\n‚Ä¢ Cache\n‚Ä¢ Avoid Graphics and Animations\n20']","Shuffling reduces risk by minimizing the impact of external conditions that change over time, such as room temperature, which can introduce bias in energy consumption measurements when comparing different versions of software. By shuffling the order of executions, you ensure that these external factors affect both versions more evenly, thus reducing the risk of biased results.

On the other hand, EcoAndroid's approach to reducing size is focused on optimizing the app itself to consume less energy. This involves techniques like dynamic retry delay, push over poll, and caching, which directly aim to make the app more energy-efficient.

In summary, shuffling is a method to ensure fair comparison by controlling external variables, while reducing size in EcoAndroid is a direct optimization strategy to lower energy consumption.",Shuffling reduce risk by balance external factor like room temperature change while EcoAndroid reduce size by optimize resource use.,0.0,1.0,0.7,0.67,0.3333333322222222,0.9309882018337486
How shuffling reduce risk when reduce size in software engineering?,"['Rest ‚è∏\n‚Ä¢ It is common practice to do a pause/sleep between executions/\nmeasurements. \n‚Ä¢ Prevent tail energy consumption from previous measurements. ? \n‚Ä¢ Prevent collateral tasks of previous measurement from affecting the next \nmeasurement. \n‚Ä¢ There is no golden rule but one minute should be enough. It can be more or \nless depending on your hardware or the duration of your energy test.\n9\n\nt\nP\nTail Energy Consumption\n\nShuffle üîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them. \n‚Ä¢ If you run 30 executions for version A and another batch for version B: \n‚Ä¢ External conditions that change over time will have a different bias in \nthe 2 versions (e.g., room temperature changes). \n‚Ä¢ If you shuffle, you reduce this risk.\n11\n\nKeep it cool üå°\n‚Ä¢ Always make sure there is a stable room temperature. \n‚Ä¢ Tricky because, some times, experiments may have to run over a few days. \n‚Ä¢ If you cannot control room temperature: collect temperature data and filter \nout measurements where the room temperature is clearly deviating.\n12\n\nAutomate Executions ü§ñ\n‚Ä¢ (Already mentioned in the previous classes) \n‚Ä¢ One cannot run 30 shuffled experiments per version without automation‚Ä¶\n13\n\nData analysis\n14\n\n1. Exploratory Analysis\n‚Ä¢ Plot the data and inspect outliers or \nunexpected biases. \n‚Ä¢ Violin+box plots are usually handy. (?) \n‚Ä¢ It‚Äôs a nice way of combining the 30 \nexperiments, and of showing \ndescriptive statistics. (?) \n‚Ä¢ Shows the shape of the distribution \nof the data.\n15\n\n1. Exploratory Analysis (II)\n‚Ä¢ Data should be Normal. Unless there‚Äôs a \ngood reason. \n‚Ä¢ E.g., somewhere amongst the 30 executions, \nthere might be 1 or 2 that failed to finish due \nto some unexpected error. \n‚Ä¢ (It happens and that‚Äôs ok!)‚Äì consequently, \nthe execution is shorter and spends less \nenergy ‚Äì falsely appearing as more \nenergy efficient. \n‚Ä¢ If data is not Normal there might be some \nissues affecting the measurements that \nmight be ruining results. It is important to \ninvestigate this.\n16\n\nEnergy data is not normal. Why?', '‚Ä¢ Opt for low-power hardware (e.g., Nvidia Jetson boards) \n‚Ä¢ Or GPUs that provide energy metrics (e.g., NVIDIA GPUs via the nvidia-smi tool) \n‚Ä¢ Report energy/carbon metrics (e.g., embed in MLFlow?) \n‚Ä¢ Use pre-trained models (Transfer Learning) \n‚Ä¢ Preprocess dataset to reduce size. \n‚Ä¢ Improve parameter-tuning strategy.\n11\n\nReporting energy/carbon footprint\n‚Ä¢ We need benchmarks. \n‚Ä¢ AllenAI leaderboard\u2028\nhttps://leaderboard.allenai.org \n‚Ä¢ No carbon metrics, yet \n‚Ä¢ Report comparable proxies for energy \nconsumption. \n‚Ä¢ ‚ö† Learning algorithms behave in a non-\ndeterministic \n‚Ä¢ ‚ö† Different data-points lead to different \nenergy consumption\n12\n\nReporting energy/carbon footprint\n‚Ä¢ Reporting measured energy consumption \n‚Ä¢ + Accurate \n‚Ä¢ + Easy to map to carbon emissions \n‚Ä¢ - Hard to measure \n‚Ä¢ - Low replicability \n‚Ä¢ Reporting time / estimation based on time & hardware \n‚Ä¢ + Easy to measure \n‚Ä¢ + Correlates with energy consumption in most cases. \n‚Ä¢ -  Difficult to compare with measurements from other setups \n‚Ä¢ E.g., floating point operations (FPOs) (?) \n‚Ä¢ + comparable across different setups \n‚Ä¢ + cheap \n‚Ä¢ - does not factor in memory energy consumption \n‚Ä¢ - does not reflect carbon emissions\n13\n\nData-centric AI\n\nData-centric AI\n‚Ä¢ Emerging discipline that deals with systematically engineering data to build AI \nsystems. \n‚Ä¢ Shift from improving the training strategy to improving the data. \n‚Ä¢ It is better to have small but reliable datasets than large but noisy \ndatasets. \n‚Ä¢ => Improve data collection, data labelling, and data preprocessing. \n‚Ä¢ More about data-centric AI by Andrew Ng:\u2028\nhttps://www.youtube.com/watch?v=06-AZXmwHjo\n15\n\n\nGreen Data-centric AI\n‚Ä¢ How do different ML algorithms compare \nin terms of energy consumption? \n‚Ä¢ How does number of rows relate to the \nenergy consumption of ML models? \n‚Ä¢ How does number of features relate to \nthe energy consumption of ML models? \n‚Ä¢ What is the impact of reducing data in the \nperformance of the model? \n‚Ä¢ Method -> results -> discussion\n17\n\nMethod\n‚Ä¢ Single object of study: natural language model to detect spam messages.']","['<1-hop>\n\nShuffle \nüîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them.\n‚Ä¢ If you run 30 executions for version A and another batch for version B:\n‚Ä¢ External conditions that change over time will have a diÔ¨Äerent bias in \nthe 2 versions (e.g., room temperature changes).\n‚Ä¢ If you shuÔ¨Ñe, you reduce this risk.\n11', '<2-hop>\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio)\n‚Ä¢ Dynamic Retry Delay\n‚Ä¢ Push Over Poll\n‚Ä¢ Reduce Size\n‚Ä¢ Cache\n‚Ä¢ Avoid Graphics and Animations\n20', '<1-hop>\n\nShuffle \nüîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them.\n‚Ä¢ If you run 30 executions for version A and another batch for version B:\n‚Ä¢ External conditions that change over time will have a diÔ¨Äerent bias in \nthe 2 versions (e.g., room temperature changes).\n‚Ä¢ If you shuÔ¨Ñe, you reduce this risk.\n11', '<2-hop>\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio)\n‚Ä¢ Dynamic Retry Delay\n‚Ä¢ Push Over Poll\n‚Ä¢ Reduce Size\n‚Ä¢ Cache\n‚Ä¢ Avoid Graphics and Animations\n20']","Shuffling reduces risk in software engineering experiments by minimizing the bias introduced by external conditions that change over time. For example, if you run multiple executions for different versions of a software, external factors like room temperature can vary and affect the results. By shuffling the order of these executions, you reduce the likelihood that these external factors will consistently bias one version over another, leading to more reliable and unbiased results.","Shuffling reduce risk by controlling external factors like room temperature changes, which help in reducing size in software engineering.",0.0,0.0,0.8333333333333334,0.8,0.0,0.9423859203931491
How spiking neural networks relate to McCulloch-Pitts model?,"[""Neuromorphic computing\nCS4575\nSustainable Software Engineering\n05.03.2025\nNergis T√∂men\n\nIntroduction\nComputer Vision Lab\nBiomorphic Intelligence Lab\nBiomedical Intervention Optimisation Lab\nNergis\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing\n\nHow many of you are familiar \nwith neural networks?\n\nSimple model of an artificial neuron\nhttps://medium.com/@cprasenjit32/perceptron-a-simple-yet-mighty-machine-learning-algorithm-9ff6b7d86a71\n\nWhat is a neural network?\nhttps://www.tibco.com/reference-center/what-is-a-neural-network\n\nWhy is it called a 'neural network'?\nhttps://www.tibco.com/reference-center/what-is-a-neural-network\n\nWhat is a neural network?\nWhy is it called a 'neural network'?\nMcCulloch-Pitts neuron [1, 2] (1943)\nWarren Sturgis McCulloch\n(Neurophysiologist)\nWalter Pitts\n(Logician)\n\nHow do biological neurons work?\nhttps://commons.wikimedia.org/wiki/File:Coincidence_detection_in_dendrites_of_pyramidal_neurons.gif\n'Input current' travels down the dendrites (top),\nget integrated (summed!) in the cell body\nwhich generates an 'output current' (bottom)\nwhich is chemically transmitted to the dendrites of \nother neurons.\n\nSimplified picture\nReal neuron\nArtificial neuron\nhttps://vajiramandravi.com/quest-upsc-notes/artificial-neural-network/\n\nWhat is a neural network?\nMcCulloch-Pitts neuron [1, 2]\n1940s: How do biological neurons compute basic \nlogic functions? (e.g. logic gates)\nNote: Ref. [3] gives a nice brief history on the ideas which lead to the \nMcCulloch-Pitts neuron.\n\nWhat is a neural network?"", 'How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \n(not publicly available) doi:10.1037/h0042519\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience.']","[""<1-hop>\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant"", '<2-hop>\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \n(not publicly available) doi:10.1037/h0042519\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568', ""<1-hop>\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant"", '<2-hop>\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \n(not publicly available) doi:10.1037/h0042519\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568', ""<1-hop>\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant"", '<2-hop>\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \n(not publicly available) doi:10.1037/h0042519\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568']","The McCulloch-Pitts model, developed in the 1940s, is one of the earliest models of artificial neurons, designed to compute basic logic functions. It represents neurons as simple binary threshold units that output a signal if the sum of their weighted inputs exceeds a certain threshold.

Spiking neural networks (SNNs), on the other hand, are a more advanced and biologically realistic model of neural networks. They incorporate the concept of time into the neural processing, where neurons communicate by sending discrete spikes at particular points in time, rather than continuous values. This allows SNNs to capture the temporal dynamics of biological neural systems more accurately.

While the McCulloch-Pitts model laid the groundwork for understanding how neurons could perform logical operations, spiking neural networks extend this by modeling the timing of spikes, which is crucial for understanding more complex neural processes. Thus, SNNs can be seen as an evolution of the ideas introduced by the McCulloch-Pitts model, incorporating more biological realism.","Spiking neural networks relate to the McCulloch-Pitts model by building upon the foundational concepts of neural computation, where the McCulloch-Pitts model introduced the idea of binary neuron states, which is extended in spiking networks to model more complex information processing through spike timing and patterns.",0.49999999995,1.0,1.0,0.94,0.0,0.9323392780262315
How spiking neural networks used in encoding strategies?,"[""ANN: Perceptron, threshold activation function:\n\nHow to model spiking neurons?\nANN: Perceptron, threshold activation function:\n\nHow to model spiking neurons?\nSpiking neural network (SNN): The 'input current' Œµ(t) is integrated over time.\nspike\n\nHow to model spiking neurons?\nEquivalence to perceptron: Computation at least as complex as a perceptron.\n\nNon-leaky integrate-and-fire (IF) neuron\nThe temporal profile of the input current Œµ(t) can be chosen differently, for different computations.\n\nQuestions?\n\nComputation with spiking neurons\nCoincidence detection\n\nComputation with spiking neurons\nCoincidence detection\nx, y ‚àà {0, 1}n\nExample: n = 2\ninput = \nx1\nx2\ny1\ny2\n= \n0\n1\n1\n1\noutput? \n\nCoincidence detection\nComputation with spiking neurons\n\nCoincidence detection\nCan be trivially computed with a single spiking neuron! Requires at least n/log(n+1) hidden \nunits for a perceptron (proof in [7]).\nComputation with spiking neurons\n\nCoincidence detection\nCan be trivially computed with a single spiking neuron! Requires at least n/log(n+1) hidden \nunits for a perceptron (proof in [7]).\nBrains are energy efficient: \n1.\nHigh temporal resolution (more computation with less neurons)\nComputation with spiking neurons\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant\n\nFiring rates\nClassical view of the brain:\n- Each neuron is selective for one specific \nfeature in the input.\n- Higher firing rate (spikes per unit time) for \n'selected' feature.\nAdapted from Hubel & Wiesel, 1959\n\nFiring rates\nClassical view of the brain:\n- Each neuron is selective for one specific \nfeature in the input.\n- Higher firing rate (spikes per unit time) for \n'selected' feature."", ""- Higher firing rate (spikes per unit time) for \n'selected' feature.\nAdapted from Hubel & Wiesel, 1959\n\nFiring rates\nClassical view of the brain:\n- Each neuron is selective for one specific \nfeature in the input.\n- Higher firing rate (spikes per unit time) for \n'selected' feature.\n- Link to modern ANNs: The scalar output of \nan artificial neuron is interpreted as the firing \nrate.\nAdapted from Hubel & Wiesel, 1959\n\nFiring rates\nClassical view of the brain:\n- Each neuron is selective for one specific \nfeature in the input.\n- Higher firing rate (spikes per unit time) for \n'selected' feature.\n- Link to modern ANNs: The scalar output of \nan artificial neuron is interpreted as the firing \nrate.\nAdapted from Hubel & Wiesel, 1959\nBut rate coding is inefficient and slow‚Ä¶\n(i.e. each neuron needs to fire many spikes to get good precision)\nboth in vivo and in silico.\n\nDifferent encoding strategies with spiking neurons [8]\n7 neurons\n7 time bins\n\nDifferent encoding strategies with spiking neurons\n7 neurons\n7 time bins\nn\n6\n(in the general \ncase a \nnumber \nbetween 0-7)\n\nDifferent encoding strategies with spiking neurons\n7 neurons\n7 time bins\nn\nTotal spike \ncount can \nencode 3 bits.\n\nDifferent encoding strategies with spiking neurons\n7 neurons\n7 time bins\nIndividual rates \ncan encode 7 \nbits.\n\nDifferent encoding strategies with spiking neurons\n7 neurons\n7 time bins\nLatency can \nencode ~3*7 or \n~19 bits.\n\nDifferent encoding strategies with spiking neurons\n7 neurons\n7 time bins\nRank order can \nencode ~12 bits.\n\nDifferent encoding strategies with spiking neurons\n\nDifferent encoding strategies with spiking neurons\nUsing latency or spatio-temporal codes\nour encoding is faster and more spike-efficient (sparser)!\n\nDifferent encoding strategies with spiking neurons\nUsing latency or spatio-temporal codes\nour encoding is faster and more spike-efficient (sparser)!\nQuestions?\n\nNeuromorphic computing\nWhat is the advantage for applications?\n-\nLess spikes = less energy consumption in specialized neuromorphic hardware\n(e.g.""]","[""<1-hop>\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant"", '<2-hop>\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \n(not publicly available) doi:10.1037/h0042519\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568']","Spiking neural networks (SNNs) use various encoding strategies to efficiently represent information. These strategies include:

1. **Firing Rates**: Each neuron is selective for a specific feature, and a higher firing rate (spikes per unit time) indicates the presence of that feature. However, this method is considered inefficient and slow because it requires many spikes to achieve good precision.

2. **Total Spike Count**: This method can encode information by counting the total number of spikes, which can represent multiple bits of information.

3. **Individual Rates**: By considering the firing rates of individual neurons, more bits of information can be encoded.

4. **Latency**: The timing of spikes (latency) can encode a significant amount of information, making it a fast and efficient encoding strategy.

5. **Rank Order**: The order in which neurons fire can also encode information, allowing for a compact representation.

Using latency or spatio-temporal codes, SNNs achieve faster and more spike-efficient encoding, which is beneficial for reducing energy consumption in neuromorphic computing applications.",Spiking neural networks use single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0) to encode information about 'features' in a large network with many spikes. This approach is supported by foundational works such as McCulloch and Pitts' logical calculus of nervous activity and later developments in spiking neuron models.,0.0,0.5,1.0,0.14,0.0,0.94038048033994
What are the benefits of neuromorphic computing in the context of green software practices?,"[""Neuromorphic computing\nCS4575\nSustainable Software Engineering\n05.03.2025\nNergis T√∂men\n\nIntroduction\nComputer Vision Lab\nBiomorphic Intelligence Lab\nBiomedical Intervention Optimisation Lab\nNergis\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing\n\nHow many of you are familiar \nwith neural networks?\n\nSimple model of an artificial neuron\nhttps://medium.com/@cprasenjit32/perceptron-a-simple-yet-mighty-machine-learning-algorithm-9ff6b7d86a71\n\nWhat is a neural network?\nhttps://www.tibco.com/reference-center/what-is-a-neural-network\n\nWhy is it called a 'neural network'?\nhttps://www.tibco.com/reference-center/what-is-a-neural-network\n\nWhat is a neural network?\nWhy is it called a 'neural network'?\nMcCulloch-Pitts neuron [1, 2] (1943)\nWarren Sturgis McCulloch\n(Neurophysiologist)\nWalter Pitts\n(Logician)\n\nHow do biological neurons work?\nhttps://commons.wikimedia.org/wiki/File:Coincidence_detection_in_dendrites_of_pyramidal_neurons.gif\n'Input current' travels down the dendrites (top),\nget integrated (summed!) in the cell body\nwhich generates an 'output current' (bottom)\nwhich is chemically transmitted to the dendrites of \nother neurons.\n\nSimplified picture\nReal neuron\nArtificial neuron\nhttps://vajiramandravi.com/quest-upsc-notes/artificial-neural-network/\n\nWhat is a neural network?\nMcCulloch-Pitts neuron [1, 2]\n1940s: How do biological neurons compute basic \nlogic functions? (e.g. logic gates)\nNote: Ref. [3] gives a nice brief history on the ideas which lead to the \nMcCulloch-Pitts neuron.\n\nWhat is a neural network?"", 'McCulloch-Pitts neuron [1, 2]\n1940s: How do biological neurons compute basic \nlogic functions? (e.g. logic gates)\nNote: Ref. [3] gives a nice brief history on the ideas which lead to the \nMcCulloch-Pitts neuron.\n\nWhat is a neural network?\n1950s: How are neurons organized to perform \nsensory perception?\n\nWhat is a neural network?\n1950s: How are neurons organized to perform \nsensory perception?\nThe first ""neural network"": Perceptron (1958). [4]\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\nFrank Rosenblatt (Psychologist)\nwith a Mark I Perceptron computer in 1960\n\nWhat is a neural network?\n1950s: How are neurons organized to perform \nsensory perception?\nThe first ""neural network"": Perceptron (1958). [4]\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\nFrank Rosenblatt (Psychologist)\nwith a Mark I Perceptron computer in 1960\nPower-efficient\n\nNeuromorphic computing\nWhy neuromorphic computing?\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\n\nNeuromorphic computing\nWhy neuromorphic computing?\n‚ÄòBiological inspiration‚Äô for artificial neural networks (ANNs) is not a new idea.\nEmulation (as opposed to simulation) of neural networks in hardware is not a new idea.\nQuestion: What can we gain from increasing biological realism in existing neural networks?\n\nPower-efficiency at scale\nModern, deep neural networks*\nare trained using GPUs.\n* It is estimated that ChatGPT was trained on \n10,000-20,000 GPUs and that it will require\n30,000 GPUs to keep running stably in the future.\n* It is estimated that ChatGPT has 10-20 billion \nparameters.']","['<1-hop>\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing', '<2-hop>\n\nReading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.', '<1-hop>\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing', '<2-hop>\n\nReading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.', '<1-hop>\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing', '<2-hop>\n\nReading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.']","Neuromorphic computing offers benefits in the context of green software practices primarily through its power-efficiency at scale. Neuromorphic systems use physical artificial neurons to perform computations, which can be more energy-efficient compared to traditional computing systems, especially those using GPUs for training modern, deep neural networks. This efficiency can lead to reduced energy consumption and lower carbon footprints, aligning with the goals of sustainable software engineering.","Neuromorphic computing offers several benefits in the context of green software practices. It is inspired by the structure and function of the human brain, making it highly energy-efficient compared to traditional computing methods. This efficiency is particularly relevant for sustainable software development, as it reduces the environmental impact of computing systems. Additionally, neuromorphic systems can process information in a way that mimics biological neural networks, which can lead to more efficient and sustainable computing solutions. These aspects make neuromorphic computing a promising approach for developers looking to implement green software practices.",0.49999999995,1.0,0.75,0.57,0.12499999984374999,0.9742565367564061
What are the challenges in creating a dataset of government-developed OS software?,"['Study test generation energy consumption\n‚Ä¢ Automatic test generation mainly focuses on making strong test suites \n‚Ä¢ Do different techniques and configurations impact the energy consumption \nduring generation? \n‚Ä¢ Preferably focus on non-LLM test generation methods (EvoSuite, Pyguin, \nDSpot)\n\nB3. Detailed energy profiling of build pipelines\n‚Ä¢ Automatic builds have become a cornerstone of quality assurance. But how \nmuch energy do they even consume? \n‚Ä¢ Create a tool that reports on the energy consumed during the (different stages \nof the) whole build (compile, build, test, package, ‚Ä¶) \n‚Ä¢ Should be integrated with build system(s), making setup for developers easy \n‚Ä¢ For local setup (to enable true energy measurements)\n\nB4. Energy profiling of static analysis tools\n‚Ä¢ What is the energy consumption of a ""typical run"" for a few OSS projects? \n‚Ä¢ Does the type of analysis matter? Are certain analysis more expensive? Does \nthe number of rules that are activated in a static analysis tool important for the \nenergy consumption? \n‚Ä¢ Differences between static analysis tools [lower priority]\n\nB5. Tool supporting SusAF workshop / process\n‚Ä¢ Lead engineers through process & questions \n‚Ä¢ Interface to create & document the two diagrams \n‚Ä¢ (!) Should be easy to start using & set up \n‚Ä¢ You may also create a simplified version / \u2028\nyour favorite sustainability framework\nEnvironmental\nEconomic\nTechnical\nIndividual\nSocial\nImmediate\nEnabling\nStructural\nAirbnb\ngreater \nearnings\nincrease \nin rents\ngentrification\ngreater racial \ndisparities\nrent \nrooms\n5\n1\n3\n4\n2\n \n \n \n \n \n \nVery \nunlikely \nVery \nlikely \n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise \n‚Ä¢ But studying government software is difficult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers \n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation? \n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!\n\nB7.', '‚Ä¢ Deadline April 4.\n6\n\nStrategy\n‚Ä¢ Week 0 \n‚Ä¢ Decide project idea (today) \n‚Ä¢ Define steering meeting schedule \n‚Ä¢ Create working document of the \narticle: Problem statement and solution \nproposal! \n‚Ä¢ Define and assign tasks for each week. \n‚Ä¢ Week 1 \n‚Ä¢ Implementation \n‚Ä¢ Agreements with supervisor. \n‚Ä¢ Week 2 \n‚Ä¢ Implementation \n‚Ä¢ Week 3 \n‚Ä¢ Implementation, Full draft of article, \ndissemination. \n‚Ä¢ Week 4 \n‚Ä¢ Final refinements \n‚Ä¢ Prepare presentation\n7\n\nProject ideas\n‚Ä¢ A1. Prototype cross-machine comparable benchmarks \n‚Ä¢ A2. Add energy metrics to LMstudio/Ollama \n‚Ä¢ A3. Visualizations built-in with EnergiBridge \n‚Ä¢ A4. Service-based version of EnergiBridge\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption \n‚Ä¢ B3. Energy profiling of static analysis tools \n‚Ä¢ B4. Detailed energy profiling of build pipelines \n‚Ä¢ B5. Tool supporting SusAF workshop / process \n‚Ä¢ B6. Dataset of government-developed OS software \n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability\n\nProject ideas\n‚Ä¢ C1. Compare energy consumption of docker images for ML workloads. \n‚Ä¢ C2. Create a plugin to visualize Hugging Face carbon emissions in detail. \n‚Ä¢ C3. Plugin for ChatGPT (footprint per chat window) \n‚Ä¢ C4. NutriScore for software libraries. \n‚Ä¢ C5. Add energy-awareness to existing software \n‚Ä¢ C6. Green Shift Left \n‚Ä¢ C7. Education for Sustainable SE\n\nA1. Prototype cross-machine comparable benchmarks\n‚Ä¢ Energy-usage comparisons require running both baseline + software on the \nsame machine ‚Üí limits how extensive our experiments can be \n‚Ä¢ Research community is in need of benchmarks that make energy \nmeasurements comparable even if executed on different machines \n‚Ä¢ Focus on a single task or model (i.e. computing vision, classification)\n\nA2.']","['<1-hop>\n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise\n‚Ä¢ But studying government software is diÔ¨Écult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation?\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!', '<2-hop>\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption\n‚Ä¢ B3. Energy proÔ¨Åling of static analysis tools\n‚Ä¢ B4. Detailed energy proÔ¨Åling of build pipelines\n‚Ä¢ B5. Tool supporting SusAF workshop / process\n‚Ä¢ B6. Dataset of government-developed OS software\n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability', '<1-hop>\n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise\n‚Ä¢ But studying government software is diÔ¨Écult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation?\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!', '<2-hop>\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption\n‚Ä¢ B3. Energy proÔ¨Åling of static analysis tools\n‚Ä¢ B4. Detailed energy proÔ¨Åling of build pipelines\n‚Ä¢ B5. Tool supporting SusAF workshop / process\n‚Ä¢ B6. Dataset of government-developed OS software\n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability', '<1-hop>\n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise\n‚Ä¢ But studying government software is diÔ¨Écult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation?\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!', '<2-hop>\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption\n‚Ä¢ B3. Energy proÔ¨Åling of static analysis tools\n‚Ä¢ B4. Detailed energy proÔ¨Åling of build pipelines\n‚Ä¢ B5. Tool supporting SusAF workshop / process\n‚Ä¢ B6. Dataset of government-developed OS software\n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability']","The challenges in creating a dataset of government-developed open-source software include:

1. **Lack of Incentive to Make Popular**: There is often little motivation for governments to promote their software, leading to a lack of visibility and awareness.

2. **Language Barriers**: Government software may be developed in various languages, making it difficult to compile a comprehensive dataset that is accessible and understandable to a wider audience.

3. **Understanding the State of Software**: It is challenging to gather data that provides insights into whether the software is buildable, has an open development history, and includes requirements documentation.

These challenges make it difficult to study and compile a comprehensive dataset of government-developed open-source software.","Creating a dataset of government-developed OS software faces challenges such as a lack of incentive to make the software popular and language barriers, which hinder comprehensive understanding of the software's buildability, open development history, and requirements documentation.",0.9999999999,1.0,0.8888888888888888,1.0,0.6666666655555555,0.9696515751694866
"What are the practical applications of neuromorphic computing, and how does its biological inspiration influence its implementation in modern computing systems?","['McCulloch-Pitts neuron [1, 2]\n1940s: How do biological neurons compute basic \nlogic functions? (e.g. logic gates)\nNote: Ref. [3] gives a nice brief history on the ideas which lead to the \nMcCulloch-Pitts neuron.\n\nWhat is a neural network?\n1950s: How are neurons organized to perform \nsensory perception?\n\nWhat is a neural network?\n1950s: How are neurons organized to perform \nsensory perception?\nThe first ""neural network"": Perceptron (1958). [4]\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\nFrank Rosenblatt (Psychologist)\nwith a Mark I Perceptron computer in 1960\n\nWhat is a neural network?\n1950s: How are neurons organized to perform \nsensory perception?\nThe first ""neural network"": Perceptron (1958). [4]\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\nFrank Rosenblatt (Psychologist)\nwith a Mark I Perceptron computer in 1960\nPower-efficient\n\nNeuromorphic computing\nWhy neuromorphic computing?\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\n\nNeuromorphic computing\nWhy neuromorphic computing?\n‚ÄòBiological inspiration‚Äô for artificial neural networks (ANNs) is not a new idea.\nEmulation (as opposed to simulation) of neural networks in hardware is not a new idea.\nQuestion: What can we gain from increasing biological realism in existing neural networks?\n\nPower-efficiency at scale\nModern, deep neural networks*\nare trained using GPUs.\n* It is estimated that ChatGPT was trained on \n10,000-20,000 GPUs and that it will require\n30,000 GPUs to keep running stably in the future.\n* It is estimated that ChatGPT has 10-20 billion \nparameters.', ""Neuromorphic computing\nCS4575\nSustainable Software Engineering\n05.03.2025\nNergis T√∂men\n\nIntroduction\nComputer Vision Lab\nBiomorphic Intelligence Lab\nBiomedical Intervention Optimisation Lab\nNergis\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing\n\nHow many of you are familiar \nwith neural networks?\n\nSimple model of an artificial neuron\nhttps://medium.com/@cprasenjit32/perceptron-a-simple-yet-mighty-machine-learning-algorithm-9ff6b7d86a71\n\nWhat is a neural network?\nhttps://www.tibco.com/reference-center/what-is-a-neural-network\n\nWhy is it called a 'neural network'?\nhttps://www.tibco.com/reference-center/what-is-a-neural-network\n\nWhat is a neural network?\nWhy is it called a 'neural network'?\nMcCulloch-Pitts neuron [1, 2] (1943)\nWarren Sturgis McCulloch\n(Neurophysiologist)\nWalter Pitts\n(Logician)\n\nHow do biological neurons work?\nhttps://commons.wikimedia.org/wiki/File:Coincidence_detection_in_dendrites_of_pyramidal_neurons.gif\n'Input current' travels down the dendrites (top),\nget integrated (summed!) in the cell body\nwhich generates an 'output current' (bottom)\nwhich is chemically transmitted to the dendrites of \nother neurons.\n\nSimplified picture\nReal neuron\nArtificial neuron\nhttps://vajiramandravi.com/quest-upsc-notes/artificial-neural-network/\n\nWhat is a neural network?\nMcCulloch-Pitts neuron [1, 2]\n1940s: How do biological neurons compute basic \nlogic functions? (e.g. logic gates)\nNote: Ref. [3] gives a nice brief history on the ideas which lead to the \nMcCulloch-Pitts neuron.\n\nWhat is a neural network?""]","['<1-hop>\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing', '<2-hop>\n\nReading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.', '<1-hop>\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing', '<2-hop>\n\nReading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.']","Neuromorphic computing is inspired by the structure and function of the human brain, and it involves using physical artificial neurons to perform computations. This approach offers several practical applications and advantages:

1. **Power Efficiency**: Neuromorphic computing systems are designed to be power-efficient, which is particularly beneficial for large-scale computations. This efficiency is crucial for applications like deep neural networks, which require significant computational resources.

2. **Real-Time Processing**: Due to their architecture, neuromorphic systems can process information in real-time, making them suitable for applications that require immediate responses, such as autonomous vehicles and robotics.

3. **Sensory Perception**: Neuromorphic computing can enhance sensory perception tasks, such as image and speech recognition, by mimicking the way biological systems process sensory information.

4. **Scalability**: The emulation of neural networks in hardware allows for scalable solutions that can handle complex tasks more efficiently than traditional computing systems.

The biological inspiration behind neuromorphic computing influences its implementation by encouraging the development of systems that mimic the parallel and distributed nature of the brain's neural networks. This leads to computing systems that are not only more efficient but also capable of handling complex, dynamic tasks in a manner similar to biological organisms.","Neuromorphic computing, inspired by the human brain, offers practical applications such as event-based vision systems and efficient processing of sensory data. Its biological inspiration influences its implementation through the use of spiking neural networks and physical artificial neurons, enabling more energy-efficient and brain-like computation methods.",0.9999999999,1.0,0.8571428571428571,0.63,,0.9383636299910348
"What are the practical applications of neuromorphic computing, and how does its biological inspiration influence its implementation?","['McCulloch-Pitts neuron [1, 2]\n1940s: How do biological neurons compute basic \nlogic functions? (e.g. logic gates)\nNote: Ref. [3] gives a nice brief history on the ideas which lead to the \nMcCulloch-Pitts neuron.\n\nWhat is a neural network?\n1950s: How are neurons organized to perform \nsensory perception?\n\nWhat is a neural network?\n1950s: How are neurons organized to perform \nsensory perception?\nThe first ""neural network"": Perceptron (1958). [4]\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\nFrank Rosenblatt (Psychologist)\nwith a Mark I Perceptron computer in 1960\n\nWhat is a neural network?\n1950s: How are neurons organized to perform \nsensory perception?\nThe first ""neural network"": Perceptron (1958). [4]\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\nFrank Rosenblatt (Psychologist)\nwith a Mark I Perceptron computer in 1960\nPower-efficient\n\nNeuromorphic computing\nWhy neuromorphic computing?\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\n\nNeuromorphic computing\nWhy neuromorphic computing?\n‚ÄòBiological inspiration‚Äô for artificial neural networks (ANNs) is not a new idea.\nEmulation (as opposed to simulation) of neural networks in hardware is not a new idea.\nQuestion: What can we gain from increasing biological realism in existing neural networks?\n\nPower-efficiency at scale\nModern, deep neural networks*\nare trained using GPUs.\n* It is estimated that ChatGPT was trained on \n10,000-20,000 GPUs and that it will require\n30,000 GPUs to keep running stably in the future.\n* It is estimated that ChatGPT has 10-20 billion \nparameters.', ""Neuromorphic computing\nCS4575\nSustainable Software Engineering\n05.03.2025\nNergis T√∂men\n\nIntroduction\nComputer Vision Lab\nBiomorphic Intelligence Lab\nBiomedical Intervention Optimisation Lab\nNergis\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing\n\nHow many of you are familiar \nwith neural networks?\n\nSimple model of an artificial neuron\nhttps://medium.com/@cprasenjit32/perceptron-a-simple-yet-mighty-machine-learning-algorithm-9ff6b7d86a71\n\nWhat is a neural network?\nhttps://www.tibco.com/reference-center/what-is-a-neural-network\n\nWhy is it called a 'neural network'?\nhttps://www.tibco.com/reference-center/what-is-a-neural-network\n\nWhat is a neural network?\nWhy is it called a 'neural network'?\nMcCulloch-Pitts neuron [1, 2] (1943)\nWarren Sturgis McCulloch\n(Neurophysiologist)\nWalter Pitts\n(Logician)\n\nHow do biological neurons work?\nhttps://commons.wikimedia.org/wiki/File:Coincidence_detection_in_dendrites_of_pyramidal_neurons.gif\n'Input current' travels down the dendrites (top),\nget integrated (summed!) in the cell body\nwhich generates an 'output current' (bottom)\nwhich is chemically transmitted to the dendrites of \nother neurons.\n\nSimplified picture\nReal neuron\nArtificial neuron\nhttps://vajiramandravi.com/quest-upsc-notes/artificial-neural-network/\n\nWhat is a neural network?\nMcCulloch-Pitts neuron [1, 2]\n1940s: How do biological neurons compute basic \nlogic functions? (e.g. logic gates)\nNote: Ref. [3] gives a nice brief history on the ideas which lead to the \nMcCulloch-Pitts neuron.\n\nWhat is a neural network?""]","['<1-hop>\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing', '<2-hop>\n\nReading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.']","The practical applications of neuromorphic computing include areas such as computer vision, robotics, and biomedical intervention optimization. Neuromorphic computing is particularly useful in scenarios where power efficiency is crucial, as it aims to emulate the brain's structure and function, which is highly efficient in processing information.

The biological inspiration for neuromorphic computing influences its implementation by using physical artificial neurons to perform computations, mimicking the way biological neurons process information. This approach allows for more efficient and scalable computing systems, as it leverages the brain's ability to perform complex tasks with minimal energy consumption. This emulation of neural networks in hardware is not a new idea, but it continues to offer potential for advancements in creating more efficient and powerful computing systems.","Neuromorphic computing, inspired by the human brain, offers practical applications through its ability to process information in a manner similar to biological neurons. This biological inspiration influences its implementation by enabling the development of systems that can efficiently handle tasks such as pattern recognition and adaptive learning, as detailed in resources like 'Computing with spiking neuron networks' and discussions on the convergence of deep learning with biological systems.",0.0,0.3333333333333333,0.75,0.4,0.0,0.9860043809554822
What are the practical applications of neuromorphic systems that leverage biological inspiration and advanced training methods for efficient computation?,"['McCulloch-Pitts neuron [1, 2]\n1940s: How do biological neurons compute basic \nlogic functions? (e.g. logic gates)\nNote: Ref. [3] gives a nice brief history on the ideas which lead to the \nMcCulloch-Pitts neuron.\n\nWhat is a neural network?\n1950s: How are neurons organized to perform \nsensory perception?\n\nWhat is a neural network?\n1950s: How are neurons organized to perform \nsensory perception?\nThe first ""neural network"": Perceptron (1958). [4]\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\nFrank Rosenblatt (Psychologist)\nwith a Mark I Perceptron computer in 1960\n\nWhat is a neural network?\n1950s: How are neurons organized to perform \nsensory perception?\nThe first ""neural network"": Perceptron (1958). [4]\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\nFrank Rosenblatt (Psychologist)\nwith a Mark I Perceptron computer in 1960\nPower-efficient\n\nNeuromorphic computing\nWhy neuromorphic computing?\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\n\nNeuromorphic computing\nWhy neuromorphic computing?\n‚ÄòBiological inspiration‚Äô for artificial neural networks (ANNs) is not a new idea.\nEmulation (as opposed to simulation) of neural networks in hardware is not a new idea.\nQuestion: What can we gain from increasing biological realism in existing neural networks?\n\nPower-efficiency at scale\nModern, deep neural networks*\nare trained using GPUs.\n* It is estimated that ChatGPT was trained on \n10,000-20,000 GPUs and that it will require\n30,000 GPUs to keep running stably in the future.\n* It is estimated that ChatGPT has 10-20 billion \nparameters.', ""Neuromorphic computing\nCS4575\nSustainable Software Engineering\n05.03.2025\nNergis T√∂men\n\nIntroduction\nComputer Vision Lab\nBiomorphic Intelligence Lab\nBiomedical Intervention Optimisation Lab\nNergis\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing\n\nHow many of you are familiar \nwith neural networks?\n\nSimple model of an artificial neuron\nhttps://medium.com/@cprasenjit32/perceptron-a-simple-yet-mighty-machine-learning-algorithm-9ff6b7d86a71\n\nWhat is a neural network?\nhttps://www.tibco.com/reference-center/what-is-a-neural-network\n\nWhy is it called a 'neural network'?\nhttps://www.tibco.com/reference-center/what-is-a-neural-network\n\nWhat is a neural network?\nWhy is it called a 'neural network'?\nMcCulloch-Pitts neuron [1, 2] (1943)\nWarren Sturgis McCulloch\n(Neurophysiologist)\nWalter Pitts\n(Logician)\n\nHow do biological neurons work?\nhttps://commons.wikimedia.org/wiki/File:Coincidence_detection_in_dendrites_of_pyramidal_neurons.gif\n'Input current' travels down the dendrites (top),\nget integrated (summed!) in the cell body\nwhich generates an 'output current' (bottom)\nwhich is chemically transmitted to the dendrites of \nother neurons.\n\nSimplified picture\nReal neuron\nArtificial neuron\nhttps://vajiramandravi.com/quest-upsc-notes/artificial-neural-network/\n\nWhat is a neural network?\nMcCulloch-Pitts neuron [1, 2]\n1940s: How do biological neurons compute basic \nlogic functions? (e.g. logic gates)\nNote: Ref. [3] gives a nice brief history on the ideas which lead to the \nMcCulloch-Pitts neuron.\n\nWhat is a neural network?""]","['<1-hop>\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing', '<2-hop>\n\nReading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.', '<1-hop>\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing', '<2-hop>\n\nReading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.', '<1-hop>\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing', '<2-hop>\n\nReading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.']","The practical applications of neuromorphic systems, which leverage biological inspiration and advanced training methods for efficient computation, include:

1. **Power-Efficient Computing**: Neuromorphic systems are designed to mimic the brain's efficiency, making them highly power-efficient, especially at scale. This is particularly beneficial for applications requiring extensive computations, such as deep learning models.

2. **Real-Time Processing**: Due to their efficiency and speed, neuromorphic systems are well-suited for real-time processing tasks, such as those needed in autonomous vehicles and robotics.

3. **Sensory Perception**: These systems can be used for advanced sensory perception tasks, similar to how biological neurons are organized for sensory processing. This includes applications in computer vision and auditory processing.

4. **Adaptive Control Systems**: Neuromorphic systems can be used in adaptive control systems that require learning and adaptation in dynamic environments, such as in smart grid management or adaptive traffic control.

5. **Biomedical Applications**: They can be applied in biomedical fields for tasks like brain-machine interfaces and neural prosthetics, where efficient and real-time processing of neural signals is crucial.

These applications benefit from the neuromorphic approach's ability to perform computations in a manner similar to the human brain, offering advantages in efficiency and speed over traditional computing methods.","Neuromorphic systems, inspired by the human brain, have practical applications such as event-based vision, which is detailed in the reading materials. These systems use advanced training methods like surrogate gradient learning to optimize spiking neural networks, enabling efficient computation and real-world applications.",0.0,0.0,0.42105263157894735,0.29,,0.9567597798554335
"What is the biological basis of neuromorphic computing, and how does it differ from conventional neural networks?","['McCulloch-Pitts neuron [1, 2]\n1940s: How do biological neurons compute basic \nlogic functions? (e.g. logic gates)\nNote: Ref. [3] gives a nice brief history on the ideas which lead to the \nMcCulloch-Pitts neuron.\n\nWhat is a neural network?\n1950s: How are neurons organized to perform \nsensory perception?\n\nWhat is a neural network?\n1950s: How are neurons organized to perform \nsensory perception?\nThe first ""neural network"": Perceptron (1958). [4]\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\nFrank Rosenblatt (Psychologist)\nwith a Mark I Perceptron computer in 1960\n\nWhat is a neural network?\n1950s: How are neurons organized to perform \nsensory perception?\nThe first ""neural network"": Perceptron (1958). [4]\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\nFrank Rosenblatt (Psychologist)\nwith a Mark I Perceptron computer in 1960\nPower-efficient\n\nNeuromorphic computing\nWhy neuromorphic computing?\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\n\nNeuromorphic computing\nWhy neuromorphic computing?\n‚ÄòBiological inspiration‚Äô for artificial neural networks (ANNs) is not a new idea.\nEmulation (as opposed to simulation) of neural networks in hardware is not a new idea.\nQuestion: What can we gain from increasing biological realism in existing neural networks?\n\nPower-efficiency at scale\nModern, deep neural networks*\nare trained using GPUs.\n* It is estimated that ChatGPT was trained on \n10,000-20,000 GPUs and that it will require\n30,000 GPUs to keep running stably in the future.\n* It is estimated that ChatGPT has 10-20 billion \nparameters.', ""Neuromorphic computing\nCS4575\nSustainable Software Engineering\n05.03.2025\nNergis T√∂men\n\nIntroduction\nComputer Vision Lab\nBiomorphic Intelligence Lab\nBiomedical Intervention Optimisation Lab\nNergis\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing\n\nHow many of you are familiar \nwith neural networks?\n\nSimple model of an artificial neuron\nhttps://medium.com/@cprasenjit32/perceptron-a-simple-yet-mighty-machine-learning-algorithm-9ff6b7d86a71\n\nWhat is a neural network?\nhttps://www.tibco.com/reference-center/what-is-a-neural-network\n\nWhy is it called a 'neural network'?\nhttps://www.tibco.com/reference-center/what-is-a-neural-network\n\nWhat is a neural network?\nWhy is it called a 'neural network'?\nMcCulloch-Pitts neuron [1, 2] (1943)\nWarren Sturgis McCulloch\n(Neurophysiologist)\nWalter Pitts\n(Logician)\n\nHow do biological neurons work?\nhttps://commons.wikimedia.org/wiki/File:Coincidence_detection_in_dendrites_of_pyramidal_neurons.gif\n'Input current' travels down the dendrites (top),\nget integrated (summed!) in the cell body\nwhich generates an 'output current' (bottom)\nwhich is chemically transmitted to the dendrites of \nother neurons.\n\nSimplified picture\nReal neuron\nArtificial neuron\nhttps://vajiramandravi.com/quest-upsc-notes/artificial-neural-network/\n\nWhat is a neural network?\nMcCulloch-Pitts neuron [1, 2]\n1940s: How do biological neurons compute basic \nlogic functions? (e.g. logic gates)\nNote: Ref. [3] gives a nice brief history on the ideas which lead to the \nMcCulloch-Pitts neuron.\n\nWhat is a neural network?""]","['<1-hop>\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing', '<2-hop>\n\nReading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.']","The biological basis of neuromorphic computing is its inspiration from the structure and function of the human brain. Neuromorphic computing involves using physical artificial neurons to perform computations, emulating the way biological neurons process information. This approach aims to mimic the brain's efficiency and adaptability.

In contrast, conventional neural networks, such as those used in deep learning, are typically implemented in software and run on general-purpose hardware like GPUs. These networks are inspired by the brain but do not emulate its physical structure. They are often less power-efficient compared to neuromorphic systems, which aim to achieve power-efficiency at scale by closely replicating the brain's architecture and processes.

In summary, neuromorphic computing seeks to emulate the brain's physical and functional characteristics in hardware, while conventional neural networks are software-based models inspired by the brain's information processing capabilities.","Neuromorphic computing is based on the biological principles of the human brain, utilizing physical artificial neurons to perform computations. Unlike conventional neural networks, which rely on traditional computing architectures, neuromorphic systems are designed to mimic the brain's structure and function, enabling more efficient and biologically inspired processing.",0.99999999995,0.5,1.0,1.0,,0.9849766818157953
What is the difference between spiking neural networks and spiking neuron networks?,"[""ANN: Perceptron, threshold activation function:\n\nHow to model spiking neurons?\nANN: Perceptron, threshold activation function:\n\nHow to model spiking neurons?\nSpiking neural network (SNN): The 'input current' Œµ(t) is integrated over time.\nspike\n\nHow to model spiking neurons?\nEquivalence to perceptron: Computation at least as complex as a perceptron.\n\nNon-leaky integrate-and-fire (IF) neuron\nThe temporal profile of the input current Œµ(t) can be chosen differently, for different computations.\n\nQuestions?\n\nComputation with spiking neurons\nCoincidence detection\n\nComputation with spiking neurons\nCoincidence detection\nx, y ‚àà {0, 1}n\nExample: n = 2\ninput = \nx1\nx2\ny1\ny2\n= \n0\n1\n1\n1\noutput? \n\nCoincidence detection\nComputation with spiking neurons\n\nCoincidence detection\nCan be trivially computed with a single spiking neuron! Requires at least n/log(n+1) hidden \nunits for a perceptron (proof in [7]).\nComputation with spiking neurons\n\nCoincidence detection\nCan be trivially computed with a single spiking neuron! Requires at least n/log(n+1) hidden \nunits for a perceptron (proof in [7]).\nBrains are energy efficient: \n1.\nHigh temporal resolution (more computation with less neurons)\nComputation with spiking neurons\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant\n\nFiring rates\nClassical view of the brain:\n- Each neuron is selective for one specific \nfeature in the input.\n- Higher firing rate (spikes per unit time) for \n'selected' feature.\nAdapted from Hubel & Wiesel, 1959\n\nFiring rates\nClassical view of the brain:\n- Each neuron is selective for one specific \nfeature in the input.\n- Higher firing rate (spikes per unit time) for \n'selected' feature."", 'Reading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020.']","[""<1-hop>\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant"", '<2-hop>\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \n(not publicly available) doi:10.1037/h0042519\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568', ""<1-hop>\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant"", '<2-hop>\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \n(not publicly available) doi:10.1037/h0042519\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568']","The sources provided do not explicitly differentiate between ""spiking neural networks"" and ""spiking neuron networks."" However, based on general understanding, these terms are often used interchangeably to describe networks that use spiking neurons as their fundamental units. Both refer to a type of artificial neural network that mimics the way biological neurons communicate through discrete spikes or action potentials. If there is a specific context or distinction you are referring to, it might not be covered in the provided sources.","Spiking neural networks (SNNs) are a type of neural network model that processes information using spikes, similar to biological neurons. Spiking neuron networks refer to the individual components within these networks, focusing on how each neuron processes and communicates information through spikes.",0.0,0.5,0.5714285714285714,0.5,0.0,0.0
What is the foundational concepts of spiking neural networks and how they are used in encoding strategies?,"[""- Higher firing rate (spikes per unit time) for \n'selected' feature.\nAdapted from Hubel & Wiesel, 1959\n\nFiring rates\nClassical view of the brain:\n- Each neuron is selective for one specific \nfeature in the input.\n- Higher firing rate (spikes per unit time) for \n'selected' feature.\n- Link to modern ANNs: The scalar output of \nan artificial neuron is interpreted as the firing \nrate.\nAdapted from Hubel & Wiesel, 1959\n\nFiring rates\nClassical view of the brain:\n- Each neuron is selective for one specific \nfeature in the input.\n- Higher firing rate (spikes per unit time) for \n'selected' feature.\n- Link to modern ANNs: The scalar output of \nan artificial neuron is interpreted as the firing \nrate.\nAdapted from Hubel & Wiesel, 1959\nBut rate coding is inefficient and slow‚Ä¶\n(i.e. each neuron needs to fire many spikes to get good precision)\nboth in vivo and in silico.\n\nDifferent encoding strategies with spiking neurons [8]\n7 neurons\n7 time bins\n\nDifferent encoding strategies with spiking neurons\n7 neurons\n7 time bins\nn\n6\n(in the general \ncase a \nnumber \nbetween 0-7)\n\nDifferent encoding strategies with spiking neurons\n7 neurons\n7 time bins\nn\nTotal spike \ncount can \nencode 3 bits.\n\nDifferent encoding strategies with spiking neurons\n7 neurons\n7 time bins\nIndividual rates \ncan encode 7 \nbits.\n\nDifferent encoding strategies with spiking neurons\n7 neurons\n7 time bins\nLatency can \nencode ~3*7 or \n~19 bits.\n\nDifferent encoding strategies with spiking neurons\n7 neurons\n7 time bins\nRank order can \nencode ~12 bits.\n\nDifferent encoding strategies with spiking neurons\n\nDifferent encoding strategies with spiking neurons\nUsing latency or spatio-temporal codes\nour encoding is faster and more spike-efficient (sparser)!\n\nDifferent encoding strategies with spiking neurons\nUsing latency or spatio-temporal codes\nour encoding is faster and more spike-efficient (sparser)!\nQuestions?\n\nNeuromorphic computing\nWhat is the advantage for applications?\n-\nLess spikes = less energy consumption in specialized neuromorphic hardware\n(e.g."", ""ANN: Perceptron, threshold activation function:\n\nHow to model spiking neurons?\nANN: Perceptron, threshold activation function:\n\nHow to model spiking neurons?\nSpiking neural network (SNN): The 'input current' Œµ(t) is integrated over time.\nspike\n\nHow to model spiking neurons?\nEquivalence to perceptron: Computation at least as complex as a perceptron.\n\nNon-leaky integrate-and-fire (IF) neuron\nThe temporal profile of the input current Œµ(t) can be chosen differently, for different computations.\n\nQuestions?\n\nComputation with spiking neurons\nCoincidence detection\n\nComputation with spiking neurons\nCoincidence detection\nx, y ‚àà {0, 1}n\nExample: n = 2\ninput = \nx1\nx2\ny1\ny2\n= \n0\n1\n1\n1\noutput? \n\nCoincidence detection\nComputation with spiking neurons\n\nCoincidence detection\nCan be trivially computed with a single spiking neuron! Requires at least n/log(n+1) hidden \nunits for a perceptron (proof in [7]).\nComputation with spiking neurons\n\nCoincidence detection\nCan be trivially computed with a single spiking neuron! Requires at least n/log(n+1) hidden \nunits for a perceptron (proof in [7]).\nBrains are energy efficient: \n1.\nHigh temporal resolution (more computation with less neurons)\nComputation with spiking neurons\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant\n\nFiring rates\nClassical view of the brain:\n- Each neuron is selective for one specific \nfeature in the input.\n- Higher firing rate (spikes per unit time) for \n'selected' feature.\nAdapted from Hubel & Wiesel, 1959\n\nFiring rates\nClassical view of the brain:\n- Each neuron is selective for one specific \nfeature in the input.\n- Higher firing rate (spikes per unit time) for \n'selected' feature.""]","[""<1-hop>\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant"", '<2-hop>\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \n(not publicly available) doi:10.1037/h0042519\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568', ""<1-hop>\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant"", '<2-hop>\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \n(not publicly available) doi:10.1037/h0042519\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568', ""<1-hop>\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant"", '<2-hop>\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \n(not publicly available) doi:10.1037/h0042519\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568', ""<1-hop>\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant"", '<2-hop>\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \n(not publicly available) doi:10.1037/h0042519\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568']","The foundational concept of spiking neural networks (SNNs) is that they model neurons as spiking units, where the 'input current' is integrated over time, leading to a spike when a threshold is reached. This is similar to the perceptron model but involves temporal dynamics.

In terms of encoding strategies, SNNs use different methods to encode information with spikes:

1. **Rate Coding**: This classical view involves neurons firing at higher rates for selected features. However, it is considered inefficient and slow as it requires many spikes for good precision.

2. **Latency Coding**: This method encodes information based on the timing of spikes, which can be more efficient and faster than rate coding.

3. **Spatio-Temporal Coding**: This involves using both spatial and temporal patterns of spikes to encode information, making it more spike-efficient and faster.

4. **Rank Order Coding**: This strategy encodes information based on the order in which neurons fire, allowing for a compact representation of information.

Overall, these encoding strategies in SNNs aim to achieve high temporal resolution and energy efficiency, allowing for more computation with fewer neurons and less energy consumption, especially in specialized neuromorphic hardware.","Spiking neural networks use spikes to encode information, with foundational concepts including the work of McCulloch and Pitts on logical calculus of nervous activity, and later developments in spiking neuron models.",0.0,,0.8125,0.12,0.0,0.9490565936383991
What is the project idea about government-developed OS software?,"['Study test generation energy consumption\n‚Ä¢ Automatic test generation mainly focuses on making strong test suites \n‚Ä¢ Do different techniques and configurations impact the energy consumption \nduring generation? \n‚Ä¢ Preferably focus on non-LLM test generation methods (EvoSuite, Pyguin, \nDSpot)\n\nB3. Detailed energy profiling of build pipelines\n‚Ä¢ Automatic builds have become a cornerstone of quality assurance. But how \nmuch energy do they even consume? \n‚Ä¢ Create a tool that reports on the energy consumed during the (different stages \nof the) whole build (compile, build, test, package, ‚Ä¶) \n‚Ä¢ Should be integrated with build system(s), making setup for developers easy \n‚Ä¢ For local setup (to enable true energy measurements)\n\nB4. Energy profiling of static analysis tools\n‚Ä¢ What is the energy consumption of a ""typical run"" for a few OSS projects? \n‚Ä¢ Does the type of analysis matter? Are certain analysis more expensive? Does \nthe number of rules that are activated in a static analysis tool important for the \nenergy consumption? \n‚Ä¢ Differences between static analysis tools [lower priority]\n\nB5. Tool supporting SusAF workshop / process\n‚Ä¢ Lead engineers through process & questions \n‚Ä¢ Interface to create & document the two diagrams \n‚Ä¢ (!) Should be easy to start using & set up \n‚Ä¢ You may also create a simplified version / \u2028\nyour favorite sustainability framework\nEnvironmental\nEconomic\nTechnical\nIndividual\nSocial\nImmediate\nEnabling\nStructural\nAirbnb\ngreater \nearnings\nincrease \nin rents\ngentrification\ngreater racial \ndisparities\nrent \nrooms\n5\n1\n3\n4\n2\n \n \n \n \n \n \nVery \nunlikely \nVery \nlikely \n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise \n‚Ä¢ But studying government software is difficult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers \n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation? \n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!\n\nB7.', '‚Ä¢ Deadline April 4.\n6\n\nStrategy\n‚Ä¢ Week 0 \n‚Ä¢ Decide project idea (today) \n‚Ä¢ Define steering meeting schedule \n‚Ä¢ Create working document of the \narticle: Problem statement and solution \nproposal! \n‚Ä¢ Define and assign tasks for each week. \n‚Ä¢ Week 1 \n‚Ä¢ Implementation \n‚Ä¢ Agreements with supervisor. \n‚Ä¢ Week 2 \n‚Ä¢ Implementation \n‚Ä¢ Week 3 \n‚Ä¢ Implementation, Full draft of article, \ndissemination. \n‚Ä¢ Week 4 \n‚Ä¢ Final refinements \n‚Ä¢ Prepare presentation\n7\n\nProject ideas\n‚Ä¢ A1. Prototype cross-machine comparable benchmarks \n‚Ä¢ A2. Add energy metrics to LMstudio/Ollama \n‚Ä¢ A3. Visualizations built-in with EnergiBridge \n‚Ä¢ A4. Service-based version of EnergiBridge\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption \n‚Ä¢ B3. Energy profiling of static analysis tools \n‚Ä¢ B4. Detailed energy profiling of build pipelines \n‚Ä¢ B5. Tool supporting SusAF workshop / process \n‚Ä¢ B6. Dataset of government-developed OS software \n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability\n\nProject ideas\n‚Ä¢ C1. Compare energy consumption of docker images for ML workloads. \n‚Ä¢ C2. Create a plugin to visualize Hugging Face carbon emissions in detail. \n‚Ä¢ C3. Plugin for ChatGPT (footprint per chat window) \n‚Ä¢ C4. NutriScore for software libraries. \n‚Ä¢ C5. Add energy-awareness to existing software \n‚Ä¢ C6. Green Shift Left \n‚Ä¢ C7. Education for Sustainable SE\n\nA1. Prototype cross-machine comparable benchmarks\n‚Ä¢ Energy-usage comparisons require running both baseline + software on the \nsame machine ‚Üí limits how extensive our experiments can be \n‚Ä¢ Research community is in need of benchmarks that make energy \nmeasurements comparable even if executed on different machines \n‚Ä¢ Focus on a single task or model (i.e. computing vision, classification)\n\nA2.']","['<1-hop>\n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise\n‚Ä¢ But studying government software is diÔ¨Écult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation?\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!', '<2-hop>\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption\n‚Ä¢ B3. Energy proÔ¨Åling of static analysis tools\n‚Ä¢ B4. Detailed energy proÔ¨Åling of build pipelines\n‚Ä¢ B5. Tool supporting SusAF workshop / process\n‚Ä¢ B6. Dataset of government-developed OS software\n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability']","The project idea about government-developed OS software involves creating a comprehensive dataset of open-source software developed and used by governments to support society. The dataset should include information to understand the state of the software, such as whether it is buildable, its open development history, and requirements documentation. The project could start with the Netherlands (NL) but would benefit from including other countries as well. The challenge lies in the lack of incentive to make such software popular and potential language barriers.","The project idea involves creating a comprehensive dataset of government-developed OS software to understand its state, including buildability, open development history, and requirements documentation. This addresses challenges like lack of incentives and language barriers.",0.99999999995,1.0,1.0,0.8,0.16666666638888888,0.9999773461374194
What is the project idea related to creating a dataset of goverment-developed OS software?,"['‚Ä¢ Deadline April 4.\n6\n\nStrategy\n‚Ä¢ Week 0 \n‚Ä¢ Decide project idea (today) \n‚Ä¢ Define steering meeting schedule \n‚Ä¢ Create working document of the \narticle: Problem statement and solution \nproposal! \n‚Ä¢ Define and assign tasks for each week. \n‚Ä¢ Week 1 \n‚Ä¢ Implementation \n‚Ä¢ Agreements with supervisor. \n‚Ä¢ Week 2 \n‚Ä¢ Implementation \n‚Ä¢ Week 3 \n‚Ä¢ Implementation, Full draft of article, \ndissemination. \n‚Ä¢ Week 4 \n‚Ä¢ Final refinements \n‚Ä¢ Prepare presentation\n7\n\nProject ideas\n‚Ä¢ A1. Prototype cross-machine comparable benchmarks \n‚Ä¢ A2. Add energy metrics to LMstudio/Ollama \n‚Ä¢ A3. Visualizations built-in with EnergiBridge \n‚Ä¢ A4. Service-based version of EnergiBridge\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption \n‚Ä¢ B3. Energy profiling of static analysis tools \n‚Ä¢ B4. Detailed energy profiling of build pipelines \n‚Ä¢ B5. Tool supporting SusAF workshop / process \n‚Ä¢ B6. Dataset of government-developed OS software \n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability\n\nProject ideas\n‚Ä¢ C1. Compare energy consumption of docker images for ML workloads. \n‚Ä¢ C2. Create a plugin to visualize Hugging Face carbon emissions in detail. \n‚Ä¢ C3. Plugin for ChatGPT (footprint per chat window) \n‚Ä¢ C4. NutriScore for software libraries. \n‚Ä¢ C5. Add energy-awareness to existing software \n‚Ä¢ C6. Green Shift Left \n‚Ä¢ C7. Education for Sustainable SE\n\nA1. Prototype cross-machine comparable benchmarks\n‚Ä¢ Energy-usage comparisons require running both baseline + software on the \nsame machine ‚Üí limits how extensive our experiments can be \n‚Ä¢ Research community is in need of benchmarks that make energy \nmeasurements comparable even if executed on different machines \n‚Ä¢ Focus on a single task or model (i.e. computing vision, classification)\n\nA2.', 'Study test generation energy consumption\n‚Ä¢ Automatic test generation mainly focuses on making strong test suites \n‚Ä¢ Do different techniques and configurations impact the energy consumption \nduring generation? \n‚Ä¢ Preferably focus on non-LLM test generation methods (EvoSuite, Pyguin, \nDSpot)\n\nB3. Detailed energy profiling of build pipelines\n‚Ä¢ Automatic builds have become a cornerstone of quality assurance. But how \nmuch energy do they even consume? \n‚Ä¢ Create a tool that reports on the energy consumed during the (different stages \nof the) whole build (compile, build, test, package, ‚Ä¶) \n‚Ä¢ Should be integrated with build system(s), making setup for developers easy \n‚Ä¢ For local setup (to enable true energy measurements)\n\nB4. Energy profiling of static analysis tools\n‚Ä¢ What is the energy consumption of a ""typical run"" for a few OSS projects? \n‚Ä¢ Does the type of analysis matter? Are certain analysis more expensive? Does \nthe number of rules that are activated in a static analysis tool important for the \nenergy consumption? \n‚Ä¢ Differences between static analysis tools [lower priority]\n\nB5. Tool supporting SusAF workshop / process\n‚Ä¢ Lead engineers through process & questions \n‚Ä¢ Interface to create & document the two diagrams \n‚Ä¢ (!) Should be easy to start using & set up \n‚Ä¢ You may also create a simplified version / \u2028\nyour favorite sustainability framework\nEnvironmental\nEconomic\nTechnical\nIndividual\nSocial\nImmediate\nEnabling\nStructural\nAirbnb\ngreater \nearnings\nincrease \nin rents\ngentrification\ngreater racial \ndisparities\nrent \nrooms\n5\n1\n3\n4\n2\n \n \n \n \n \n \nVery \nunlikely \nVery \nlikely \n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise \n‚Ä¢ But studying government software is difficult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers \n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation? \n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!\n\nB7.']","['<1-hop>\n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise\n‚Ä¢ But studying government software is diÔ¨Écult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation?\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!', '<2-hop>\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption\n‚Ä¢ B3. Energy proÔ¨Åling of static analysis tools\n‚Ä¢ B4. Detailed energy proÔ¨Åling of build pipelines\n‚Ä¢ B5. Tool supporting SusAF workshop / process\n‚Ä¢ B6. Dataset of government-developed OS software\n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability', '<1-hop>\n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise\n‚Ä¢ But studying government software is diÔ¨Écult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation?\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!', '<2-hop>\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption\n‚Ä¢ B3. Energy proÔ¨Åling of static analysis tools\n‚Ä¢ B4. Detailed energy proÔ¨Åling of build pipelines\n‚Ä¢ B5. Tool supporting SusAF workshop / process\n‚Ä¢ B6. Dataset of government-developed OS software\n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability', '<1-hop>\n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise\n‚Ä¢ But studying government software is diÔ¨Écult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation?\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!', '<2-hop>\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption\n‚Ä¢ B3. Energy proÔ¨Åling of static analysis tools\n‚Ä¢ B4. Detailed energy proÔ¨Åling of build pipelines\n‚Ä¢ B5. Tool supporting SusAF workshop / process\n‚Ä¢ B6. Dataset of government-developed OS software\n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability', '<1-hop>\n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise\n‚Ä¢ But studying government software is diÔ¨Écult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation?\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!', '<2-hop>\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption\n‚Ä¢ B3. Energy proÔ¨Åling of static analysis tools\n‚Ä¢ B4. Detailed energy proÔ¨Åling of build pipelines\n‚Ä¢ B5. Tool supporting SusAF workshop / process\n‚Ä¢ B6. Dataset of government-developed OS software\n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability', '<1-hop>\n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise\n‚Ä¢ But studying government software is diÔ¨Écult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation?\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!', '<2-hop>\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption\n‚Ä¢ B3. Energy proÔ¨Åling of static analysis tools\n‚Ä¢ B4. Detailed energy proÔ¨Åling of build pipelines\n‚Ä¢ B5. Tool supporting SusAF workshop / process\n‚Ä¢ B6. Dataset of government-developed OS software\n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability']","The project idea related to creating a dataset of government-developed OS software involves compiling a comprehensive dataset that includes data to understand the state of such software. This includes determining if the software is buildable, its open development history, and requirements documentation. The project acknowledges the challenges in studying government software due to a lack of incentive to make it popular and language barriers. It suggests starting with the Netherlands (NL) but encourages including other countries as well.","The project idea is to create a dataset of government-developed OS software, which would help in understanding the state of such software, including whether it is buildable, has open development history, and has requirements documentation.",0.99999999995,1.0,1.0,0.67,0.0,0.9980923627914131
What is the project idea related to creating a dataset of government-developed OS software?,"['Study test generation energy consumption\n‚Ä¢ Automatic test generation mainly focuses on making strong test suites \n‚Ä¢ Do different techniques and configurations impact the energy consumption \nduring generation? \n‚Ä¢ Preferably focus on non-LLM test generation methods (EvoSuite, Pyguin, \nDSpot)\n\nB3. Detailed energy profiling of build pipelines\n‚Ä¢ Automatic builds have become a cornerstone of quality assurance. But how \nmuch energy do they even consume? \n‚Ä¢ Create a tool that reports on the energy consumed during the (different stages \nof the) whole build (compile, build, test, package, ‚Ä¶) \n‚Ä¢ Should be integrated with build system(s), making setup for developers easy \n‚Ä¢ For local setup (to enable true energy measurements)\n\nB4. Energy profiling of static analysis tools\n‚Ä¢ What is the energy consumption of a ""typical run"" for a few OSS projects? \n‚Ä¢ Does the type of analysis matter? Are certain analysis more expensive? Does \nthe number of rules that are activated in a static analysis tool important for the \nenergy consumption? \n‚Ä¢ Differences between static analysis tools [lower priority]\n\nB5. Tool supporting SusAF workshop / process\n‚Ä¢ Lead engineers through process & questions \n‚Ä¢ Interface to create & document the two diagrams \n‚Ä¢ (!) Should be easy to start using & set up \n‚Ä¢ You may also create a simplified version / \u2028\nyour favorite sustainability framework\nEnvironmental\nEconomic\nTechnical\nIndividual\nSocial\nImmediate\nEnabling\nStructural\nAirbnb\ngreater \nearnings\nincrease \nin rents\ngentrification\ngreater racial \ndisparities\nrent \nrooms\n5\n1\n3\n4\n2\n \n \n \n \n \n \nVery \nunlikely \nVery \nlikely \n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise \n‚Ä¢ But studying government software is difficult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers \n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation? \n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!\n\nB7.', '‚Ä¢ Deadline April 4.\n6\n\nStrategy\n‚Ä¢ Week 0 \n‚Ä¢ Decide project idea (today) \n‚Ä¢ Define steering meeting schedule \n‚Ä¢ Create working document of the \narticle: Problem statement and solution \nproposal! \n‚Ä¢ Define and assign tasks for each week. \n‚Ä¢ Week 1 \n‚Ä¢ Implementation \n‚Ä¢ Agreements with supervisor. \n‚Ä¢ Week 2 \n‚Ä¢ Implementation \n‚Ä¢ Week 3 \n‚Ä¢ Implementation, Full draft of article, \ndissemination. \n‚Ä¢ Week 4 \n‚Ä¢ Final refinements \n‚Ä¢ Prepare presentation\n7\n\nProject ideas\n‚Ä¢ A1. Prototype cross-machine comparable benchmarks \n‚Ä¢ A2. Add energy metrics to LMstudio/Ollama \n‚Ä¢ A3. Visualizations built-in with EnergiBridge \n‚Ä¢ A4. Service-based version of EnergiBridge\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption \n‚Ä¢ B3. Energy profiling of static analysis tools \n‚Ä¢ B4. Detailed energy profiling of build pipelines \n‚Ä¢ B5. Tool supporting SusAF workshop / process \n‚Ä¢ B6. Dataset of government-developed OS software \n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability\n\nProject ideas\n‚Ä¢ C1. Compare energy consumption of docker images for ML workloads. \n‚Ä¢ C2. Create a plugin to visualize Hugging Face carbon emissions in detail. \n‚Ä¢ C3. Plugin for ChatGPT (footprint per chat window) \n‚Ä¢ C4. NutriScore for software libraries. \n‚Ä¢ C5. Add energy-awareness to existing software \n‚Ä¢ C6. Green Shift Left \n‚Ä¢ C7. Education for Sustainable SE\n\nA1. Prototype cross-machine comparable benchmarks\n‚Ä¢ Energy-usage comparisons require running both baseline + software on the \nsame machine ‚Üí limits how extensive our experiments can be \n‚Ä¢ Research community is in need of benchmarks that make energy \nmeasurements comparable even if executed on different machines \n‚Ä¢ Focus on a single task or model (i.e. computing vision, classification)\n\nA2.']","['<1-hop>\n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise\n‚Ä¢ But studying government software is diÔ¨Écult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation?\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!', '<2-hop>\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption\n‚Ä¢ B3. Energy proÔ¨Åling of static analysis tools\n‚Ä¢ B4. Detailed energy proÔ¨Åling of build pipelines\n‚Ä¢ B5. Tool supporting SusAF workshop / process\n‚Ä¢ B6. Dataset of government-developed OS software\n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability']","The project idea related to creating a dataset of government-developed OS software involves compiling a comprehensive dataset that includes data to understand the state of such software. This includes information on whether the software is buildable, its open development history, and requirements documentation. The project acknowledges the challenges in studying government software due to a lack of incentive to make it popular and language barriers. It suggests starting with the Netherlands (NL) but appreciates the inclusion of other countries.","The project idea is to create a comprehensive dataset of government-developed OS software to understand the state of such software, including its buildability, open development history, and requirements documentation. This addresses challenges like the lack of incentive to make software popular and language barriers.",0.99999999995,1.0,1.0,0.86,,0.9916173317814447
How EcoAndroid reduce risk by reduce size?,"['‚Ä¢ When a connection is not possible, the app automatically retries later. \n‚Ä¢ https://github.com/k9mail/k-9/commit/\n86f3b28f79509d1a4d613eb39f60603e08579ea3\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio) \n‚Ä¢ Dynamic Retry Delay \n‚Ä¢ Push Over Poll \n‚Ä¢ Reduce Size \n‚Ä¢ Cache \n‚Ä¢ Avoid Graphics and Animations\n20\n\nCarbon-Aware Computing for \nDatacenters \nhttps://sites.google.com/view/energy-efficiency-languages\n21\nAna Radovanovic ÃÅ,', '*/\n6028 \nchanges\n\nThematic Analysis\n1. Familiarization with data \n2. Generating initial labels \n3. Reviewing themes\n4. Defining and naming themes\n\n‚Ä¢ Energy Pattern: design pattern to improve energy efficiency.. \n‚Ä¢ 22 energy patterns. \n‚Ä¢ Each pattern is described by Context, Solution, Example, References from \nliterature, and Occurences (links to code changes from git repositories).\n8\n\nhttps://tqrg.github.io/energy-patterns\n\nDark UI Colors \nProvide a dark UI color theme to \nsave battery on devices with \nAMOLED screens.\n‚Ä¢ Context: [‚Ä¶] Apps that require heavy usage of screen can \nhave a substantial negative impact on battery life. \n‚Ä¢ Solution: Provide a UI theme with dark background colors. [‚Ä¶]\n‚Ä¢ Example: In a reading app, provide a theme with a dark \nbackground using light colors to display text. [‚Ä¶] \n10\n\nDark UI Colors \nProvide a dark UI color theme to \nsave battery on devices with \nAMOLED screens.\n‚Ä¢ Context: [‚Ä¶] Apps that require heavy usage of screen can \nhave a substantial negative impact on battery life. \n‚Ä¢ Solution: Provide a UI theme with dark background colors. [‚Ä¶]\n‚Ä¢ Example: In a reading app, provide a theme with a dark \nbackground using light colors to display text. [‚Ä¶] \n11\n\nDynamic Retry Delay\n‚Ä¢ Context: [‚Ä¶] In a mobile app, when a given resource is \nunavailable, the app will unnecessarily try to connect the resource \nfor a number of times, leading to unnecessary power consumption. \n‚Ä¢ Solution: Increase retry interval after each failed connection. [‚Ä¶]\n‚Ä¢ Example: Consider a mobile app that provides a news feed and \nthe app is not able to reach the server to collect updates. [‚Ä¶] use \nthe Fibonacci series to increase the time between attempts.\nWhenever an attempt to access a \nresource fails, increase the time \ninterval before retrying.\n12\n\nBatch Operations \n‚Ä¢ Context: Executing operations separately leads to extraneous \ntail energy consumptions  \n‚Ä¢ Solution: Bundle multiple operations in a single one. [‚Ä¶]\n‚Ä¢ Example: Use system provided APIs to schedule background \ntasks. These APIs, guarantee that device will exit sleep mode \nonly when there is a reasonable amount of work to do or when a \ngiven task is urgent. [‚Ä¶]\n13\n\nAvoid Extraneous Graphics and \nAnimations  \n‚Ä¢ Context: Mobile apps that feature impressive graphics \nand animations.', 'Green Architectural Tactics for ML-Enabled \nSystem\n38\nICSE-SEIS 2024\n\nArchitectural tactics\n39\n\nData-centric\n40\n‚Ä¢ Reduce data size \n‚Ä¢ Sampling \n‚Ä¢ Dimensionality reduction \n‚Ä¢ Quantization\n\nAlgorithm Design\n41\n‚Ä¢ Carefully select your algorithm \n‚Ä¢ You don‚Äôt need the fanciest \ntechniques\n\nModel Optimization\n42\n‚Ä¢ Add energy to training parameters \n‚Ä¢ Reduce FLOPs \n‚Ä¢ Pruning,']","['<1-hop>\n\nShuffle \nüîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them.\n‚Ä¢ If you run 30 executions for version A and another batch for version B:\n‚Ä¢ External conditions that change over time will have a diÔ¨Äerent bias in \nthe 2 versions (e.g., room temperature changes).\n‚Ä¢ If you shuÔ¨Ñe, you reduce this risk.\n11', '<2-hop>\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio)\n‚Ä¢ Dynamic Retry Delay\n‚Ä¢ Push Over Poll\n‚Ä¢ Reduce Size\n‚Ä¢ Cache\n‚Ä¢ Avoid Graphics and Animations\n20', '<1-hop>\n\nShuffle \nüîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them.\n‚Ä¢ If you run 30 executions for version A and another batch for version B:\n‚Ä¢ External conditions that change over time will have a diÔ¨Äerent bias in \nthe 2 versions (e.g., room temperature changes).\n‚Ä¢ If you shuÔ¨Ñe, you reduce this risk.\n11', '<2-hop>\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio)\n‚Ä¢ Dynamic Retry Delay\n‚Ä¢ Push Over Poll\n‚Ä¢ Reduce Size\n‚Ä¢ Cache\n‚Ä¢ Avoid Graphics and Animations\n20']","EcoAndroid reduces risk by reducing size through techniques such as caching and avoiding graphics and animations. By minimizing the size of data and resources used, the app can operate more efficiently, which can lead to lower energy consumption and improved performance. This approach helps in mitigating risks associated with excessive resource usage and potential performance bottlenecks.",EcoAndroid reduce risk by using Reduce Size feature which help minimize energy consumption and reduce impact of external factors like temperature changes.,0.0,0.5,0.14285714285714285,0.8,0.49999999875,0.954177828757381
How can static code analysis in data science be used to improve the energy efficiency of data centers and contribute to sustainable software engineering?,"['Energy profiling of static analysis tools\n‚Ä¢ What is the energy consumption of a ""typical run"" for a few OSS projects? \n‚Ä¢ Does the type of analysis matter? Are certain analysis more expensive? Does \nthe number of rules that are activated in a static analysis tool important for the \nenergy consumption? \n‚Ä¢ Differences between static analysis tools [lower priority]\n\nB5.', '‚Ä¢ => Improve data collection, data labelling, and data preprocessing. \n‚Ä¢ More about data-centric AI by Andrew Ng:\u2028\nhttps://www.youtube.com/watch?v=06-AZXmwHjo\n15\n\n\nGreen Data-centric AI\n‚Ä¢ How do different ML algorithms compare \nin terms of energy consumption? \n‚Ä¢ How does number of rows relate to the \nenergy consumption of ML models? \n‚Ä¢ How does number of features relate to \nthe energy consumption of ML models? \n‚Ä¢ What is the impact of reducing data in the \nperformance of the model?', '19\n(?)\n\nResults: energy consumption of algorithms\n\nResults: energy vs data shape\n\nResults: performance vs data shape\n\nDiscussion\n‚Ä¢ Other data properties should be investigated. \n‚Ä¢ E.g., data types \n‚Ä¢ Reporting energy data is essential. It can lead to different model selection \nwithout hindering model performance. \n‚Ä¢ There is a big opportunity in Model and Data Simplification.\n23\n\nData/Model Simplification\n‚Ä¢ (?) \n‚Ä¢ Data selection \n‚Ä¢ Data quantisation. Posit? \n‚Ä¢ Data distillation \n‚Ä¢ Coreset extraction (?)']","['<1-hop>\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy eÔ¨Éciency using static code analysis.\n‚Ä¢ We don‚Äôt need an accurate value.\n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.\n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27', '<2-hop>\n\nWhy?\n‚Ä¢ Throughout your career you might:\n‚Ä¢ Design/maintain/contract data centers\n‚Ä¢ Set up operations/devops\n‚Ä¢ Develop AI for IoT devices\n‚Ä¢ Be the next CEO/CTO of a software company\n‚Ä¢ Sustainability can be your main role:\n‚Ä¢ Green Software Developer\n‚Ä¢ Sustainability Consultant\n‚Ä¢ Green Advocate \n‚Ä¢ Founder of a Green Tech startup (B2B?)\n28', '<1-hop>\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy eÔ¨Éciency using static code analysis.\n‚Ä¢ We don‚Äôt need an accurate value.\n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.\n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27', '<2-hop>\n\nWhy?\n‚Ä¢ Throughout your career you might:\n‚Ä¢ Design/maintain/contract data centers\n‚Ä¢ Set up operations/devops\n‚Ä¢ Develop AI for IoT devices\n‚Ä¢ Be the next CEO/CTO of a software company\n‚Ä¢ Sustainability can be your main role:\n‚Ä¢ Green Software Developer\n‚Ä¢ Sustainability Consultant\n‚Ä¢ Green Advocate \n‚Ä¢ Founder of a Green Tech startup (B2B?)\n28', '<1-hop>\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy eÔ¨Éciency using static code analysis.\n‚Ä¢ We don‚Äôt need an accurate value.\n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.\n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27', '<2-hop>\n\nWhy?\n‚Ä¢ Throughout your career you might:\n‚Ä¢ Design/maintain/contract data centers\n‚Ä¢ Set up operations/devops\n‚Ä¢ Develop AI for IoT devices\n‚Ä¢ Be the next CEO/CTO of a software company\n‚Ä¢ Sustainability can be your main role:\n‚Ä¢ Green Software Developer\n‚Ä¢ Sustainability Consultant\n‚Ä¢ Green Advocate \n‚Ä¢ Founder of a Green Tech startup (B2B?)\n28', '<1-hop>\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy eÔ¨Éciency using static code analysis.\n‚Ä¢ We don‚Äôt need an accurate value.\n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.\n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27', '<2-hop>\n\nWhy?\n‚Ä¢ Throughout your career you might:\n‚Ä¢ Design/maintain/contract data centers\n‚Ä¢ Set up operations/devops\n‚Ä¢ Develop AI for IoT devices\n‚Ä¢ Be the next CEO/CTO of a software company\n‚Ä¢ Sustainability can be your main role:\n‚Ä¢ Green Software Developer\n‚Ä¢ Sustainability Consultant\n‚Ä¢ Green Advocate \n‚Ä¢ Founder of a Green Tech startup (B2B?)\n28']","Static code analysis in data science can improve the energy efficiency of data centers and contribute to sustainable software engineering in several ways:

1. **Optimizing Code for Efficiency**: Static analysis tools can identify inefficient code patterns that consume more energy. By optimizing these patterns, developers can reduce the energy consumption of software applications.

2. **Reducing Redundant Computations**: Static analysis can detect redundant computations or unnecessary data processing steps, allowing developers to streamline code execution and reduce energy usage.

3. **Improving Resource Management**: By analyzing code, static analysis tools can suggest better resource management practices, such as efficient memory usage and optimal data storage solutions, which can lead to lower energy consumption.

4. **Identifying Energy-Intensive Operations**: Static analysis can highlight operations that are particularly energy-intensive, enabling developers to refactor or replace them with more energy-efficient alternatives.

5. **Guiding Data-Centric Improvements**: As mentioned in the sources, improving data collection, labeling, and preprocessing can contribute to energy efficiency. Static analysis can help ensure that data handling in software is optimized for minimal energy use.

By incorporating static code analysis into the software development lifecycle, data centers can achieve more energy-efficient operations, aligning with the goals of sustainable software engineering.","Static code analysis in data science can be used to estimate energy efficiency by identifying potential energy hotspots in the code. This helps in reviewing and optimizing the code to reduce energy consumption. By applying this approach, developers can contribute to the design and maintenance of more energy-efficient data centers, aligning with sustainable software engineering practices.",0.9999999999,0.6666666666666666,1.0,0.88,0.0,0.9831639478086864
How can static code analysis in data science contribute to the development of more sustainable data centers?,"['Debugging Energy with \nDocker Images\n\nUnveiling the Energy Vampires \nA methodology for debugging Software \nEnergy Consumption\n ‚úÖ ICSE 2025\n\nData Centers and Docker\n‚Ä¢ Containers are the most popular way to deploy apps into the cloud \n‚Ä¢ Base image is an important choice when building an image \n‚Ä¢ Criteria \n‚Ä¢ Linux distribution and binaries \n‚Ä¢ Image size \n‚Ä¢ Energy?', '‚Ä¢ Libraries for stats? ML? Web Dev? Cloud?\n\nC5. Add energy-awareness to existing software\n26\n‚Ä¢ Streamlit, Notebooks, JSFiddle, \nPyScript, zsh, etc. \n‚Ä¢\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy efficiency using static code analysis. \n‚Ä¢ We don‚Äôt need an accurate value. \n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.', '19\n(?)\n\nResults: energy consumption of algorithms\n\nResults: energy vs data shape\n\nResults: performance vs data shape\n\nDiscussion\n‚Ä¢ Other data properties should be investigated. \n‚Ä¢ E.g., data types \n‚Ä¢ Reporting energy data is essential. It can lead to different model selection \nwithout hindering model performance. \n‚Ä¢ There is a big opportunity in Model and Data Simplification.\n23\n\nData/Model Simplification\n‚Ä¢ (?) \n‚Ä¢ Data selection \n‚Ä¢ Data quantisation. Posit? \n‚Ä¢ Data distillation \n‚Ä¢ Coreset extraction (?)']","['<1-hop>\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy eÔ¨Éciency using static code analysis.\n‚Ä¢ We don‚Äôt need an accurate value.\n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.\n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27', '<2-hop>\n\nWhy?\n‚Ä¢ Throughout your career you might:\n‚Ä¢ Design/maintain/contract data centers\n‚Ä¢ Set up operations/devops\n‚Ä¢ Develop AI for IoT devices\n‚Ä¢ Be the next CEO/CTO of a software company\n‚Ä¢ Sustainability can be your main role:\n‚Ä¢ Green Software Developer\n‚Ä¢ Sustainability Consultant\n‚Ä¢ Green Advocate \n‚Ä¢ Founder of a Green Tech startup (B2B?)\n28']","Static code analysis can contribute to the development of more sustainable data centers by estimating energy efficiency. This process helps identify which parts of the code are more likely to introduce energy hotspots. By reviewing and optimizing these areas, developers can reduce the energy consumption of their applications, leading to more energy-efficient software deployments in data centers. This approach aligns with the ""Green Shift Left"" methodology, which emphasizes the importance of considering energy efficiency early in the software development process.","Static code analysis in data science can contribute to the development of more sustainable data centers by estimating energy efficiency and identifying potential energy hotspots within the code. This approach allows developers to focus on reviewing code segments that are more likely to introduce inefficiencies, thereby optimizing resource usage. By integrating such practices, especially in domains like data science, developers can help create more sustainable solutions, which aligns with broader career goals in sustainability, such as designing or maintaining energy-efficient data centers.",0.49999999995,0.6666666666666666,1.0,0.67,0.0,0.9846241457649475
How can static code analysis in data science projects help in designing more sustainablility-focused data centers?,"['‚Ä¢ Libraries for stats? ML? Web Dev? Cloud?\n\nC5. Add energy-awareness to existing software\n26\n‚Ä¢ Streamlit, Notebooks, JSFiddle, \nPyScript, zsh, etc. \n‚Ä¢\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy efficiency using static code analysis. \n‚Ä¢ We don‚Äôt need an accurate value. \n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.', 'Green Architectural Tactics for ML-Enabled \nSystem\n38\nICSE-SEIS 2024\n\nArchitectural tactics\n39\n\nData-centric\n40\n‚Ä¢ Reduce data size \n‚Ä¢ Sampling \n‚Ä¢ Dimensionality reduction \n‚Ä¢ Quantization\n\nAlgorithm Design\n41\n‚Ä¢ Carefully select your algorithm \n‚Ä¢ You don‚Äôt need the fanciest \ntechniques\n\nModel Optimization\n42\n‚Ä¢ Add energy to training parameters \n‚Ä¢ Reduce FLOPs \n‚Ä¢ Pruning,', '‚Ä¢ Energy/Power is more useful at the software usecase level. \n‚Ä¢ Carbon is more useful at the infrastructure level (e.g., datacenter) or at the \nproject level (e.g., the impact of developing a full software project). \n‚Ä¢ Choose your metrics wisely ;)\n26\n\n‚Ä¢ Carbon emissions ‚úÖ \n‚Ä¢ How do we go from energy consumption to carbon consumption?\n27\n\nCarbon intensity\n‚Ä¢ How much carbon is emitted per kWh of electricity consumed. \n‚Ä¢ The common unit: \n ü§∑ \n‚Ä¢ E.g.,  gas-based power plants emit less carbon than coal-based plants.']","['<1-hop>\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy eÔ¨Éciency using static code analysis.\n‚Ä¢ We don‚Äôt need an accurate value.\n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.\n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27', '<2-hop>\n\nWhy?\n‚Ä¢ Throughout your career you might:\n‚Ä¢ Design/maintain/contract data centers\n‚Ä¢ Set up operations/devops\n‚Ä¢ Develop AI for IoT devices\n‚Ä¢ Be the next CEO/CTO of a software company\n‚Ä¢ Sustainability can be your main role:\n‚Ä¢ Green Software Developer\n‚Ä¢ Sustainability Consultant\n‚Ä¢ Green Advocate \n‚Ä¢ Founder of a Green Tech startup (B2B?)\n28', '<1-hop>\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy eÔ¨Éciency using static code analysis.\n‚Ä¢ We don‚Äôt need an accurate value.\n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.\n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27', '<2-hop>\n\nWhy?\n‚Ä¢ Throughout your career you might:\n‚Ä¢ Design/maintain/contract data centers\n‚Ä¢ Set up operations/devops\n‚Ä¢ Develop AI for IoT devices\n‚Ä¢ Be the next CEO/CTO of a software company\n‚Ä¢ Sustainability can be your main role:\n‚Ä¢ Green Software Developer\n‚Ä¢ Sustainability Consultant\n‚Ä¢ Green Advocate \n‚Ä¢ Founder of a Green Tech startup (B2B?)\n28', '<1-hop>\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy eÔ¨Éciency using static code analysis.\n‚Ä¢ We don‚Äôt need an accurate value.\n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.\n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27', '<2-hop>\n\nWhy?\n‚Ä¢ Throughout your career you might:\n‚Ä¢ Design/maintain/contract data centers\n‚Ä¢ Set up operations/devops\n‚Ä¢ Develop AI for IoT devices\n‚Ä¢ Be the next CEO/CTO of a software company\n‚Ä¢ Sustainability can be your main role:\n‚Ä¢ Green Software Developer\n‚Ä¢ Sustainability Consultant\n‚Ä¢ Green Advocate \n‚Ä¢ Founder of a Green Tech startup (B2B?)\n28']","Static code analysis in data science projects can help in designing more sustainability-focused data centers by identifying parts of the code that are likely to introduce energy hotspots. By estimating energy efficiency through static code analysis, developers can pinpoint inefficient code segments that may lead to higher energy consumption. This allows for targeted optimization efforts, reducing the overall energy demand of software applications. Consequently, this can lead to more efficient use of resources in data centers, contributing to their sustainability by lowering energy consumption and, indirectly, carbon emissions.","Static code analysis in data science projects can help in designing more sustainablility-focused data centers by identifying energy hotspots in the code. This allows developers to review and optimize code that may contribute to higher energy consumption, thereby supporting the development of more efficient and sustainable data centers.",0.9999999999,1.0,0.3,0.86,0.12499999984374999,0.9683760004857153
How does the use of static code analysis in data science projects contribute to the design and optimization of more sustanable data centers?,"['‚Ä¢ Libraries for stats? ML? Web Dev? Cloud?\n\nC5. Add energy-awareness to existing software\n26\n‚Ä¢ Streamlit, Notebooks, JSFiddle, \nPyScript, zsh, etc. \n‚Ä¢\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy efficiency using static code analysis. \n‚Ä¢ We don‚Äôt need an accurate value. \n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.', '‚Ä¢ DeepSeek-V3 claims ‚Äúonly‚Äù 2.78M GPU hours \n‚Ä¢ Bloom by Huggingface reports 25 tons, 51 when considering embodied \nand operational carbon footprint. (176billion params)\n9\n\nRed AI\nAccuracy: 0.999999999\nGreen AI\n‚Ä¢ Energy \n‚Ä¢ Time \n‚Ä¢ Reproducibility \n‚Ä¢ Reusage\n\nHow can we adopt Green AI\n‚Ä¢ Check whether AI is needed. \n‚Ä¢ Select green datacenters. \n‚Ä¢ Run on low carbon intensity hours. \n‚Ä¢ Opt for GPU-optimised solutions (?)', 'Energy profiling of static analysis tools\n‚Ä¢ What is the energy consumption of a ""typical run"" for a few OSS projects? \n‚Ä¢ Does the type of analysis matter? Are certain analysis more expensive? Does \nthe number of rules that are activated in a static analysis tool important for the \nenergy consumption? \n‚Ä¢ Differences between static analysis tools [lower priority]\n\nB5.']","['<1-hop>\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy eÔ¨Éciency using static code analysis.\n‚Ä¢ We don‚Äôt need an accurate value.\n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.\n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27', '<2-hop>\n\nWhy?\n‚Ä¢ Throughout your career you might:\n‚Ä¢ Design/maintain/contract data centers\n‚Ä¢ Set up operations/devops\n‚Ä¢ Develop AI for IoT devices\n‚Ä¢ Be the next CEO/CTO of a software company\n‚Ä¢ Sustainability can be your main role:\n‚Ä¢ Green Software Developer\n‚Ä¢ Sustainability Consultant\n‚Ä¢ Green Advocate \n‚Ä¢ Founder of a Green Tech startup (B2B?)\n28', '<1-hop>\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy eÔ¨Éciency using static code analysis.\n‚Ä¢ We don‚Äôt need an accurate value.\n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.\n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27', '<2-hop>\n\nWhy?\n‚Ä¢ Throughout your career you might:\n‚Ä¢ Design/maintain/contract data centers\n‚Ä¢ Set up operations/devops\n‚Ä¢ Develop AI for IoT devices\n‚Ä¢ Be the next CEO/CTO of a software company\n‚Ä¢ Sustainability can be your main role:\n‚Ä¢ Green Software Developer\n‚Ä¢ Sustainability Consultant\n‚Ä¢ Green Advocate \n‚Ä¢ Founder of a Green Tech startup (B2B?)\n28']","The use of static code analysis in data science projects can contribute to the design and optimization of more sustainable data centers by identifying energy hotspots in the code. By estimating energy efficiency through static code analysis, developers can pinpoint which parts of the code are likely to consume more energy and should be reviewed more attentively. This process doesn't require precise energy values but helps in identifying areas that could be optimized to reduce energy consumption. Consequently, optimizing these areas can lead to more efficient use of resources in data centers, thereby contributing to sustainability efforts.","The use of static code analysis in data science projects contributes to the design and optimization of more sustainable data centers by identifying energy hotspots within the code. This process allows developers to focus on reviewing and optimizing sections of code that are more likely to introduce energy inefficiencies. By doing so, it supports the broader goal of creating more energy-efficient systems, which is crucial for the sustainable operation of data centers. This approach aligns with the growing need for green software development practices, where professionals can play roles such as green software developers or sustainability consultants, ensuring that energy efficiency is a key consideration throughout the software lifecycle.",0.9999999999,0.75,0.9,0.67,0.08333333326388888,0.9801163369424023
How reduce risk and reduce size in software engineering?,"['Green Architectural Tactics for ML-Enabled \nSystem\n38\nICSE-SEIS 2024\n\nArchitectural tactics\n39\n\nData-centric\n40\n‚Ä¢ Reduce data size \n‚Ä¢ Sampling \n‚Ä¢ Dimensionality reduction \n‚Ä¢ Quantization\n\nAlgorithm Design\n41\n‚Ä¢ Carefully select your algorithm \n‚Ä¢ You don‚Äôt need the fanciest \ntechniques\n\nModel Optimization\n42\n‚Ä¢ Add energy to training parameters \n‚Ä¢ Reduce FLOPs \n‚Ä¢ Pruning, sparsity \n‚Ä¢  Take advantage of existing models\n\nModel Training\n43\n‚Ä¢ Quantization\n‚Ä¢ SAVE TRAINING PROGRESS\n\nModel Deployment\n44\n‚Ä¢ Distributed deployment \n‚Ä¢ Energy efficient hardware and \nconfigurations\n\nModel Management\n45\n‚Ä¢ Reuse the model as much as possible \n\nRethinking the Architecture: Spiking Neural Networks\n46\n\nRethinking the Architecture: Spiking Neural Networks\n47\n\nSELF Lab\n48\n\nrecap\n\n\nLu√≠s Cruz \nL.Cruz@tudelft.nl \n10. Project 2\nSustainable Software Engineering\u2028\nCS4575\nSustainableSE 2025\nCarolin Brandt \nC.E.Brandt@tudelft.nl \nEnrique Barba Roque \nE.BarbaRoque@tudelft.nl\n\n1. Goal/assignment \n2. Deliverables \n3. Strategy \n4. Ideas\n\nAssignment\n‚Ä¢ Goal: Solve a Sustainable Software Engineering problem. \n‚Ä¢ Identify 1 problem that should be fixed to help enabling sustainability in \nthe software engineering industry/community. \n‚Ä¢ Propose a solution. A tool, framework, guidelines, etc. \n‚Ä¢ Implementation. \n‚Ä¢ Validation. (Depending on the idea) \n‚Ä¢ Dissemination/social impact. (Solution should be open source, welcome \ncontributors, post on social media? Tool website? Available in a package \nmanager?)\n3\n\nDeliverables\n‚Ä¢ Paper-like article. (Min 4 pages, max 10) \n‚Ä¢ Online git repo with open source codebase and/or replication package. \n‚Ä¢ Presentation: 5 min + 5min Q&A\n4\n\nArticle\n‚Ä¢ Different projects will have different expectations -> Make agreements with \nyour coach. \n‚Ä¢ Some projects are more technical and some projects more theoretical. \n‚Ä¢ Common requirements: \n‚Ä¢ Motivation, formulation of the problem being addressed, etc. \n‚Ä¢ Description of the solution.', 'Energy Efficiency vs Code \nQuality\n\nMeasuring Maintainability\n‚Ä¢ According to ISO/IEC 25010, Maintainability is ‚Äúthe degree of \neffectiveness and efficiency with which a software product or \nsystem can be modified to improve it, correct it or adapt it to \nchanges in environment, and in requirements‚Äù \n‚Ä¢ We use the code analysis tool Better Code Hub to assess \nmaintainability \n‚Ä¢ Better Code Hub maps the ISO/IEC 25010 standard on \nmaintainability into a set of guidelines derived from static analysis\n46\n\nMaintainability of Energy Changes\n‚Ä¢ What is the impact of making energy-oriented code changes on \nthe maintainability of mobile apps? \nMaintainability \nDifference \nvE-2\nvE-1\nvE\nEnergy \nCommit\nvE+1\nM(vE-1)\nM(vE)\nParent \nCommit\n‚àÜM\n47\n\nThreshold Marks\n48\n\nBetter Code Hub\nMaintainability\nCombine\ndatasets\nEnergy\nCommits\nBaseline\nCommits\nBao et al. \n(2015)\nMoura et al. \n(2016)\nCruz et al. \n(2018)\nCruz et al. \n(2019)\nEnergy Code Changes \nDataset\n539 commits\u2028\nfrom 306 mobile apps\n539 baseline commits\u2028\nfrom 306 mobile apps\n49\n\nImpact of energy changes on \nmaintainability\n50\n\nWhich energy \npatterns are more \nlikely to affect \nmaintainability?\n51\n\nTypical maintainability issue I\nhttps://github.com/einmalfel/PodListen/commit/2ed5a65\n4 changed files with 28 additions and 0 deletions.\n‚Ä¶\n‚Ä¶\n52\n\nTypical maintainability issue II\nhttps://github.com/mozilla/MozStumbler/commit/6ea0268\n5 changed files with 66 additions and 14 deletions.\n53\n\n54', 'Carolin Brandt \nC.E.Brandt@tudelft.nl \nLu√≠s Cruz \nL.Cruz@tudelft.nl \n1. Intro Class\nSustainable Software Engineering\u2028\nCS4575\nSustainableSE 2025\nEnrique Barba Roque \nE.BarbaRoque@tudelft.nl\n\n1. Intro to Sustainable SE \n2. Intro to the course\n2\n\nof the electricity consumed worldwide \nby 2040 will stem from ICT\n14%\n\n4\nhttps://xkcd.com/1007/\n\nBuzz words\n‚Ä¢ Eco-friendly \n‚Ä¢ Climate change, action, adaption \n‚Ä¢ Energy efficiency \n‚Ä¢ Environmental-responsible \n‚Ä¢ Carbon-neutral; Climate-neutral; Net zero \n‚Ä¢ Carbon-offsetting \n‚Ä¢ Carbon-free \n‚Ä¢ Clean technology \n‚Ä¢ E-waste\n5\n\nhttps://www.menti.com/uns9d89kzn\nWhat is Sustainable \nSoftware Engineering?\n?\n6\n\nSustainable Software \nEngineering is‚Ä¶\n7\n‚Ä¶the discipline that studies the process of creating software systems that are able \nto create value in the long term without hindering its surrounding environment.\n\n8\nEconomical\nSocial\nTechnical\nIndividual\nEnvironmental\nSustainable\nSoftware\nEngineering\n‚≠ê\nTechnical\u2028\n‚öô\nEconomical\u2028\nüí∞\nSocial\u2028\nüë©üíºüë®üíºüë©üíºüë©üíº\nIndividual\u2028\nüë©üíª\nEnvironmental\u2028\nüå±\nSustainable\u2028\nSoftware \nEngineering\n\nEconomical\n‚Ä¢ Focused on assets, capital and added value\u2028\n(wealth creation, prosperity, profitability, capital \ninvestment, income, etc.) \n‚Ä¢ Nr of customers  \n‚Ä¢ Man-day-rate estimate \n‚Ä¢ Next round of funding \n‚Ä¢ Meet requirements in the contract\n9\n\nTechnical\n‚Ä¢ Longevity of information, systems, and infrastructure and their \nadequate evolution with changing surrounding conditions. \n‚Ä¢ Examples: \n‚Ä¢ Technical Debt \n‚Ä¢ Does it scale? \n‚Ä¢ Software testing \n‚Ä¢ Bus-factor \n‚Ä¢ Data integrity \n‚Ä¢ Innovation \n‚Ä¢ ‚Ä¶\n10\n\nIndividual\n‚Ä¢ Well-being of the individuals in an organisation.\u2028\nNote that it also includes how well individuals interact \nwith each other within the org.']","['<1-hop>\n\nShuffle \nüîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them.\n‚Ä¢ If you run 30 executions for version A and another batch for version B:\n‚Ä¢ External conditions that change over time will have a diÔ¨Äerent bias in \nthe 2 versions (e.g., room temperature changes).\n‚Ä¢ If you shuÔ¨Ñe, you reduce this risk.\n11', '<2-hop>\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio)\n‚Ä¢ Dynamic Retry Delay\n‚Ä¢ Push Over Poll\n‚Ä¢ Reduce Size\n‚Ä¢ Cache\n‚Ä¢ Avoid Graphics and Animations\n20', '<1-hop>\n\nShuffle \nüîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them.\n‚Ä¢ If you run 30 executions for version A and another batch for version B:\n‚Ä¢ External conditions that change over time will have a diÔ¨Äerent bias in \nthe 2 versions (e.g., room temperature changes).\n‚Ä¢ If you shuÔ¨Ñe, you reduce this risk.\n11', '<2-hop>\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio)\n‚Ä¢ Dynamic Retry Delay\n‚Ä¢ Push Over Poll\n‚Ä¢ Reduce Size\n‚Ä¢ Cache\n‚Ä¢ Avoid Graphics and Animations\n20']","To reduce risk and reduce size in software engineering, you can employ several strategies:

1. **Reduce Data Size**: Implement data-centric tactics such as sampling, dimensionality reduction, and quantization to minimize the amount of data processed and stored.

2. **Algorithm Design**: Carefully select algorithms that are efficient and effective without being unnecessarily complex. Avoid using the most complex techniques if simpler ones suffice.

3. **Model Optimization**: Optimize models by reducing the number of floating-point operations (FLOPs), using pruning and sparsity techniques, and leveraging existing models to avoid redundant work.

4. **Model Training**: Use quantization and save training progress to prevent unnecessary re-computation and reduce the computational load.

5. **Model Deployment**: Deploy models in a distributed manner and use energy-efficient hardware configurations to minimize resource usage.

By implementing these tactics, you can effectively reduce both the risk and size of software systems, leading to more sustainable and efficient software engineering practices.","To reduce risk, shuffling executions helps control external factors like temperature changes. To reduce size, EcoAndroid uses features like dynamic retry delay and push over poll.",0.0,0.0,0.8571428571428571,0.0,0.0,0.980885315377629
How shuffling reduce risk and EcoAndroid reduce size?,"['‚Ä¢ When a connection is not possible, the app automatically retries later. \n‚Ä¢ https://github.com/k9mail/k-9/commit/\n86f3b28f79509d1a4d613eb39f60603e08579ea3\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio) \n‚Ä¢ Dynamic Retry Delay \n‚Ä¢ Push Over Poll \n‚Ä¢ Reduce Size \n‚Ä¢ Cache \n‚Ä¢ Avoid Graphics and Animations\n20\n\nCarbon-Aware Computing for \nDatacenters \nhttps://sites.google.com/view/energy-efficiency-languages\n21\nAna Radovanovic ÃÅ,', '*/\n6028 \nchanges\n\nThematic Analysis\n1. Familiarization with data \n2. Generating initial labels \n3. Reviewing themes\n4. Defining and naming themes\n\n‚Ä¢ Energy Pattern: design pattern to improve energy efficiency.. \n‚Ä¢ 22 energy patterns. \n‚Ä¢ Each pattern is described by Context, Solution, Example, References from \nliterature, and Occurences (links to code changes from git repositories).\n8\n\nhttps://tqrg.github.io/energy-patterns\n\nDark UI Colors \nProvide a dark UI color theme to \nsave battery on devices with \nAMOLED screens.\n‚Ä¢ Context: [‚Ä¶] Apps that require heavy usage of screen can \nhave a substantial negative impact on battery life. \n‚Ä¢ Solution: Provide a UI theme with dark background colors. [‚Ä¶]\n‚Ä¢ Example: In a reading app, provide a theme with a dark \nbackground using light colors to display text. [‚Ä¶] \n10\n\nDark UI Colors \nProvide a dark UI color theme to \nsave battery on devices with \nAMOLED screens.\n‚Ä¢ Context: [‚Ä¶] Apps that require heavy usage of screen can \nhave a substantial negative impact on battery life. \n‚Ä¢ Solution: Provide a UI theme with dark background colors. [‚Ä¶]\n‚Ä¢ Example: In a reading app, provide a theme with a dark \nbackground using light colors to display text. [‚Ä¶] \n11\n\nDynamic Retry Delay\n‚Ä¢ Context: [‚Ä¶] In a mobile app, when a given resource is \nunavailable, the app will unnecessarily try to connect the resource \nfor a number of times, leading to unnecessary power consumption. \n‚Ä¢ Solution: Increase retry interval after each failed connection. [‚Ä¶]\n‚Ä¢ Example: Consider a mobile app that provides a news feed and \nthe app is not able to reach the server to collect updates. [‚Ä¶] use \nthe Fibonacci series to increase the time between attempts.\nWhenever an attempt to access a \nresource fails, increase the time \ninterval before retrying.\n12\n\nBatch Operations \n‚Ä¢ Context: Executing operations separately leads to extraneous \ntail energy consumptions  \n‚Ä¢ Solution: Bundle multiple operations in a single one. [‚Ä¶]\n‚Ä¢ Example: Use system provided APIs to schedule background \ntasks. These APIs, guarantee that device will exit sleep mode \nonly when there is a reasonable amount of work to do or when a \ngiven task is urgent. [‚Ä¶]\n13\n\nAvoid Extraneous Graphics and \nAnimations  \n‚Ä¢ Context: Mobile apps that feature impressive graphics \nand animations.', '19\n(?)\n\nResults: energy consumption of algorithms\n\nResults: energy vs data shape\n\nResults: performance vs data shape\n\nDiscussion\n‚Ä¢ Other data properties should be investigated. \n‚Ä¢ E.g., data types \n‚Ä¢ Reporting energy data is essential. It can lead to different model selection \nwithout hindering model performance. \n‚Ä¢ There is a big opportunity in Model and Data Simplification.\n23\n\nData/Model Simplification\n‚Ä¢ (?) \n‚Ä¢ Data selection \n‚Ä¢ Data quantisation. Posit? \n‚Ä¢ Data distillation \n‚Ä¢ Coreset extraction (?)']","['<1-hop>\n\nShuffle \nüîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them.\n‚Ä¢ If you run 30 executions for version A and another batch for version B:\n‚Ä¢ External conditions that change over time will have a diÔ¨Äerent bias in \nthe 2 versions (e.g., room temperature changes).\n‚Ä¢ If you shuÔ¨Ñe, you reduce this risk.\n11', '<2-hop>\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio)\n‚Ä¢ Dynamic Retry Delay\n‚Ä¢ Push Over Poll\n‚Ä¢ Reduce Size\n‚Ä¢ Cache\n‚Ä¢ Avoid Graphics and Animations\n20', '<1-hop>\n\nShuffle \nüîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them.\n‚Ä¢ If you run 30 executions for version A and another batch for version B:\n‚Ä¢ External conditions that change over time will have a diÔ¨Äerent bias in \nthe 2 versions (e.g., room temperature changes).\n‚Ä¢ If you shuÔ¨Ñe, you reduce this risk.\n11', '<2-hop>\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio)\n‚Ä¢ Dynamic Retry Delay\n‚Ä¢ Push Over Poll\n‚Ä¢ Reduce Size\n‚Ä¢ Cache\n‚Ä¢ Avoid Graphics and Animations\n20', '<1-hop>\n\nShuffle \nüîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them.\n‚Ä¢ If you run 30 executions for version A and another batch for version B:\n‚Ä¢ External conditions that change over time will have a diÔ¨Äerent bias in \nthe 2 versions (e.g., room temperature changes).\n‚Ä¢ If you shuÔ¨Ñe, you reduce this risk.\n11', '<2-hop>\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio)\n‚Ä¢ Dynamic Retry Delay\n‚Ä¢ Push Over Poll\n‚Ä¢ Reduce Size\n‚Ä¢ Cache\n‚Ä¢ Avoid Graphics and Animations\n20']","The sources provided do not specifically mention how shuffling reduces risk or how EcoAndroid reduces size. However, based on general knowledge:

1. **Shuffling to Reduce Risk**: In the context of data processing or machine learning, shuffling data can help reduce the risk of overfitting by ensuring that the model does not learn the order of the data, which might contain patterns not representative of the general data distribution.

2. **EcoAndroid Reducing Size**: EcoAndroid likely reduces size by optimizing the app's code and resources, possibly by avoiding unnecessary graphics and animations, caching data efficiently, and using other techniques to minimize the app's footprint on the device. This can lead to reduced energy consumption and better performance on mobile devices.",Shuffling reduce risk by controlling external factors like room temperature changes. EcoAndroid reduce size by using features like caching and avoiding graphics and animations.,0.0,0.5,0.5,0.33,0.16666666638888888,0.0
How shuffling reduce risk when compare to EcoAndroid reduce size?,"['‚Ä¢ When a connection is not possible, the app automatically retries later. \n‚Ä¢ https://github.com/k9mail/k-9/commit/\n86f3b28f79509d1a4d613eb39f60603e08579ea3\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio) \n‚Ä¢ Dynamic Retry Delay \n‚Ä¢ Push Over Poll \n‚Ä¢ Reduce Size \n‚Ä¢ Cache \n‚Ä¢ Avoid Graphics and Animations\n20\n\nCarbon-Aware Computing for \nDatacenters \nhttps://sites.google.com/view/energy-efficiency-languages\n21\nAna Radovanovic ÃÅ,', 'Green Architectural Tactics for ML-Enabled \nSystem\n38\nICSE-SEIS 2024\n\nArchitectural tactics\n39\n\nData-centric\n40\n‚Ä¢ Reduce data size \n‚Ä¢ Sampling \n‚Ä¢ Dimensionality reduction \n‚Ä¢ Quantization\n\nAlgorithm Design\n41\n‚Ä¢ Carefully select your algorithm \n‚Ä¢ You don‚Äôt need the fanciest \ntechniques\n\nModel Optimization\n42\n‚Ä¢ Add energy to training parameters \n‚Ä¢ Reduce FLOPs \n‚Ä¢ Pruning,', '[‚Ä¶] \n‚Ä¢ Solution: Study the importance of graphics and \nanimations to the user experience and reduce them when \napplicable. [‚Ä¶]\n‚Ä¢ Example: Resort to low frame rates for animations when \npossible. \nDespite being important to improve user experience, graphics \nand animations are battery intensive and should be used with \nmoderation.  \n14\n\nEnergy Patterns are \nmore Frequent\nin Android Apps\n\nExample case: Nextcloud\nFOSS\n\nExample case: Nextcloud\n‚Ä¢ Users complain that sometimes they go on a trip and  Nextcloud drains their \nbattery. Users consider uninstalling the app when battery life is essential. \n‚Ä¢ File sync can be energy-greedy. Send large files to the server, long 3G/4G data connections. \n‚Ä¢ It is mostly used for backup. No real-time collaboration is needed. \n‚Ä¢ Energy requirements vary depending on context and user. Some days you really \nneed all the battery you can get. \n‚Ä¢ https://github.com/nextcloud/android/commit/\n8bc432027e0d33e8043cf40192203203a40ca29c\nSolutions?\n17\n\nExample case: K-9 mail\n18\n\nExample case: K-9 mail\n19\nSolutions?\n‚Ä¢ Some users noticed that K-9 mail was spending more energy than usual. üôâ \n‚Ä¢ A user that was having issues with a personal mail server  noticed that K-9 \nmail was the one of the most energy-greedy apps. IMAP IDLE protocol for real-time \nnotifications. \n‚Ä¢ When a connection is not possible, the app automatically retries later.']","['<1-hop>\n\nShuffle \nüîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them.\n‚Ä¢ If you run 30 executions for version A and another batch for version B:\n‚Ä¢ External conditions that change over time will have a diÔ¨Äerent bias in \nthe 2 versions (e.g., room temperature changes).\n‚Ä¢ If you shuÔ¨Ñe, you reduce this risk.\n11', '<2-hop>\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio)\n‚Ä¢ Dynamic Retry Delay\n‚Ä¢ Push Over Poll\n‚Ä¢ Reduce Size\n‚Ä¢ Cache\n‚Ä¢ Avoid Graphics and Animations\n20']","The provided sources do not mention ""shuffling"" in the context of reducing risk, nor do they provide a direct comparison between shuffling and EcoAndroid's tactic of reducing size. However, in general terms, shuffling data can help in reducing risk by ensuring that data is not processed or stored in a predictable order, which can enhance security and privacy. On the other hand, EcoAndroid's tactic of reducing size focuses on minimizing resource usage, such as memory and processing power, which can lead to improved energy efficiency and performance. Both tactics aim to optimize different aspects of system performance and security.",Shuffling reduce risk by balance external factor like room temperature change while EcoAndroid reduce size by optimize resource use.,0.0,0.5,0.5714285714285714,0.67,0.249999999375,0.0
How shuffling reduce risk when reduce size in software engineering?,"['‚Ä¢ If you run 30 executions for version A and another batch for version B: \n‚Ä¢ External conditions that change over time will have a different bias in \nthe 2 versions (e.g., room temperature changes). \n‚Ä¢ If you shuffle, you reduce this risk.\n11\n\nKeep it cool üå°\n‚Ä¢ Always make sure there is a stable room temperature. \n‚Ä¢ Tricky because, some times, experiments may have to run over a few days. \n‚Ä¢ If you cannot control room temperature: collect temperature data and filter \nout measurements where the room temperature is clearly deviating.', 'Green Architectural Tactics for ML-Enabled \nSystem\n38\nICSE-SEIS 2024\n\nArchitectural tactics\n39\n\nData-centric\n40\n‚Ä¢ Reduce data size \n‚Ä¢ Sampling \n‚Ä¢ Dimensionality reduction \n‚Ä¢ Quantization\n\nAlgorithm Design\n41\n‚Ä¢ Carefully select your algorithm \n‚Ä¢ You don‚Äôt need the fanciest \ntechniques\n\nModel Optimization\n42\n‚Ä¢ Add energy to training parameters \n‚Ä¢ Reduce FLOPs \n‚Ä¢ Pruning, sparsity \n‚Ä¢  Take advantage of existing models\n\nModel Training\n43\n‚Ä¢ Quantization\n‚Ä¢ SAVE TRAINING PROGRESS\n\nModel Deployment\n44\n‚Ä¢ Distributed deployment \n‚Ä¢ Energy efficient hardware and \nconfigurations\n\nModel Management\n45\n‚Ä¢ Reuse the model as much as possible \n\nRethinking the Architecture: Spiking Neural Networks\n46\n\nRethinking the Architecture: Spiking Neural Networks\n47\n\nSELF Lab\n48\n\nrecap\n\n\nLu√≠s Cruz \nL.Cruz@tudelft.nl \n10. Project 2\nSustainable Software Engineering\u2028\nCS4575\nSustainableSE 2025\nCarolin Brandt \nC.E.Brandt@tudelft.nl \nEnrique Barba Roque \nE.BarbaRoque@tudelft.nl\n\n1. Goal/assignment \n2. Deliverables \n3. Strategy \n4. Ideas\n\nAssignment\n‚Ä¢ Goal: Solve a Sustainable Software Engineering problem. \n‚Ä¢ Identify 1 problem that should be fixed to help enabling sustainability in \nthe software engineering industry/community. \n‚Ä¢ Propose a solution. A tool, framework, guidelines, etc. \n‚Ä¢ Implementation. \n‚Ä¢ Validation. (Depending on the idea) \n‚Ä¢ Dissemination/social impact. (Solution should be open source, welcome \ncontributors, post on social media? Tool website? Available in a package \nmanager?)\n3\n\nDeliverables\n‚Ä¢ Paper-like article. (Min 4 pages, max 10) \n‚Ä¢ Online git repo with open source codebase and/or replication package. \n‚Ä¢ Presentation: 5 min + 5min Q&A\n4\n\nArticle\n‚Ä¢ Different projects will have different expectations -> Make agreements with \nyour coach. \n‚Ä¢ Some projects are more technical and some projects more theoretical. \n‚Ä¢ Common requirements: \n‚Ä¢ Motivation, formulation of the problem being addressed, etc. \n‚Ä¢ Description of the solution.', '‚Ä¢ What is the impact of reducing data in the \nperformance of the model? \n‚Ä¢ Method -> results -> discussion\n17\n\nMethod\n‚Ä¢ Single object of study: natural language model to detect spam messages. \n‚Ä¢ 6 machine learning algorithms: SVM, Decision Tree, KNN, Random Forrest, \nAdaBoost, Bagging Classifier. \n‚Ä¢ Reduce the number of rows. 10%, 20%, .., 100% \n‚Ä¢ Stratified random sampling (?) \n‚Ä¢ Reduce the number of features.']","['<1-hop>\n\nShuffle \nüîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them.\n‚Ä¢ If you run 30 executions for version A and another batch for version B:\n‚Ä¢ External conditions that change over time will have a diÔ¨Äerent bias in \nthe 2 versions (e.g., room temperature changes).\n‚Ä¢ If you shuÔ¨Ñe, you reduce this risk.\n11', '<2-hop>\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio)\n‚Ä¢ Dynamic Retry Delay\n‚Ä¢ Push Over Poll\n‚Ä¢ Reduce Size\n‚Ä¢ Cache\n‚Ä¢ Avoid Graphics and Animations\n20', '<1-hop>\n\nShuffle \nüîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them.\n‚Ä¢ If you run 30 executions for version A and another batch for version B:\n‚Ä¢ External conditions that change over time will have a diÔ¨Äerent bias in \nthe 2 versions (e.g., room temperature changes).\n‚Ä¢ If you shuÔ¨Ñe, you reduce this risk.\n11', '<2-hop>\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio)\n‚Ä¢ Dynamic Retry Delay\n‚Ä¢ Push Over Poll\n‚Ä¢ Reduce Size\n‚Ä¢ Cache\n‚Ä¢ Avoid Graphics and Animations\n20']","Shuffling reduces risk by minimizing the impact of external conditions that may change over time, such as room temperature, which can introduce bias in different versions of an experiment. By shuffling, you ensure that these external factors are evenly distributed across all versions, thereby reducing the risk of biased results when reducing data size in software engineering experiments.","Shuffling reduce risk by controlling external factors like room temperature changes, which help in reducing size in software engineering.",0.0,0.0,0.5,0.0,0.0,0.9544273024077174
How spiking neural networks relate to McCulloch-Pitts model?,"['References\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947.', 'Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012).', 'https://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997.']","[""<1-hop>\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant"", '<2-hop>\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \n(not publicly available) doi:10.1037/h0042519\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568', ""<1-hop>\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant"", '<2-hop>\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \n(not publicly available) doi:10.1037/h0042519\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568', ""<1-hop>\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant"", '<2-hop>\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \n(not publicly available) doi:10.1037/h0042519\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568']","Spiking neural networks (SNNs) and the McCulloch-Pitts model both represent approaches to modeling neural activity, but they differ significantly in their complexity and biological realism.

The McCulloch-Pitts model, introduced in 1943, is a simplified mathematical model of a neuron that uses binary threshold units to simulate neural activity. It operates on the principle that neurons either fire or do not fire based on whether the weighted sum of their inputs exceeds a certain threshold (Source 1).

Spiking neural networks, on the other hand, are considered the third generation of neural network models and aim to more closely mimic the temporal dynamics of biological neurons. SNNs incorporate the concept of time into their operation, where neurons communicate by sending discrete spikes at particular points in time. This allows SNNs to capture the timing of spikes, which is crucial for understanding many neural processes (Source 8).

In summary, while the McCulloch-Pitts model provides a foundational framework for understanding neural computation, spiking neural networks offer a more detailed and biologically plausible representation by incorporating the temporal aspect of neural signaling.","Spiking neural networks relate to the McCulloch-Pitts model by building upon the foundational concepts of neural computation, where the McCulloch-Pitts model introduced the idea of binary neuron states, which is extended in spiking networks to model more complex information processing through spike timing and patterns.",0.0,1.0,0.8571428571428571,0.8,0.0,0.9397517533932936
How spiking neural networks used in encoding strategies?,"[""‚Ä¶ with energy costs reaching 200M USD!\n\nPower-efficiency at scale\nYour brain runs on:\n\nPower-efficiency at scale\nYour brain runs on:\nHigh estimate ~3000 kcal a day\n   ‚âà145 Watts\n* Human brain has ~600 trillion synapses \n(‚âàparameters).\n\nPower-efficiency at scale\nYour brain runs on:\nHigh estimate ~3000 kcal a day\n   ‚âà145 Watts\n* Human brain has ~600 trillion synapses \n(‚âàparameters).\nOversimplification\nThere are also multiple other advantages‚Ä¶\n\nHuman vs. computer computation\n- Fast real-time decision making, e.g. sports, e-sports\n- Adaptive, e.g. context-aware and employs selective attention\n- Energy efficient: Close to 100 billion neurons in the brain\n- Robust, for example to changes in illumination or obstructions in object tracking\n\nHuman vs. computer computation\nBrains are energy efficient: Why?\n1.\nHigh temporal resolution (more computation with less neurons)\n2.\nSparse encoding\n\nHuman vs. computer computation\nQuestions?\nBrains are energy efficient: Why?\n1.\nHigh temporal resolution (more computation with less neurons)\n2.\nSparse encoding\n\nHow do biological neurons communicate?\nAnalogy to artificial neural networks\nReal neuron\nArtificial neuron\nCurrent\n\nHow do biological neurons communicate?\nHow does the electrical activity propagate?\n?\nCurrent\n\nHow do biological neurons work?\ntime\nelectrode\nhttps://tinmard.github.io/spike-sorting-animation.html\nQuick electrical pulses trigger chemical signals for the next neuron ‚Üí Spikes\n\nHow do biological neurons work?\nQuick electrical pulses trigger chemical signals for the next neuron ‚Üí Spikes\nhttps://tinmard.github.io/spike-sorting-animation.html\ntime\nelectrode\nFrom CS perspective:\nSparse binary \nencoding\n\nBiologically realistic spiking neuron models\nBiologically realistic neuron models have \na new dimension: Time!\nSpiking neural networks (SNNs):\nThe input x  (t  ) to each neuron is summed \n(integrated) over time.\nscalar\nfunction of \ntime\n(t)\n(t)\nhttps://www.mdpi.com/2076-3425/12/7/863\n\nHow to model spiking neurons?\nANN: Perceptron, threshold activation function:\n\nHow to model spiking neurons?\nANN: Perceptron, threshold activation function:\n\nHow to model spiking neurons?\nSpiking neural network (SNN): The 'input current' Œµ(t) is integrated over time.\nspike\n\nHow to model spiking neurons?\nEquivalence to perceptron: Computation at least as complex as a perceptron.\n\nNon-leaky integrate-and-fire (IF) neuron\nThe temporal profile of the input current Œµ(t) can be chosen differently, for different computations.\n\nQuestions?\n\nComputation with spiking neurons\nCoincidence detection\n\nComputation with spiking neurons\nCoincidence detection\nx, y ‚àà {0, 1}n\nExample: n = 2\ninput = \nx1\nx2\ny1\ny2\n= \n0\n1\n1\n1\noutput? \n\nCoincidence detection\nComputation with spiking neurons\n\nCoincidence detection\nCan be trivially computed with a single spiking neuron! Requires at least n/log(n+1) hidden \nunits for a perceptron (proof in [7]).\nComputation with spiking neurons\n\nCoincidence detection\nCan be trivially computed with a single spiking neuron! Requires at least n/log(n+1) hidden \nunits for a perceptron (proof in [7]).\nBrains are energy efficient: \n1.\nHigh temporal resolution (more computation with less neurons)\nComputation with spiking neurons\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant\n\nFiring rates\nClassical view of the brain:\n- Each neuron is selective for one specific \nfeature in the input.\n- Higher firing rate (spikes per unit time) for \n'selected' feature.\nAdapted from Hubel & Wiesel, 1959\n\nFiring rates\nClassical view of the brain:\n- Each neuron is selective for one specific \nfeature in the input.\n- Higher firing rate (spikes per unit time) for \n'selected' feature.\n- Link to modern ANNs: The scalar output of \nan artificial neuron is interpreted as the firing \nrate.\nAdapted from Hubel & Wiesel, 1959\n\nFiring rates\nClassical view of the brain:\n- Each neuron is selective for one specific \nfeature in the input.\n- Higher firing rate (spikes per unit time) for \n'selected' feature.\n- Link to modern ANNs: The scalar output of \nan artificial neuron is interpreted as the firing \nrate.\nAdapted from Hubel & Wiesel, 1959\nBut rate coding is inefficient and slow‚Ä¶\n(i.e. each neuron needs to fire many spikes to get good precision)\nboth in vivo and in silico.\n\nDifferent encoding strategies with spiking neurons [8]\n7 neurons\n7 time bins\n\nDifferent encoding strategies with spiking neurons\n7 neurons\n7 time bins\nn\n6\n(in the general \ncase a \nnumber \nbetween 0-7)\n\nDifferent encoding strategies with spiking neurons\n7 neurons\n7 time bins\nn\nTotal spike \ncount can \nencode 3 bits.\n\nDifferent encoding strategies with spiking neurons\n7 neurons\n7 time bins\nIndividual rates \ncan encode 7 \nbits.\n\nDifferent encoding strategies with spiking neurons\n7 neurons\n7 time bins\nLatency can \nencode ~3*7 or \n~19 bits.\n\nDifferent encoding strategies with spiking neurons\n7 neurons\n7 time bins\nRank order can \nencode ~12 bits.\n\nDifferent encoding strategies with spiking neurons\n\nDifferent encoding strategies with spiking neurons\nUsing latency or spatio-temporal codes\nour encoding is faster and more spike-efficient (sparser)!\n\nDifferent encoding strategies with spiking neurons\nUsing latency or spatio-temporal codes\nour encoding is faster and more spike-efficient (sparser)!\nQuestions?\n\nNeuromorphic computing\nWhat is the advantage for applications?\n-\nLess spikes = less energy consumption in specialized neuromorphic hardware\n(e.g. Intel Loihi [12])\nBrains are energy efficient: \n2. Sparse encoding\n\nMultiply-accumulate (MAC) operations:\nNormal neuron: Multiplies input with \nweights, then adds.\nSpiking neuron: Consider binary input (e.g. input currents are piecewise \nconstant and assume values {0,1}). There is no multiplication, only addition.\n\nAssume one multiplier and one adder circuit uses M and A energy respectively with AÔπ§M\n(e.g., for a 45nm CMOS process, standard energy usage is A = 0.9 pJ and M = 3.7 pJ).\nNormal neuron: nin x nout multiplications,\n(nin‚Äì 1) x nout additions\nSpiking neuron: 0 multiplications, (nactive‚Äì 1) x nout \nadditions, with nactive ‚â§ nin\nEnergy consumption:\nEnormal = M nin nout + A (nin‚Äì 1) nout = 17.5 pJ\nEnergy consumption:\nEspiking = A (nactive‚Äì 1) nout = 2.7 pJ\nMultiply-accumulate (MAC) operations:\n\nAssume one multiplier and one adder circuit uses M and A energy respectively with AÔπ§M\n(e.g., for a 45nm CMOS process, standard energy usage is A = 0.9 pJ and M = 3.7 pJ).\nNormal neuron: nin x nout multiplications,\n(nin‚Äì 1) x nout additions\nSpiking neuron: 0 multiplications, (nactive‚Äì 1) x nout \nadditions, with nactive ‚â§ nin\nEnergy consumption:\nEnormal = M nin nout + A (nin‚Äì 1) nout = 17.5 pJ\nEnergy consumption:\nEspiking = A (nactive‚Äì 1) nout = 2.7 pJ\nMultiply-accumulate (MAC) operations:\nSNN challenge: how to \ncompute with the least \namount of spikes!\n\nOften, we observe a \nsparsity (energy)-\ntask accuracy trade-off\n(Left: results for image \nclassification)\nSNN challenge: how to \ncompute with the least \namount of spikes!\nhttps://arxiv.org/pdf/2409.08290\n\nIn practice, energy \nconsumption computations \nare complex. \nNeed to take into account\n- memory access,\n- addressing,\n- auxiliary operations,\nin addition to MACs.\nEstimated energy consumption for 3 different datasets (CIFAR10, GSC, NCARS; image, sound \nand video classification respectively). FNN‚Äôs are conventional feed-forward neural networks.\nIn this example: SNNs are 6 to 8 times more energy efficient than FNNs.\nhttps://arxiv.org/pdf/2210.13107\nComputing energy consumption\n\nIn practice, energy \nconsumption computations \nare complex. \nNeed to take into account\n- memory access,\n- addressing,\n- auxiliary operations,\nin addition to MACs.\nEstimated energy consumption for 3 different datasets (CIFAR10, GSC, NCARS; image, sound \nand video classification respectively). FNN‚Äôs are conventional feed-forward neural networks."", 'Often, we observe a \nsparsity (energy)-\ntask accuracy trade-off\n(Left: results for image \nclassification)\nSNN challenge: how to \ncompute with the least \namount of spikes!\nhttps://arxiv.org/pdf/2409.08290\n\nIn practice, energy \nconsumption computations \nare complex. \nNeed to take into account\n- memory access,\n- addressing,\n- auxiliary operations,\nin addition to MACs.\nEstimated energy consumption for 3 different datasets (CIFAR10, GSC, NCARS; image, sound \nand video classification respectively).', 'Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945.']","[""<1-hop>\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant"", '<2-hop>\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \n(not publicly available) doi:10.1037/h0042519\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568']","Spiking neural networks (SNNs) use various encoding strategies to efficiently process information. These strategies include:

1. **Latency Encoding**: The timing of spikes is used to encode information. This method can encode a significant amount of data quickly and efficiently, as it relies on the precise timing of spikes rather than the rate of firing.

2. **Rate Encoding**: This classical view involves each neuron being selective for a specific feature, with the firing rate (spikes per unit time) representing the intensity of that feature. However, this method is considered inefficient and slow because it requires many spikes to achieve good precision.

3. **Rank Order Encoding**: This strategy uses the order in which neurons fire to encode information, which can be more efficient than rate encoding.

4. **Sparse Encoding**: SNNs often use sparse encoding, where fewer spikes are used to represent information, leading to reduced energy consumption. This is particularly advantageous in neuromorphic hardware, where less energy is consumed with fewer spikes.

These encoding strategies allow SNNs to be more energy-efficient and faster in processing information compared to traditional neural networks.",Spiking neural networks use single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0) to encode information about 'features' in a large network with many spikes. This approach is supported by foundational works such as McCulloch and Pitts' logical calculus of nervous activity and later developments in spiking neuron models.,0.9999999999,0.5,1.0,0.0,0.0,0.9540629279431819
What are the benefits of neuromorphic computing in the context of green software practices?,"['Questions?\n\nNeuromorphic computing\nWhat is the advantage for applications?\n-\nLess spikes = less energy consumption in specialized neuromorphic hardware\n(e.g. Intel Loihi [12])\nBrains are energy efficient: \n2. Sparse encoding\n\nMultiply-accumulate (MAC) operations:\nNormal neuron: Multiplies input with \nweights, then adds.\nSpiking neuron: Consider binary input (e.g. input currents are piecewise \nconstant and assume values {0,1}). There is no multiplication, only addition.', 'Oversimplification\nThere are also multiple other advantages‚Ä¶\n\nHuman vs. computer computation\n- Fast real-time decision making, e.g. sports, e-sports\n- Adaptive, e.g. context-aware and employs selective attention\n- Energy efficient: Close to 100 billion neurons in the brain\n- Robust, for example to changes in illumination or obstructions in object tracking\n\nHuman vs. computer computation\nBrains are energy efficient: Why?\n1.\nHigh temporal resolution (more computation with less neurons)\n2.\nSparse encoding\n\nHuman vs. computer computation\nQuestions?\nBrains are energy efficient: Why?', 'Browser plugin?\n24\nCO2\n\nC4. NutriScore for software libraries\n25\n‚Ä¢ NutriScore labels are not perfect but they are a good starting point! \n‚Ä¢ What if we could do the same thing for the energy efficiency of software. \n‚Ä¢ (Also open to individual or social sustainability) \n‚Ä¢ This work can be scoped in particular domains/ecossystems/use cases. \n‚Ä¢ Libraries for stats? ML? Web Dev? Cloud?\n\nC5. Add energy-awareness to existing software\n26\n‚Ä¢ Streamlit, Notebooks, JSFiddle, \nPyScript, zsh, etc. \n‚Ä¢\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy efficiency using static code analysis. \n‚Ä¢ We don‚Äôt need an accurate value. \n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention. \n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27\n\nC7 - Education\n‚Ä¢ Educational game for Software \nSustainability practices \n‚Ä¢ Purpose: use within software teams to \ndiscuss or learn about different sustainable \nIT practices: at the organisation level, \nsoftware, etc.\n28\nhttps://github.com/OttoKaaij/Ticket-To-Sustainability/?tab=readme-ov-file\n\nProject ideas (old)\n‚Ä¢ Plugin from EnergiBridge (GUI, report generator, python library, etc.) \n‚Ä¢ Plugin for ChatGPT (carbon emissions per chat window) \n‚Ä¢ Seamless measurements for AI libraries \n‚Ä¢ Energy patterns for Green AI \n‚Ä¢ Sustainable SW dev gamification \n‚Ä¢ Sustainability auditor for AI projects \n‚Ä¢ Energy Profiling of screen colour filter tools (or display settings) \n‚Ä¢ ‚Ä¶ you can also propose yours!\n\nhttps://edu.nl/64gpk\nedu.nl/64gpk\n\n\nNeuromorphic computing\nCS4575\nSustainable Software Engineering\n05.03.2025\nNergis T√∂men\n\nIntroduction\nComputer Vision Lab\nBiomorphic Intelligence Lab\nBiomedical Intervention Optimisation Lab\nNergis\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.']","['<1-hop>\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing', '<2-hop>\n\nReading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.', '<1-hop>\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing', '<2-hop>\n\nReading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.', '<1-hop>\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing', '<2-hop>\n\nReading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.']","Neuromorphic computing offers several benefits in the context of green software practices:

1. **Energy Efficiency**: Neuromorphic computing is inspired by the human brain, which is highly energy efficient. It uses less energy due to sparse encoding and the nature of spiking neurons, which only perform addition instead of multiply-accumulate operations. This results in less energy consumption, especially in specialized neuromorphic hardware like Intel's Loihi.

2. **Real-time Decision Making**: Neuromorphic systems can make fast real-time decisions, which is beneficial for applications requiring quick responses, such as sports or e-sports, while maintaining energy efficiency.

3. **Adaptive and Robust**: These systems are adaptive and robust, similar to the human brain, allowing them to handle changes in conditions like illumination or obstructions in object tracking without significant energy overhead.

Overall, neuromorphic computing aligns well with green software practices by reducing energy consumption and improving computational efficiency.","Neuromorphic computing offers several benefits in the context of green software practices. It is inspired by the structure and function of the human brain, making it highly energy-efficient compared to traditional computing methods. This efficiency is particularly relevant for sustainable software development, as it reduces the environmental impact of computing systems. Additionally, neuromorphic systems can process information in a way that mimics biological neural networks, which can lead to more efficient and sustainable computing solutions. These aspects make neuromorphic computing a promising approach for developers looking to implement green software practices.",0.9999999999,1.0,1.0,0.5,0.1111111109876543,1.0000000000000009
What are the challenges in creating a dataset of government-developed OS software?,"['Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise \n‚Ä¢ But studying government software is difficult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers \n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation? \n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!\n\nB7.', '(2016)\nCruz et al. \n(2018)\nCruz et al. \n(2019)\nEnergy Code Changes \nDataset\n539 commits\u2028\nfrom 306 mobile apps\n539 baseline commits\u2028\nfrom 306 mobile apps\n49\n\nImpact of energy changes on \nmaintainability\n50\n\nWhich energy \npatterns are more \nlikely to affect \nmaintainability?\n51\n\nTypical maintainability issue I\nhttps://github.com/einmalfel/PodListen/commit/2ed5a65\n4 changed files with 28 additions and 0 deletions.', 'This is time consuming and requires \nexpertise. \n‚Ä¢ How can we reuse these efforts?\n4\n\nEnergy Patterns for Mobile \nApps\nhttps://tqrg.github.io/energy-patterns/\n\nMethodology\n5. Catalog of Energy Patterns\n22 \npatterns\nF-droid\nCurated Lists\n1. App Collection\n1783 \napps\n3. Manual Refinement of Subjects of \nInterest\n1563 \nchanges\n4. Thematic Analysis\n431 \nreusable \nchanges\n2. Collect Changes With Potential Interest\n/.*(energy|power|battery).']","['<1-hop>\n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise\n‚Ä¢ But studying government software is diÔ¨Écult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation?\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!', '<2-hop>\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption\n‚Ä¢ B3. Energy proÔ¨Åling of static analysis tools\n‚Ä¢ B4. Detailed energy proÔ¨Åling of build pipelines\n‚Ä¢ B5. Tool supporting SusAF workshop / process\n‚Ä¢ B6. Dataset of government-developed OS software\n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability', '<1-hop>\n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise\n‚Ä¢ But studying government software is diÔ¨Écult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation?\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!', '<2-hop>\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption\n‚Ä¢ B3. Energy proÔ¨Åling of static analysis tools\n‚Ä¢ B4. Detailed energy proÔ¨Åling of build pipelines\n‚Ä¢ B5. Tool supporting SusAF workshop / process\n‚Ä¢ B6. Dataset of government-developed OS software\n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability', '<1-hop>\n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise\n‚Ä¢ But studying government software is diÔ¨Écult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation?\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!', '<2-hop>\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption\n‚Ä¢ B3. Energy proÔ¨Åling of static analysis tools\n‚Ä¢ B4. Detailed energy proÔ¨Åling of build pipelines\n‚Ä¢ B5. Tool supporting SusAF workshop / process\n‚Ä¢ B6. Dataset of government-developed OS software\n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability']","The challenges in creating a dataset of government-developed OS software include:

1. **Lack of Incentive to Make Software Popular**: There is often little motivation for governments to promote their software widely, which can lead to difficulties in discovering and cataloging these projects.

2. **Language Barriers**: Government software may be developed in various languages, making it challenging to compile and understand the software across different regions.

3. **Difficulty in Understanding the State of Software**: It is challenging to determine whether the software is buildable, has an open development history, or includes requirements documentation.

These factors make it difficult to study and create a comprehensive dataset of government-developed software.","Creating a dataset of government-developed OS software faces challenges such as a lack of incentive to make the software popular and language barriers, which hinder comprehensive understanding of the software's buildability, open development history, and requirements documentation.",0.9999999999,1.0,0.7272727272727273,1.0,0.16666666638888888,0.9999999999999997
"What are the practical applications of neuromorphic computing, and how does its biological inspiration influence its implementation in modern computing systems?","['Questions?\n\nNeuromorphic computing\nWhat is the advantage for applications?\n-\nLess spikes = less energy consumption in specialized neuromorphic hardware\n(e.g. Intel Loihi [12])\nBrains are energy efficient: \n2. Sparse encoding\n\nMultiply-accumulate (MAC) operations:\nNormal neuron: Multiplies input with \nweights, then adds.\nSpiking neuron: Consider binary input (e.g. input currents are piecewise \nconstant and assume values {0,1}). There is no multiplication, only addition.', 'A neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing\n\nHow many of you are familiar \nwith neural networks?\n\nSimple model of an artificial neuron\nhttps://medium.com/@cprasenjit32/perceptron-a-simple-yet-mighty-machine-learning-algorithm-9ff6b7d86a71\n\nWhat is a neural network?\nhttps://www.tibco.com/reference-center/what-is-a-neural-network\n\nWhy is it called a \'neural network\'?\nhttps://www.tibco.com/reference-center/what-is-a-neural-network\n\nWhat is a neural network?\nWhy is it called a \'neural network\'?\nMcCulloch-Pitts neuron [1, 2] (1943)\nWarren Sturgis McCulloch\n(Neurophysiologist)\nWalter Pitts\n(Logician)\n\nHow do biological neurons work?\nhttps://commons.wikimedia.org/wiki/File:Coincidence_detection_in_dendrites_of_pyramidal_neurons.gif\n\'Input current\' travels down the dendrites (top),\nget integrated (summed!) in the cell body\nwhich generates an \'output current\' (bottom)\nwhich is chemically transmitted to the dendrites of \nother neurons.\n\nSimplified picture\nReal neuron\nArtificial neuron\nhttps://vajiramandravi.com/quest-upsc-notes/artificial-neural-network/\n\nWhat is a neural network?\nMcCulloch-Pitts neuron [1, 2]\n1940s: How do biological neurons compute basic \nlogic functions? (e.g. logic gates)\nNote: Ref. [3] gives a nice brief history on the ideas which lead to the \nMcCulloch-Pitts neuron.\n\nWhat is a neural network?\n1950s: How are neurons organized to perform \nsensory perception?\n\nWhat is a neural network?\n1950s: How are neurons organized to perform \nsensory perception?\nThe first ""neural network"": Perceptron (1958).', 'https://edu.nl/64gpk\nedu.nl/64gpk\n\n\nNeuromorphic computing\nCS4575\nSustainable Software Engineering\n05.03.2025\nNergis T√∂men\n\nIntroduction\nComputer Vision Lab\nBiomorphic Intelligence Lab\nBiomedical Intervention Optimisation Lab\nNergis\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.']","['<1-hop>\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing', '<2-hop>\n\nReading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.', '<1-hop>\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing', '<2-hop>\n\nReading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.']","Neuromorphic computing is inspired by the structure and function of the human brain, and it uses physical artificial neurons to perform computations. This approach offers several advantages for practical applications, particularly in areas where energy efficiency and processing speed are critical.

1. **Energy Efficiency**: Neuromorphic systems, such as Intel's Loihi chip, consume less energy because they use spiking neurons that perform operations with fewer spikes, leading to reduced energy consumption. This is particularly beneficial for applications that require continuous processing with minimal power usage.

2. **Sparse Encoding**: Neuromorphic systems use sparse encoding, which mimics the brain's way of processing information. This allows for efficient data representation and processing, making it suitable for applications like real-time data analysis and sensory processing.

3. **Efficient Computation**: Unlike traditional neurons that perform multiply-accumulate (MAC) operations, spiking neurons in neuromorphic systems only perform addition, which simplifies computations and reduces the computational load.

These characteristics make neuromorphic computing particularly suitable for applications in computer vision, sensory perception, and other areas where mimicking the brain's efficiency and processing capabilities can lead to significant improvements in performance and energy savings.","Neuromorphic computing, inspired by the human brain, offers practical applications such as event-based vision systems and efficient processing of sensory data. Its biological inspiration influences its implementation through the use of spiking neural networks and physical artificial neurons, enabling more energy-efficient and brain-like computation methods.",0.0,0.5,0.5714285714285714,0.6,0.16666666638888888,0.8882777092019438
"What are the practical applications of neuromorphic computing, and how does its biological inspiration influence its implementation?","['Questions?\n\nNeuromorphic computing\nWhat is the advantage for applications?\n-\nLess spikes = less energy consumption in specialized neuromorphic hardware\n(e.g. Intel Loihi [12])\nBrains are energy efficient: \n2. Sparse encoding\n\nMultiply-accumulate (MAC) operations:\nNormal neuron: Multiplies input with \nweights, then adds.\nSpiking neuron: Consider binary input (e.g. input currents are piecewise \nconstant and assume values {0,1}). There is no multiplication, only addition.', 'The first ""neural network"": Perceptron (1958). [4]\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\nFrank Rosenblatt (Psychologist)\nwith a Mark I Perceptron computer in 1960\nPower-efficient\n\nNeuromorphic computing\nWhy neuromorphic computing?\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.', 'Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \n(not publicly available) doi:10.1037/h0042519\n5) Tappert CC.']","['<1-hop>\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing', '<2-hop>\n\nReading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.']","Neuromorphic computing is inspired by the structure and function of the human brain, which influences its implementation by using physical artificial neurons to perform computations. This approach offers several advantages for practical applications:

1. **Energy Efficiency**: Neuromorphic systems, like the human brain, are highly energy-efficient. They consume less energy, especially in specialized neuromorphic hardware, because they use sparse encoding and fewer spikes, which reduces energy consumption (e.g., Intel Loihi).

2. **Efficient Computation**: Unlike traditional neurons that perform multiply-accumulate (MAC) operations, spiking neurons in neuromorphic systems use binary input and only perform addition, which simplifies computations and reduces power usage.

3. **Event-Based Vision**: Neuromorphic computing is particularly useful in vision systems, such as event cameras, which mimic the way biological systems process visual information. These systems can efficiently handle dynamic scenes and reduce data redundancy by only recording changes in the visual field.

Overall, the biological inspiration of neuromorphic computing leads to systems that are more efficient in terms of energy and computation, making them suitable for applications in areas like robotics, sensory processing, and real-time data analysis.","Neuromorphic computing, inspired by the human brain, offers practical applications through its ability to process information in a manner similar to biological neurons. This biological inspiration influences its implementation by enabling the development of systems that can efficiently handle tasks such as pattern recognition and adaptive learning, as detailed in resources like 'Computing with spiking neuron networks' and discussions on the convergence of deep learning with biological systems.",0.0,0.6666666666666666,0.5333333333333333,0.31,0.14285714265306124,0.9262469479800736
What are the practical applications of neuromorphic systems that leverage biological inspiration and advanced training methods for efficient computation?,"['Questions?\n\nNeuromorphic computing\nWhat is the advantage for applications?\n-\nLess spikes = less energy consumption in specialized neuromorphic hardware\n(e.g. Intel Loihi [12])\nBrains are energy efficient: \n2. Sparse encoding\n\nMultiply-accumulate (MAC) operations:\nNormal neuron: Multiplies input with \nweights, then adds.\nSpiking neuron: Consider binary input (e.g. input currents are piecewise \nconstant and assume values {0,1}). There is no multiplication, only addition.', 'FNN‚Äôs are conventional feed-forward neural networks.\nIn this example: SNNs are 6 to 8 times more energy efficient than FNNs.\nComputing energy consumption\nQuestions?\n\nReading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020.', 'Oversimplification\nThere are also multiple other advantages‚Ä¶\n\nHuman vs. computer computation\n- Fast real-time decision making, e.g. sports, e-sports\n- Adaptive, e.g. context-aware and employs selective attention\n- Energy efficient: Close to 100 billion neurons in the brain\n- Robust, for example to changes in illumination or obstructions in object tracking\n\nHuman vs. computer computation\nBrains are energy efficient: Why?\n1.\nHigh temporal resolution (more computation with less neurons)\n2.\nSparse encoding\n\nHuman vs. computer computation\nQuestions?\nBrains are energy efficient: Why?']","['<1-hop>\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing', '<2-hop>\n\nReading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.', '<1-hop>\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing', '<2-hop>\n\nReading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.', '<1-hop>\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing', '<2-hop>\n\nReading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.']","Neuromorphic systems, inspired by biological processes and advanced training methods, have several practical applications due to their efficient computation capabilities. These include:

1. **Energy Efficiency**: Neuromorphic systems, such as those using spiking neural networks (SNNs), are significantly more energy-efficient than conventional feed-forward neural networks (FNNs). This makes them suitable for applications where power consumption is a critical factor.

2. **Real-Time Decision Making**: They are capable of fast real-time decision making, which is beneficial in applications like sports and e-sports, where quick responses are crucial.

3. **Adaptive Systems**: Neuromorphic systems can be context-aware and employ selective attention, making them useful in adaptive applications that require dynamic responses to changing environments.

4. **Robustness**: These systems are robust to changes, such as variations in illumination or obstructions in object tracking, making them ideal for vision and tracking applications.

5. **Sparse Encoding**: By leveraging sparse encoding, neuromorphic systems can perform high temporal resolution computations with fewer neurons, which is advantageous in applications requiring efficient data processing.

Overall, neuromorphic systems are well-suited for applications that require efficient, adaptive, and robust computation with low energy consumption.","Neuromorphic systems, inspired by the human brain, have practical applications such as event-based vision, which is detailed in the reading materials. These systems use advanced training methods like surrogate gradient learning to optimize spiking neural networks, enabling efficient computation and real-world applications.",0.49999999995,1.0,0.9375,0.5,0.1111111109876543,0.9552170717465485
"What is the biological basis of neuromorphic computing, and how does it differ from conventional neural networks?","['https://edu.nl/64gpk\nedu.nl/64gpk\n\n\nNeuromorphic computing\nCS4575\nSustainable Software Engineering\n05.03.2025\nNergis T√∂men\n\nIntroduction\nComputer Vision Lab\nBiomorphic Intelligence Lab\nBiomedical Intervention Optimisation Lab\nNergis\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.', ""Computation with spiking neurons\n\nCoincidence detection\nCan be trivially computed with a single spiking neuron! Requires at least n/log(n+1) hidden \nunits for a perceptron (proof in [7]).\nBrains are energy efficient: \n1.\nHigh temporal resolution (more computation with less neurons)\nComputation with spiking neurons\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?"", 'Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021.']","['<1-hop>\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing', '<2-hop>\n\nReading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.']","Neuromorphic computing is inspired by the structure and function of the human brain. It involves using physical artificial neurons to perform computations, mimicking the way biological neurons operate. This approach is based on biology, as it seeks to replicate the brain's energy efficiency and high temporal resolution, allowing for more computation with fewer neurons.

In contrast, conventional neural networks, while also inspired by the brain, typically use mathematical models to simulate neuron behavior and are not necessarily designed to mimic the brain's physical structure or energy efficiency. Neuromorphic computing often involves spiking neurons, which encode information using spikes (binary signals), whereas conventional neural networks generally use continuous values for neuron outputs.","Neuromorphic computing is based on the biological principles of the human brain, utilizing physical artificial neurons to perform computations. Unlike conventional neural networks, which rely on traditional computing architectures, neuromorphic systems are designed to mimic the brain's structure and function, enabling more efficient and biologically inspired processing.",0.8333333332916666,0.5,0.6666666666666666,0.73,0.12499999984374999,0.9354184907309843
What is the difference between spiking neural networks and spiking neuron networks?,"['Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012).', '9 pJ and M = 3.7 pJ).\nNormal neuron: nin x nout multiplications,\n(nin‚Äì 1) x nout additions\nSpiking neuron: 0 multiplications, (nactive‚Äì 1) x nout \nadditions, with nactive ‚â§ nin\nEnergy consumption:\nEnormal = M nin nout + A (nin‚Äì 1) nout = 17.5 pJ\nEnergy consumption:\nEspiking = A (nactive‚Äì 1) nout = 2.7 pJ\nMultiply-accumulate (MAC) operations:\nSNN challenge: how to \ncompute with the least \namount of spikes!', ""‚Ä¶ with energy costs reaching 200M USD!\n\nPower-efficiency at scale\nYour brain runs on:\n\nPower-efficiency at scale\nYour brain runs on:\nHigh estimate ~3000 kcal a day\n   ‚âà145 Watts\n* Human brain has ~600 trillion synapses \n(‚âàparameters).\n\nPower-efficiency at scale\nYour brain runs on:\nHigh estimate ~3000 kcal a day\n   ‚âà145 Watts\n* Human brain has ~600 trillion synapses \n(‚âàparameters).\nOversimplification\nThere are also multiple other advantages‚Ä¶\n\nHuman vs. computer computation\n- Fast real-time decision making, e.g. sports, e-sports\n- Adaptive, e.g. context-aware and employs selective attention\n- Energy efficient: Close to 100 billion neurons in the brain\n- Robust, for example to changes in illumination or obstructions in object tracking\n\nHuman vs. computer computation\nBrains are energy efficient: Why?\n1.\nHigh temporal resolution (more computation with less neurons)\n2.\nSparse encoding\n\nHuman vs. computer computation\nQuestions?\nBrains are energy efficient: Why?\n1.\nHigh temporal resolution (more computation with less neurons)\n2.\nSparse encoding\n\nHow do biological neurons communicate?\nAnalogy to artificial neural networks\nReal neuron\nArtificial neuron\nCurrent\n\nHow do biological neurons communicate?\nHow does the electrical activity propagate?\n?\nCurrent\n\nHow do biological neurons work?\ntime\nelectrode\nhttps://tinmard.github.io/spike-sorting-animation.html\nQuick electrical pulses trigger chemical signals for the next neuron ‚Üí Spikes\n\nHow do biological neurons work?\nQuick electrical pulses trigger chemical signals for the next neuron ‚Üí Spikes\nhttps://tinmard.github.io/spike-sorting-animation.html\ntime\nelectrode\nFrom CS perspective:\nSparse binary \nencoding\n\nBiologically realistic spiking neuron models\nBiologically realistic neuron models have \na new dimension: Time!\nSpiking neural networks (SNNs):\nThe input x  (t  ) to each neuron is summed \n(integrated) over time.\nscalar\nfunction of \ntime\n(t)\n(t)\nhttps://www.mdpi.com/2076-3425/12/7/863\n\nHow to model spiking neurons?\nANN: Perceptron, threshold activation function:\n\nHow to model spiking neurons?\nANN: Perceptron, threshold activation function:\n\nHow to model spiking neurons?\nSpiking neural network (SNN): The 'input current' Œµ(t) is integrated over time.\nspike\n\nHow to model spiking neurons?\nEquivalence to perceptron: Computation at least as complex as a perceptron.\n\nNon-leaky integrate-and-fire (IF) neuron\nThe temporal profile of the input current Œµ(t) can be chosen differently, for different computations.\n\nQuestions?\n\nComputation with spiking neurons\nCoincidence detection\n\nComputation with spiking neurons\nCoincidence detection\nx, y ‚àà {0, 1}n\nExample: n = 2\ninput = \nx1\nx2\ny1\ny2\n= \n0\n1\n1\n1\noutput? \n\nCoincidence detection\nComputation with spiking neurons\n\nCoincidence detection\nCan be trivially computed with a single spiking neuron! Requires at least n/log(n+1) hidden \nunits for a perceptron (proof in [7]).\nComputation with spiking neurons\n\nCoincidence detection\nCan be trivially computed with a single spiking neuron! Requires at least n/log(n+1) hidden \nunits for a perceptron (proof in [7]).\nBrains are energy efficient: \n1.\nHigh temporal resolution (more computation with less neurons)\nComputation with spiking neurons\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant\n\nFiring rates\nClassical view of the brain:\n- Each neuron is selective for one specific \nfeature in the input.\n- Higher firing rate (spikes per unit time) for \n'selected' feature.\nAdapted from Hubel & Wiesel, 1959\n\nFiring rates\nClassical view of the brain:\n- Each neuron is selective for one specific \nfeature in the input.\n- Higher firing rate (spikes per unit time) for \n'selected' feature.\n- Link to modern ANNs: The scalar output of \nan artificial neuron is interpreted as the firing \nrate.\nAdapted from Hubel & Wiesel, 1959\n\nFiring rates\nClassical view of the brain:\n- Each neuron is selective for one specific \nfeature in the input.\n- Higher firing rate (spikes per unit time) for \n'selected' feature.\n- Link to modern ANNs: The scalar output of \nan artificial neuron is interpreted as the firing \nrate.\nAdapted from Hubel & Wiesel, 1959\nBut rate coding is inefficient and slow‚Ä¶\n(i.e. each neuron needs to fire many spikes to get good precision)\nboth in vivo and in silico.\n\nDifferent encoding strategies with spiking neurons [8]\n7 neurons\n7 time bins\n\nDifferent encoding strategies with spiking neurons\n7 neurons\n7 time bins\nn\n6\n(in the general \ncase a \nnumber \nbetween 0-7)\n\nDifferent encoding strategies with spiking neurons\n7 neurons\n7 time bins\nn\nTotal spike \ncount can \nencode 3 bits.\n\nDifferent encoding strategies with spiking neurons\n7 neurons\n7 time bins\nIndividual rates \ncan encode 7 \nbits.\n\nDifferent encoding strategies with spiking neurons\n7 neurons\n7 time bins\nLatency can \nencode ~3*7 or \n~19 bits.\n\nDifferent encoding strategies with spiking neurons\n7 neurons\n7 time bins\nRank order can \nencode ~12 bits.\n\nDifferent encoding strategies with spiking neurons\n\nDifferent encoding strategies with spiking neurons\nUsing latency or spatio-temporal codes\nour encoding is faster and more spike-efficient (sparser)!\n\nDifferent encoding strategies with spiking neurons\nUsing latency or spatio-temporal codes\nour encoding is faster and more spike-efficient (sparser)!\nQuestions?\n\nNeuromorphic computing\nWhat is the advantage for applications?\n-\nLess spikes = less energy consumption in specialized neuromorphic hardware\n(e.g. Intel Loihi [12])\nBrains are energy efficient: \n2. Sparse encoding\n\nMultiply-accumulate (MAC) operations:\nNormal neuron: Multiplies input with \nweights, then adds.\nSpiking neuron: Consider binary input (e.g. input currents are piecewise \nconstant and assume values {0,1}). There is no multiplication, only addition.\n\nAssume one multiplier and one adder circuit uses M and A energy respectively with AÔπ§M\n(e.g., for a 45nm CMOS process, standard energy usage is A = 0.9 pJ and M = 3.7 pJ).\nNormal neuron: nin x nout multiplications,\n(nin‚Äì 1) x nout additions\nSpiking neuron: 0 multiplications, (nactive‚Äì 1) x nout \nadditions, with nactive ‚â§ nin\nEnergy consumption:\nEnormal = M nin nout + A (nin‚Äì 1) nout = 17.5 pJ\nEnergy consumption:\nEspiking = A (nactive‚Äì 1) nout = 2.7 pJ\nMultiply-accumulate (MAC) operations:\n\nAssume one multiplier and one adder circuit uses M and A energy respectively with AÔπ§M\n(e.g., for a 45nm CMOS process, standard energy usage is A = 0.9 pJ and M = 3.7 pJ).\nNormal neuron: nin x nout multiplications,\n(nin‚Äì 1) x nout additions\nSpiking neuron: 0 multiplications, (nactive‚Äì 1) x nout \nadditions, with nactive ‚â§ nin\nEnergy consumption:\nEnormal = M nin nout + A (nin‚Äì 1) nout = 17.5 pJ\nEnergy consumption:\nEspiking = A (nactive‚Äì 1) nout = 2.7 pJ\nMultiply-accumulate (MAC) operations:\nSNN challenge: how to \ncompute with the least \namount of spikes!\n\nOften, we observe a \nsparsity (energy)-\ntask accuracy trade-off\n(Left: results for image \nclassification)\nSNN challenge: how to \ncompute with the least \namount of spikes!\nhttps://arxiv.org/pdf/2409.08290\n\nIn practice, energy \nconsumption computations \nare complex. \nNeed to take into account\n- memory access,\n- addressing,\n- auxiliary operations,\nin addition to MACs.\nEstimated energy consumption for 3 different datasets (CIFAR10, GSC, NCARS; image, sound \nand video classification respectively). FNN‚Äôs are conventional feed-forward neural networks.\nIn this example: SNNs are 6 to 8 times more energy efficient than FNNs.\nhttps://arxiv.org/pdf/2210.13107\nComputing energy consumption\n\nIn practice, energy \nconsumption computations \nare complex. \nNeed to take into account\n- memory access,\n- addressing,\n- auxiliary operations,\nin addition to MACs.\nEstimated energy consumption for 3 different datasets (CIFAR10, GSC, NCARS; image, sound \nand video classification respectively). FNN‚Äôs are conventional feed-forward neural networks.""]","[""<1-hop>\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant"", '<2-hop>\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \n(not publicly available) doi:10.1037/h0042519\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568', ""<1-hop>\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant"", '<2-hop>\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \n(not publicly available) doi:10.1037/h0042519\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568']","The terms ""spiking neural networks"" (SNNs) and ""spiking neuron networks"" are often used interchangeably to refer to the same concept. Both describe a type of artificial neural network that more closely mimics the way biological neurons communicate through spikes or discrete events over time. These networks use spiking neurons, which integrate input over time and fire spikes when a certain threshold is reached, as opposed to traditional artificial neural networks that use continuous activation functions.

The key characteristics of SNNs include the integration of input over time, sparse encoding, and the use of spikes for communication, which can lead to more energy-efficient computations compared to traditional neural networks. They are particularly noted for their potential in neuromorphic computing, where less energy consumption is achieved through fewer spikes and sparse encoding strategies.","Spiking neural networks (SNNs) are a type of neural network model that processes information using spikes, similar to biological neurons. Spiking neuron networks refer to the individual components within these networks, focusing on how each neuron processes and communicates information through spikes.",0.0,,0.8181818181818182,0.5,0.0,0.905323854344371
What is the foundational concepts of spiking neural networks and how they are used in encoding strategies?,"[""‚Ä¶ with energy costs reaching 200M USD!\n\nPower-efficiency at scale\nYour brain runs on:\n\nPower-efficiency at scale\nYour brain runs on:\nHigh estimate ~3000 kcal a day\n   ‚âà145 Watts\n* Human brain has ~600 trillion synapses \n(‚âàparameters).\n\nPower-efficiency at scale\nYour brain runs on:\nHigh estimate ~3000 kcal a day\n   ‚âà145 Watts\n* Human brain has ~600 trillion synapses \n(‚âàparameters).\nOversimplification\nThere are also multiple other advantages‚Ä¶\n\nHuman vs. computer computation\n- Fast real-time decision making, e.g. sports, e-sports\n- Adaptive, e.g. context-aware and employs selective attention\n- Energy efficient: Close to 100 billion neurons in the brain\n- Robust, for example to changes in illumination or obstructions in object tracking\n\nHuman vs. computer computation\nBrains are energy efficient: Why?\n1.\nHigh temporal resolution (more computation with less neurons)\n2.\nSparse encoding\n\nHuman vs. computer computation\nQuestions?\nBrains are energy efficient: Why?\n1.\nHigh temporal resolution (more computation with less neurons)\n2.\nSparse encoding\n\nHow do biological neurons communicate?\nAnalogy to artificial neural networks\nReal neuron\nArtificial neuron\nCurrent\n\nHow do biological neurons communicate?\nHow does the electrical activity propagate?\n?\nCurrent\n\nHow do biological neurons work?\ntime\nelectrode\nhttps://tinmard.github.io/spike-sorting-animation.html\nQuick electrical pulses trigger chemical signals for the next neuron ‚Üí Spikes\n\nHow do biological neurons work?\nQuick electrical pulses trigger chemical signals for the next neuron ‚Üí Spikes\nhttps://tinmard.github.io/spike-sorting-animation.html\ntime\nelectrode\nFrom CS perspective:\nSparse binary \nencoding\n\nBiologically realistic spiking neuron models\nBiologically realistic neuron models have \na new dimension: Time!\nSpiking neural networks (SNNs):\nThe input x  (t  ) to each neuron is summed \n(integrated) over time.\nscalar\nfunction of \ntime\n(t)\n(t)\nhttps://www.mdpi.com/2076-3425/12/7/863\n\nHow to model spiking neurons?\nANN: Perceptron, threshold activation function:\n\nHow to model spiking neurons?\nANN: Perceptron, threshold activation function:\n\nHow to model spiking neurons?\nSpiking neural network (SNN): The 'input current' Œµ(t) is integrated over time.\nspike\n\nHow to model spiking neurons?\nEquivalence to perceptron: Computation at least as complex as a perceptron.\n\nNon-leaky integrate-and-fire (IF) neuron\nThe temporal profile of the input current Œµ(t) can be chosen differently, for different computations.\n\nQuestions?\n\nComputation with spiking neurons\nCoincidence detection\n\nComputation with spiking neurons\nCoincidence detection\nx, y ‚àà {0, 1}n\nExample: n = 2\ninput = \nx1\nx2\ny1\ny2\n= \n0\n1\n1\n1\noutput? \n\nCoincidence detection\nComputation with spiking neurons\n\nCoincidence detection\nCan be trivially computed with a single spiking neuron! Requires at least n/log(n+1) hidden \nunits for a perceptron (proof in [7]).\nComputation with spiking neurons\n\nCoincidence detection\nCan be trivially computed with a single spiking neuron! Requires at least n/log(n+1) hidden \nunits for a perceptron (proof in [7]).\nBrains are energy efficient: \n1.\nHigh temporal resolution (more computation with less neurons)\nComputation with spiking neurons\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant\n\nFiring rates\nClassical view of the brain:\n- Each neuron is selective for one specific \nfeature in the input.\n- Higher firing rate (spikes per unit time) for \n'selected' feature.\nAdapted from Hubel & Wiesel, 1959\n\nFiring rates\nClassical view of the brain:\n- Each neuron is selective for one specific \nfeature in the input.\n- Higher firing rate (spikes per unit time) for \n'selected' feature.\n- Link to modern ANNs: The scalar output of \nan artificial neuron is interpreted as the firing \nrate.\nAdapted from Hubel & Wiesel, 1959\n\nFiring rates\nClassical view of the brain:\n- Each neuron is selective for one specific \nfeature in the input.\n- Higher firing rate (spikes per unit time) for \n'selected' feature.\n- Link to modern ANNs: The scalar output of \nan artificial neuron is interpreted as the firing \nrate.\nAdapted from Hubel & Wiesel, 1959\nBut rate coding is inefficient and slow‚Ä¶\n(i.e. each neuron needs to fire many spikes to get good precision)\nboth in vivo and in silico.\n\nDifferent encoding strategies with spiking neurons [8]\n7 neurons\n7 time bins\n\nDifferent encoding strategies with spiking neurons\n7 neurons\n7 time bins\nn\n6\n(in the general \ncase a \nnumber \nbetween 0-7)\n\nDifferent encoding strategies with spiking neurons\n7 neurons\n7 time bins\nn\nTotal spike \ncount can \nencode 3 bits.\n\nDifferent encoding strategies with spiking neurons\n7 neurons\n7 time bins\nIndividual rates \ncan encode 7 \nbits.\n\nDifferent encoding strategies with spiking neurons\n7 neurons\n7 time bins\nLatency can \nencode ~3*7 or \n~19 bits.\n\nDifferent encoding strategies with spiking neurons\n7 neurons\n7 time bins\nRank order can \nencode ~12 bits.\n\nDifferent encoding strategies with spiking neurons\n\nDifferent encoding strategies with spiking neurons\nUsing latency or spatio-temporal codes\nour encoding is faster and more spike-efficient (sparser)!\n\nDifferent encoding strategies with spiking neurons\nUsing latency or spatio-temporal codes\nour encoding is faster and more spike-efficient (sparser)!\nQuestions?\n\nNeuromorphic computing\nWhat is the advantage for applications?\n-\nLess spikes = less energy consumption in specialized neuromorphic hardware\n(e.g. Intel Loihi [12])\nBrains are energy efficient: \n2. Sparse encoding\n\nMultiply-accumulate (MAC) operations:\nNormal neuron: Multiplies input with \nweights, then adds.\nSpiking neuron: Consider binary input (e.g. input currents are piecewise \nconstant and assume values {0,1}). There is no multiplication, only addition.\n\nAssume one multiplier and one adder circuit uses M and A energy respectively with AÔπ§M\n(e.g., for a 45nm CMOS process, standard energy usage is A = 0.9 pJ and M = 3.7 pJ).\nNormal neuron: nin x nout multiplications,\n(nin‚Äì 1) x nout additions\nSpiking neuron: 0 multiplications, (nactive‚Äì 1) x nout \nadditions, with nactive ‚â§ nin\nEnergy consumption:\nEnormal = M nin nout + A (nin‚Äì 1) nout = 17.5 pJ\nEnergy consumption:\nEspiking = A (nactive‚Äì 1) nout = 2.7 pJ\nMultiply-accumulate (MAC) operations:\n\nAssume one multiplier and one adder circuit uses M and A energy respectively with AÔπ§M\n(e.g., for a 45nm CMOS process, standard energy usage is A = 0.9 pJ and M = 3.7 pJ).\nNormal neuron: nin x nout multiplications,\n(nin‚Äì 1) x nout additions\nSpiking neuron: 0 multiplications, (nactive‚Äì 1) x nout \nadditions, with nactive ‚â§ nin\nEnergy consumption:\nEnormal = M nin nout + A (nin‚Äì 1) nout = 17.5 pJ\nEnergy consumption:\nEspiking = A (nactive‚Äì 1) nout = 2.7 pJ\nMultiply-accumulate (MAC) operations:\nSNN challenge: how to \ncompute with the least \namount of spikes!\n\nOften, we observe a \nsparsity (energy)-\ntask accuracy trade-off\n(Left: results for image \nclassification)\nSNN challenge: how to \ncompute with the least \namount of spikes!\nhttps://arxiv.org/pdf/2409.08290\n\nIn practice, energy \nconsumption computations \nare complex. \nNeed to take into account\n- memory access,\n- addressing,\n- auxiliary operations,\nin addition to MACs.\nEstimated energy consumption for 3 different datasets (CIFAR10, GSC, NCARS; image, sound \nand video classification respectively). FNN‚Äôs are conventional feed-forward neural networks.\nIn this example: SNNs are 6 to 8 times more energy efficient than FNNs.\nhttps://arxiv.org/pdf/2210.13107\nComputing energy consumption\n\nIn practice, energy \nconsumption computations \nare complex. \nNeed to take into account\n- memory access,\n- addressing,\n- auxiliary operations,\nin addition to MACs.\nEstimated energy consumption for 3 different datasets (CIFAR10, GSC, NCARS; image, sound \nand video classification respectively). FNN‚Äôs are conventional feed-forward neural networks."", 'Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945.']","[""<1-hop>\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant"", '<2-hop>\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \n(not publicly available) doi:10.1037/h0042519\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568', ""<1-hop>\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant"", '<2-hop>\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \n(not publicly available) doi:10.1037/h0042519\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568', ""<1-hop>\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant"", '<2-hop>\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \n(not publicly available) doi:10.1037/h0042519\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568', ""<1-hop>\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant"", '<2-hop>\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \n(not publicly available) doi:10.1037/h0042519\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568']","Spiking Neural Networks (SNNs) are a type of neural network that mimic the way biological neurons communicate. The foundational concept of SNNs involves the use of spikes, or quick electrical pulses, to transmit information. Unlike traditional artificial neural networks (ANNs) that use continuous values, SNNs use discrete events (spikes) to represent and process information over time.

Key foundational concepts of SNNs include:

1. **Temporal Dynamics**: SNNs incorporate the dimension of time, where the input to each neuron is integrated over time. This allows for the modeling of temporal patterns and dynamics similar to biological neurons.

2. **Sparse Encoding**: SNNs use sparse encoding strategies, which means fewer spikes are used to represent information. This leads to energy efficiency, as less energy is consumed in processing fewer spikes.

3. **Coincidence Detection**: SNNs can perform computations such as coincidence detection, which can be efficiently computed with a single spiking neuron.

In terms of encoding strategies, SNNs utilize various methods to encode information:

- **Firing Rates**: Each neuron is selective for specific features, and the firing rate (spikes per unit time) increases for selected features. However, this method can be inefficient and slow.

- **Latency and Spatio-Temporal Codes**: These methods use the timing of spikes to encode information, which is faster and more spike-efficient compared to rate coding.

- **Rank Order and Total Spike Count**: These strategies involve encoding information based on the order of spikes or the total number of spikes, allowing for efficient information representation.

Overall, SNNs are designed to be more energy-efficient and capable of processing temporal information effectively, making them suitable for applications in neuromorphic computing.","Spiking neural networks use spikes to encode information, with foundational concepts including the work of McCulloch and Pitts on logical calculus of nervous activity, and later developments in spiking neuron models.",0.0,0.6666666666666666,0.9285714285714286,0.13,0.0,0.9397042055314735
What is the project idea about government-developed OS software?,"['Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise \n‚Ä¢ But studying government software is difficult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers \n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation? \n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!\n\nB7.', '‚Ä¢ Description of the solution. \n‚Ä¢ Validation of the solution (if applicable -> discuss with coach) \n‚Ä¢ Discussion of the solution. (Including limitations)\n5\n\nStrategy\n‚Ä¢ Starting next week, there are no lectures  \n‚Ä¢ Steering meetings from week 5 till week 9 (either online or in person).  \n‚Ä¢ 1 steering meeting per week. (4+1 sprints) \n‚Ä¢ Every week, you need to plan different tasks and assignments. \n‚Ä¢ Deadline April 4.\n6\n\nStrategy\n‚Ä¢ Week 0 \n‚Ä¢ Decide project idea (today) \n‚Ä¢ Define steering meeting schedule \n‚Ä¢ Create working document of the \narticle: Problem statement and solution \nproposal! \n‚Ä¢ Define and assign tasks for each week. \n‚Ä¢ Week 1 \n‚Ä¢ Implementation \n‚Ä¢ Agreements with supervisor. \n‚Ä¢ Week 2 \n‚Ä¢ Implementation \n‚Ä¢ Week 3 \n‚Ä¢ Implementation, Full draft of article, \ndissemination. \n‚Ä¢ Week 4 \n‚Ä¢ Final refinements \n‚Ä¢ Prepare presentation\n7\n\nProject ideas\n‚Ä¢ A1. Prototype cross-machine comparable benchmarks \n‚Ä¢ A2. Add energy metrics to LMstudio/Ollama \n‚Ä¢ A3. Visualizations built-in with EnergiBridge \n‚Ä¢ A4. Service-based version of EnergiBridge\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption \n‚Ä¢ B3. Energy profiling of static analysis tools \n‚Ä¢ B4. Detailed energy profiling of build pipelines \n‚Ä¢ B5. Tool supporting SusAF workshop / process \n‚Ä¢ B6. Dataset of government-developed OS software \n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability\n\nProject ideas\n‚Ä¢ C1. Compare energy consumption of docker images for ML workloads. \n‚Ä¢ C2. Create a plugin to visualize Hugging Face carbon emissions in detail. \n‚Ä¢ C3. Plugin for ChatGPT (footprint per chat window) \n‚Ä¢ C4. NutriScore for software libraries. \n‚Ä¢ C5. Add energy-awareness to existing software \n‚Ä¢ C6. Green Shift Left \n‚Ä¢ C7. Education for Sustainable SE\n\nA1.']","['<1-hop>\n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise\n‚Ä¢ But studying government software is diÔ¨Écult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation?\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!', '<2-hop>\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption\n‚Ä¢ B3. Energy proÔ¨Åling of static analysis tools\n‚Ä¢ B4. Detailed energy proÔ¨Åling of build pipelines\n‚Ä¢ B5. Tool supporting SusAF workshop / process\n‚Ä¢ B6. Dataset of government-developed OS software\n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability']","The project idea about government-developed OS software involves creating a comprehensive dataset of software developed and used by governments to support society. The focus is on open-source development and policies, which are on the rise. The project aims to include data that helps understand the state of this software, such as whether it is buildable, has an open development history, and includes requirements documentation. The initiative could start with the Netherlands (NL), but contributions from other countries are also appreciated. The project addresses challenges like the lack of incentive to make such software popular and language barriers.","The project idea involves creating a comprehensive dataset of government-developed OS software to understand its state, including buildability, open development history, and requirements documentation. This addresses challenges like lack of incentives and language barriers.",0.99999999995,1.0,0.8461538461538461,0.57,0.0,0.9999999999999997
What is the project idea related to creating a dataset of goverment-developed OS software?,"['Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise \n‚Ä¢ But studying government software is difficult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers \n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation? \n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!\n\nB7.', 'Ideas\n\nAssignment\n‚Ä¢ Goal: Solve a Sustainable Software Engineering problem. \n‚Ä¢ Identify 1 problem that should be fixed to help enabling sustainability in \nthe software engineering industry/community. \n‚Ä¢ Propose a solution. A tool, framework, guidelines, etc. \n‚Ä¢ Implementation. \n‚Ä¢ Validation. (Depending on the idea) \n‚Ä¢ Dissemination/social impact. (Solution should be open source, welcome \ncontributors, post on social media? Tool website? Available in a package \nmanager?)\n3\n\nDeliverables\n‚Ä¢ Paper-like article.']","['<1-hop>\n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise\n‚Ä¢ But studying government software is diÔ¨Écult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation?\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!', '<2-hop>\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption\n‚Ä¢ B3. Energy proÔ¨Åling of static analysis tools\n‚Ä¢ B4. Detailed energy proÔ¨Åling of build pipelines\n‚Ä¢ B5. Tool supporting SusAF workshop / process\n‚Ä¢ B6. Dataset of government-developed OS software\n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability', '<1-hop>\n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise\n‚Ä¢ But studying government software is diÔ¨Écult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation?\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!', '<2-hop>\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption\n‚Ä¢ B3. Energy proÔ¨Åling of static analysis tools\n‚Ä¢ B4. Detailed energy proÔ¨Åling of build pipelines\n‚Ä¢ B5. Tool supporting SusAF workshop / process\n‚Ä¢ B6. Dataset of government-developed OS software\n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability', '<1-hop>\n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise\n‚Ä¢ But studying government software is diÔ¨Écult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation?\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!', '<2-hop>\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption\n‚Ä¢ B3. Energy proÔ¨Åling of static analysis tools\n‚Ä¢ B4. Detailed energy proÔ¨Åling of build pipelines\n‚Ä¢ B5. Tool supporting SusAF workshop / process\n‚Ä¢ B6. Dataset of government-developed OS software\n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability', '<1-hop>\n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise\n‚Ä¢ But studying government software is diÔ¨Écult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation?\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!', '<2-hop>\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption\n‚Ä¢ B3. Energy proÔ¨Åling of static analysis tools\n‚Ä¢ B4. Detailed energy proÔ¨Åling of build pipelines\n‚Ä¢ B5. Tool supporting SusAF workshop / process\n‚Ä¢ B6. Dataset of government-developed OS software\n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability', '<1-hop>\n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise\n‚Ä¢ But studying government software is diÔ¨Écult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation?\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!', '<2-hop>\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption\n‚Ä¢ B3. Energy proÔ¨Åling of static analysis tools\n‚Ä¢ B4. Detailed energy proÔ¨Åling of build pipelines\n‚Ä¢ B5. Tool supporting SusAF workshop / process\n‚Ä¢ B6. Dataset of government-developed OS software\n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability']","The project idea involves creating a comprehensive dataset of government-developed open-source software. This dataset would include data necessary to understand the state of the software, such as whether it is buildable, has an open development history, and includes requirements documentation. The project acknowledges the challenges in studying government software due to a lack of incentive to make it popular and language barriers. It suggests starting with the Netherlands but welcomes the inclusion of data from other countries.","The project idea is to create a dataset of government-developed OS software, which would help in understanding the state of such software, including whether it is buildable, has open development history, and has requirements documentation.",0.9999999999,1.0,1.0,0.67,0.0,0.9333015229008687
What is the project idea related to creating a dataset of government-developed OS software?,"['Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise \n‚Ä¢ But studying government software is difficult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers \n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation? \n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!\n\nB7.', 'Ideas\n\nAssignment\n‚Ä¢ Goal: Solve a Sustainable Software Engineering problem. \n‚Ä¢ Identify 1 problem that should be fixed to help enabling sustainability in \nthe software engineering industry/community. \n‚Ä¢ Propose a solution. A tool, framework, guidelines, etc. \n‚Ä¢ Implementation. \n‚Ä¢ Validation. (Depending on the idea) \n‚Ä¢ Dissemination/social impact. (Solution should be open source, welcome \ncontributors, post on social media? Tool website? Available in a package \nmanager?)\n3\n\nDeliverables\n‚Ä¢ Paper-like article.', 'Browser plugin?\n24\nCO2\n\nC4. NutriScore for software libraries\n25\n‚Ä¢ NutriScore labels are not perfect but they are a good starting point! \n‚Ä¢ What if we could do the same thing for the energy efficiency of software. \n‚Ä¢ (Also open to individual or social sustainability) \n‚Ä¢ This work can be scoped in particular domains/ecossystems/use cases. \n‚Ä¢ Libraries for stats? ML? Web Dev? Cloud?\n\nC5. Add energy-awareness to existing software\n26\n‚Ä¢ Streamlit, Notebooks, JSFiddle, \nPyScript, zsh, etc. \n‚Ä¢\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy efficiency using static code analysis. \n‚Ä¢ We don‚Äôt need an accurate value. \n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention. \n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27\n\nC7 - Education\n‚Ä¢ Educational game for Software \nSustainability practices \n‚Ä¢ Purpose: use within software teams to \ndiscuss or learn about different sustainable \nIT practices: at the organisation level, \nsoftware, etc.\n28\nhttps://github.com/OttoKaaij/Ticket-To-Sustainability/?tab=readme-ov-file\n\nProject ideas (old)\n‚Ä¢ Plugin from EnergiBridge (GUI, report generator, python library, etc.) \n‚Ä¢ Plugin for ChatGPT (carbon emissions per chat window) \n‚Ä¢ Seamless measurements for AI libraries \n‚Ä¢ Energy patterns for Green AI \n‚Ä¢ Sustainable SW dev gamification \n‚Ä¢ Sustainability auditor for AI projects \n‚Ä¢ Energy Profiling of screen colour filter tools (or display settings) \n‚Ä¢ ‚Ä¶ you can also propose yours!\n\nhttps://edu.nl/64gpk\nedu.nl/64gpk\n\n\nNeuromorphic computing\nCS4575\nSustainable Software Engineering\n05.03.2025\nNergis T√∂men\n\nIntroduction\nComputer Vision Lab\nBiomorphic Intelligence Lab\nBiomedical Intervention Optimisation Lab\nNergis\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.']","['<1-hop>\n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise\n‚Ä¢ But studying government software is diÔ¨Écult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation?\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!', '<2-hop>\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption\n‚Ä¢ B3. Energy proÔ¨Åling of static analysis tools\n‚Ä¢ B4. Detailed energy proÔ¨Åling of build pipelines\n‚Ä¢ B5. Tool supporting SusAF workshop / process\n‚Ä¢ B6. Dataset of government-developed OS software\n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability']","The project idea related to creating a dataset of government-developed OS software involves compiling a comprehensive dataset that includes data to understand the state of such software. This would involve determining if the software is buildable, has an open development history, and includes requirements documentation. The project could start with the Netherlands (NL) but would benefit from including data from other countries as well. The challenge in studying government software is due to the lack of incentive to make it popular and language barriers.","The project idea is to create a comprehensive dataset of government-developed OS software to understand the state of such software, including its buildability, open development history, and requirements documentation. This addresses challenges like the lack of incentive to make software popular and language barriers.",0.9999999999,1.0,1.0,0.89,0.16666666638888888,0.9879774311726609
How EcoAndroid reduce risk by reduce size?,"['[‚Ä¶]\r\n13\r\n\r\nAvoid Extraneous Graphics and \r\nAnimations  \r\n‚Ä¢ Context: Mobile apps that feature impressive graphics \r\nand animations. [‚Ä¶] \r\n‚Ä¢ Solution: Study the importance of graphics and \r\nanimations to the user experience and reduce them when \r\napplicable. [‚Ä¶]\r\n‚Ä¢ Example: Resort to low frame rates for animations when \r\npossible. \r\nDespite being important to improve user experience, graphics \r\nand animations are battery intensive and should be used with \r\nmoderation.  \r\n14\r\n\r\nEnergy Patterns are \r\nmore Frequent\r\nin Android Apps\r\n\r\nExample case: Nextcloud\r\nFOSS\r\n\r\nExample case: Nextcloud\r\n‚Ä¢ Users complain that sometimes they go on a trip and  Nextcloud drains their \r\nbattery. Users consider uninstalling the app when battery life is essential. \r\n‚Ä¢ File sync can be energy-greedy. Send large files to the server, long 3G/4G data connections. \r\n‚Ä¢ It is mostly used for backup. No real-time collaboration is needed. \r\n‚Ä¢ Energy requirements vary depending on context and user. Some days you really \r\nneed all the battery you can get. \r\n‚Ä¢ https://github.com/nextcloud/android/commit/\r\n8bc432027e0d33e8043cf40192203203a40ca29c\r\nSolutions?\r\n17\r\n\r\nExample case: K-9 mail\r\n18\r\n\r\nExample case: K-9 mail\r\n19\r\nSolutions?\r\n‚Ä¢ Some users noticed that K-9 mail was spending more energy than usual. üôâ \r\n‚Ä¢ A user that was having issues with a personal mail server  noticed that K-9 \r\nmail was the one of the most energy-greedy apps. IMAP IDLE protocol for real-time \r\nnotifications. \r\n‚Ä¢ When a connection is not possible, the app automatically retries later. \r\n‚Ä¢ https://github.com/k9mail/k-9/commit/\r\n86f3b28f79509d1a4d613eb39f60603e08579ea3\r\n\r\nEcoAndroid\r\n‚Ä¢ Plugin for IntelliJ (Android Studio) \r\n‚Ä¢ Dynamic Retry Delay \r\n‚Ä¢ Push Over Poll \r\n‚Ä¢ Reduce Size \r\n‚Ä¢ Cache \r\n‚Ä¢ Avoid Graphics and Animations\r\n20\r\n\r\nCarbon-Aware Computing for \r\nDatacenters \r\nhttps://sites.google.com/view/energy-efficiency-languages\r\n21\r\nAna Radovanovic ÃÅ, Ross Koningstein, Ian Schneider, Bokan \r\nChen, Alexandre Duarte, Binz Roy, Diyue Xiao, Maya \r\nHaridasan, Patrick Hung, Nick Care, Saurav Talukdar, Eric \r\nMullen, Kendal Smith, MariEllen Cottman, and Walfredo Cirne \r\n\r\n\r\n‚Ä¢ Google‚Äôs Carbon-Intelligent Computing System (CICS) \r\n‚Ä¢ Main idea: use carbon-intensity data to shift datacenter jobs in time \r\n‚Ä¢ Typically, job schedulers use a metric of cluster capacity to schedule a job in \r\na particular cluster. \r\n‚Ä¢ CICS overrides this metric with the virtual capacity curve (VCC) that \r\nfactors in Carbon intensity \r\n‚Ä¢ When a new job comes in, the scheduler estimates its CPU load and power \r\nusage and assigns it to a cluster if the VCC is not exceeded.\r\n23\r\n\r\n‚Ä¢ Jobs are divided between flexible and inflexible. \r\n‚Ä¢ Flexible load is considered shapeable/shiftable as long as its total daily \r\ncompute (CPU) demand is preserved \r\n‚Ä¢ The system needs to consider that, while running a job, the virtual capacity \r\ncurve (VCC) might drop. Hence, this job should not start in the first place. \r\n‚Ä¢ They forecast VCC for the next day\r\n24\r\n\r\n\r\nVirtual Cluster Capacity (VCC)\r\n‚Ä¢ Aims at reducing the peak load at carbon intensive hours but in total it should allow for the \r\nsome amount of daily computation!', '8. Green AI\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nLu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\nCarolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl\r\n\r\n- Overview of Green AI \r\n- Large language models \r\n- Green data-centric AI \r\n- Model simplification \r\n- Hyper parameter tuning \r\n- Mixture of Experts and DeepSeek \r\n- Green AI at Meta \r\n\r\nAI\r\n‚Ä¢ Artificial Intelligence (AI) is the branch of computer science that deals with \r\nautomating tasks that typically require human intelligence. \r\n‚Ä¢ In the past years AI has been widely applied across different domains.\u2028\r\nE.g., health care, transportation, finance. \r\n‚Ä¢ To deploy AI systems, we test them against benchmarks (or validation sets). \r\n‚Ä¢ The goal is to outperform the previous existing models. \r\n‚Ä¢ E.g., in Machine Learning we usually resort to accuracy metrics. The \r\nhighest the accuracy, the better the model.\r\n3\r\n\r\nSince 2012, the amount of computing used for AI \r\ntraining has been doubling every 6 months\r\n‚Ä¢ https://epoch.ai/blog/compute-trends\r\n4\r\n\r\n‚Ä¢ To create better AI systems we are currently adding \r\n‚Ä¢ More data \r\n‚Ä¢ More experiments \r\n‚Ä¢ Larger models\r\n5\r\n\r\nThe Equation of Red AI\r\nCost(R) ‚àùE¬∑D¬∑H\r\nCost of a single (E)xample\r\nSize of (D)ataset\r\nNumber of (H)yperparameters\r\nBy Schwartz et al. (2020)\r\n\r\nIssues of Red AI\r\n‚Ä¢ High costs (hardware, electricity, data access, etc.) \r\n‚Ä¢ Limited reproducibility.  \r\n‚Ä¢ Energy consumption. \r\n‚Ä¢ Carbon emissions. \r\n‚Ä¢ SMEs can hardly be competitive. \r\n‚Ä¢ Groundbreaking AI research is mostly done by tech giants.\r\n7\r\n\r\nA few examples of Red AI\r\n‚Ä¢ Google‚Äôs BERT-large \r\n‚Ä¢ 350 million features \r\n‚Ä¢ Trained for 2.5 days using 512 TPU chips, costing $60K+ \r\n‚Ä¢ Open-GPT3 (now GPT-4/o1) \r\n‚Ä¢ 550 tonnes CO2-eq (Patterson, 2021) \r\n‚Ä¢ 175 billion features \r\n‚Ä¢ API is open but no-pretrained model is available \r\n‚Ä¢ AlphaGo \r\n‚Ä¢ 1920 CPUs, 280 GPUs, costing $35M\r\n8\r\n\r\nRed AI in Large Language Models (LLMs)\r\n‚Ä¢ OPT by Meta reports 75 tons CO2-eq (1/7 of OpenGPT‚Äôs footprint).\u2028\r\n(Also 175billion params) \r\n‚Ä¢ However, Llama 3 reported 2,290 tons of CO2-eq (7.7M GPU hours \r\ntraining ) \r\n‚Ä¢ Open science: release includes both the pretrained models and the code \r\nneeded to train and use them. \r\n‚Ä¢ DeepSeek-V3 claims ‚Äúonly‚Äù 2.78M GPU hours \r\n‚Ä¢ Bloom by Huggingface reports 25 tons, 51 when considering embodied \r\nand operational carbon footprint. (176billion params)\r\n9\r\n\r\nRed AI\r\nAccuracy: 0.999999999\r\nGreen AI\r\n‚Ä¢ Energy \r\n‚Ä¢ Time \r\n‚Ä¢ Reproducibility \r\n‚Ä¢ Reusage\r\n\r\nHow can we adopt Green AI\r\n‚Ä¢ Check whether AI is needed. \r\n‚Ä¢ Select green datacenters. \r\n‚Ä¢ Run on low carbon intensity hours. \r\n‚Ä¢ Opt for GPU-optimised solutions (?) \r\n‚Ä¢ Opt for low-power hardware (e.g., Nvidia Jetson boards) \r\n‚Ä¢ Or GPUs that provide energy metrics (e.g., NVIDIA GPUs via the nvidia-smi tool) \r\n‚Ä¢ Report energy/carbon metrics (e.g., embed in MLFlow?)', '‚Ä¢ Groundbreaking AI research is mostly done by tech giants.\r\n7\r\n\r\nA few examples of Red AI\r\n‚Ä¢ Google‚Äôs BERT-large \r\n‚Ä¢ 350 million features \r\n‚Ä¢ Trained for 2.5 days using 512 TPU chips, costing $60K+ \r\n‚Ä¢ Open-GPT3 (now GPT-4/o1) \r\n‚Ä¢ 550 tonnes CO2-eq (Patterson, 2021) \r\n‚Ä¢ 175 billion features \r\n‚Ä¢ API is open but no-pretrained model is available \r\n‚Ä¢ AlphaGo \r\n‚Ä¢ 1920 CPUs, 280 GPUs, costing $35M\r\n8\r\n\r\nRed AI in Large Language Models (LLMs)\r\n‚Ä¢ OPT by Meta reports 75 tons CO2-eq (1/7 of OpenGPT‚Äôs footprint).\u2028\r\n(Also 175billion params) \r\n‚Ä¢ However, Llama 3 reported 2,290 tons of CO2-eq (7.7M GPU hours \r\ntraining ) \r\n‚Ä¢ Open science: release includes both the pretrained models and the code \r\nneeded to train and use them. \r\n‚Ä¢ DeepSeek-V3 claims ‚Äúonly‚Äù 2.78M GPU hours \r\n‚Ä¢ Bloom by Huggingface reports 25 tons, 51 when considering embodied \r\nand operational carbon footprint. (176billion params)\r\n9\r\n\r\nRed AI\r\nAccuracy: 0.999999999\r\nGreen AI\r\n‚Ä¢ Energy \r\n‚Ä¢ Time \r\n‚Ä¢ Reproducibility \r\n‚Ä¢ Reusage\r\n\r\nHow can we adopt Green AI\r\n‚Ä¢ Check whether AI is needed. \r\n‚Ä¢ Select green datacenters. \r\n‚Ä¢ Run on low carbon intensity hours. \r\n‚Ä¢ Opt for GPU-optimised solutions (?) \r\n‚Ä¢ Opt for low-power hardware (e.g., Nvidia Jetson boards) \r\n‚Ä¢ Or GPUs that provide energy metrics (e.g., NVIDIA GPUs via the nvidia-smi tool) \r\n‚Ä¢ Report energy/carbon metrics (e.g., embed in MLFlow?) \r\n‚Ä¢ Use pre-trained models (Transfer Learning) \r\n‚Ä¢ Preprocess dataset to reduce size. \r\n‚Ä¢ Improve parameter-tuning strategy.\r\n11\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ We need benchmarks. \r\n‚Ä¢ AllenAI leaderboard\u2028\r\nhttps://leaderboard.allenai.org \r\n‚Ä¢ No carbon metrics, yet \r\n‚Ä¢ Report comparable proxies for energy \r\nconsumption. \r\n‚Ä¢ ‚ö† Learning algorithms behave in a non-\r\ndeterministic \r\n‚Ä¢ ‚ö† Different data-points lead to different \r\nenergy consumption\r\n12\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ Reporting measured energy consumption \r\n‚Ä¢ + Accurate \r\n‚Ä¢ + Easy to map to carbon emissions \r\n‚Ä¢ - Hard to measure \r\n‚Ä¢ - Low replicability \r\n‚Ä¢ Reporting time / estimation based on time & hardware \r\n‚Ä¢ + Easy to measure \r\n‚Ä¢ + Correlates with energy consumption in most cases. \r\n‚Ä¢ -  Difficult to compare with measurements from other setups \r\n‚Ä¢ E.g., floating point operations (FPOs) (?) \r\n‚Ä¢ + comparable across different setups \r\n‚Ä¢ + cheap \r\n‚Ä¢ - does not factor in memory energy consumption \r\n‚Ä¢ - does not reflect carbon emissions\r\n13\r\n\r\nData-centric AI\r\n\r\nData-centric AI\r\n‚Ä¢ Emerging discipline that deals with systematically engineering data to build AI \r\nsystems. \r\n‚Ä¢ Shift from improving the training strategy to improving the data. \r\n‚Ä¢ It is better to have small but reliable datasets than large but noisy \r\ndatasets. \r\n‚Ä¢ => Improve data collection, data labelling, and data preprocessing. \r\n‚Ä¢ More about data-centric AI by Andrew Ng:\u2028\r\nhttps://www.youtube.com/watch?v=06-AZXmwHjo\r\n15\r\n\r\n\r\nGreen Data-centric AI\r\n‚Ä¢ How do different ML algorithms compare \r\nin terms of energy consumption? \r\n‚Ä¢ How does number of rows relate to the \r\nenergy consumption of ML models? \r\n‚Ä¢ How does number of features relate to \r\nthe energy consumption of ML models? \r\n‚Ä¢ What is the impact of reducing data in the \r\nperformance of the model?', ""‚Ä¢ Our question: Can we save energy with alternative approaches? \r\n‚Ä¢ We studied Grid Search, Random Search and Bayesian \r\nOptimisation.\r\n27\r\nTim's MSc Thesis, 2022 \r\nAccepted at CAIN‚Äô23\r\n\r\n\r\nResults\r\n29\r\nConclusions? \r\n‚Ä¢ Bayesian converges faster. \r\n‚Ä¢ No clear winner between Grid and Random\r\n\r\nDeepSeekMoE\r\n30\r\nPreprint at ArXiv, 2024 https://arxiv.org/pdf/\r\n2401.06066\r\n\r\nMixture of Experts\r\n‚Ä¢ Llama3.1 has 405B parameters, DeepSeek V3 671B \r\n‚Ä¢ Yet DeepSeek has quicker inference times and claims less energy \r\nconsumption (?) \r\n‚Ä¢ Divide the model into smaller blocks of experts \r\n‚Ä¢ Tokens get routed to certain experts based on the query \r\n‚Ä¢ Only part of the network is active during inference \r\n‚Ä¢ DeepSeek claims only 37B out of 671B parameters get active\r\n31\r\n\r\nDeepSeekMoE\r\n32\r\n\r\nDeepSeekMoE\r\n33\r\n‚Ä¢ Comparable performance to \r\nLLaMA2 7B effectively using \r\nless half the parameters \r\n‚Ä¢ Less computational power \r\n‚Ä¢ Problems (?) \r\n‚Ä¢ Still need to load all the \r\nparameters \r\n‚Ä¢ High memory -> high \r\nembodied carbon\r\n\r\nGreen AI at FacebookMeta\r\n34\r\nSustainable AI: Environmental Implications, \r\nChallenges and Opportunities (2022)\r\n\r\nCarbon footprint mapped to the AI lifecycle\r\n‚Ä¢ There are 4 main overarching stages where carbon emissions need to be isolated: data \r\ncollection, experimentation, training, inference. \r\n‚Ä¢ At Facebook, recommendation systems split energy consumption evenly between \r\ntraining and inference; text translation models have a 35%/65% split. (Operational cost) \r\n‚Ä¢ Operational/embodied cost split: 30%/70%\r\n35\r\n\r\nOpen issues according to Meta\r\n‚Ä¢ A vast portion of projects only use GPUs at 30%.\u2028\r\nShould be higher to attenuate embodied carbon.\r\n36\r\nBased on 10K AI projects\r\n\r\nData Jan\r\nInformed Adaptation\r\nData Feb\r\nData Mar\r\nData Apr\r\nData May\r\n‚Ä¶\r\n~Data Dec\r\n~Data Dec\r\nData Jan\r\nData Feb\r\nData Mar\r\nData Apr\r\nData May\r\n‚Ä¶\r\nModel update Model update Model update\r\nCheck if \r\ndata change\r\nCheck if \r\ndata change\r\nCheck if \r\ndata change\r\nModel update\r\nBlind Adaptation\r\nThe AI Model will be \r\nupdated fewer times and \r\nonly when necessary.\r\nKnow when to retrain models\r\nNeither too early nor too late\r\n37\r\nAdaptation Techniques\r\n?\r\n\r\nGreen Architectural Tactics for ML-Enabled \r\nSystem\r\n38\r\nICSE-SEIS 2024\r\n\r\nArchitectural tactics\r\n39\r\n\r\nData-centric\r\n40\r\n‚Ä¢ Reduce data size \r\n‚Ä¢ Sampling \r\n‚Ä¢ Dimensionality reduction \r\n‚Ä¢ Quantization\r\n\r\nAlgorithm Design\r\n41\r\n‚Ä¢ Carefully select your algorithm \r\n‚Ä¢ You don‚Äôt need the fanciest \r\ntechniques\r\n\r\nModel Optimization\r\n42\r\n‚Ä¢ Add energy to training parameters \r\n‚Ä¢ Reduce FLOPs \r\n‚Ä¢ Pruning, sparsity \r\n‚Ä¢  Take advantage of existing models\r\n\r\nModel Training\r\n43\r\n‚Ä¢ Quantization\r\n‚Ä¢ SAVE TRAINING PROGRESS\r\n\r\nModel Deployment\r\n44\r\n‚Ä¢ Distributed deployment \r\n‚Ä¢ Energy efficient hardware and \r\nconfigurations\r\n\r\nModel Management\r\n45\r\n‚Ä¢ Reuse the model as much as possible \r\n\r\nRethinking the Architecture: Spiking Neural Networks\r\n46\r\n\r\nRethinking the Architecture: Spiking Neural Networks\r\n47\r\n\r\nSELF Lab\r\n48\r\n\r\nrecap"", ""‚Ä¢ 6 machine learning algorithms: SVM, Decision Tree, KNN, Random Forrest, \r\nAdaBoost, Bagging Classifier. \r\n‚Ä¢ Reduce the number of rows. 10%, 20%, .., 100% \r\n‚Ä¢ Stratified random sampling (?) \r\n‚Ä¢ Reduce the number of features. 10%, 20%, .., 100% \r\n‚Ä¢ Feature importance metric based on the Chi-Square Test (Chi2) \r\n‚Ä¢ Estimate energy consumption using a RAPL-based tool. (?)\r\n18\r\n\r\n‚Ä¢ Repeat 30 times \r\n‚Ä¢ Fix random seeds \r\n‚Ä¢ ‚Ä¶ \r\n‚Ä¢ Data was not Normal => tailed Normal distribution.\r\n19\r\n(?)\r\n\r\nResults: energy consumption of algorithms\r\n\r\nResults: energy vs data shape\r\n\r\nResults: performance vs data shape\r\n\r\nDiscussion\r\n‚Ä¢ Other data properties should be investigated. \r\n‚Ä¢ E.g., data types \r\n‚Ä¢ Reporting energy data is essential. It can lead to different model selection \r\nwithout hindering model performance. \r\n‚Ä¢ There is a big opportunity in Model and Data Simplification.\r\n23\r\n\r\nData/Model Simplification\r\n‚Ä¢ (?) \r\n‚Ä¢ Data selection \r\n‚Ä¢ Data quantisation. Posit? \r\n‚Ä¢ Data distillation \r\n‚Ä¢ Coreset extraction (?) \r\n‚Ä¢ Model distillation \r\n‚Ä¢ Model quantisation \r\n‚Ä¢ Model pruning \r\n‚Ä¢ ‚Ä¶\r\n24\r\n\r\nPosit vs Float\r\nMore about this: https://spectrum.ieee.org/floating-point-numbers-posits-processor\r\nBetter for DL use cases\r\n\r\nHow can we tune \r\nlearning \r\nparameters \r\nefficiently?\r\n\r\nHyper parameter tuning\r\n‚Ä¢ When training an ML model, there are several parameters that need to be \r\ntuned. \r\n‚Ä¢ E.g., in SVM we have the Regularization parameter C, the kernel function, \r\nthe degree of the kernel function, and depending on the case, many other. \r\n‚Ä¢ The common approach revolves around grid search. The user provides a \r\nsequence of possible values for each parameter and the pipeline runs all \r\npossible combinations. \r\n‚Ä¢ Our question: Can we save energy with alternative approaches? \r\n‚Ä¢ We studied Grid Search, Random Search and Bayesian \r\nOptimisation.\r\n27\r\nTim's MSc Thesis, 2022 \r\nAccepted at CAIN‚Äô23\r\n\r\n\r\nResults\r\n29\r\nConclusions? \r\n‚Ä¢ Bayesian converges faster. \r\n‚Ä¢ No clear winner between Grid and Random\r\n\r\nDeepSeekMoE\r\n30\r\nPreprint at ArXiv, 2024 https://arxiv.org/pdf/\r\n2401.06066\r\n\r\nMixture of Experts\r\n‚Ä¢ Llama3.1 has 405B parameters, DeepSeek V3 671B \r\n‚Ä¢ Yet DeepSeek has quicker inference times and claims less energy \r\nconsumption (?) \r\n‚Ä¢ Divide the model into smaller blocks of experts \r\n‚Ä¢ Tokens get routed to certain experts based on the query \r\n‚Ä¢ Only part of the network is active during inference \r\n‚Ä¢ DeepSeek claims only 37B out of 671B parameters get active\r\n31\r\n\r\nDeepSeekMoE\r\n32\r\n\r\nDeepSeekMoE\r\n33\r\n‚Ä¢ Comparable performance to \r\nLLaMA2 7B effectively using \r\nless half the parameters \r\n‚Ä¢ Less computational power \r\n‚Ä¢ Problems (?) \r\n‚Ä¢ Still need to load all the \r\nparameters \r\n‚Ä¢ High memory -> high \r\nembodied carbon\r\n\r\nGreen AI at FacebookMeta\r\n34\r\nSustainable AI: Environmental Implications, \r\nChallenges and Opportunities (2022)\r\n\r\nCarbon footprint mapped to the AI lifecycle\r\n‚Ä¢ There are 4 main overarching stages where carbon emissions need to be isolated: data \r\ncollection, experimentation, training, inference. \r\n‚Ä¢ At Facebook, recommendation systems split energy consumption evenly between \r\ntraining and inference; text translation models have a 35%/65% split. (Operational cost) \r\n‚Ä¢ Operational/embodied cost split: 30%/70%\r\n35\r\n\r\nOpen issues according to Meta\r\n‚Ä¢ A vast portion of projects only use GPUs at 30%.\u2028\r\nShould be higher to attenuate embodied carbon."", 'Lu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\n7. Green SE ‚Äì Research\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nCarolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl\r\n\r\n1. Energy patterns for mobile apps \r\n2. Carbon-aware datacenters \r\n3. Energy Regression Testing \r\n4. Debugging Energy with Docker images \r\n5. Energy Efficiency vs Code Quality \r\n\r\n‚Ä¢ While learning about these works, try to be critical about them and find their \r\npitfalls.\r\n3\r\n\r\n‚Ä¢ We have seen that measuring energy consumption is not trivial \r\n‚Ä¢ It is not practical considering that developers have other priorities above \r\nenergy efficiency \r\n‚Ä¢ At the same time, every now and then there are some efforts to improve \r\nenergy efficiency in some cases. This is time consuming and requires \r\nexpertise. \r\n‚Ä¢ How can we reuse these efforts?\r\n4\r\n\r\nEnergy Patterns for Mobile \r\nApps\r\nhttps://tqrg.github.io/energy-patterns/\r\n\r\nMethodology\r\n5. Catalog of Energy Patterns\r\n22 \r\npatterns\r\nF-droid\r\nCurated Lists\r\n1. App Collection\r\n1783 \r\napps\r\n3. Manual Refinement of Subjects of \r\nInterest\r\n1563 \r\nchanges\r\n4. Thematic Analysis\r\n431 \r\nreusable \r\nchanges\r\n2. Collect Changes With Potential Interest\r\n/.*(energy|power|battery).*/\r\n6028 \r\nchanges\r\n\r\nThematic Analysis\r\n1. Familiarization with data \r\n2. Generating initial labels \r\n3. Reviewing themes\r\n4. Defining and naming themes\r\n\r\n‚Ä¢ Energy Pattern: design pattern to improve energy efficiency.. \r\n‚Ä¢ 22 energy patterns. \r\n‚Ä¢ Each pattern is described by Context, Solution, Example, References from \r\nliterature, and Occurences (links to code changes from git repositories).\r\n8\r\n\r\nhttps://tqrg.github.io/energy-patterns\r\n\r\nDark UI Colors \r\nProvide a dark UI color theme to \r\nsave battery on devices with \r\nAMOLED screens.\r\n‚Ä¢ Context: [‚Ä¶] Apps that require heavy usage of screen can \r\nhave a substantial negative impact on battery life. \r\n‚Ä¢ Solution: Provide a UI theme with dark background colors. [‚Ä¶]\r\n‚Ä¢ Example: In a reading app, provide a theme with a dark \r\nbackground using light colors to display text. [‚Ä¶] \r\n10\r\n\r\nDark UI Colors \r\nProvide a dark UI color theme to \r\nsave battery on devices with \r\nAMOLED screens.\r\n‚Ä¢ Context: [‚Ä¶] Apps that require heavy usage of screen can \r\nhave a substantial negative impact on battery life. \r\n‚Ä¢ Solution: Provide a UI theme with dark background colors. [‚Ä¶]\r\n‚Ä¢ Example: In a reading app, provide a theme with a dark \r\nbackground using light colors to display text. [‚Ä¶] \r\n11\r\n\r\nDynamic Retry Delay\r\n‚Ä¢ Context: [‚Ä¶] In a mobile app, when a given resource is \r\nunavailable, the app will unnecessarily try to connect the resource \r\nfor a number of times, leading to unnecessary power consumption. \r\n‚Ä¢ Solution: Increase retry interval after each failed connection. [‚Ä¶]\r\n‚Ä¢ Example: Consider a mobile app that provides a news feed and \r\nthe app is not able to reach the server to collect updates. [‚Ä¶] use \r\nthe Fibonacci series to increase the time between attempts.\r\nWhenever an attempt to access a \r\nresource fails, increase the time \r\ninterval before retrying.\r\n12\r\n\r\nBatch Operations \r\n‚Ä¢ Context: Executing operations separately leads to extraneous \r\ntail energy consumptions  \r\n‚Ä¢ Solution: Bundle multiple operations in a single one. [‚Ä¶]\r\n‚Ä¢ Example: Use system provided APIs to schedule background \r\ntasks. These APIs, guarantee that device will exit sleep mode \r\nonly when there is a reasonable amount of work to do or when a \r\ngiven task is urgent.', '‚Ä¢ Examples: \r\n‚Ä¢ Technical Debt \r\n‚Ä¢ Does it scale? \r\n‚Ä¢ Software testing \r\n‚Ä¢ Bus-factor \r\n‚Ä¢ Data integrity \r\n‚Ä¢ Innovation \r\n‚Ä¢ ‚Ä¶\r\n10\r\n\r\nIndividual\r\n‚Ä¢ Well-being of the individuals in an organisation.\u2028\r\nNote that it also includes how well individuals interact \r\nwith each other within the org. \r\n‚Ä¢ Examples: \r\n‚Ä¢ mental and physical well-being \r\n‚Ä¢ self-respect \r\n‚Ä¢ education/skills \r\n‚Ä¢ career development \r\n‚Ä¢ ‚Ä¶\r\n11\r\n\r\nSocial\r\n‚Ä¢ concerned with societal communities (groups of people, \r\norganisations) and the factors that erode trust in society. \r\n‚Ä¢ Examples: \r\n‚Ä¢ Social equity \r\n‚Ä¢ Justice \r\n‚Ä¢ Employment \r\n‚Ä¢ Democracy \r\n‚Ä¢ ‚Ä¶ \r\n‚Ä¢ Also includes compliance with policies and regulations \r\n12\r\n\r\nEnvironmental Sustainability\r\n‚Ä¢ the branch of Software Engineering that studies \r\nthe development of software that has minimal \r\nimpact in our planet throughout its whole \r\nlifecycle. \r\n‚Ä¢ Looking at software at different levels: \r\n‚Ä¢ Developing, Using, Serving, ‚Ä¶ \r\n‚Ä¢ Also includes e-waste. \r\n‚Ä¢ Almost identical to Green Software. (?)\r\n13\r\nBordallo II\r\n\r\nGreen Software\r\n‚Ä¢ Sustainability and energy efficiency. \r\n‚Ä¢ Building energy-efficient software is important also from a \r\ntechnical sustainability POV. \r\n‚Ä¢ Smartphones, smart wearables, IoT devices, etc. run on limited \r\npower resources. \r\n‚Ä¢ Developing software to these devices require energy-efficiency \r\ntesting and improvement. \r\n‚Ä¢ It also leads to environmental sustainability (e.g., less battery \r\ncycles) \r\n‚Ä¢ Important for UX (e.g., no need to walk around with power banks)\r\n14\r\n\r\nhttps://www.menti.com/uns9d89kzn\r\nWhat is the sustainability \r\ndimension you are most \r\ninterested in?\r\n?\r\n15\r\n\r\nEconomical sustainability tops the environment\r\n‚Ä¢ In general, a software project will not survive if it‚Äôs not economical \r\nsustainable \r\n‚Ä¢ Yet, a project can survive even if it is not environmental sustainable \r\n‚Ä¢ The mindset is changing! \r\n‚Ä¢ Software consumers have started to worry about the climate impact \r\nof their behaviour as users. \r\n‚Ä¢ Being environmentally sustainable is now an important competitive \r\nfactor \r\n‚Ä¢ Marketing teams are already using all eco-friendly labels. Technical \r\nteams are not there yet, though. \r\n‚Ä¢ It‚Äôs easier said than done!\r\n$\r\n16\r\n\r\nGreen Washing\r\n‚Ä¢ Deceptively use marketing techniques to \r\nclaim being eco-friendly. \r\n‚Ä¢ Opting for green-coloured designs. \r\n‚Ä¢ Red/orange is usually perceived as \r\ntasty. \r\n‚Ä¢ Green is perceived as eco-friendly. \r\n‚Ä¢ The VW case. (?)\r\n17\r\n\r\nThe VW scandal\r\nGreenwashing\r\n‚Ä¢ Used software to cheat on vehicle emissions \r\ntests. \r\n‚Ä¢ The vehicle‚Äôs software could detect whether they \r\nwere being tested, changing the performance \r\naccordingly to improve results. \r\n‚Ä¢ Affected 11M cars worldwide, 8M in Europe.\r\n18\r\n\r\nHow can we drive sustainability \r\nin the SE industry?\r\n\r\nGreen Procurement\r\n‚Ä¢ Customers decide on providers that share their values \r\n‚Ä¢ This is currently the main trigger reason why organisations \r\nworry about Sustainability and Green Software. \r\n‚Ä¢ Examples of green procurement: \r\n‚Ä¢ Customers that only buy green services/products \r\n‚Ä¢ Companies that only use green providers \r\n‚Ä¢ Developers that only work for green companies \r\n‚Ä¢ Green procurement makes environmental sustainability \r\nessential for economical sustainability.\r\n20\r\n\r\nSustainability via compliance\r\n‚Ä¢ EU wants to be carbon neutral by 2030 \r\n‚Ä¢ This also affects the ICT sector. Estimated to impact \r\n14% of the global carbon footprint by 2040. \r\n‚Ä¢ Some initiatives are already being negotiated. \r\n‚Ä¢ Extending the smartphone lifetime to 7 years. \r\n‚Ä¢ Right-to-repair movement. https://repair.eu \r\n‚Ä¢ Making IT services relying on clean energy more \r\naccessible (e.g., less taxes).\r\n21\r\n\r\nSoftware for Sustainability \r\n‚Ä¢ We are not covering it in this course.', '27\r\n\r\nCarbon intensity\r\n‚Ä¢ How much carbon is emitted per kWh of electricity consumed. \r\n‚Ä¢ The common unit: \r\n ü§∑ \r\n‚Ä¢ E.g.,  gas-based power plants emit less carbon than coal-based plants. \r\n‚Ä¢ The power grid is a mix between different sources of electricity ‚Äì different \r\nlocations have different carbon intensity.\r\ngCO2eq/kWh\r\n28\r\n\r\nhttps://app.electricitymaps.com/map\r\n\r\nBy Asim Hussain: https://principles.green/principles/carbon-intensity/\r\nüìù Reducing software energy consumption can help reduce the carbon intensity. Why?\r\n\r\nOne would expect zero carbon intensity from solar-\r\npanels or wind farms, but that‚Äôs not the case.\r\n‚ö†\r\n?\r\n\r\nMarginal Power Plant\r\n‚Ä¢ Renewable-based power plants cannot adapt to demand. \r\n‚Ä¢ When demand is higher than the existing power in the electricity grid, we \r\nneed a power plant that is able to scale up to that demand. \r\n‚Ä¢ This is usually done by fossil-based power plants. They are called the \r\nmarginal power plants. \r\n‚Ä¢ The problem is that marginal power plants do not scale down to zero. \r\n‚Ä¢ There is always a minimum carbon that needs to be emitted, even if there is \r\na lot of renewable energy in the grid.\r\n32\r\n\r\nBy Asim Hussain: https://principles.green/principles/carbon-intensity/\r\nHow could we fix this?\r\nWhat‚Äôs the problem here?\r\n\r\nMarginal Carbon Intensity\r\n‚Ä¢ Increase or decrease in carbon emissions in the electrical grid, in response \r\nto an infinitesimal increase/decrease in power demand/supply.\r\n\r\nFrom: ‚ÄúLiterature Review: On the effectiveness of a Marginal Carbon Intensity Signal ‚Äú\r\n\r\nWhy is marginal carbon intensity \r\nrelevant for software?\r\n‚Ä¢ Tip: consider a task scheduler in a datacenter.\r\n\r\nRecap\r\n‚Ä¢ Power \r\n‚Ä¢ Energy \r\n‚Ä¢ Average Power \r\n‚Ä¢ Energy Delay Product \r\n‚Ä¢ Electric charge (battery capacity) \r\n‚Ä¢ Carbon dioxide equivalent (carbon emissions) \r\n‚Ä¢ 100-global-warming potential \r\n‚Ä¢ Carbon Intensity \r\n‚Ä¢ Marginal Carbon Intensity\r\n37\r\n?\r\n\r\nFurther Reading\r\n‚Ä¢ Blog post on energy units:\u2028\r\nhttps://luiscruz.github.io/2023/05/13/energy-units.html \r\n38\r\n?', ""Unless there‚Äôs a \r\ngood reason. \r\n‚Ä¢ E.g., somewhere amongst the 30 executions, \r\nthere might be 1 or 2 that failed to finish due \r\nto some unexpected error. \r\n‚Ä¢ (It happens and that‚Äôs ok!)‚Äì consequently, \r\nthe execution is shorter and spends less \r\nenergy ‚Äì falsely appearing as more \r\nenergy efficient. \r\n‚Ä¢ If data is not Normal there might be some \r\nissues affecting the measurements that \r\nmight be ruining results. It is important to \r\ninvestigate this.\r\n16\r\n\r\nEnergy data is not normal. Why?\r\n‚Ä¢ It might be caused by one of the following reasons: \r\n‚Ä¢ There was an error in some of the executions. If not detected and fixed it \r\nmight ruin results. \r\n‚Ä¢ Your tests are not fully replicable or are not deterministic. Quite frequent \r\nwhen you have internet requests or random-based algorithms. \r\n‚Ä¢ There is an unusual task being run by the system during some experiments. \r\n‚Ä¢ The computer entered a different power mode. \r\n‚Ä¢ External physical conditions have changed. E.g., someone opened a \r\nwindow.\r\n17\r\n\r\nEnergy data is not normal. How to fix?\r\n‚Ä¢ We have 2+1 options: \r\n1. Remove outliers. If there are only a few points that deviate from the normal \r\ndistribution, it is okay to simply remove them. \r\n‚Ä¢ Use the z-score outlier removal. (?) \r\n‚Ä¢ Remove all data points that deviate from the mean more than 3 standard \r\ndeviations: \r\n \r\n2. Fix the issue and rerun experiments. \r\n3. Conclude that nothing can be done about it and data will never be normal. (e.g., \r\nin AI, executions are rarely deterministic). ‚ö† Only after ruling out the previous \r\npoints.\r\n| ¬Øx ‚àíx| > 3s\r\n18\r\n\r\nHow do we know whether data is Normal?\r\n‚Ä¢ Visualise distribution shape: violin plots, histograms, density plot.\u2028\r\n \r\n‚Ä¢ Shapiro-Wilk test.\u2028\r\ndata is not normal;\u2028\r\nwe are not sure but it is okay to assume that data is \r\nnormal.\r\np-value < 0.05 ‚áí\r\np-value ‚â•0.05 ‚áí\r\n19\r\n\r\nAfter having all data ready, which artefact \r\nis more energy efficient(?) \r\nFirst approach: compare sample means. \r\n‚ö† assuming normal distribution\r\n\r\nStatistical significance\r\n‚Ä¢ Even if, on average, one artefact has lower \r\nenergy consumption than other,  it might be just \r\na random difference. \r\n‚Ä¢ When we extract a sample from a normal \r\ndistribution it will never be the exact same \r\n‚Ä¢ Statistical significance tests help you \r\nunderstand the differences in the average are \r\nconclusive/significant or inconclusive/\r\ninsignificant.\r\n21\r\n‚ö† assuming normal distribution\r\n\r\nStatistical significance test\r\n‚Ä¢ Two-sided parametric test Welch‚Äôs t-test. \r\n‚Ä¢ Less known alternative to student‚Äôs t-test.\r\n22\r\nWelch‚Äôs t-test in Python\r\nfrom scipy.stats import ttest_ind \r\n_,pvalue = ttest_ind(sample_a, sample_b, \r\n                     equal_var=False, \r\n                     alternative='two-sided')\r\n(?)\r\n‚ö† assuming normal distribution\r\n\r\nEffect Size analysis\r\n‚Ä¢ Now that we know that results are statistically significant we need to \r\nmeasure the difference between the two samples. \r\n‚Ä¢ Mean difference: \r\n \r\n‚Ä¢ Percent change: \r\n \r\n‚Ä¢ Cohen‚Äôs d (informal definition: mean difference normalized by a combined \r\nstandard deviation): \r\nŒî¬Øx\r\nxB ‚àíxA\r\nxA\r\n√ó 100 % = Œî¬Øx\r\nxA\r\n√ó 100 %\r\nŒî¬Øx\r\n1\r\n2\r\ns21 + s22\r\n23\r\n‚ö† assuming normal distribution\r\n\r\nImagine that version A spends 70J and \r\nversion B spends 69J with a \r\n."", '8\r\n\r\nhttps://tqrg.github.io/energy-patterns\r\n\r\nDark UI Colors \r\nProvide a dark UI color theme to \r\nsave battery on devices with \r\nAMOLED screens.\r\n‚Ä¢ Context: [‚Ä¶] Apps that require heavy usage of screen can \r\nhave a substantial negative impact on battery life. \r\n‚Ä¢ Solution: Provide a UI theme with dark background colors. [‚Ä¶]\r\n‚Ä¢ Example: In a reading app, provide a theme with a dark \r\nbackground using light colors to display text. [‚Ä¶] \r\n10\r\n\r\nDark UI Colors \r\nProvide a dark UI color theme to \r\nsave battery on devices with \r\nAMOLED screens.\r\n‚Ä¢ Context: [‚Ä¶] Apps that require heavy usage of screen can \r\nhave a substantial negative impact on battery life. \r\n‚Ä¢ Solution: Provide a UI theme with dark background colors. [‚Ä¶]\r\n‚Ä¢ Example: In a reading app, provide a theme with a dark \r\nbackground using light colors to display text. [‚Ä¶] \r\n11\r\n\r\nDynamic Retry Delay\r\n‚Ä¢ Context: [‚Ä¶] In a mobile app, when a given resource is \r\nunavailable, the app will unnecessarily try to connect the resource \r\nfor a number of times, leading to unnecessary power consumption. \r\n‚Ä¢ Solution: Increase retry interval after each failed connection. [‚Ä¶]\r\n‚Ä¢ Example: Consider a mobile app that provides a news feed and \r\nthe app is not able to reach the server to collect updates. [‚Ä¶] use \r\nthe Fibonacci series to increase the time between attempts.\r\nWhenever an attempt to access a \r\nresource fails, increase the time \r\ninterval before retrying.\r\n12\r\n\r\nBatch Operations \r\n‚Ä¢ Context: Executing operations separately leads to extraneous \r\ntail energy consumptions  \r\n‚Ä¢ Solution: Bundle multiple operations in a single one. [‚Ä¶]\r\n‚Ä¢ Example: Use system provided APIs to schedule background \r\ntasks. These APIs, guarantee that device will exit sleep mode \r\nonly when there is a reasonable amount of work to do or when a \r\ngiven task is urgent. [‚Ä¶]\r\n13\r\n\r\nAvoid Extraneous Graphics and \r\nAnimations  \r\n‚Ä¢ Context: Mobile apps that feature impressive graphics \r\nand animations. [‚Ä¶] \r\n‚Ä¢ Solution: Study the importance of graphics and \r\nanimations to the user experience and reduce them when \r\napplicable. [‚Ä¶]\r\n‚Ä¢ Example: Resort to low frame rates for animations when \r\npossible. \r\nDespite being important to improve user experience, graphics \r\nand animations are battery intensive and should be used with \r\nmoderation.  \r\n14\r\n\r\nEnergy Patterns are \r\nmore Frequent\r\nin Android Apps\r\n\r\nExample case: Nextcloud\r\nFOSS\r\n\r\nExample case: Nextcloud\r\n‚Ä¢ Users complain that sometimes they go on a trip and  Nextcloud drains their \r\nbattery. Users consider uninstalling the app when battery life is essential. \r\n‚Ä¢ File sync can be energy-greedy. Send large files to the server, long 3G/4G data connections. \r\n‚Ä¢ It is mostly used for backup. No real-time collaboration is needed. \r\n‚Ä¢ Energy requirements vary depending on context and user. Some days you really \r\nneed all the battery you can get. \r\n‚Ä¢ https://github.com/nextcloud/android/commit/\r\n8bc432027e0d33e8043cf40192203203a40ca29c\r\nSolutions?\r\n17\r\n\r\nExample case: K-9 mail\r\n18\r\n\r\nExample case: K-9 mail\r\n19\r\nSolutions?\r\n‚Ä¢ Some users noticed that K-9 mail was spending more energy than usual. üôâ \r\n‚Ä¢ A user that was having issues with a personal mail server  noticed that K-9 \r\nmail was the one of the most energy-greedy apps. IMAP IDLE protocol for real-time \r\nnotifications. \r\n‚Ä¢ When a connection is not possible, the app automatically retries later. \r\n‚Ä¢ https://github.', 'Carolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nLu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\n1. Intro Class\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl\r\n\r\n1. Intro to Sustainable SE \r\n2. Intro to the course\r\n2\r\n\r\nof the electricity consumed worldwide \r\nby 2040 will stem from ICT\r\n14%\r\n\r\n4\r\nhttps://xkcd.com/1007/\r\n\r\nBuzz words\r\n‚Ä¢ Eco-friendly \r\n‚Ä¢ Climate change, action, adaption \r\n‚Ä¢ Energy efficiency \r\n‚Ä¢ Environmental-responsible \r\n‚Ä¢ Carbon-neutral; Climate-neutral; Net zero \r\n‚Ä¢ Carbon-offsetting \r\n‚Ä¢ Carbon-free \r\n‚Ä¢ Clean technology \r\n‚Ä¢ E-waste\r\n5\r\n\r\nhttps://www.menti.com/uns9d89kzn\r\nWhat is Sustainable \r\nSoftware Engineering?\r\n?\r\n6\r\n\r\nSustainable Software \r\nEngineering is‚Ä¶\r\n7\r\n‚Ä¶the discipline that studies the process of creating software systems that are able \r\nto create value in the long term without hindering its surrounding environment.\r\n\r\n8\r\nEconomical\r\nSocial\r\nTechnical\r\nIndividual\r\nEnvironmental\r\nSustainable\r\nSoftware\r\nEngineering\r\n‚≠ê\r\nTechnical\u2028\r\n‚öô\r\nEconomical\u2028\r\nüí∞\r\nSocial\u2028\r\nüë©üíºüë®üíºüë©üíºüë©üíº\r\nIndividual\u2028\r\nüë©üíª\r\nEnvironmental\u2028\r\nüå±\r\nSustainable\u2028\r\nSoftware \r\nEngineering\r\n\r\nEconomical\r\n‚Ä¢ Focused on assets, capital and added value\u2028\r\n(wealth creation, prosperity, profitability, capital \r\ninvestment, income, etc.) \r\n‚Ä¢ Nr of customers  \r\n‚Ä¢ Man-day-rate estimate \r\n‚Ä¢ Next round of funding \r\n‚Ä¢ Meet requirements in the contract\r\n9\r\n\r\nTechnical\r\n‚Ä¢ Longevity of information, systems, and infrastructure and their \r\nadequate evolution with changing surrounding conditions. \r\n‚Ä¢ Examples: \r\n‚Ä¢ Technical Debt \r\n‚Ä¢ Does it scale? \r\n‚Ä¢ Software testing \r\n‚Ä¢ Bus-factor \r\n‚Ä¢ Data integrity \r\n‚Ä¢ Innovation \r\n‚Ä¢ ‚Ä¶\r\n10\r\n\r\nIndividual\r\n‚Ä¢ Well-being of the individuals in an organisation.\u2028\r\nNote that it also includes how well individuals interact \r\nwith each other within the org. \r\n‚Ä¢ Examples: \r\n‚Ä¢ mental and physical well-being \r\n‚Ä¢ self-respect \r\n‚Ä¢ education/skills \r\n‚Ä¢ career development \r\n‚Ä¢ ‚Ä¶\r\n11\r\n\r\nSocial\r\n‚Ä¢ concerned with societal communities (groups of people, \r\norganisations) and the factors that erode trust in society. \r\n‚Ä¢ Examples: \r\n‚Ä¢ Social equity \r\n‚Ä¢ Justice \r\n‚Ä¢ Employment \r\n‚Ä¢ Democracy \r\n‚Ä¢ ‚Ä¶ \r\n‚Ä¢ Also includes compliance with policies and regulations \r\n12\r\n\r\nEnvironmental Sustainability\r\n‚Ä¢ the branch of Software Engineering that studies \r\nthe development of software that has minimal \r\nimpact in our planet throughout its whole \r\nlifecycle. \r\n‚Ä¢ Looking at software at different levels: \r\n‚Ä¢ Developing, Using, Serving, ‚Ä¶ \r\n‚Ä¢ Also includes e-waste. \r\n‚Ä¢ Almost identical to Green Software. (?)\r\n13\r\nBordallo II\r\n\r\nGreen Software\r\n‚Ä¢ Sustainability and energy efficiency. \r\n‚Ä¢ Building energy-efficient software is important also from a \r\ntechnical sustainability POV. \r\n‚Ä¢ Smartphones, smart wearables, IoT devices, etc. run on limited \r\npower resources. \r\n‚Ä¢ Developing software to these devices require energy-efficiency \r\ntesting and improvement. \r\n‚Ä¢ It also leads to environmental sustainability (e.g., less battery \r\ncycles) \r\n‚Ä¢ Important for UX (e.g., no need to walk around with power banks)\r\n14\r\n\r\nhttps://www.menti.com/uns9d89kzn\r\nWhat is the sustainability \r\ndimension you are most \r\ninterested in?\r\n?', 'Energy profiling of static analysis tools\r\n‚Ä¢ What is the energy consumption of a ""typical run"" for a few OSS projects? \r\n‚Ä¢ Does the type of analysis matter? Are certain analysis more expensive? Does \r\nthe number of rules that are activated in a static analysis tool important for the \r\nenergy consumption? \r\n‚Ä¢ Differences between static analysis tools [lower priority]\r\n\r\nB5. Tool supporting SusAF workshop / process\r\n‚Ä¢ Lead engineers through process & questions \r\n‚Ä¢ Interface to create & document the two diagrams \r\n‚Ä¢ (!) Should be easy to start using & set up \r\n‚Ä¢ You may also create a simplified version / \u2028\r\nyour favorite sustainability framework\r\nEnvironmental\r\nEconomic\r\nTechnical\r\nIndividual\r\nSocial\r\nImmediate\r\nEnabling\r\nStructural\r\nAirbnb\r\ngreater \r\nearnings\r\nincrease \r\nin rents\r\ngentrification\r\ngreater racial \r\ndisparities\r\nrent \r\nrooms\r\n5\r\n1\r\n3\r\n4\r\n2\r\n \r\n \r\n \r\n \r\n \r\n \r\nVery \r\nunlikely \r\nVery \r\nlikely \r\n\r\nB6. Dataset of government-developed OS software\r\n‚Ä¢ Governments develop & use software for supporting society\u2028\r\nOpen-source development & policies are on the rise \r\n‚Ä¢ But studying government software is difficult b/c we don‚Äôt know what is out \r\nthere\u2028\r\n‚Üí Lack of incentive to make popular \u2028\r\n‚Üí Language barriers \r\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \r\nbuildable?, open dev. history?, requirements documentation? \r\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!\r\n\r\nB7. Queue - but better for the student / TA society\r\n‚Ä¢ Requirements analysis regarding social and individual sustainability effects \r\nof Queue \r\n‚Ä¢ Other EIP / TUD used software also possible: e.g., Answers EWI \r\n‚Ä¢ Non-technical project ‚Üí proper process (workshops? Interviews?) & rich \r\ndescription of outcomes focus of grading\r\nhttps://eip.pages.ewi.tudelft.nl/eip-website/queue.html\r\n\r\nC1. Compare energy consumption of docker images for \r\nML workloads.\r\n‚Ä¢ Similar to what we have seen in the lectures but for ML-specific workloads. \r\n‚Ä¢ We can reuse existing experiment replication packages.\r\n22\r\n\r\nC2. Plugin to visualize Hugging Face carbon emissions.\r\n‚Ä¢ https://huggingface.co/blog/leaderboard-emissions-\r\nanalysis \r\n‚Ä¢\r\nYoo, Taewon, et al. ""Visualizing the Carbon Intensity of Machine Learning Inference for Image Analysis on TensorFlow Hub.""\r\n\r\nC3. Plugin for ChatGPT\r\n‚Ä¢ Users seldom know how much carbon they are emitting when they interact \r\nwith chat GPT. \r\n‚Ä¢ Let‚Äôs make it transparent to the users. Browser plugin?\r\n24\r\nCO2\r\n\r\nC4. NutriScore for software libraries\r\n25\r\n‚Ä¢ NutriScore labels are not perfect but they are a good starting point! \r\n‚Ä¢ What if we could do the same thing for the energy efficiency of software. \r\n‚Ä¢ (Also open to individual or social sustainability) \r\n‚Ä¢ This work can be scoped in particular domains/ecossystems/use cases. \r\n‚Ä¢ Libraries for stats? ML? Web Dev? Cloud?\r\n\r\nC5. Add energy-awareness to existing software\r\n26\r\n‚Ä¢ Streamlit, Notebooks, JSFiddle, \r\nPyScript, zsh, etc. \r\n‚Ä¢\r\n\r\nC6 - Green Shift Left\r\n‚Ä¢ Estimate energy efficiency using static code analysis. \r\n‚Ä¢ We don‚Äôt need an accurate value. \r\n‚Ä¢ It is useful to know which code is more likely to \r\nintroduce energy hotspots and that should be \r\nreviewed with more attention. \r\n‚Ä¢ Can be scoped to a particular domain (react, php, data \r\nscience, web, etc., etc.)', '‚Ä¢ By using money cost instead of carbon cost, they have more data available.\r\n26\r\n\r\nVirtual Cluster Capacity (VCC)\r\n‚Ä¢ If the forecast of VCC fails it shift flexible workload more than expected.  \r\n‚Ä¢ This happens because the amount of workload forecasted was below the \r\nworkload needed, and VCC was ‚Äúaggressively‚Äù low. \r\n‚Ä¢ The systems fall back to the real cluster capacity for 1 week until results \r\nstart being realistic again.\r\n27\r\n\r\nNext steps\r\n‚Ä¢ They will consider spatial flexibility. \r\n‚Ä¢ I.e., tasks that can be shifted over time and over space. \r\n‚Ä¢ It needs to factor in relocation overheads, though.\r\n28\r\n\r\nCritical questions\r\n‚Ä¢ Who defines what is flexible and inflexible? \r\n‚Ä¢ How do you estimate the CPU load of a given task?\r\n29\r\n\r\nEnergy Regression Testing\r\n‚ÜíEnergy?\r\nGreener? Greener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\n\r\nE-compare\r\nGithub Actions\r\n‚ûú https://koenhagen.github.io/E-Compare/\r\n\r\nEnergy Regression Testing \r\n\r\n4. Debugging Energy with \r\nDocker Images\r\n\r\nUnveiling the Energy Vampires \r\nA methodology for debugging Software \r\nEnergy Consumption\r\n ‚úÖ ICSE 2025\r\n\r\nData Centers and Docker\r\n‚Ä¢ Containers are the most popular way to deploy apps into the cloud \r\n‚Ä¢ Base image is an important choice when building an image \r\n‚Ä¢ Criteria \r\n‚Ä¢ Linux distribution and binaries \r\n‚Ä¢ Image size \r\n‚Ä¢ Energy?\r\n35\r\n\r\nRedis energy consumption\r\n‚Ä¢ Ubuntu/Alpine base images have different energy consumption for Redis\r\n36\r\n\r\nRedis Energy Consumption\r\n‚Ä¢RQ1: What is the difference \r\nin energy consumption \r\nbetween glibc and musl? \r\n‚Ä¢RQ2: Can we use tracing \r\nto compare energy \r\nconsumption in shared \r\nlibraries? \r\n‚Ä¢RQ3: Can we verify the \r\norigin of energy \r\nconsumption differences by \r\nrecreating the workload \r\nbehavior closely?\r\n37\r\n\r\nTracing\r\n‚Ä¢ Find libc function running at the end of the benchmark \r\n‚Ä¢ Tracing: Capture calls made to libc \r\n‚Ä¢ Introduces non-linear overhead\r\n38\r\n\r\nSynchronization\r\n‚Ä¢ Tracing slows down execution and increase energy consumption \r\n‚Ä¢ Run separately and synchronize with logs\r\n39\r\n\r\nTracing Analysis\r\n40\r\n\r\nTracing Analysis\r\n41\r\n\r\nBenchmarking memcpy\r\n‚Ä¢ Copy bytes from one part of memory to \r\nanother \r\n‚Ä¢ Depending on function parameters, different \r\nassembly-level optimizations \r\n‚Ä¢ Some not included in musl\r\n42\r\n\r\nBenchmarking memcpy\r\n‚Ä¢ Copy 4 bytes from fixed \r\npointer to moving pointer \r\n‚Ä¢ (100,300,500,600) x 1M \r\nrequests \r\n‚Ä¢  15% more power and 3X time\r\n43\r\n\r\nConclusions\r\n‚Ä¢ Significant difference in energy consumption for memcpy \r\n‚Ä¢ 8.6% difference for Redis workload and 13% in our benchmark \r\n‚Ä¢ musl trades performance for a smaller codebase \r\n‚Ä¢ No official documentation \r\n‚Ä¢ No awareness about energy performance\r\n44\r\n\r\n5. Energy Efficiency vs Code \r\nQuality\r\n\r\nMeasuring Maintainability\r\n‚Ä¢ According to ISO/IEC 25010, Maintainability is ‚Äúthe degree of \r\neffectiveness and efficiency with which a software product or \r\nsystem can be modified to improve it, correct it or adapt it to \r\nchanges in environment, and in requirements‚Äù \r\n‚Ä¢ We use the code analysis tool Better Code Hub to assess \r\nmaintainability \r\n‚Ä¢ Better Code Hub maps the ISO/IEC 25010 standard on \r\nmaintainability into a set of guidelines derived from static analysis\r\n46\r\n\r\nMaintainability of Energy Changes\r\n‚Ä¢ What is the impact of making energy-oriented code changes on \r\nthe maintainability of mobile apps?', 'google.com/view/energy-efficiency-languages\r\n21\r\nAna Radovanovic ÃÅ, Ross Koningstein, Ian Schneider, Bokan \r\nChen, Alexandre Duarte, Binz Roy, Diyue Xiao, Maya \r\nHaridasan, Patrick Hung, Nick Care, Saurav Talukdar, Eric \r\nMullen, Kendal Smith, MariEllen Cottman, and Walfredo Cirne \r\n\r\n\r\n‚Ä¢ Google‚Äôs Carbon-Intelligent Computing System (CICS) \r\n‚Ä¢ Main idea: use carbon-intensity data to shift datacenter jobs in time \r\n‚Ä¢ Typically, job schedulers use a metric of cluster capacity to schedule a job in \r\na particular cluster. \r\n‚Ä¢ CICS overrides this metric with the virtual capacity curve (VCC) that \r\nfactors in Carbon intensity \r\n‚Ä¢ When a new job comes in, the scheduler estimates its CPU load and power \r\nusage and assigns it to a cluster if the VCC is not exceeded.\r\n23\r\n\r\n‚Ä¢ Jobs are divided between flexible and inflexible. \r\n‚Ä¢ Flexible load is considered shapeable/shiftable as long as its total daily \r\ncompute (CPU) demand is preserved \r\n‚Ä¢ The system needs to consider that, while running a job, the virtual capacity \r\ncurve (VCC) might drop. Hence, this job should not start in the first place. \r\n‚Ä¢ They forecast VCC for the next day\r\n24\r\n\r\n\r\nVirtual Cluster Capacity (VCC)\r\n‚Ä¢ Aims at reducing the peak load at carbon intensive hours but in total it should allow for the \r\nsome amount of daily computation! \r\n‚Ä¢ Considers Carbon intensity \r\n‚Ä¢ Using data from electricityMap.org \r\n‚Ä¢ It does not use carbon intensity directly.\u2028\r\nCarbon intensity is converted to a cost (kgCO2 -> $$) \r\n‚Ä¢ This way, they can factor in other metrics that can also be converted to money. E.g., the \r\ncost saved by preventing peak load \r\n‚Ä¢ Peak workload entails extra cost at the infrastructure level (e.g., control faclities‚Äô \r\ntemperature). \r\n‚Ä¢ By using money cost instead of carbon cost, they have more data available.\r\n26\r\n\r\nVirtual Cluster Capacity (VCC)\r\n‚Ä¢ If the forecast of VCC fails it shift flexible workload more than expected.  \r\n‚Ä¢ This happens because the amount of workload forecasted was below the \r\nworkload needed, and VCC was ‚Äúaggressively‚Äù low. \r\n‚Ä¢ The systems fall back to the real cluster capacity for 1 week until results \r\nstart being realistic again.\r\n27\r\n\r\nNext steps\r\n‚Ä¢ They will consider spatial flexibility. \r\n‚Ä¢ I.e., tasks that can be shifted over time and over space. \r\n‚Ä¢ It needs to factor in relocation overheads, though.\r\n28\r\n\r\nCritical questions\r\n‚Ä¢ Who defines what is flexible and inflexible? \r\n‚Ä¢ How do you estimate the CPU load of a given task?\r\n29\r\n\r\nEnergy Regression Testing\r\n‚ÜíEnergy?\r\nGreener? Greener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\n\r\nE-compare\r\nGithub Actions\r\n‚ûú https://koenhagen.github.io/E-Compare/\r\n\r\nEnergy Regression Testing \r\n\r\n4. Debugging Energy with \r\nDocker Images\r\n\r\nUnveiling the Energy Vampires \r\nA methodology for debugging Software \r\nEnergy Consumption\r\n ‚úÖ ICSE 2025\r\n\r\nData Centers and Docker\r\n‚Ä¢ Containers are the most popular way to deploy apps into the cloud \r\n‚Ä¢ Base image is an important choice when building an image \r\n‚Ä¢ Criteria \r\n‚Ä¢ Linux distribution and binaries \r\n‚Ä¢ Image size \r\n‚Ä¢ Energy?\r\n35\r\n\r\nRedis energy consumption\r\n‚Ä¢ Ubuntu/Alpine base images have different energy consumption for Redis\r\n36\r\n\r\nRedis Energy Consumption\r\n‚Ä¢RQ1: What is the difference \r\nin energy consumption \r\nbetween glibc and musl? \r\n‚Ä¢RQ2: Can we use tracing \r\nto compare energy \r\nconsumption in shared \r\nlibraries?', '‚Ä¢ Improve parameter-tuning strategy.\r\n11\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ We need benchmarks. \r\n‚Ä¢ AllenAI leaderboard\u2028\r\nhttps://leaderboard.allenai.org \r\n‚Ä¢ No carbon metrics, yet \r\n‚Ä¢ Report comparable proxies for energy \r\nconsumption. \r\n‚Ä¢ ‚ö† Learning algorithms behave in a non-\r\ndeterministic \r\n‚Ä¢ ‚ö† Different data-points lead to different \r\nenergy consumption\r\n12\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ Reporting measured energy consumption \r\n‚Ä¢ + Accurate \r\n‚Ä¢ + Easy to map to carbon emissions \r\n‚Ä¢ - Hard to measure \r\n‚Ä¢ - Low replicability \r\n‚Ä¢ Reporting time / estimation based on time & hardware \r\n‚Ä¢ + Easy to measure \r\n‚Ä¢ + Correlates with energy consumption in most cases. \r\n‚Ä¢ -  Difficult to compare with measurements from other setups \r\n‚Ä¢ E.g., floating point operations (FPOs) (?) \r\n‚Ä¢ + comparable across different setups \r\n‚Ä¢ + cheap \r\n‚Ä¢ - does not factor in memory energy consumption \r\n‚Ä¢ - does not reflect carbon emissions\r\n13\r\n\r\nData-centric AI\r\n\r\nData-centric AI\r\n‚Ä¢ Emerging discipline that deals with systematically engineering data to build AI \r\nsystems. \r\n‚Ä¢ Shift from improving the training strategy to improving the data. \r\n‚Ä¢ It is better to have small but reliable datasets than large but noisy \r\ndatasets. \r\n‚Ä¢ => Improve data collection, data labelling, and data preprocessing. \r\n‚Ä¢ More about data-centric AI by Andrew Ng:\u2028\r\nhttps://www.youtube.com/watch?v=06-AZXmwHjo\r\n15\r\n\r\n\r\nGreen Data-centric AI\r\n‚Ä¢ How do different ML algorithms compare \r\nin terms of energy consumption? \r\n‚Ä¢ How does number of rows relate to the \r\nenergy consumption of ML models? \r\n‚Ä¢ How does number of features relate to \r\nthe energy consumption of ML models? \r\n‚Ä¢ What is the impact of reducing data in the \r\nperformance of the model? \r\n‚Ä¢ Method -> results -> discussion\r\n17\r\n\r\nMethod\r\n‚Ä¢ Single object of study: natural language model to detect spam messages. \r\n‚Ä¢ 6 machine learning algorithms: SVM, Decision Tree, KNN, Random Forrest, \r\nAdaBoost, Bagging Classifier. \r\n‚Ä¢ Reduce the number of rows. 10%, 20%, .., 100% \r\n‚Ä¢ Stratified random sampling (?) \r\n‚Ä¢ Reduce the number of features. 10%, 20%, .., 100% \r\n‚Ä¢ Feature importance metric based on the Chi-Square Test (Chi2) \r\n‚Ä¢ Estimate energy consumption using a RAPL-based tool. (?)\r\n18\r\n\r\n‚Ä¢ Repeat 30 times \r\n‚Ä¢ Fix random seeds \r\n‚Ä¢ ‚Ä¶ \r\n‚Ä¢ Data was not Normal => tailed Normal distribution.\r\n19\r\n(?)\r\n\r\nResults: energy consumption of algorithms\r\n\r\nResults: energy vs data shape\r\n\r\nResults: performance vs data shape\r\n\r\nDiscussion\r\n‚Ä¢ Other data properties should be investigated. \r\n‚Ä¢ E.g., data types \r\n‚Ä¢ Reporting energy data is essential. It can lead to different model selection \r\nwithout hindering model performance. \r\n‚Ä¢ There is a big opportunity in Model and Data Simplification.\r\n23\r\n\r\nData/Model Simplification\r\n‚Ä¢ (?) \r\n‚Ä¢ Data selection \r\n‚Ä¢ Data quantisation. Posit? \r\n‚Ä¢ Data distillation \r\n‚Ä¢ Coreset extraction (?) \r\n‚Ä¢ Model distillation \r\n‚Ä¢ Model quantisation \r\n‚Ä¢ Model pruning \r\n‚Ä¢ ‚Ä¶\r\n24\r\n\r\nPosit vs Float\r\nMore about this: https://spectrum.ieee.org/floating-point-numbers-posits-processor\r\nBetter for DL use cases\r\n\r\nHow can we tune \r\nlearning \r\nparameters \r\nefficiently?\r\n\r\nHyper parameter tuning\r\n‚Ä¢ When training an ML model, there are several parameters that need to be \r\ntuned. \r\n‚Ä¢ E.g., in SVM we have the Regularization parameter C, the kernel function, \r\nthe degree of the kernel function, and depending on the case, many other. \r\n‚Ä¢ The common approach revolves around grid search.', '‚Ä¢ In a scientific project, the magic number is 30.\r\n7\r\n\r\n\r\nRest ‚è∏\r\n‚Ä¢ It is common practice to do a pause/sleep between executions/\r\nmeasurements. \r\n‚Ä¢ Prevent tail energy consumption from previous measurements. ? \r\n‚Ä¢ Prevent collateral tasks of previous measurement from affecting the next \r\nmeasurement. \r\n‚Ä¢ There is no golden rule but one minute should be enough. It can be more or \r\nless depending on your hardware or the duration of your energy test.\r\n9\r\n\r\nt\r\nP\r\nTail Energy Consumption\r\n\r\nShuffle üîÄ\r\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \r\nit is impossible to control all of them. \r\n‚Ä¢ If you run 30 executions for version A and another batch for version B: \r\n‚Ä¢ External conditions that change over time will have a different bias in \r\nthe 2 versions (e.g., room temperature changes). \r\n‚Ä¢ If you shuffle, you reduce this risk.\r\n11\r\n\r\nKeep it cool üå°\r\n‚Ä¢ Always make sure there is a stable room temperature. \r\n‚Ä¢ Tricky because, some times, experiments may have to run over a few days. \r\n‚Ä¢ If you cannot control room temperature: collect temperature data and filter \r\nout measurements where the room temperature is clearly deviating.\r\n12\r\n\r\nAutomate Executions ü§ñ\r\n‚Ä¢ (Already mentioned in the previous classes) \r\n‚Ä¢ One cannot run 30 shuffled experiments per version without automation‚Ä¶\r\n13\r\n\r\nData analysis\r\n14\r\n\r\n1. Exploratory Analysis\r\n‚Ä¢ Plot the data and inspect outliers or \r\nunexpected biases. \r\n‚Ä¢ Violin+box plots are usually handy. (?) \r\n‚Ä¢ It‚Äôs a nice way of combining the 30 \r\nexperiments, and of showing \r\ndescriptive statistics. (?) \r\n‚Ä¢ Shows the shape of the distribution \r\nof the data.\r\n15\r\n\r\n1. Exploratory Analysis (II)\r\n‚Ä¢ Data should be Normal. Unless there‚Äôs a \r\ngood reason. \r\n‚Ä¢ E.g., somewhere amongst the 30 executions, \r\nthere might be 1 or 2 that failed to finish due \r\nto some unexpected error. \r\n‚Ä¢ (It happens and that‚Äôs ok!)‚Äì consequently, \r\nthe execution is shorter and spends less \r\nenergy ‚Äì falsely appearing as more \r\nenergy efficient. \r\n‚Ä¢ If data is not Normal there might be some \r\nissues affecting the measurements that \r\nmight be ruining results. It is important to \r\ninvestigate this.\r\n16\r\n\r\nEnergy data is not normal. Why?\r\n‚Ä¢ It might be caused by one of the following reasons: \r\n‚Ä¢ There was an error in some of the executions. If not detected and fixed it \r\nmight ruin results. \r\n‚Ä¢ Your tests are not fully replicable or are not deterministic. Quite frequent \r\nwhen you have internet requests or random-based algorithms. \r\n‚Ä¢ There is an unusual task being run by the system during some experiments. \r\n‚Ä¢ The computer entered a different power mode. \r\n‚Ä¢ External physical conditions have changed. E.g., someone opened a \r\nwindow.\r\n17\r\n\r\nEnergy data is not normal. How to fix?\r\n‚Ä¢ We have 2+1 options: \r\n1. Remove outliers. If there are only a few points that deviate from the normal \r\ndistribution, it is okay to simply remove them. \r\n‚Ä¢ Use the z-score outlier removal. (?) \r\n‚Ä¢ Remove all data points that deviate from the mean more than 3 standard \r\ndeviations: \r\n \r\n2. Fix the issue and rerun experiments. \r\n3. Conclude that nothing can be done about it and data will never be normal. (e.g., \r\nin AI, executions are rarely deterministic). ‚ö† Only after ruling out the previous \r\npoints.\r\n| ¬Øx ‚àíx| > 3s\r\n18\r\n\r\nHow do we know whether data is Normal?', 'Carbon-free giants\r\n‚Ä¢ Google, Microsoft, Meta/Facebook want to be carbon free by 2030 \r\n‚Ä¢ Carbon free is different from carbon neutral \r\n‚Ä¢ Green IT experts are needed to meet these goals\r\n23\r\n\r\n\r\nRebound effect*\r\n‚Ä¢ Energy consumption decreases ‚Üì‚Üì but demand also increases ‚Üë‚Üë. \r\n‚Ä¢ *a.k.a. Jevons Paradox in economics; Downs‚ÄìThomson paradox in\xa0mobility.\r\nEnergy per prompt\r\nPrompts\r\n100\r\n80\r\n30\r\n38\r\nChat \r\nGPT\r\n‚ÄúEnergy-efficient‚Äù \r\nChat GPT\r\n0\r\n\r\nIs sustainability an\u2028\r\nethical issue?\r\n‚Ä¢ Climate change is more likely to affect the \r\npoorest countries. \r\n‚Ä¢ Less financial resources to adapt \r\n‚Ä¢ Climate-impact does not necessarily affect \r\npolluting countries. \r\n‚Ä¢ Poorest countries have contributed less to the \r\nclimate change. \r\n‚Ä¢ We need to figure out how to do more using \r\nless resources.\r\n26\r\n\r\nMorality ‚â† Moralising\r\n‚Ä¢ We should not use climate action as a \r\nshaming weapon \r\n‚Ä¢ Climate action should be agnostic of political \r\nviews, ideology, social status, etc. \r\n‚Ä¢ We need everyone to take action!\r\n27\r\n\r\nWhy?\r\n‚Ä¢ Throughout your career you might: \r\n‚Ä¢ Design/maintain/contract data centers \r\n‚Ä¢ Set up operations/devops \r\n‚Ä¢ Develop AI for IoT devices \r\n‚Ä¢ Be the next CEO/CTO of a software company \r\n‚Ä¢ Sustainability can be your main role: \r\n‚Ä¢ Green Software Developer \r\n‚Ä¢ Sustainability Consultant \r\n‚Ä¢ Green Advocate  \r\n‚Ä¢ Founder of a Green Tech startup (B2B?)\r\n28\r\n\r\nFormat of classes\r\n‚Ä¢ In-person. \r\n‚Ä¢ Collegerama recordings. \r\n‚Ä¢ Lectures and Labs. \r\n‚Ä¢ Guest lectures. \r\n‚Ä¢ Steering meetings (after week 5, new schedule)\r\n29\r\n\r\nFormat of classes\r\n‚Ä¢ There‚Äôs no exam in this course. It‚Äôs more important that we learn how to \r\ndiscuss this topic and come up with new ideas than learning all the theory. \r\nCritical thinking over checkboxes. \r\n‚Ä¢ Mix of content and discussion \r\n‚Ä¢ Ultimately, the lectures aim to give you food for thought and the necessary \r\nknowledge to excel in Project 2. (We will talk about it later)\r\n30\r\n\r\nhttps://luiscruz.github.io/course_sustainableSE/\r\n31\r\nContent of the course üëá\r\n\r\n32\r\nhttps://mattermost.tudelft.nl/signup_user_complete/?id=1nj9tk6usjf8xmsws8wpq3s5uy&md=link&sbr=su\r\n\r\nProject 1\r\n‚Ä¢ Goal: Measure the energy consumption of software applications. \r\n‚Ä¢ Approach: energy measurement tools; use case testing. \r\n‚Ä¢ Deliverable: blog-style report (approx. 2500 words) \r\n‚Ä¢ Deadline: Week 3, Feb 28, 2025 \r\n‚Ä¢ Group size: 4‚Äì5\r\n33\r\n\r\nProject 2\r\n‚Ä¢ Goal: Create a solution/tool/technique that helps building green software. (You \r\ncan come up with your own idea or choose one from a list of suggestions). \r\n‚Ä¢ Approach: open-source software development; literature review. \r\n‚Ä¢ Deliverable: library/tool/app; paper; presentation. \r\n‚Ä¢ Two deadlines:\u2028\r\n1. Paper and software: Week 8, April 4, 2025\u2028\r\n2. Presentation: Week 9, April 11, 2025 \r\n‚Ä¢ Group size: 4‚Äì5\r\n34\r\n\r\nGuest Lectures\r\nNergis T√∂men \r\nComputer Vision lab | TU Delft \r\nWeek 4, Wed, Mar 5, 2025\r\n35\r\n\r\nCommunity \r\nHow to get involved?', 'computing vision, classification)\r\n\r\nA2. Adding energy metrics to LMstudio/Ollama\r\n‚Ä¢ Make energy consumption visible to users \r\nwithin local chat-interface for LLMs \r\n‚Ä¢ LMstudio/Ollama are tools for easy \r\ndeployment of LLMs \r\n‚Ä¢ Do not show energy metrics \r\n‚Ä¢ Add energy metrics to LMstudio-python \r\nor Ollama\r\nhttps://lmstudio.ai/\r\n\r\nA3. Visualizations built-in with EnergiBridge\r\n‚Ä¢ EnergiBridge simplifies energy measurement, but analysis & visualization is \r\nstill left to the user \r\n‚Ä¢ Extend the tool with well-chosen visualizations and analyses directly from the \r\nprovided data\r\n\r\nA4. Service-based version of EnergiBridge\r\n‚Ä¢ Simplify interaction & setup with EnergiBridge \r\n‚Ä¢ Service that runs independently, start/stop signals over RPC to manage \r\nexperiments \r\n‚Ä¢ Potential: create EnergiBridge interface for other prog. lang\r\n\r\nB1. Measure energy consumption of single JUnit tests\r\n‚Ä¢ We‚Äôd like to identify energy anti patterns in unit tests \r\n‚Ä¢ As a first step, we need tooling to measure and compare the energy \r\nconsumption of single unit tests \r\n‚Ä¢ Ideally including preliminary analysis looking at potential reasons for high-\r\nenergy-consuming tests\r\n\r\nB2. Study test generation energy consumption\r\n‚Ä¢ Automatic test generation mainly focuses on making strong test suites \r\n‚Ä¢ Do different techniques and configurations impact the energy consumption \r\nduring generation? \r\n‚Ä¢ Preferably focus on non-LLM test generation methods (EvoSuite, Pyguin, \r\nDSpot)\r\n\r\nB3. Detailed energy profiling of build pipelines\r\n‚Ä¢ Automatic builds have become a cornerstone of quality assurance. But how \r\nmuch energy do they even consume? \r\n‚Ä¢ Create a tool that reports on the energy consumed during the (different stages \r\nof the) whole build (compile, build, test, package, ‚Ä¶) \r\n‚Ä¢ Should be integrated with build system(s), making setup for developers easy \r\n‚Ä¢ For local setup (to enable true energy measurements)\r\n\r\nB4. Energy profiling of static analysis tools\r\n‚Ä¢ What is the energy consumption of a ""typical run"" for a few OSS projects? \r\n‚Ä¢ Does the type of analysis matter? Are certain analysis more expensive? Does \r\nthe number of rules that are activated in a static analysis tool important for the \r\nenergy consumption? \r\n‚Ä¢ Differences between static analysis tools [lower priority]\r\n\r\nB5. Tool supporting SusAF workshop / process\r\n‚Ä¢ Lead engineers through process & questions \r\n‚Ä¢ Interface to create & document the two diagrams \r\n‚Ä¢ (!) Should be easy to start using & set up \r\n‚Ä¢ You may also create a simplified version / \u2028\r\nyour favorite sustainability framework\r\nEnvironmental\r\nEconomic\r\nTechnical\r\nIndividual\r\nSocial\r\nImmediate\r\nEnabling\r\nStructural\r\nAirbnb\r\ngreater \r\nearnings\r\nincrease \r\nin rents\r\ngentrification\r\ngreater racial \r\ndisparities\r\nrent \r\nrooms\r\n5\r\n1\r\n3\r\n4\r\n2\r\n \r\n \r\n \r\n \r\n \r\n \r\nVery \r\nunlikely \r\nVery \r\nlikely \r\n\r\nB6. Dataset of government-developed OS software\r\n‚Ä¢ Governments develop & use software for supporting society\u2028\r\nOpen-source development & policies are on the rise \r\n‚Ä¢ But studying government software is difficult b/c we don‚Äôt know what is out \r\nthere\u2028\r\n‚Üí Lack of incentive to make popular \u2028\r\n‚Üí Language barriers \r\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \r\nbuildable?, open dev. history?, requirements documentation? \r\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!\r\n\r\nB7. Queue - but better for the student / TA society\r\n‚Ä¢ Requirements analysis regarding social and individual sustainability effects \r\nof Queue \r\n‚Ä¢ Other EIP / TUD used software also possible: e.g., Answers EWI \r\n‚Ä¢ Non-technical project ‚Üí proper process (workshops?', 'CO2eq =\r\n‚àë\r\ng‚ààGHG\r\n(GWPg ‚ãÖmg)\r\n23\r\nCO2eq = GWPCO2 ‚ãÖmCO2 + GWPCH4 ‚ãÖmCH4 + GWPN2O ‚ãÖmN2O\r\n= 1 √ó 1000 + 21 √ó 20 + 310 √ó 5\r\n= 2670kgCO2eq\r\n\r\nNote: \r\n- 100-GWP is only an estimation;  \r\n- different sources reveal different estimations; \r\n- there is also the 20-GWP and the 500-GWP. \r\nI use this source: Foster et al. (2017) Changes in Atmospheric Constituents and in Radiative Forcing  \r\nhttps://archive.ipcc.ch/pdf/assessment-report/ar4/wg1/ar4-wg1-chapter2.pdf \r\n\r\nCarbon credits (quick detour)\r\n‚Ä¢ Strategy used to regulate allowed emissions and to make carbon emission \r\nrights tradable. \r\n‚Ä¢ Each entity (e.g., company/country) has a budget of carbon credits. \r\n‚Ä¢ Entities can buy carbon credits from other entities when they are over budget. \r\n‚Ä¢ In the case of companies, carbon credits can only be bought from GHG \r\nmitigation projects. \r\n‚Ä¢ 1 carbon credit = 1 tonne CO2-eq  \r\n‚Ä¢ Consequence: the price of carbon credits is rising and carbon trading is \r\nstarting to be interesting for investors.\r\n25\r\n\r\nWhen should we use Carbon vs Energy?\r\n‚Ä¢ Energy/Power is more useful at the software usecase level. \r\n‚Ä¢ Carbon is more useful at the infrastructure level (e.g., datacenter) or at the \r\nproject level (e.g., the impact of developing a full software project). \r\n‚Ä¢ Choose your metrics wisely ;)\r\n26\r\n\r\n‚Ä¢ Carbon emissions ‚úÖ \r\n‚Ä¢ How do we go from energy consumption to carbon consumption?\r\n27\r\n\r\nCarbon intensity\r\n‚Ä¢ How much carbon is emitted per kWh of electricity consumed. \r\n‚Ä¢ The common unit: \r\n ü§∑ \r\n‚Ä¢ E.g.,  gas-based power plants emit less carbon than coal-based plants. \r\n‚Ä¢ The power grid is a mix between different sources of electricity ‚Äì different \r\nlocations have different carbon intensity.\r\ngCO2eq/kWh\r\n28\r\n\r\nhttps://app.electricitymaps.com/map\r\n\r\nBy Asim Hussain: https://principles.green/principles/carbon-intensity/\r\nüìù Reducing software energy consumption can help reduce the carbon intensity. Why?\r\n\r\nOne would expect zero carbon intensity from solar-\r\npanels or wind farms, but that‚Äôs not the case.\r\n‚ö†\r\n?\r\n\r\nMarginal Power Plant\r\n‚Ä¢ Renewable-based power plants cannot adapt to demand. \r\n‚Ä¢ When demand is higher than the existing power in the electricity grid, we \r\nneed a power plant that is able to scale up to that demand. \r\n‚Ä¢ This is usually done by fossil-based power plants. They are called the \r\nmarginal power plants. \r\n‚Ä¢ The problem is that marginal power plants do not scale down to zero. \r\n‚Ä¢ There is always a minimum carbon that needs to be emitted, even if there is \r\na lot of renewable energy in the grid.\r\n32\r\n\r\nBy Asim Hussain: https://principles.green/principles/carbon-intensity/\r\nHow could we fix this?\r\nWhat‚Äôs the problem here?\r\n\r\nMarginal Carbon Intensity\r\n‚Ä¢ Increase or decrease in carbon emissions in the electrical grid, in response \r\nto an infinitesimal increase/decrease in power demand/supply.\r\n\r\nFrom: ‚ÄúLiterature Review: On the effectiveness of a Marginal Carbon Intensity Signal ‚Äú\r\n\r\nWhy is marginal carbon intensity \r\nrelevant for software?\r\n‚Ä¢ Tip: consider a task scheduler in a datacenter.', 'It‚Äôs more important that we learn how to \r\ndiscuss this topic and come up with new ideas than learning all the theory. \r\nCritical thinking over checkboxes. \r\n‚Ä¢ Mix of content and discussion \r\n‚Ä¢ Ultimately, the lectures aim to give you food for thought and the necessary \r\nknowledge to excel in Project 2. (We will talk about it later)\r\n30\r\n\r\nhttps://luiscruz.github.io/course_sustainableSE/\r\n31\r\nContent of the course üëá\r\n\r\n32\r\nhttps://mattermost.tudelft.nl/signup_user_complete/?id=1nj9tk6usjf8xmsws8wpq3s5uy&md=link&sbr=su\r\n\r\nProject 1\r\n‚Ä¢ Goal: Measure the energy consumption of software applications. \r\n‚Ä¢ Approach: energy measurement tools; use case testing. \r\n‚Ä¢ Deliverable: blog-style report (approx. 2500 words) \r\n‚Ä¢ Deadline: Week 3, Feb 28, 2025 \r\n‚Ä¢ Group size: 4‚Äì5\r\n33\r\n\r\nProject 2\r\n‚Ä¢ Goal: Create a solution/tool/technique that helps building green software. (You \r\ncan come up with your own idea or choose one from a list of suggestions). \r\n‚Ä¢ Approach: open-source software development; literature review. \r\n‚Ä¢ Deliverable: library/tool/app; paper; presentation. \r\n‚Ä¢ Two deadlines:\u2028\r\n1. Paper and software: Week 8, April 4, 2025\u2028\r\n2. Presentation: Week 9, April 11, 2025 \r\n‚Ä¢ Group size: 4‚Äì5\r\n34\r\n\r\nGuest Lectures\r\nNergis T√∂men \r\nComputer Vision lab | TU Delft \r\nWeek 4, Wed, Mar 5, 2025\r\n35\r\n\r\nCommunity \r\nHow to get involved?\r\n36\r\n\r\nGreen TU\r\n‚Ä¢ https://www.tudelft.nl/sustainability/get-\r\ninvolved/greentu \r\n‚Ä¢ Student organisation at the TU Delft devoted \r\nto stimulating sustainability in education, \r\nresearch, university operations and \r\ncommunity engagement.\r\n37\r\n\r\nClimateAction.tech\r\n‚Ä¢ Great community for outreach \r\n‚Ä¢ Based on Slack  \r\n‚Ä¢ Regular meetings, talks, social events \r\n‚Ä¢ You can join as a volunteer or simply to \r\nconnect to other techies \r\n‚Ä¢ Also good to for job hunting on green tech.\r\n38\r\n\r\nClimateAction.tech\r\n39\r\n\r\nBranch magazine\r\n‚Ä¢ Stay up-to-date on sustainable tech \r\n‚Ä¢ Creativity booster \r\n‚Ä¢ Carbon-aware UI \r\n‚Ä¢ https://branch.climateaction.tech üîó\r\n40\r\n\r\nThis is the fourth edition\r\n‚Ä¢ Any feedback is welcome! Email or DM!\r\n41\r\n\r\n42\r\n\r\nCarolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nLu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\n1. Intro Class\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl']","['<1-hop>\n\nShuffle \nüîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them.\n‚Ä¢ If you run 30 executions for version A and another batch for version B:\n‚Ä¢ External conditions that change over time will have a diÔ¨Äerent bias in \nthe 2 versions (e.g., room temperature changes).\n‚Ä¢ If you shuÔ¨Ñe, you reduce this risk.\n11', '<2-hop>\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio)\n‚Ä¢ Dynamic Retry Delay\n‚Ä¢ Push Over Poll\n‚Ä¢ Reduce Size\n‚Ä¢ Cache\n‚Ä¢ Avoid Graphics and Animations\n20', '<1-hop>\n\nShuffle \nüîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them.\n‚Ä¢ If you run 30 executions for version A and another batch for version B:\n‚Ä¢ External conditions that change over time will have a diÔ¨Äerent bias in \nthe 2 versions (e.g., room temperature changes).\n‚Ä¢ If you shuÔ¨Ñe, you reduce this risk.\n11', '<2-hop>\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio)\n‚Ä¢ Dynamic Retry Delay\n‚Ä¢ Push Over Poll\n‚Ä¢ Reduce Size\n‚Ä¢ Cache\n‚Ä¢ Avoid Graphics and Animations\n20']","EcoAndroid reduces risk by reducing the size of applications, which likely involves minimizing the amount of data and resources that an app uses. This can lead to lower energy consumption and improved performance, as smaller apps typically require less processing power and memory. By optimizing the size, EcoAndroid helps in making apps more efficient and less resource-intensive, which can also contribute to a better user experience and longer battery life. However, specific details on how EcoAndroid achieves this are not provided in the sources.",EcoAndroid reduce risk by using Reduce Size feature which help minimize energy consumption and reduce impact of external factors like temperature changes.,0.5833333333041667,0.5,,0.78,,0.0
How can static code analysis in data science be used to improve the energy efficiency of data centers and contribute to sustainable software engineering?,"['Interviews?) & rich \r\ndescription of outcomes focus of grading\r\nhttps://eip.pages.ewi.tudelft.nl/eip-website/queue.html\r\n\r\nC1. Compare energy consumption of docker images for \r\nML workloads.\r\n‚Ä¢ Similar to what we have seen in the lectures but for ML-specific workloads. \r\n‚Ä¢ We can reuse existing experiment replication packages.\r\n22\r\n\r\nC2. Plugin to visualize Hugging Face carbon emissions.\r\n‚Ä¢ https://huggingface.co/blog/leaderboard-emissions-\r\nanalysis \r\n‚Ä¢\r\nYoo, Taewon, et al. ""Visualizing the Carbon Intensity of Machine Learning Inference for Image Analysis on TensorFlow Hub.""\r\n\r\nC3. Plugin for ChatGPT\r\n‚Ä¢ Users seldom know how much carbon they are emitting when they interact \r\nwith chat GPT. \r\n‚Ä¢ Let‚Äôs make it transparent to the users. Browser plugin?\r\n24\r\nCO2\r\n\r\nC4. NutriScore for software libraries\r\n25\r\n‚Ä¢ NutriScore labels are not perfect but they are a good starting point! \r\n‚Ä¢ What if we could do the same thing for the energy efficiency of software. \r\n‚Ä¢ (Also open to individual or social sustainability) \r\n‚Ä¢ This work can be scoped in particular domains/ecossystems/use cases. \r\n‚Ä¢ Libraries for stats? ML? Web Dev? Cloud?\r\n\r\nC5. Add energy-awareness to existing software\r\n26\r\n‚Ä¢ Streamlit, Notebooks, JSFiddle, \r\nPyScript, zsh, etc. \r\n‚Ä¢\r\n\r\nC6 - Green Shift Left\r\n‚Ä¢ Estimate energy efficiency using static code analysis. \r\n‚Ä¢ We don‚Äôt need an accurate value. \r\n‚Ä¢ It is useful to know which code is more likely to \r\nintroduce energy hotspots and that should be \r\nreviewed with more attention. \r\n‚Ä¢ Can be scoped to a particular domain (react, php, data \r\nscience, web, etc., etc.)\r\n27\r\n\r\nC7 - Education\r\n‚Ä¢ Educational game for Software \r\nSustainability practices \r\n‚Ä¢ Purpose: use within software teams to \r\ndiscuss or learn about different sustainable \r\nIT practices: at the organisation level, \r\nsoftware, etc.\r\n28\r\nhttps://github.com/OttoKaaij/Ticket-To-Sustainability/?tab=readme-ov-file\r\n\r\nProject ideas (old)\r\n‚Ä¢ Plugin from EnergiBridge (GUI, report generator, python library, etc.) \r\n‚Ä¢ Plugin for ChatGPT (carbon emissions per chat window) \r\n‚Ä¢ Seamless measurements for AI libraries \r\n‚Ä¢ Energy patterns for Green AI \r\n‚Ä¢ Sustainable SW dev gamification \r\n‚Ä¢ Sustainability auditor for AI projects \r\n‚Ä¢ Energy Profiling of screen colour filter tools (or display settings) \r\n‚Ä¢ ‚Ä¶ you can also propose yours!\r\n\r\nhttps://edu.nl/64gpk\r\nedu.nl/64gpk', 'Energy profiling of static analysis tools\r\n‚Ä¢ What is the energy consumption of a ""typical run"" for a few OSS projects? \r\n‚Ä¢ Does the type of analysis matter? Are certain analysis more expensive? Does \r\nthe number of rules that are activated in a static analysis tool important for the \r\nenergy consumption? \r\n‚Ä¢ Differences between static analysis tools [lower priority]\r\n\r\nB5. Tool supporting SusAF workshop / process\r\n‚Ä¢ Lead engineers through process & questions \r\n‚Ä¢ Interface to create & document the two diagrams \r\n‚Ä¢ (!) Should be easy to start using & set up \r\n‚Ä¢ You may also create a simplified version / \u2028\r\nyour favorite sustainability framework\r\nEnvironmental\r\nEconomic\r\nTechnical\r\nIndividual\r\nSocial\r\nImmediate\r\nEnabling\r\nStructural\r\nAirbnb\r\ngreater \r\nearnings\r\nincrease \r\nin rents\r\ngentrification\r\ngreater racial \r\ndisparities\r\nrent \r\nrooms\r\n5\r\n1\r\n3\r\n4\r\n2\r\n \r\n \r\n \r\n \r\n \r\n \r\nVery \r\nunlikely \r\nVery \r\nlikely \r\n\r\nB6. Dataset of government-developed OS software\r\n‚Ä¢ Governments develop & use software for supporting society\u2028\r\nOpen-source development & policies are on the rise \r\n‚Ä¢ But studying government software is difficult b/c we don‚Äôt know what is out \r\nthere\u2028\r\n‚Üí Lack of incentive to make popular \u2028\r\n‚Üí Language barriers \r\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \r\nbuildable?, open dev. history?, requirements documentation? \r\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!\r\n\r\nB7. Queue - but better for the student / TA society\r\n‚Ä¢ Requirements analysis regarding social and individual sustainability effects \r\nof Queue \r\n‚Ä¢ Other EIP / TUD used software also possible: e.g., Answers EWI \r\n‚Ä¢ Non-technical project ‚Üí proper process (workshops? Interviews?) & rich \r\ndescription of outcomes focus of grading\r\nhttps://eip.pages.ewi.tudelft.nl/eip-website/queue.html\r\n\r\nC1. Compare energy consumption of docker images for \r\nML workloads.\r\n‚Ä¢ Similar to what we have seen in the lectures but for ML-specific workloads. \r\n‚Ä¢ We can reuse existing experiment replication packages.\r\n22\r\n\r\nC2. Plugin to visualize Hugging Face carbon emissions.\r\n‚Ä¢ https://huggingface.co/blog/leaderboard-emissions-\r\nanalysis \r\n‚Ä¢\r\nYoo, Taewon, et al. ""Visualizing the Carbon Intensity of Machine Learning Inference for Image Analysis on TensorFlow Hub.""\r\n\r\nC3. Plugin for ChatGPT\r\n‚Ä¢ Users seldom know how much carbon they are emitting when they interact \r\nwith chat GPT. \r\n‚Ä¢ Let‚Äôs make it transparent to the users. Browser plugin?\r\n24\r\nCO2\r\n\r\nC4. NutriScore for software libraries\r\n25\r\n‚Ä¢ NutriScore labels are not perfect but they are a good starting point! \r\n‚Ä¢ What if we could do the same thing for the energy efficiency of software. \r\n‚Ä¢ (Also open to individual or social sustainability) \r\n‚Ä¢ This work can be scoped in particular domains/ecossystems/use cases. \r\n‚Ä¢ Libraries for stats? ML? Web Dev? Cloud?\r\n\r\nC5. Add energy-awareness to existing software\r\n26\r\n‚Ä¢ Streamlit, Notebooks, JSFiddle, \r\nPyScript, zsh, etc. \r\n‚Ä¢\r\n\r\nC6 - Green Shift Left\r\n‚Ä¢ Estimate energy efficiency using static code analysis. \r\n‚Ä¢ We don‚Äôt need an accurate value. \r\n‚Ä¢ It is useful to know which code is more likely to \r\nintroduce energy hotspots and that should be \r\nreviewed with more attention. \r\n‚Ä¢ Can be scoped to a particular domain (react, php, data \r\nscience, web, etc., etc.)', 'Different \r\nscreen brightness, different results. \r\n‚Ä¢ You need to reduce tasks to the bare minimum: \r\n‚Ä¢ Set brightness to a fixed value; turn off notifications, kill all user-owned \r\nprocesses, turn off cellular data, bluetooth, location services, account \r\nsyncs; uninstall all unnecessary apps, etc.\r\n11\r\n\r\nWhen it comes to desktop/cloud software, the sources \r\nof noise are different but the same concerns apply. \r\n \r\nEach case is different ‚Äì think it through!\r\n‚ö†\r\n\r\nEnergy Profilers\r\n‚Ä¢ Simple setup! Quite reliable (if you choose the profiler wisely). \r\n‚Ä¢ Recently, they are starting to rely on internal power sensors. \r\n‚Ä¢ Still sensitive to noise from concurrent processes/tasks! ‚ö†\r\n13\r\n\r\nExamples of Energy Profilers\r\n\r\n15\r\nhttps://www.websitecarbon.com\r\n\r\n16\r\nhttps://mlco2.github.io/impact/\r\n\r\nIntel Power Monitor\r\n‚Ä¢ Install: https://software.intel.com/content/www/us/en/\r\ndevelop/articles/intel-power-gadget.html \r\n‚Ä¢ To collect: Logging > Log to File \r\n \r\n‚Ä¢ It will store a CSV file with all the collected power data. \r\n(File location is specified in the settings) \r\n‚Ä¢ Based on Intel RAPL. Works with Intel-based Windows \r\nand Macs. \r\n‚Ä¢ Alternative-twin for M1-based Macs: Mx Power Gadget.\u2028\r\nhttps://www.seense.com/menubarstats/mxpg/\r\n17\r\n‚ö† No longer supported by Intel ‚ö†  \r\n\r\n18\r\nüîó https://luiscruz.github.io/\r\n2021/07/20/measuring-energy.html\r\n(Missing Apple m1 tools: mxpg, powermetrics)\r\n\r\n19\r\nEnergiBridge\r\nhttps://github.com/tdurieux/energibridge\r\n> target/release/energibridge -o results.csv --summary sleep 10\r\n\r\nHands-on 1\r\n‚Ä¢ Install your energy profiler (EnergiBridge). \r\n‚Ä¢ Collect the energy data of using Coral BodyPix for 30 seconds.\u2028\r\nhttps://storage.googleapis.com/tfjs-models/demos/body-pix/index.html \r\n‚Ä¢ Report the total energy consumption. \r\n‚Ä¢ Extra-mile: \r\n‚Ä¢ Compare the energy consumption in different browsers. \r\n‚Ä¢ Check the spikes and drops in Power and Temperature.\r\n20\r\n\r\nRetrospection\r\nHands-on 1\r\n‚Ä¢ Are the measurements repeatable? \r\n‚Ä¢ What were the confounding factors? \r\n‚Ä¢ How can we automate this process?\r\n21\r\n\r\nEnergy testing\r\n(Different from energy monitoring)\r\n1. Create a reproducible scenario of the execution of your software. Preferably \r\nthis should be an automated script ‚Äì e.g., using a bash or python script. \r\n2. Execute the scenario in a version of your software. Use the energy profiler to \r\nmeasure the energy consumption. \r\n3. Improve your software in parts of the code that you suspect have low \r\nperformance. \r\n4. Execute the same scenario with the new version. Compare the energy data \r\nin this version with the previous one.\u2028\r\nEnergy is lower, test passes; energy is higher test fails.\r\n22\r\n\r\nHands-on 2\r\n‚Ä¢ Create a reproducible scenario. (Usually easier with command-line interfaces) \r\n‚Ä¢ Automatically start/stop energy profiling.\r\n23\r\n\r\nProject 1\r\n‚Ä¢ Deadline: March 1 \r\n‚Ä¢  Compare energy consumption in common software use cases. \r\n‚Ä¢ Examples: \r\n‚Ä¢ Different versions of the same app; \r\n‚Ä¢ Same use case but different apps \r\n‚Ä¢ Same version, same app, but different user settings (e.g., enable/disable GPU optimisation) \r\n‚Ä¢ Same version, same app, but different running environment \r\n‚Ä¢ Submission via PR (markdown). \r\n‚Ä¢ Blog-style report (markdown, approx 2500 words). \r\n‚Ä¢ Replication package. \r\n‚Ä¢ Points if the experiment is automated.', '‚Ä¢RQ3: Can we verify the \r\norigin of energy \r\nconsumption differences by \r\nrecreating the workload \r\nbehavior closely?\r\n37\r\n\r\nTracing\r\n‚Ä¢ Find libc function running at the end of the benchmark \r\n‚Ä¢ Tracing: Capture calls made to libc \r\n‚Ä¢ Introduces non-linear overhead\r\n38\r\n\r\nSynchronization\r\n‚Ä¢ Tracing slows down execution and increase energy consumption \r\n‚Ä¢ Run separately and synchronize with logs\r\n39\r\n\r\nTracing Analysis\r\n40\r\n\r\nTracing Analysis\r\n41\r\n\r\nBenchmarking memcpy\r\n‚Ä¢ Copy bytes from one part of memory to \r\nanother \r\n‚Ä¢ Depending on function parameters, different \r\nassembly-level optimizations \r\n‚Ä¢ Some not included in musl\r\n42\r\n\r\nBenchmarking memcpy\r\n‚Ä¢ Copy 4 bytes from fixed \r\npointer to moving pointer \r\n‚Ä¢ (100,300,500,600) x 1M \r\nrequests \r\n‚Ä¢  15% more power and 3X time\r\n43\r\n\r\nConclusions\r\n‚Ä¢ Significant difference in energy consumption for memcpy \r\n‚Ä¢ 8.6% difference for Redis workload and 13% in our benchmark \r\n‚Ä¢ musl trades performance for a smaller codebase \r\n‚Ä¢ No official documentation \r\n‚Ä¢ No awareness about energy performance\r\n44\r\n\r\n5. Energy Efficiency vs Code \r\nQuality\r\n\r\nMeasuring Maintainability\r\n‚Ä¢ According to ISO/IEC 25010, Maintainability is ‚Äúthe degree of \r\neffectiveness and efficiency with which a software product or \r\nsystem can be modified to improve it, correct it or adapt it to \r\nchanges in environment, and in requirements‚Äù \r\n‚Ä¢ We use the code analysis tool Better Code Hub to assess \r\nmaintainability \r\n‚Ä¢ Better Code Hub maps the ISO/IEC 25010 standard on \r\nmaintainability into a set of guidelines derived from static analysis\r\n46\r\n\r\nMaintainability of Energy Changes\r\n‚Ä¢ What is the impact of making energy-oriented code changes on \r\nthe maintainability of mobile apps? \r\nMaintainability \r\nDifference \r\nvE-2\r\nvE-1\r\nvE\r\nEnergy \r\nCommit\r\nvE+1\r\nM(vE-1)\r\nM(vE)\r\nParent \r\nCommit\r\n‚àÜM\r\n47\r\n\r\nThreshold Marks\r\n48\r\n\r\nBetter Code Hub\r\nMaintainability\r\nCombine\r\ndatasets\r\nEnergy\r\nCommits\r\nBaseline\r\nCommits\r\nBao et al. \r\n(2015)\r\nMoura et al. \r\n(2016)\r\nCruz et al. \r\n(2018)\r\nCruz et al. \r\n(2019)\r\nEnergy Code Changes \r\nDataset\r\n539 commits\u2028\r\nfrom 306 mobile apps\r\n539 baseline commits\u2028\r\nfrom 306 mobile apps\r\n49\r\n\r\nImpact of energy changes on \r\nmaintainability\r\n50\r\n\r\nWhich energy \r\npatterns are more \r\nlikely to affect \r\nmaintainability?\r\n51\r\n\r\nTypical maintainability issue I\r\nhttps://github.com/einmalfel/PodListen/commit/2ed5a65\r\n4 changed files with 28 additions and 0 deletions.\r\n‚Ä¶\r\n‚Ä¶\r\n52\r\n\r\nTypical maintainability issue II\r\nhttps://github.com/mozilla/MozStumbler/commit/6ea0268\r\n5 changed files with 66 additions and 14 deletions.\r\n53\r\n\r\n54', 'google.com/view/energy-efficiency-languages\r\n21\r\nAna Radovanovic ÃÅ, Ross Koningstein, Ian Schneider, Bokan \r\nChen, Alexandre Duarte, Binz Roy, Diyue Xiao, Maya \r\nHaridasan, Patrick Hung, Nick Care, Saurav Talukdar, Eric \r\nMullen, Kendal Smith, MariEllen Cottman, and Walfredo Cirne \r\n\r\n\r\n‚Ä¢ Google‚Äôs Carbon-Intelligent Computing System (CICS) \r\n‚Ä¢ Main idea: use carbon-intensity data to shift datacenter jobs in time \r\n‚Ä¢ Typically, job schedulers use a metric of cluster capacity to schedule a job in \r\na particular cluster. \r\n‚Ä¢ CICS overrides this metric with the virtual capacity curve (VCC) that \r\nfactors in Carbon intensity \r\n‚Ä¢ When a new job comes in, the scheduler estimates its CPU load and power \r\nusage and assigns it to a cluster if the VCC is not exceeded.\r\n23\r\n\r\n‚Ä¢ Jobs are divided between flexible and inflexible. \r\n‚Ä¢ Flexible load is considered shapeable/shiftable as long as its total daily \r\ncompute (CPU) demand is preserved \r\n‚Ä¢ The system needs to consider that, while running a job, the virtual capacity \r\ncurve (VCC) might drop. Hence, this job should not start in the first place. \r\n‚Ä¢ They forecast VCC for the next day\r\n24\r\n\r\n\r\nVirtual Cluster Capacity (VCC)\r\n‚Ä¢ Aims at reducing the peak load at carbon intensive hours but in total it should allow for the \r\nsome amount of daily computation! \r\n‚Ä¢ Considers Carbon intensity \r\n‚Ä¢ Using data from electricityMap.org \r\n‚Ä¢ It does not use carbon intensity directly.\u2028\r\nCarbon intensity is converted to a cost (kgCO2 -> $$) \r\n‚Ä¢ This way, they can factor in other metrics that can also be converted to money. E.g., the \r\ncost saved by preventing peak load \r\n‚Ä¢ Peak workload entails extra cost at the infrastructure level (e.g., control faclities‚Äô \r\ntemperature). \r\n‚Ä¢ By using money cost instead of carbon cost, they have more data available.\r\n26\r\n\r\nVirtual Cluster Capacity (VCC)\r\n‚Ä¢ If the forecast of VCC fails it shift flexible workload more than expected.  \r\n‚Ä¢ This happens because the amount of workload forecasted was below the \r\nworkload needed, and VCC was ‚Äúaggressively‚Äù low. \r\n‚Ä¢ The systems fall back to the real cluster capacity for 1 week until results \r\nstart being realistic again.\r\n27\r\n\r\nNext steps\r\n‚Ä¢ They will consider spatial flexibility. \r\n‚Ä¢ I.e., tasks that can be shifted over time and over space. \r\n‚Ä¢ It needs to factor in relocation overheads, though.\r\n28\r\n\r\nCritical questions\r\n‚Ä¢ Who defines what is flexible and inflexible? \r\n‚Ä¢ How do you estimate the CPU load of a given task?\r\n29\r\n\r\nEnergy Regression Testing\r\n‚ÜíEnergy?\r\nGreener? Greener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\n\r\nE-compare\r\nGithub Actions\r\n‚ûú https://koenhagen.github.io/E-Compare/\r\n\r\nEnergy Regression Testing \r\n\r\n4. Debugging Energy with \r\nDocker Images\r\n\r\nUnveiling the Energy Vampires \r\nA methodology for debugging Software \r\nEnergy Consumption\r\n ‚úÖ ICSE 2025\r\n\r\nData Centers and Docker\r\n‚Ä¢ Containers are the most popular way to deploy apps into the cloud \r\n‚Ä¢ Base image is an important choice when building an image \r\n‚Ä¢ Criteria \r\n‚Ä¢ Linux distribution and binaries \r\n‚Ä¢ Image size \r\n‚Ä¢ Energy?\r\n35\r\n\r\nRedis energy consumption\r\n‚Ä¢ Ubuntu/Alpine base images have different energy consumption for Redis\r\n36\r\n\r\nRedis Energy Consumption\r\n‚Ä¢RQ1: What is the difference \r\nin energy consumption \r\nbetween glibc and musl? \r\n‚Ä¢RQ2: Can we use tracing \r\nto compare energy \r\nconsumption in shared \r\nlibraries?', ""‚Ä¢ Our question: Can we save energy with alternative approaches? \r\n‚Ä¢ We studied Grid Search, Random Search and Bayesian \r\nOptimisation.\r\n27\r\nTim's MSc Thesis, 2022 \r\nAccepted at CAIN‚Äô23\r\n\r\n\r\nResults\r\n29\r\nConclusions? \r\n‚Ä¢ Bayesian converges faster. \r\n‚Ä¢ No clear winner between Grid and Random\r\n\r\nDeepSeekMoE\r\n30\r\nPreprint at ArXiv, 2024 https://arxiv.org/pdf/\r\n2401.06066\r\n\r\nMixture of Experts\r\n‚Ä¢ Llama3.1 has 405B parameters, DeepSeek V3 671B \r\n‚Ä¢ Yet DeepSeek has quicker inference times and claims less energy \r\nconsumption (?) \r\n‚Ä¢ Divide the model into smaller blocks of experts \r\n‚Ä¢ Tokens get routed to certain experts based on the query \r\n‚Ä¢ Only part of the network is active during inference \r\n‚Ä¢ DeepSeek claims only 37B out of 671B parameters get active\r\n31\r\n\r\nDeepSeekMoE\r\n32\r\n\r\nDeepSeekMoE\r\n33\r\n‚Ä¢ Comparable performance to \r\nLLaMA2 7B effectively using \r\nless half the parameters \r\n‚Ä¢ Less computational power \r\n‚Ä¢ Problems (?) \r\n‚Ä¢ Still need to load all the \r\nparameters \r\n‚Ä¢ High memory -> high \r\nembodied carbon\r\n\r\nGreen AI at FacebookMeta\r\n34\r\nSustainable AI: Environmental Implications, \r\nChallenges and Opportunities (2022)\r\n\r\nCarbon footprint mapped to the AI lifecycle\r\n‚Ä¢ There are 4 main overarching stages where carbon emissions need to be isolated: data \r\ncollection, experimentation, training, inference. \r\n‚Ä¢ At Facebook, recommendation systems split energy consumption evenly between \r\ntraining and inference; text translation models have a 35%/65% split. (Operational cost) \r\n‚Ä¢ Operational/embodied cost split: 30%/70%\r\n35\r\n\r\nOpen issues according to Meta\r\n‚Ä¢ A vast portion of projects only use GPUs at 30%.\u2028\r\nShould be higher to attenuate embodied carbon.\r\n36\r\nBased on 10K AI projects\r\n\r\nData Jan\r\nInformed Adaptation\r\nData Feb\r\nData Mar\r\nData Apr\r\nData May\r\n‚Ä¶\r\n~Data Dec\r\n~Data Dec\r\nData Jan\r\nData Feb\r\nData Mar\r\nData Apr\r\nData May\r\n‚Ä¶\r\nModel update Model update Model update\r\nCheck if \r\ndata change\r\nCheck if \r\ndata change\r\nCheck if \r\ndata change\r\nModel update\r\nBlind Adaptation\r\nThe AI Model will be \r\nupdated fewer times and \r\nonly when necessary.\r\nKnow when to retrain models\r\nNeither too early nor too late\r\n37\r\nAdaptation Techniques\r\n?\r\n\r\nGreen Architectural Tactics for ML-Enabled \r\nSystem\r\n38\r\nICSE-SEIS 2024\r\n\r\nArchitectural tactics\r\n39\r\n\r\nData-centric\r\n40\r\n‚Ä¢ Reduce data size \r\n‚Ä¢ Sampling \r\n‚Ä¢ Dimensionality reduction \r\n‚Ä¢ Quantization\r\n\r\nAlgorithm Design\r\n41\r\n‚Ä¢ Carefully select your algorithm \r\n‚Ä¢ You don‚Äôt need the fanciest \r\ntechniques\r\n\r\nModel Optimization\r\n42\r\n‚Ä¢ Add energy to training parameters \r\n‚Ä¢ Reduce FLOPs \r\n‚Ä¢ Pruning, sparsity \r\n‚Ä¢  Take advantage of existing models\r\n\r\nModel Training\r\n43\r\n‚Ä¢ Quantization\r\n‚Ä¢ SAVE TRAINING PROGRESS\r\n\r\nModel Deployment\r\n44\r\n‚Ä¢ Distributed deployment \r\n‚Ä¢ Energy efficient hardware and \r\nconfigurations\r\n\r\nModel Management\r\n45\r\n‚Ä¢ Reuse the model as much as possible \r\n\r\nRethinking the Architecture: Spiking Neural Networks\r\n46\r\n\r\nRethinking the Architecture: Spiking Neural Networks\r\n47\r\n\r\nSELF Lab\r\n48\r\n\r\nrecap"", 'Lu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\n10. Project 2\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nCarolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl\r\n\r\n1. Goal/assignment \r\n2. Deliverables \r\n3. Strategy \r\n4. Ideas\r\n\r\nAssignment\r\n‚Ä¢ Goal: Solve a Sustainable Software Engineering problem. \r\n‚Ä¢ Identify 1 problem that should be fixed to help enabling sustainability in \r\nthe software engineering industry/community. \r\n‚Ä¢ Propose a solution. A tool, framework, guidelines, etc. \r\n‚Ä¢ Implementation. \r\n‚Ä¢ Validation. (Depending on the idea) \r\n‚Ä¢ Dissemination/social impact. (Solution should be open source, welcome \r\ncontributors, post on social media? Tool website? Available in a package \r\nmanager?)\r\n3\r\n\r\nDeliverables\r\n‚Ä¢ Paper-like article. (Min 4 pages, max 10) \r\n‚Ä¢ Online git repo with open source codebase and/or replication package. \r\n‚Ä¢ Presentation: 5 min + 5min Q&A\r\n4\r\n\r\nArticle\r\n‚Ä¢ Different projects will have different expectations -> Make agreements with \r\nyour coach. \r\n‚Ä¢ Some projects are more technical and some projects more theoretical. \r\n‚Ä¢ Common requirements: \r\n‚Ä¢ Motivation, formulation of the problem being addressed, etc. \r\n‚Ä¢ Description of the solution. \r\n‚Ä¢ Validation of the solution (if applicable -> discuss with coach) \r\n‚Ä¢ Discussion of the solution. (Including limitations)\r\n5\r\n\r\nStrategy\r\n‚Ä¢ Starting next week, there are no lectures  \r\n‚Ä¢ Steering meetings from week 5 till week 9 (either online or in person).  \r\n‚Ä¢ 1 steering meeting per week. (4+1 sprints) \r\n‚Ä¢ Every week, you need to plan different tasks and assignments. \r\n‚Ä¢ Deadline April 4.\r\n6\r\n\r\nStrategy\r\n‚Ä¢ Week 0 \r\n‚Ä¢ Decide project idea (today) \r\n‚Ä¢ Define steering meeting schedule \r\n‚Ä¢ Create working document of the \r\narticle: Problem statement and solution \r\nproposal! \r\n‚Ä¢ Define and assign tasks for each week. \r\n‚Ä¢ Week 1 \r\n‚Ä¢ Implementation \r\n‚Ä¢ Agreements with supervisor. \r\n‚Ä¢ Week 2 \r\n‚Ä¢ Implementation \r\n‚Ä¢ Week 3 \r\n‚Ä¢ Implementation, Full draft of article, \r\ndissemination. \r\n‚Ä¢ Week 4 \r\n‚Ä¢ Final refinements \r\n‚Ä¢ Prepare presentation\r\n7\r\n\r\nProject ideas\r\n‚Ä¢ A1. Prototype cross-machine comparable benchmarks \r\n‚Ä¢ A2. Add energy metrics to LMstudio/Ollama \r\n‚Ä¢ A3. Visualizations built-in with EnergiBridge \r\n‚Ä¢ A4. Service-based version of EnergiBridge\r\n\r\nProject ideas\r\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \r\n‚Ä¢ B2. Study test generation energy consumption \r\n‚Ä¢ B3. Energy profiling of static analysis tools \r\n‚Ä¢ B4. Detailed energy profiling of build pipelines \r\n‚Ä¢ B5. Tool supporting SusAF workshop / process \r\n‚Ä¢ B6. Dataset of government-developed OS software \r\n‚Ä¢ B7. Queue - but better for the student / TA society\r\nQuality Assurance & Testing\r\nSocial & Individual \u2028\r\nSustainability\r\n\r\nProject ideas\r\n‚Ä¢ C1. Compare energy consumption of docker images for ML workloads. \r\n‚Ä¢ C2. Create a plugin to visualize Hugging Face carbon emissions in detail. \r\n‚Ä¢ C3. Plugin for ChatGPT (footprint per chat window) \r\n‚Ä¢ C4. NutriScore for software libraries. \r\n‚Ä¢ C5. Add energy-awareness to existing software \r\n‚Ä¢ C6. Green Shift Left \r\n‚Ä¢ C7. Education for Sustainable SE\r\n\r\nA1.', '‚Ä¢ Deadline April 4.\r\n6\r\n\r\nStrategy\r\n‚Ä¢ Week 0 \r\n‚Ä¢ Decide project idea (today) \r\n‚Ä¢ Define steering meeting schedule \r\n‚Ä¢ Create working document of the \r\narticle: Problem statement and solution \r\nproposal! \r\n‚Ä¢ Define and assign tasks for each week. \r\n‚Ä¢ Week 1 \r\n‚Ä¢ Implementation \r\n‚Ä¢ Agreements with supervisor. \r\n‚Ä¢ Week 2 \r\n‚Ä¢ Implementation \r\n‚Ä¢ Week 3 \r\n‚Ä¢ Implementation, Full draft of article, \r\ndissemination. \r\n‚Ä¢ Week 4 \r\n‚Ä¢ Final refinements \r\n‚Ä¢ Prepare presentation\r\n7\r\n\r\nProject ideas\r\n‚Ä¢ A1. Prototype cross-machine comparable benchmarks \r\n‚Ä¢ A2. Add energy metrics to LMstudio/Ollama \r\n‚Ä¢ A3. Visualizations built-in with EnergiBridge \r\n‚Ä¢ A4. Service-based version of EnergiBridge\r\n\r\nProject ideas\r\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \r\n‚Ä¢ B2. Study test generation energy consumption \r\n‚Ä¢ B3. Energy profiling of static analysis tools \r\n‚Ä¢ B4. Detailed energy profiling of build pipelines \r\n‚Ä¢ B5. Tool supporting SusAF workshop / process \r\n‚Ä¢ B6. Dataset of government-developed OS software \r\n‚Ä¢ B7. Queue - but better for the student / TA society\r\nQuality Assurance & Testing\r\nSocial & Individual \u2028\r\nSustainability\r\n\r\nProject ideas\r\n‚Ä¢ C1. Compare energy consumption of docker images for ML workloads. \r\n‚Ä¢ C2. Create a plugin to visualize Hugging Face carbon emissions in detail. \r\n‚Ä¢ C3. Plugin for ChatGPT (footprint per chat window) \r\n‚Ä¢ C4. NutriScore for software libraries. \r\n‚Ä¢ C5. Add energy-awareness to existing software \r\n‚Ä¢ C6. Green Shift Left \r\n‚Ä¢ C7. Education for Sustainable SE\r\n\r\nA1. Prototype cross-machine comparable benchmarks\r\n‚Ä¢ Energy-usage comparisons require running both baseline + software on the \r\nsame machine ‚Üí limits how extensive our experiments can be \r\n‚Ä¢ Research community is in need of benchmarks that make energy \r\nmeasurements comparable even if executed on different machines \r\n‚Ä¢ Focus on a single task or model (i.e. computing vision, classification)\r\n\r\nA2. Adding energy metrics to LMstudio/Ollama\r\n‚Ä¢ Make energy consumption visible to users \r\nwithin local chat-interface for LLMs \r\n‚Ä¢ LMstudio/Ollama are tools for easy \r\ndeployment of LLMs \r\n‚Ä¢ Do not show energy metrics \r\n‚Ä¢ Add energy metrics to LMstudio-python \r\nor Ollama\r\nhttps://lmstudio.ai/\r\n\r\nA3. Visualizations built-in with EnergiBridge\r\n‚Ä¢ EnergiBridge simplifies energy measurement, but analysis & visualization is \r\nstill left to the user \r\n‚Ä¢ Extend the tool with well-chosen visualizations and analyses directly from the \r\nprovided data\r\n\r\nA4. Service-based version of EnergiBridge\r\n‚Ä¢ Simplify interaction & setup with EnergiBridge \r\n‚Ä¢ Service that runs independently, start/stop signals over RPC to manage \r\nexperiments \r\n‚Ä¢ Potential: create EnergiBridge interface for other prog. lang\r\n\r\nB1. Measure energy consumption of single JUnit tests\r\n‚Ä¢ We‚Äôd like to identify energy anti patterns in unit tests \r\n‚Ä¢ As a first step, we need tooling to measure and compare the energy \r\nconsumption of single unit tests \r\n‚Ä¢ Ideally including preliminary analysis looking at potential reasons for high-\r\nenergy-consuming tests\r\n\r\nB2. Study test generation energy consumption\r\n‚Ä¢ Automatic test generation mainly focuses on making strong test suites \r\n‚Ä¢ Do different techniques and configurations impact the energy consumption \r\nduring generation? \r\n‚Ä¢ Preferably focus on non-LLM test generation methods (EvoSuite, Pyguin, \r\nDSpot)\r\n\r\nB3. Detailed energy profiling of build pipelines\r\n‚Ä¢ Automatic builds have become a cornerstone of quality assurance.', '‚Ä¢ Improve parameter-tuning strategy.\r\n11\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ We need benchmarks. \r\n‚Ä¢ AllenAI leaderboard\u2028\r\nhttps://leaderboard.allenai.org \r\n‚Ä¢ No carbon metrics, yet \r\n‚Ä¢ Report comparable proxies for energy \r\nconsumption. \r\n‚Ä¢ ‚ö† Learning algorithms behave in a non-\r\ndeterministic \r\n‚Ä¢ ‚ö† Different data-points lead to different \r\nenergy consumption\r\n12\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ Reporting measured energy consumption \r\n‚Ä¢ + Accurate \r\n‚Ä¢ + Easy to map to carbon emissions \r\n‚Ä¢ - Hard to measure \r\n‚Ä¢ - Low replicability \r\n‚Ä¢ Reporting time / estimation based on time & hardware \r\n‚Ä¢ + Easy to measure \r\n‚Ä¢ + Correlates with energy consumption in most cases. \r\n‚Ä¢ -  Difficult to compare with measurements from other setups \r\n‚Ä¢ E.g., floating point operations (FPOs) (?) \r\n‚Ä¢ + comparable across different setups \r\n‚Ä¢ + cheap \r\n‚Ä¢ - does not factor in memory energy consumption \r\n‚Ä¢ - does not reflect carbon emissions\r\n13\r\n\r\nData-centric AI\r\n\r\nData-centric AI\r\n‚Ä¢ Emerging discipline that deals with systematically engineering data to build AI \r\nsystems. \r\n‚Ä¢ Shift from improving the training strategy to improving the data. \r\n‚Ä¢ It is better to have small but reliable datasets than large but noisy \r\ndatasets. \r\n‚Ä¢ => Improve data collection, data labelling, and data preprocessing. \r\n‚Ä¢ More about data-centric AI by Andrew Ng:\u2028\r\nhttps://www.youtube.com/watch?v=06-AZXmwHjo\r\n15\r\n\r\n\r\nGreen Data-centric AI\r\n‚Ä¢ How do different ML algorithms compare \r\nin terms of energy consumption? \r\n‚Ä¢ How does number of rows relate to the \r\nenergy consumption of ML models? \r\n‚Ä¢ How does number of features relate to \r\nthe energy consumption of ML models? \r\n‚Ä¢ What is the impact of reducing data in the \r\nperformance of the model? \r\n‚Ä¢ Method -> results -> discussion\r\n17\r\n\r\nMethod\r\n‚Ä¢ Single object of study: natural language model to detect spam messages. \r\n‚Ä¢ 6 machine learning algorithms: SVM, Decision Tree, KNN, Random Forrest, \r\nAdaBoost, Bagging Classifier. \r\n‚Ä¢ Reduce the number of rows. 10%, 20%, .., 100% \r\n‚Ä¢ Stratified random sampling (?) \r\n‚Ä¢ Reduce the number of features. 10%, 20%, .., 100% \r\n‚Ä¢ Feature importance metric based on the Chi-Square Test (Chi2) \r\n‚Ä¢ Estimate energy consumption using a RAPL-based tool. (?)\r\n18\r\n\r\n‚Ä¢ Repeat 30 times \r\n‚Ä¢ Fix random seeds \r\n‚Ä¢ ‚Ä¶ \r\n‚Ä¢ Data was not Normal => tailed Normal distribution.\r\n19\r\n(?)\r\n\r\nResults: energy consumption of algorithms\r\n\r\nResults: energy vs data shape\r\n\r\nResults: performance vs data shape\r\n\r\nDiscussion\r\n‚Ä¢ Other data properties should be investigated. \r\n‚Ä¢ E.g., data types \r\n‚Ä¢ Reporting energy data is essential. It can lead to different model selection \r\nwithout hindering model performance. \r\n‚Ä¢ There is a big opportunity in Model and Data Simplification.\r\n23\r\n\r\nData/Model Simplification\r\n‚Ä¢ (?) \r\n‚Ä¢ Data selection \r\n‚Ä¢ Data quantisation. Posit? \r\n‚Ä¢ Data distillation \r\n‚Ä¢ Coreset extraction (?) \r\n‚Ä¢ Model distillation \r\n‚Ä¢ Model quantisation \r\n‚Ä¢ Model pruning \r\n‚Ä¢ ‚Ä¶\r\n24\r\n\r\nPosit vs Float\r\nMore about this: https://spectrum.ieee.org/floating-point-numbers-posits-processor\r\nBetter for DL use cases\r\n\r\nHow can we tune \r\nlearning \r\nparameters \r\nefficiently?\r\n\r\nHyper parameter tuning\r\n‚Ä¢ When training an ML model, there are several parameters that need to be \r\ntuned. \r\n‚Ä¢ E.g., in SVM we have the Regularization parameter C, the kernel function, \r\nthe degree of the kernel function, and depending on the case, many other. \r\n‚Ä¢ The common approach revolves around grid search.', '‚Ä¢ By using money cost instead of carbon cost, they have more data available.\r\n26\r\n\r\nVirtual Cluster Capacity (VCC)\r\n‚Ä¢ If the forecast of VCC fails it shift flexible workload more than expected.  \r\n‚Ä¢ This happens because the amount of workload forecasted was below the \r\nworkload needed, and VCC was ‚Äúaggressively‚Äù low. \r\n‚Ä¢ The systems fall back to the real cluster capacity for 1 week until results \r\nstart being realistic again.\r\n27\r\n\r\nNext steps\r\n‚Ä¢ They will consider spatial flexibility. \r\n‚Ä¢ I.e., tasks that can be shifted over time and over space. \r\n‚Ä¢ It needs to factor in relocation overheads, though.\r\n28\r\n\r\nCritical questions\r\n‚Ä¢ Who defines what is flexible and inflexible? \r\n‚Ä¢ How do you estimate the CPU load of a given task?\r\n29\r\n\r\nEnergy Regression Testing\r\n‚ÜíEnergy?\r\nGreener? Greener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\n\r\nE-compare\r\nGithub Actions\r\n‚ûú https://koenhagen.github.io/E-Compare/\r\n\r\nEnergy Regression Testing \r\n\r\n4. Debugging Energy with \r\nDocker Images\r\n\r\nUnveiling the Energy Vampires \r\nA methodology for debugging Software \r\nEnergy Consumption\r\n ‚úÖ ICSE 2025\r\n\r\nData Centers and Docker\r\n‚Ä¢ Containers are the most popular way to deploy apps into the cloud \r\n‚Ä¢ Base image is an important choice when building an image \r\n‚Ä¢ Criteria \r\n‚Ä¢ Linux distribution and binaries \r\n‚Ä¢ Image size \r\n‚Ä¢ Energy?\r\n35\r\n\r\nRedis energy consumption\r\n‚Ä¢ Ubuntu/Alpine base images have different energy consumption for Redis\r\n36\r\n\r\nRedis Energy Consumption\r\n‚Ä¢RQ1: What is the difference \r\nin energy consumption \r\nbetween glibc and musl? \r\n‚Ä¢RQ2: Can we use tracing \r\nto compare energy \r\nconsumption in shared \r\nlibraries? \r\n‚Ä¢RQ3: Can we verify the \r\norigin of energy \r\nconsumption differences by \r\nrecreating the workload \r\nbehavior closely?\r\n37\r\n\r\nTracing\r\n‚Ä¢ Find libc function running at the end of the benchmark \r\n‚Ä¢ Tracing: Capture calls made to libc \r\n‚Ä¢ Introduces non-linear overhead\r\n38\r\n\r\nSynchronization\r\n‚Ä¢ Tracing slows down execution and increase energy consumption \r\n‚Ä¢ Run separately and synchronize with logs\r\n39\r\n\r\nTracing Analysis\r\n40\r\n\r\nTracing Analysis\r\n41\r\n\r\nBenchmarking memcpy\r\n‚Ä¢ Copy bytes from one part of memory to \r\nanother \r\n‚Ä¢ Depending on function parameters, different \r\nassembly-level optimizations \r\n‚Ä¢ Some not included in musl\r\n42\r\n\r\nBenchmarking memcpy\r\n‚Ä¢ Copy 4 bytes from fixed \r\npointer to moving pointer \r\n‚Ä¢ (100,300,500,600) x 1M \r\nrequests \r\n‚Ä¢  15% more power and 3X time\r\n43\r\n\r\nConclusions\r\n‚Ä¢ Significant difference in energy consumption for memcpy \r\n‚Ä¢ 8.6% difference for Redis workload and 13% in our benchmark \r\n‚Ä¢ musl trades performance for a smaller codebase \r\n‚Ä¢ No official documentation \r\n‚Ä¢ No awareness about energy performance\r\n44\r\n\r\n5. Energy Efficiency vs Code \r\nQuality\r\n\r\nMeasuring Maintainability\r\n‚Ä¢ According to ISO/IEC 25010, Maintainability is ‚Äúthe degree of \r\neffectiveness and efficiency with which a software product or \r\nsystem can be modified to improve it, correct it or adapt it to \r\nchanges in environment, and in requirements‚Äù \r\n‚Ä¢ We use the code analysis tool Better Code Hub to assess \r\nmaintainability \r\n‚Ä¢ Better Code Hub maps the ISO/IEC 25010 standard on \r\nmaintainability into a set of guidelines derived from static analysis\r\n46\r\n\r\nMaintainability of Energy Changes\r\n‚Ä¢ What is the impact of making energy-oriented code changes on \r\nthe maintainability of mobile apps?', 'computing vision, classification)\r\n\r\nA2. Adding energy metrics to LMstudio/Ollama\r\n‚Ä¢ Make energy consumption visible to users \r\nwithin local chat-interface for LLMs \r\n‚Ä¢ LMstudio/Ollama are tools for easy \r\ndeployment of LLMs \r\n‚Ä¢ Do not show energy metrics \r\n‚Ä¢ Add energy metrics to LMstudio-python \r\nor Ollama\r\nhttps://lmstudio.ai/\r\n\r\nA3. Visualizations built-in with EnergiBridge\r\n‚Ä¢ EnergiBridge simplifies energy measurement, but analysis & visualization is \r\nstill left to the user \r\n‚Ä¢ Extend the tool with well-chosen visualizations and analyses directly from the \r\nprovided data\r\n\r\nA4. Service-based version of EnergiBridge\r\n‚Ä¢ Simplify interaction & setup with EnergiBridge \r\n‚Ä¢ Service that runs independently, start/stop signals over RPC to manage \r\nexperiments \r\n‚Ä¢ Potential: create EnergiBridge interface for other prog. lang\r\n\r\nB1. Measure energy consumption of single JUnit tests\r\n‚Ä¢ We‚Äôd like to identify energy anti patterns in unit tests \r\n‚Ä¢ As a first step, we need tooling to measure and compare the energy \r\nconsumption of single unit tests \r\n‚Ä¢ Ideally including preliminary analysis looking at potential reasons for high-\r\nenergy-consuming tests\r\n\r\nB2. Study test generation energy consumption\r\n‚Ä¢ Automatic test generation mainly focuses on making strong test suites \r\n‚Ä¢ Do different techniques and configurations impact the energy consumption \r\nduring generation? \r\n‚Ä¢ Preferably focus on non-LLM test generation methods (EvoSuite, Pyguin, \r\nDSpot)\r\n\r\nB3. Detailed energy profiling of build pipelines\r\n‚Ä¢ Automatic builds have become a cornerstone of quality assurance. But how \r\nmuch energy do they even consume? \r\n‚Ä¢ Create a tool that reports on the energy consumed during the (different stages \r\nof the) whole build (compile, build, test, package, ‚Ä¶) \r\n‚Ä¢ Should be integrated with build system(s), making setup for developers easy \r\n‚Ä¢ For local setup (to enable true energy measurements)\r\n\r\nB4. Energy profiling of static analysis tools\r\n‚Ä¢ What is the energy consumption of a ""typical run"" for a few OSS projects? \r\n‚Ä¢ Does the type of analysis matter? Are certain analysis more expensive? Does \r\nthe number of rules that are activated in a static analysis tool important for the \r\nenergy consumption? \r\n‚Ä¢ Differences between static analysis tools [lower priority]\r\n\r\nB5. Tool supporting SusAF workshop / process\r\n‚Ä¢ Lead engineers through process & questions \r\n‚Ä¢ Interface to create & document the two diagrams \r\n‚Ä¢ (!) Should be easy to start using & set up \r\n‚Ä¢ You may also create a simplified version / \u2028\r\nyour favorite sustainability framework\r\nEnvironmental\r\nEconomic\r\nTechnical\r\nIndividual\r\nSocial\r\nImmediate\r\nEnabling\r\nStructural\r\nAirbnb\r\ngreater \r\nearnings\r\nincrease \r\nin rents\r\ngentrification\r\ngreater racial \r\ndisparities\r\nrent \r\nrooms\r\n5\r\n1\r\n3\r\n4\r\n2\r\n \r\n \r\n \r\n \r\n \r\n \r\nVery \r\nunlikely \r\nVery \r\nlikely \r\n\r\nB6. Dataset of government-developed OS software\r\n‚Ä¢ Governments develop & use software for supporting society\u2028\r\nOpen-source development & policies are on the rise \r\n‚Ä¢ But studying government software is difficult b/c we don‚Äôt know what is out \r\nthere\u2028\r\n‚Üí Lack of incentive to make popular \u2028\r\n‚Üí Language barriers \r\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \r\nbuildable?, open dev. history?, requirements documentation? \r\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!\r\n\r\nB7. Queue - but better for the student / TA society\r\n‚Ä¢ Requirements analysis regarding social and individual sustainability effects \r\nof Queue \r\n‚Ä¢ Other EIP / TUD used software also possible: e.g., Answers EWI \r\n‚Ä¢ Non-technical project ‚Üí proper process (workshops?', 'Lu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\n7. Green SE ‚Äì Research\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nCarolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl\r\n\r\n1. Energy patterns for mobile apps \r\n2. Carbon-aware datacenters \r\n3. Energy Regression Testing \r\n4. Debugging Energy with Docker images \r\n5. Energy Efficiency vs Code Quality \r\n\r\n‚Ä¢ While learning about these works, try to be critical about them and find their \r\npitfalls.\r\n3\r\n\r\n‚Ä¢ We have seen that measuring energy consumption is not trivial \r\n‚Ä¢ It is not practical considering that developers have other priorities above \r\nenergy efficiency \r\n‚Ä¢ At the same time, every now and then there are some efforts to improve \r\nenergy efficiency in some cases. This is time consuming and requires \r\nexpertise. \r\n‚Ä¢ How can we reuse these efforts?\r\n4\r\n\r\nEnergy Patterns for Mobile \r\nApps\r\nhttps://tqrg.github.io/energy-patterns/\r\n\r\nMethodology\r\n5. Catalog of Energy Patterns\r\n22 \r\npatterns\r\nF-droid\r\nCurated Lists\r\n1. App Collection\r\n1783 \r\napps\r\n3. Manual Refinement of Subjects of \r\nInterest\r\n1563 \r\nchanges\r\n4. Thematic Analysis\r\n431 \r\nreusable \r\nchanges\r\n2. Collect Changes With Potential Interest\r\n/.*(energy|power|battery).*/\r\n6028 \r\nchanges\r\n\r\nThematic Analysis\r\n1. Familiarization with data \r\n2. Generating initial labels \r\n3. Reviewing themes\r\n4. Defining and naming themes\r\n\r\n‚Ä¢ Energy Pattern: design pattern to improve energy efficiency.. \r\n‚Ä¢ 22 energy patterns. \r\n‚Ä¢ Each pattern is described by Context, Solution, Example, References from \r\nliterature, and Occurences (links to code changes from git repositories).\r\n8\r\n\r\nhttps://tqrg.github.io/energy-patterns\r\n\r\nDark UI Colors \r\nProvide a dark UI color theme to \r\nsave battery on devices with \r\nAMOLED screens.\r\n‚Ä¢ Context: [‚Ä¶] Apps that require heavy usage of screen can \r\nhave a substantial negative impact on battery life. \r\n‚Ä¢ Solution: Provide a UI theme with dark background colors. [‚Ä¶]\r\n‚Ä¢ Example: In a reading app, provide a theme with a dark \r\nbackground using light colors to display text. [‚Ä¶] \r\n10\r\n\r\nDark UI Colors \r\nProvide a dark UI color theme to \r\nsave battery on devices with \r\nAMOLED screens.\r\n‚Ä¢ Context: [‚Ä¶] Apps that require heavy usage of screen can \r\nhave a substantial negative impact on battery life. \r\n‚Ä¢ Solution: Provide a UI theme with dark background colors. [‚Ä¶]\r\n‚Ä¢ Example: In a reading app, provide a theme with a dark \r\nbackground using light colors to display text. [‚Ä¶] \r\n11\r\n\r\nDynamic Retry Delay\r\n‚Ä¢ Context: [‚Ä¶] In a mobile app, when a given resource is \r\nunavailable, the app will unnecessarily try to connect the resource \r\nfor a number of times, leading to unnecessary power consumption. \r\n‚Ä¢ Solution: Increase retry interval after each failed connection. [‚Ä¶]\r\n‚Ä¢ Example: Consider a mobile app that provides a news feed and \r\nthe app is not able to reach the server to collect updates. [‚Ä¶] use \r\nthe Fibonacci series to increase the time between attempts.\r\nWhenever an attempt to access a \r\nresource fails, increase the time \r\ninterval before retrying.\r\n12\r\n\r\nBatch Operations \r\n‚Ä¢ Context: Executing operations separately leads to extraneous \r\ntail energy consumptions  \r\n‚Ä¢ Solution: Bundle multiple operations in a single one. [‚Ä¶]\r\n‚Ä¢ Example: Use system provided APIs to schedule background \r\ntasks. These APIs, guarantee that device will exit sleep mode \r\nonly when there is a reasonable amount of work to do or when a \r\ngiven task is urgent.', '‚Ä¢ Comparing different programming languages is not an easy task. \r\n‚Ä¢ They differ in many mechanisms: \r\n‚Ä¢ Interpreted vs Compiled \r\n‚Ä¢ Optimisations at the compiler level \r\n‚Ä¢ Virtual machine \r\n‚Ä¢ Garbage collector \r\n‚Ä¢ Available libraries\r\n30\r\n\r\nResearch Questions\r\n‚Ä¢ Can we compare the energy efficiency of software languages?  \r\n‚Ä¢ Is the faster language always the most energy efficient? \r\n‚Ä¢ How does memory usage relate to energy consumption? (We don‚Äôt cover this one) \r\n‚Ä¢ Can we automatically decide what is the best programming language \r\nconsidering energy, time, and memory usage?  \r\n‚Ä¢ How do the results of our energy consumption analysis of programming \r\nlanguages gathered from rigorous performance benchmarking solutions \r\ncompare to results of average day-to-day solutions? \u2028\r\n31\r\n\r\nMethodology\r\n\r\nThe Computer Language Benchmarks Game \r\n‚Ä¢ https://benchmarksgame-team.pages.debian.net/benchmarksgame/\r\n33\r\n\r\nProblems in the Computer Language Benchmarks Game\r\n34\r\n\r\n‚Ä¢ 27 Programming languages across different paradigms  \r\n‚Ä¢ Functional (e.g., Ocaml, F#, Haskell) \r\n‚Ä¢ Imperative (e.g., C, Go, Python) \r\n‚Ä¢ Object-oriented (e.g., C++, C#, Java) \r\n‚Ä¢ Scripting (or interpretative) (e.g., JavaScript, Python, Ruby) \r\n‚Ä¢ (These are not mutual exclusive) \r\n‚Ä¢ Intel RAPL‚Äôs C library to measure energy consumption\r\n35\r\n\r\n‚Ä¢ Execute each benchmark solution 10 times. \r\n‚Ä¢ Collect energy data and timestamps. \r\n‚Ä¢ Two-minute interval between executions\r\n36\r\n\r\n\r\n\r\n\r\nCritical thinking\r\n‚Ä¢ There is no doubt this is an excellent study. Yet, as any excellent study, there‚Äôs \r\na lot we can discuss and criticise constructively. \r\n‚Ä¢ What kind of issues you see in drawing conclusions from such a table of \r\nresults? \r\n‚Ä¢ Is the benchmark representative of the most common usage behaviour? \r\n‚Ä¢ Are the implemented solutions representative? \r\n‚Ä¢ Does it make sense to use the average to compare energy consumption \r\nacross different problems? \r\n‚Ä¢ ‚Ä¶\r\n40\r\n\r\nReproducing with Rosetta Code \r\n‚Ä¢ Rosetta Code is a programming chrestomathy repository \r\n \r\n‚Ä¢ 900 usecases/tasks solved across 700 different programming languages \r\n‚Ä¢ Purpose: if you know a programming language we can easily learn how the \r\nsame task is solved in a language you are not familiar with.\r\n41\r\n(?)\r\n\r\n\r\n\r\nRevisiting Research Questions\r\n‚Ä¢ Can we compare the energy efficiency of software languages?  \r\n‚Ä¢ Is the faster language always the most energy efficient? \r\n‚Ä¢ How does memory usage relate to energy consumption?  \r\n‚Ä¢ Can we automatically decide what is the best programming language considering \r\nenergy, time, and memory usage?  \r\n‚Ä¢ How do the results of our energy consumption analysis of programming \r\nlanguages gathered from rigorous performance benchmarking solutions \r\ncompare to results of average day-to-day solutions?  \r\n‚Ä¢ What would happen if we cherry picked the tasks?\u2028\r\n44\r\n\r\n\r\nLu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\n3. Scientific Guide for Reliable \r\nEnergy Experiments\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nCarolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl', ""‚Ä¢ 6 machine learning algorithms: SVM, Decision Tree, KNN, Random Forrest, \r\nAdaBoost, Bagging Classifier. \r\n‚Ä¢ Reduce the number of rows. 10%, 20%, .., 100% \r\n‚Ä¢ Stratified random sampling (?) \r\n‚Ä¢ Reduce the number of features. 10%, 20%, .., 100% \r\n‚Ä¢ Feature importance metric based on the Chi-Square Test (Chi2) \r\n‚Ä¢ Estimate energy consumption using a RAPL-based tool. (?)\r\n18\r\n\r\n‚Ä¢ Repeat 30 times \r\n‚Ä¢ Fix random seeds \r\n‚Ä¢ ‚Ä¶ \r\n‚Ä¢ Data was not Normal => tailed Normal distribution.\r\n19\r\n(?)\r\n\r\nResults: energy consumption of algorithms\r\n\r\nResults: energy vs data shape\r\n\r\nResults: performance vs data shape\r\n\r\nDiscussion\r\n‚Ä¢ Other data properties should be investigated. \r\n‚Ä¢ E.g., data types \r\n‚Ä¢ Reporting energy data is essential. It can lead to different model selection \r\nwithout hindering model performance. \r\n‚Ä¢ There is a big opportunity in Model and Data Simplification.\r\n23\r\n\r\nData/Model Simplification\r\n‚Ä¢ (?) \r\n‚Ä¢ Data selection \r\n‚Ä¢ Data quantisation. Posit? \r\n‚Ä¢ Data distillation \r\n‚Ä¢ Coreset extraction (?) \r\n‚Ä¢ Model distillation \r\n‚Ä¢ Model quantisation \r\n‚Ä¢ Model pruning \r\n‚Ä¢ ‚Ä¶\r\n24\r\n\r\nPosit vs Float\r\nMore about this: https://spectrum.ieee.org/floating-point-numbers-posits-processor\r\nBetter for DL use cases\r\n\r\nHow can we tune \r\nlearning \r\nparameters \r\nefficiently?\r\n\r\nHyper parameter tuning\r\n‚Ä¢ When training an ML model, there are several parameters that need to be \r\ntuned. \r\n‚Ä¢ E.g., in SVM we have the Regularization parameter C, the kernel function, \r\nthe degree of the kernel function, and depending on the case, many other. \r\n‚Ä¢ The common approach revolves around grid search. The user provides a \r\nsequence of possible values for each parameter and the pipeline runs all \r\npossible combinations. \r\n‚Ä¢ Our question: Can we save energy with alternative approaches? \r\n‚Ä¢ We studied Grid Search, Random Search and Bayesian \r\nOptimisation.\r\n27\r\nTim's MSc Thesis, 2022 \r\nAccepted at CAIN‚Äô23\r\n\r\n\r\nResults\r\n29\r\nConclusions? \r\n‚Ä¢ Bayesian converges faster. \r\n‚Ä¢ No clear winner between Grid and Random\r\n\r\nDeepSeekMoE\r\n30\r\nPreprint at ArXiv, 2024 https://arxiv.org/pdf/\r\n2401.06066\r\n\r\nMixture of Experts\r\n‚Ä¢ Llama3.1 has 405B parameters, DeepSeek V3 671B \r\n‚Ä¢ Yet DeepSeek has quicker inference times and claims less energy \r\nconsumption (?) \r\n‚Ä¢ Divide the model into smaller blocks of experts \r\n‚Ä¢ Tokens get routed to certain experts based on the query \r\n‚Ä¢ Only part of the network is active during inference \r\n‚Ä¢ DeepSeek claims only 37B out of 671B parameters get active\r\n31\r\n\r\nDeepSeekMoE\r\n32\r\n\r\nDeepSeekMoE\r\n33\r\n‚Ä¢ Comparable performance to \r\nLLaMA2 7B effectively using \r\nless half the parameters \r\n‚Ä¢ Less computational power \r\n‚Ä¢ Problems (?) \r\n‚Ä¢ Still need to load all the \r\nparameters \r\n‚Ä¢ High memory -> high \r\nembodied carbon\r\n\r\nGreen AI at FacebookMeta\r\n34\r\nSustainable AI: Environmental Implications, \r\nChallenges and Opportunities (2022)\r\n\r\nCarbon footprint mapped to the AI lifecycle\r\n‚Ä¢ There are 4 main overarching stages where carbon emissions need to be isolated: data \r\ncollection, experimentation, training, inference. \r\n‚Ä¢ At Facebook, recommendation systems split energy consumption evenly between \r\ntraining and inference; text translation models have a 35%/65% split. (Operational cost) \r\n‚Ä¢ Operational/embodied cost split: 30%/70%\r\n35\r\n\r\nOpen issues according to Meta\r\n‚Ä¢ A vast portion of projects only use GPUs at 30%.\u2028\r\nShould be higher to attenuate embodied carbon."", '‚Ä¢ Groundbreaking AI research is mostly done by tech giants.\r\n7\r\n\r\nA few examples of Red AI\r\n‚Ä¢ Google‚Äôs BERT-large \r\n‚Ä¢ 350 million features \r\n‚Ä¢ Trained for 2.5 days using 512 TPU chips, costing $60K+ \r\n‚Ä¢ Open-GPT3 (now GPT-4/o1) \r\n‚Ä¢ 550 tonnes CO2-eq (Patterson, 2021) \r\n‚Ä¢ 175 billion features \r\n‚Ä¢ API is open but no-pretrained model is available \r\n‚Ä¢ AlphaGo \r\n‚Ä¢ 1920 CPUs, 280 GPUs, costing $35M\r\n8\r\n\r\nRed AI in Large Language Models (LLMs)\r\n‚Ä¢ OPT by Meta reports 75 tons CO2-eq (1/7 of OpenGPT‚Äôs footprint).\u2028\r\n(Also 175billion params) \r\n‚Ä¢ However, Llama 3 reported 2,290 tons of CO2-eq (7.7M GPU hours \r\ntraining ) \r\n‚Ä¢ Open science: release includes both the pretrained models and the code \r\nneeded to train and use them. \r\n‚Ä¢ DeepSeek-V3 claims ‚Äúonly‚Äù 2.78M GPU hours \r\n‚Ä¢ Bloom by Huggingface reports 25 tons, 51 when considering embodied \r\nand operational carbon footprint. (176billion params)\r\n9\r\n\r\nRed AI\r\nAccuracy: 0.999999999\r\nGreen AI\r\n‚Ä¢ Energy \r\n‚Ä¢ Time \r\n‚Ä¢ Reproducibility \r\n‚Ä¢ Reusage\r\n\r\nHow can we adopt Green AI\r\n‚Ä¢ Check whether AI is needed. \r\n‚Ä¢ Select green datacenters. \r\n‚Ä¢ Run on low carbon intensity hours. \r\n‚Ä¢ Opt for GPU-optimised solutions (?) \r\n‚Ä¢ Opt for low-power hardware (e.g., Nvidia Jetson boards) \r\n‚Ä¢ Or GPUs that provide energy metrics (e.g., NVIDIA GPUs via the nvidia-smi tool) \r\n‚Ä¢ Report energy/carbon metrics (e.g., embed in MLFlow?) \r\n‚Ä¢ Use pre-trained models (Transfer Learning) \r\n‚Ä¢ Preprocess dataset to reduce size. \r\n‚Ä¢ Improve parameter-tuning strategy.\r\n11\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ We need benchmarks. \r\n‚Ä¢ AllenAI leaderboard\u2028\r\nhttps://leaderboard.allenai.org \r\n‚Ä¢ No carbon metrics, yet \r\n‚Ä¢ Report comparable proxies for energy \r\nconsumption. \r\n‚Ä¢ ‚ö† Learning algorithms behave in a non-\r\ndeterministic \r\n‚Ä¢ ‚ö† Different data-points lead to different \r\nenergy consumption\r\n12\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ Reporting measured energy consumption \r\n‚Ä¢ + Accurate \r\n‚Ä¢ + Easy to map to carbon emissions \r\n‚Ä¢ - Hard to measure \r\n‚Ä¢ - Low replicability \r\n‚Ä¢ Reporting time / estimation based on time & hardware \r\n‚Ä¢ + Easy to measure \r\n‚Ä¢ + Correlates with energy consumption in most cases. \r\n‚Ä¢ -  Difficult to compare with measurements from other setups \r\n‚Ä¢ E.g., floating point operations (FPOs) (?) \r\n‚Ä¢ + comparable across different setups \r\n‚Ä¢ + cheap \r\n‚Ä¢ - does not factor in memory energy consumption \r\n‚Ä¢ - does not reflect carbon emissions\r\n13\r\n\r\nData-centric AI\r\n\r\nData-centric AI\r\n‚Ä¢ Emerging discipline that deals with systematically engineering data to build AI \r\nsystems. \r\n‚Ä¢ Shift from improving the training strategy to improving the data. \r\n‚Ä¢ It is better to have small but reliable datasets than large but noisy \r\ndatasets. \r\n‚Ä¢ => Improve data collection, data labelling, and data preprocessing. \r\n‚Ä¢ More about data-centric AI by Andrew Ng:\u2028\r\nhttps://www.youtube.com/watch?v=06-AZXmwHjo\r\n15\r\n\r\n\r\nGreen Data-centric AI\r\n‚Ä¢ How do different ML algorithms compare \r\nin terms of energy consumption? \r\n‚Ä¢ How does number of rows relate to the \r\nenergy consumption of ML models? \r\n‚Ä¢ How does number of features relate to \r\nthe energy consumption of ML models? \r\n‚Ä¢ What is the impact of reducing data in the \r\nperformance of the model?', 'p-value = 0.04\r\nOn average, version B spent less energy than version A  ‚Äî  ‚úÖ \r\nThere is statistical significance ‚Äî  ‚úÖ \r\nEffect size, percent-change is ‚âà1% ‚Äî ü§î \r\n‚ö† Do we care?\r\n(?)\r\n\r\nPractical Significance\r\n‚Ä¢ Depending on the case, a 2% improvement might be either wonderful or completely \r\nuseless. \r\n‚Ä¢ Effect size analyses help assess practical significance but might not be enough. \r\n‚Ä¢ A critical discussion always needs to be performed. Consider context and explain in what \r\nsense the effect size might be relevant. \r\n‚Ä¢ E.g.: \r\n‚Ä¢  to improve 2% in energy efficiency the code will be less readable or the user \r\nexperience is not so appealing. \r\n‚Ä¢ A particular method improves 2% but it will only be used 1% of the time. \r\n‚Ä¢ There is no particular metric or structure, but this kind of critical analysis is very important.\r\n25\r\n\r\nWhat if data is not Normal?\r\nSame approach but different tests/metrics!\r\n\r\nNon-normal data\r\n‚Ä¢ Statistical significance: non-parametric test (?) \r\n‚Ä¢ Mann-Whitney U test. Instead of looking at standard deviation or mean, it orders \r\nsamples and compares with each other. \r\n‚Ä¢ Less power than parametric-tests (?) \r\n‚Ä¢ Effect size \r\n‚Ä¢ Median difference: \r\n \r\n‚Ä¢ Percentage of pairs supporting a conclusion\u2028\r\n(i.e., # pairs where version A > version B/ total pairs) \r\n‚Ä¢ Common language effect size: \r\nŒîM\r\nU1\r\nN1N2\r\n27\r\n\r\nRecap\r\nImpossible to \r\nfix but \r\nexplainable.\r\n\r\nEnergy Efficiency Across \r\nProgramming Languages\r\nhttps://sites.google.com/view/energy-efficiency-languages\r\n29\r\nRui Pereira, Marco Couto, Francisco Ribeiro, Rui Rua, J√°come \r\nCunha, Jo√£o Paulo Fernandes, and Jo√£o Saraiva\r\n\r\n‚Ä¢ Is a faster programming language also more energy efficient? \r\n‚Ä¢ Comparing different programming languages is not an easy task. \r\n‚Ä¢ They differ in many mechanisms: \r\n‚Ä¢ Interpreted vs Compiled \r\n‚Ä¢ Optimisations at the compiler level \r\n‚Ä¢ Virtual machine \r\n‚Ä¢ Garbage collector \r\n‚Ä¢ Available libraries\r\n30\r\n\r\nResearch Questions\r\n‚Ä¢ Can we compare the energy efficiency of software languages?  \r\n‚Ä¢ Is the faster language always the most energy efficient? \r\n‚Ä¢ How does memory usage relate to energy consumption? (We don‚Äôt cover this one) \r\n‚Ä¢ Can we automatically decide what is the best programming language \r\nconsidering energy, time, and memory usage?  \r\n‚Ä¢ How do the results of our energy consumption analysis of programming \r\nlanguages gathered from rigorous performance benchmarking solutions \r\ncompare to results of average day-to-day solutions? \u2028\r\n31\r\n\r\nMethodology\r\n\r\nThe Computer Language Benchmarks Game \r\n‚Ä¢ https://benchmarksgame-team.pages.debian.net/benchmarksgame/\r\n33\r\n\r\nProblems in the Computer Language Benchmarks Game\r\n34\r\n\r\n‚Ä¢ 27 Programming languages across different paradigms  \r\n‚Ä¢ Functional (e.g., Ocaml, F#, Haskell) \r\n‚Ä¢ Imperative (e.g., C, Go, Python) \r\n‚Ä¢ Object-oriented (e.g., C++, C#, Java) \r\n‚Ä¢ Scripting (or interpretative) (e.g., JavaScript, Python, Ruby) \r\n‚Ä¢ (These are not mutual exclusive) \r\n‚Ä¢ Intel RAPL‚Äôs C library to measure energy consumption\r\n35\r\n\r\n‚Ä¢ Execute each benchmark solution 10 times. \r\n‚Ä¢ Collect energy data and timestamps. \r\n‚Ä¢ Two-minute interval between executions\r\n36\r\n\r\n\r\n\r\n\r\nCritical thinking\r\n‚Ä¢ There is no doubt this is an excellent study. Yet, as any excellent study, there‚Äôs \r\na lot we can discuss and criticise constructively. \r\n‚Ä¢ What kind of issues you see in drawing conclusions from such a table of \r\nresults?', '8. Green AI\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nLu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\nCarolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl\r\n\r\n- Overview of Green AI \r\n- Large language models \r\n- Green data-centric AI \r\n- Model simplification \r\n- Hyper parameter tuning \r\n- Mixture of Experts and DeepSeek \r\n- Green AI at Meta \r\n\r\nAI\r\n‚Ä¢ Artificial Intelligence (AI) is the branch of computer science that deals with \r\nautomating tasks that typically require human intelligence. \r\n‚Ä¢ In the past years AI has been widely applied across different domains.\u2028\r\nE.g., health care, transportation, finance. \r\n‚Ä¢ To deploy AI systems, we test them against benchmarks (or validation sets). \r\n‚Ä¢ The goal is to outperform the previous existing models. \r\n‚Ä¢ E.g., in Machine Learning we usually resort to accuracy metrics. The \r\nhighest the accuracy, the better the model.\r\n3\r\n\r\nSince 2012, the amount of computing used for AI \r\ntraining has been doubling every 6 months\r\n‚Ä¢ https://epoch.ai/blog/compute-trends\r\n4\r\n\r\n‚Ä¢ To create better AI systems we are currently adding \r\n‚Ä¢ More data \r\n‚Ä¢ More experiments \r\n‚Ä¢ Larger models\r\n5\r\n\r\nThe Equation of Red AI\r\nCost(R) ‚àùE¬∑D¬∑H\r\nCost of a single (E)xample\r\nSize of (D)ataset\r\nNumber of (H)yperparameters\r\nBy Schwartz et al. (2020)\r\n\r\nIssues of Red AI\r\n‚Ä¢ High costs (hardware, electricity, data access, etc.) \r\n‚Ä¢ Limited reproducibility.  \r\n‚Ä¢ Energy consumption. \r\n‚Ä¢ Carbon emissions. \r\n‚Ä¢ SMEs can hardly be competitive. \r\n‚Ä¢ Groundbreaking AI research is mostly done by tech giants.\r\n7\r\n\r\nA few examples of Red AI\r\n‚Ä¢ Google‚Äôs BERT-large \r\n‚Ä¢ 350 million features \r\n‚Ä¢ Trained for 2.5 days using 512 TPU chips, costing $60K+ \r\n‚Ä¢ Open-GPT3 (now GPT-4/o1) \r\n‚Ä¢ 550 tonnes CO2-eq (Patterson, 2021) \r\n‚Ä¢ 175 billion features \r\n‚Ä¢ API is open but no-pretrained model is available \r\n‚Ä¢ AlphaGo \r\n‚Ä¢ 1920 CPUs, 280 GPUs, costing $35M\r\n8\r\n\r\nRed AI in Large Language Models (LLMs)\r\n‚Ä¢ OPT by Meta reports 75 tons CO2-eq (1/7 of OpenGPT‚Äôs footprint).\u2028\r\n(Also 175billion params) \r\n‚Ä¢ However, Llama 3 reported 2,290 tons of CO2-eq (7.7M GPU hours \r\ntraining ) \r\n‚Ä¢ Open science: release includes both the pretrained models and the code \r\nneeded to train and use them. \r\n‚Ä¢ DeepSeek-V3 claims ‚Äúonly‚Äù 2.78M GPU hours \r\n‚Ä¢ Bloom by Huggingface reports 25 tons, 51 when considering embodied \r\nand operational carbon footprint. (176billion params)\r\n9\r\n\r\nRed AI\r\nAccuracy: 0.999999999\r\nGreen AI\r\n‚Ä¢ Energy \r\n‚Ä¢ Time \r\n‚Ä¢ Reproducibility \r\n‚Ä¢ Reusage\r\n\r\nHow can we adopt Green AI\r\n‚Ä¢ Check whether AI is needed. \r\n‚Ä¢ Select green datacenters. \r\n‚Ä¢ Run on low carbon intensity hours. \r\n‚Ä¢ Opt for GPU-optimised solutions (?) \r\n‚Ä¢ Opt for low-power hardware (e.g., Nvidia Jetson boards) \r\n‚Ä¢ Or GPUs that provide energy metrics (e.g., NVIDIA GPUs via the nvidia-smi tool) \r\n‚Ä¢ Report energy/carbon metrics (e.g., embed in MLFlow?)', '‚Ä¢ In a scientific project, the magic number is 30.\r\n7\r\n\r\n\r\nRest ‚è∏\r\n‚Ä¢ It is common practice to do a pause/sleep between executions/\r\nmeasurements. \r\n‚Ä¢ Prevent tail energy consumption from previous measurements. ? \r\n‚Ä¢ Prevent collateral tasks of previous measurement from affecting the next \r\nmeasurement. \r\n‚Ä¢ There is no golden rule but one minute should be enough. It can be more or \r\nless depending on your hardware or the duration of your energy test.\r\n9\r\n\r\nt\r\nP\r\nTail Energy Consumption\r\n\r\nShuffle üîÄ\r\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \r\nit is impossible to control all of them. \r\n‚Ä¢ If you run 30 executions for version A and another batch for version B: \r\n‚Ä¢ External conditions that change over time will have a different bias in \r\nthe 2 versions (e.g., room temperature changes). \r\n‚Ä¢ If you shuffle, you reduce this risk.\r\n11\r\n\r\nKeep it cool üå°\r\n‚Ä¢ Always make sure there is a stable room temperature. \r\n‚Ä¢ Tricky because, some times, experiments may have to run over a few days. \r\n‚Ä¢ If you cannot control room temperature: collect temperature data and filter \r\nout measurements where the room temperature is clearly deviating.\r\n12\r\n\r\nAutomate Executions ü§ñ\r\n‚Ä¢ (Already mentioned in the previous classes) \r\n‚Ä¢ One cannot run 30 shuffled experiments per version without automation‚Ä¶\r\n13\r\n\r\nData analysis\r\n14\r\n\r\n1. Exploratory Analysis\r\n‚Ä¢ Plot the data and inspect outliers or \r\nunexpected biases. \r\n‚Ä¢ Violin+box plots are usually handy. (?) \r\n‚Ä¢ It‚Äôs a nice way of combining the 30 \r\nexperiments, and of showing \r\ndescriptive statistics. (?) \r\n‚Ä¢ Shows the shape of the distribution \r\nof the data.\r\n15\r\n\r\n1. Exploratory Analysis (II)\r\n‚Ä¢ Data should be Normal. Unless there‚Äôs a \r\ngood reason. \r\n‚Ä¢ E.g., somewhere amongst the 30 executions, \r\nthere might be 1 or 2 that failed to finish due \r\nto some unexpected error. \r\n‚Ä¢ (It happens and that‚Äôs ok!)‚Äì consequently, \r\nthe execution is shorter and spends less \r\nenergy ‚Äì falsely appearing as more \r\nenergy efficient. \r\n‚Ä¢ If data is not Normal there might be some \r\nissues affecting the measurements that \r\nmight be ruining results. It is important to \r\ninvestigate this.\r\n16\r\n\r\nEnergy data is not normal. Why?\r\n‚Ä¢ It might be caused by one of the following reasons: \r\n‚Ä¢ There was an error in some of the executions. If not detected and fixed it \r\nmight ruin results. \r\n‚Ä¢ Your tests are not fully replicable or are not deterministic. Quite frequent \r\nwhen you have internet requests or random-based algorithms. \r\n‚Ä¢ There is an unusual task being run by the system during some experiments. \r\n‚Ä¢ The computer entered a different power mode. \r\n‚Ä¢ External physical conditions have changed. E.g., someone opened a \r\nwindow.\r\n17\r\n\r\nEnergy data is not normal. How to fix?\r\n‚Ä¢ We have 2+1 options: \r\n1. Remove outliers. If there are only a few points that deviate from the normal \r\ndistribution, it is okay to simply remove them. \r\n‚Ä¢ Use the z-score outlier removal. (?) \r\n‚Ä¢ Remove all data points that deviate from the mean more than 3 standard \r\ndeviations: \r\n \r\n2. Fix the issue and rerun experiments. \r\n3. Conclude that nothing can be done about it and data will never be normal. (e.g., \r\nin AI, executions are rarely deterministic). ‚ö† Only after ruling out the previous \r\npoints.\r\n| ¬Øx ‚àíx| > 3s\r\n18\r\n\r\nHow do we know whether data is Normal?', ""Unless there‚Äôs a \r\ngood reason. \r\n‚Ä¢ E.g., somewhere amongst the 30 executions, \r\nthere might be 1 or 2 that failed to finish due \r\nto some unexpected error. \r\n‚Ä¢ (It happens and that‚Äôs ok!)‚Äì consequently, \r\nthe execution is shorter and spends less \r\nenergy ‚Äì falsely appearing as more \r\nenergy efficient. \r\n‚Ä¢ If data is not Normal there might be some \r\nissues affecting the measurements that \r\nmight be ruining results. It is important to \r\ninvestigate this.\r\n16\r\n\r\nEnergy data is not normal. Why?\r\n‚Ä¢ It might be caused by one of the following reasons: \r\n‚Ä¢ There was an error in some of the executions. If not detected and fixed it \r\nmight ruin results. \r\n‚Ä¢ Your tests are not fully replicable or are not deterministic. Quite frequent \r\nwhen you have internet requests or random-based algorithms. \r\n‚Ä¢ There is an unusual task being run by the system during some experiments. \r\n‚Ä¢ The computer entered a different power mode. \r\n‚Ä¢ External physical conditions have changed. E.g., someone opened a \r\nwindow.\r\n17\r\n\r\nEnergy data is not normal. How to fix?\r\n‚Ä¢ We have 2+1 options: \r\n1. Remove outliers. If there are only a few points that deviate from the normal \r\ndistribution, it is okay to simply remove them. \r\n‚Ä¢ Use the z-score outlier removal. (?) \r\n‚Ä¢ Remove all data points that deviate from the mean more than 3 standard \r\ndeviations: \r\n \r\n2. Fix the issue and rerun experiments. \r\n3. Conclude that nothing can be done about it and data will never be normal. (e.g., \r\nin AI, executions are rarely deterministic). ‚ö† Only after ruling out the previous \r\npoints.\r\n| ¬Øx ‚àíx| > 3s\r\n18\r\n\r\nHow do we know whether data is Normal?\r\n‚Ä¢ Visualise distribution shape: violin plots, histograms, density plot.\u2028\r\n \r\n‚Ä¢ Shapiro-Wilk test.\u2028\r\ndata is not normal;\u2028\r\nwe are not sure but it is okay to assume that data is \r\nnormal.\r\np-value < 0.05 ‚áí\r\np-value ‚â•0.05 ‚áí\r\n19\r\n\r\nAfter having all data ready, which artefact \r\nis more energy efficient(?) \r\nFirst approach: compare sample means. \r\n‚ö† assuming normal distribution\r\n\r\nStatistical significance\r\n‚Ä¢ Even if, on average, one artefact has lower \r\nenergy consumption than other,  it might be just \r\na random difference. \r\n‚Ä¢ When we extract a sample from a normal \r\ndistribution it will never be the exact same \r\n‚Ä¢ Statistical significance tests help you \r\nunderstand the differences in the average are \r\nconclusive/significant or inconclusive/\r\ninsignificant.\r\n21\r\n‚ö† assuming normal distribution\r\n\r\nStatistical significance test\r\n‚Ä¢ Two-sided parametric test Welch‚Äôs t-test. \r\n‚Ä¢ Less known alternative to student‚Äôs t-test.\r\n22\r\nWelch‚Äôs t-test in Python\r\nfrom scipy.stats import ttest_ind \r\n_,pvalue = ttest_ind(sample_a, sample_b, \r\n                     equal_var=False, \r\n                     alternative='two-sided')\r\n(?)\r\n‚ö† assuming normal distribution\r\n\r\nEffect Size analysis\r\n‚Ä¢ Now that we know that results are statistically significant we need to \r\nmeasure the difference between the two samples. \r\n‚Ä¢ Mean difference: \r\n \r\n‚Ä¢ Percent change: \r\n \r\n‚Ä¢ Cohen‚Äôs d (informal definition: mean difference normalized by a combined \r\nstandard deviation): \r\nŒî¬Øx\r\nxB ‚àíxA\r\nxA\r\n√ó 100 % = Œî¬Øx\r\nxA\r\n√ó 100 %\r\nŒî¬Øx\r\n1\r\n2\r\ns21 + s22\r\n23\r\n‚ö† assuming normal distribution\r\n\r\nImagine that version A spends 70J and \r\nversion B spends 69J with a \r\n."", 'Lu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\n3. Scientific Guide for Reliable \r\nEnergy Experiments\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nCarolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl\r\n\r\n1. Scientific guide for energy measurements \r\n2. Energy consumption data analysis \r\n\r\nEnergy tests are flaky\r\n‚Ä¢ Multiple runs might yield different results \r\n‚Ä¢ There are many confounding factors that need to be controlled/minimized.\r\n3\r\n?\r\n\r\nZen mode üßò\r\n‚Ä¢ Close all applications. \r\n‚Ä¢ Turn off notifications. \r\n‚Ä¢ Only the required hardware should be connected (avoid USB drives, external \r\ndisks, external displays, etc.). \r\n‚Ä¢ Kill unnecessary services running in the background (e.g., web server, file \r\nsharing, etc.). \r\n‚Ä¢ If you do not need an internet or intranet connection, switch off your network. \r\n‚Ä¢ Prefer cable over wireless ‚Äì the energy consumption from a cable connection \r\nis more stable than from a wireless connection.\r\n4\r\n\r\nFreeze and report your settings ü•∂\r\n‚Ä¢ Fix display brightness; switch off auto brightness \r\n‚Ä¢ If Wifi is on, it should always be on, connected to the same network/\r\nendpoint.‚Ä¶\r\n5\r\n\r\nWarm-up üì∂\r\n‚Ä¢ Energy consumption is highly affected by the temperature of your hardware. \r\n‚Ä¢ Higher the temperature -> higher the resistance of electrical conductors ->\u2028\r\n-> higher dissipation -> higher energy consumption \r\n‚Ä¢ The first execution will appear more efficient because the hardware is still \r\ncold. \r\n‚Ä¢ Run a CPU-intensive task before measuring energy consumption. E.g., \r\nFibonacci sequence. At least 1min; 5min recommended. \r\n‚Ä¢\r\n6\r\n\r\nRepeat üîÅ\r\n‚Ä¢ The best way to make sure a measurement is valid is by repeating it. \r\n‚Ä¢ In a scientific project, the magic number is 30.\r\n7\r\n\r\n\r\nRest ‚è∏\r\n‚Ä¢ It is common practice to do a pause/sleep between executions/\r\nmeasurements. \r\n‚Ä¢ Prevent tail energy consumption from previous measurements. ? \r\n‚Ä¢ Prevent collateral tasks of previous measurement from affecting the next \r\nmeasurement. \r\n‚Ä¢ There is no golden rule but one minute should be enough. It can be more or \r\nless depending on your hardware or the duration of your energy test.\r\n9\r\n\r\nt\r\nP\r\nTail Energy Consumption\r\n\r\nShuffle üîÄ\r\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \r\nit is impossible to control all of them. \r\n‚Ä¢ If you run 30 executions for version A and another batch for version B: \r\n‚Ä¢ External conditions that change over time will have a different bias in \r\nthe 2 versions (e.g., room temperature changes). \r\n‚Ä¢ If you shuffle, you reduce this risk.\r\n11\r\n\r\nKeep it cool üå°\r\n‚Ä¢ Always make sure there is a stable room temperature. \r\n‚Ä¢ Tricky because, some times, experiments may have to run over a few days. \r\n‚Ä¢ If you cannot control room temperature: collect temperature data and filter \r\nout measurements where the room temperature is clearly deviating.\r\n12\r\n\r\nAutomate Executions ü§ñ\r\n‚Ä¢ (Already mentioned in the previous classes) \r\n‚Ä¢ One cannot run 30 shuffled experiments per version without automation‚Ä¶\r\n13\r\n\r\nData analysis\r\n14\r\n\r\n1. Exploratory Analysis\r\n‚Ä¢ Plot the data and inspect outliers or \r\nunexpected biases. \r\n‚Ä¢ Violin+box plots are usually handy. (?) \r\n‚Ä¢ It‚Äôs a nice way of combining the 30 \r\nexperiments, and of showing \r\ndescriptive statistics. (?) \r\n‚Ä¢ Shows the shape of the distribution \r\nof the data.\r\n15\r\n\r\n1. Exploratory Analysis (II)\r\n‚Ä¢ Data should be Normal.']","['<1-hop>\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy eÔ¨Éciency using static code analysis.\n‚Ä¢ We don‚Äôt need an accurate value.\n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.\n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27', '<2-hop>\n\nWhy?\n‚Ä¢ Throughout your career you might:\n‚Ä¢ Design/maintain/contract data centers\n‚Ä¢ Set up operations/devops\n‚Ä¢ Develop AI for IoT devices\n‚Ä¢ Be the next CEO/CTO of a software company\n‚Ä¢ Sustainability can be your main role:\n‚Ä¢ Green Software Developer\n‚Ä¢ Sustainability Consultant\n‚Ä¢ Green Advocate \n‚Ä¢ Founder of a Green Tech startup (B2B?)\n28', '<1-hop>\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy eÔ¨Éciency using static code analysis.\n‚Ä¢ We don‚Äôt need an accurate value.\n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.\n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27', '<2-hop>\n\nWhy?\n‚Ä¢ Throughout your career you might:\n‚Ä¢ Design/maintain/contract data centers\n‚Ä¢ Set up operations/devops\n‚Ä¢ Develop AI for IoT devices\n‚Ä¢ Be the next CEO/CTO of a software company\n‚Ä¢ Sustainability can be your main role:\n‚Ä¢ Green Software Developer\n‚Ä¢ Sustainability Consultant\n‚Ä¢ Green Advocate \n‚Ä¢ Founder of a Green Tech startup (B2B?)\n28', '<1-hop>\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy eÔ¨Éciency using static code analysis.\n‚Ä¢ We don‚Äôt need an accurate value.\n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.\n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27', '<2-hop>\n\nWhy?\n‚Ä¢ Throughout your career you might:\n‚Ä¢ Design/maintain/contract data centers\n‚Ä¢ Set up operations/devops\n‚Ä¢ Develop AI for IoT devices\n‚Ä¢ Be the next CEO/CTO of a software company\n‚Ä¢ Sustainability can be your main role:\n‚Ä¢ Green Software Developer\n‚Ä¢ Sustainability Consultant\n‚Ä¢ Green Advocate \n‚Ä¢ Founder of a Green Tech startup (B2B?)\n28', '<1-hop>\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy eÔ¨Éciency using static code analysis.\n‚Ä¢ We don‚Äôt need an accurate value.\n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.\n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27', '<2-hop>\n\nWhy?\n‚Ä¢ Throughout your career you might:\n‚Ä¢ Design/maintain/contract data centers\n‚Ä¢ Set up operations/devops\n‚Ä¢ Develop AI for IoT devices\n‚Ä¢ Be the next CEO/CTO of a software company\n‚Ä¢ Sustainability can be your main role:\n‚Ä¢ Green Software Developer\n‚Ä¢ Sustainability Consultant\n‚Ä¢ Green Advocate \n‚Ä¢ Founder of a Green Tech startup (B2B?)\n28']","Static code analysis in data science can be used to improve the energy efficiency of data centers and contribute to sustainable software engineering by identifying potential energy hotspots in the code. This process, often referred to as ""Green Shift Left,"" involves estimating energy efficiency using static code analysis to pinpoint which parts of the code are more likely to introduce energy inefficiencies. By focusing on these areas, developers can make targeted improvements to reduce energy consumption.

Additionally, static code analysis can help in optimizing algorithms and data processing tasks, which are significant contributors to energy usage in data centers. By ensuring that the code is efficient and free from unnecessary computations, the overall energy consumption can be reduced. This approach not only helps in lowering operational costs but also minimizes the carbon footprint of data centers, aligning with the goals of sustainable software engineering.

Furthermore, static code analysis tools can be integrated into the development process to provide continuous feedback on energy efficiency, allowing developers to make informed decisions about code changes and optimizations. This proactive approach can lead to more sustainable software development practices over time.","Static code analysis in data science can be used to estimate energy efficiency by identifying potential energy hotspots in the code. This helps in reviewing and optimizing the code to reduce energy consumption. By applying this approach, developers can contribute to the design and maintenance of more energy-efficient data centers, aligning with sustainable software engineering practices.",0.6482142857013213,,,0.73,,0.9493671273658091
How can static code analysis in data science contribute to the development of more sustainable data centers?,"['Interviews?) & rich \r\ndescription of outcomes focus of grading\r\nhttps://eip.pages.ewi.tudelft.nl/eip-website/queue.html\r\n\r\nC1. Compare energy consumption of docker images for \r\nML workloads.\r\n‚Ä¢ Similar to what we have seen in the lectures but for ML-specific workloads. \r\n‚Ä¢ We can reuse existing experiment replication packages.\r\n22\r\n\r\nC2. Plugin to visualize Hugging Face carbon emissions.\r\n‚Ä¢ https://huggingface.co/blog/leaderboard-emissions-\r\nanalysis \r\n‚Ä¢\r\nYoo, Taewon, et al. ""Visualizing the Carbon Intensity of Machine Learning Inference for Image Analysis on TensorFlow Hub.""\r\n\r\nC3. Plugin for ChatGPT\r\n‚Ä¢ Users seldom know how much carbon they are emitting when they interact \r\nwith chat GPT. \r\n‚Ä¢ Let‚Äôs make it transparent to the users. Browser plugin?\r\n24\r\nCO2\r\n\r\nC4. NutriScore for software libraries\r\n25\r\n‚Ä¢ NutriScore labels are not perfect but they are a good starting point! \r\n‚Ä¢ What if we could do the same thing for the energy efficiency of software. \r\n‚Ä¢ (Also open to individual or social sustainability) \r\n‚Ä¢ This work can be scoped in particular domains/ecossystems/use cases. \r\n‚Ä¢ Libraries for stats? ML? Web Dev? Cloud?\r\n\r\nC5. Add energy-awareness to existing software\r\n26\r\n‚Ä¢ Streamlit, Notebooks, JSFiddle, \r\nPyScript, zsh, etc. \r\n‚Ä¢\r\n\r\nC6 - Green Shift Left\r\n‚Ä¢ Estimate energy efficiency using static code analysis. \r\n‚Ä¢ We don‚Äôt need an accurate value. \r\n‚Ä¢ It is useful to know which code is more likely to \r\nintroduce energy hotspots and that should be \r\nreviewed with more attention. \r\n‚Ä¢ Can be scoped to a particular domain (react, php, data \r\nscience, web, etc., etc.)\r\n27\r\n\r\nC7 - Education\r\n‚Ä¢ Educational game for Software \r\nSustainability practices \r\n‚Ä¢ Purpose: use within software teams to \r\ndiscuss or learn about different sustainable \r\nIT practices: at the organisation level, \r\nsoftware, etc.\r\n28\r\nhttps://github.com/OttoKaaij/Ticket-To-Sustainability/?tab=readme-ov-file\r\n\r\nProject ideas (old)\r\n‚Ä¢ Plugin from EnergiBridge (GUI, report generator, python library, etc.) \r\n‚Ä¢ Plugin for ChatGPT (carbon emissions per chat window) \r\n‚Ä¢ Seamless measurements for AI libraries \r\n‚Ä¢ Energy patterns for Green AI \r\n‚Ä¢ Sustainable SW dev gamification \r\n‚Ä¢ Sustainability auditor for AI projects \r\n‚Ä¢ Energy Profiling of screen colour filter tools (or display settings) \r\n‚Ä¢ ‚Ä¶ you can also propose yours!\r\n\r\nhttps://edu.nl/64gpk\r\nedu.nl/64gpk', 'Energy profiling of static analysis tools\r\n‚Ä¢ What is the energy consumption of a ""typical run"" for a few OSS projects? \r\n‚Ä¢ Does the type of analysis matter? Are certain analysis more expensive? Does \r\nthe number of rules that are activated in a static analysis tool important for the \r\nenergy consumption? \r\n‚Ä¢ Differences between static analysis tools [lower priority]\r\n\r\nB5. Tool supporting SusAF workshop / process\r\n‚Ä¢ Lead engineers through process & questions \r\n‚Ä¢ Interface to create & document the two diagrams \r\n‚Ä¢ (!) Should be easy to start using & set up \r\n‚Ä¢ You may also create a simplified version / \u2028\r\nyour favorite sustainability framework\r\nEnvironmental\r\nEconomic\r\nTechnical\r\nIndividual\r\nSocial\r\nImmediate\r\nEnabling\r\nStructural\r\nAirbnb\r\ngreater \r\nearnings\r\nincrease \r\nin rents\r\ngentrification\r\ngreater racial \r\ndisparities\r\nrent \r\nrooms\r\n5\r\n1\r\n3\r\n4\r\n2\r\n \r\n \r\n \r\n \r\n \r\n \r\nVery \r\nunlikely \r\nVery \r\nlikely \r\n\r\nB6. Dataset of government-developed OS software\r\n‚Ä¢ Governments develop & use software for supporting society\u2028\r\nOpen-source development & policies are on the rise \r\n‚Ä¢ But studying government software is difficult b/c we don‚Äôt know what is out \r\nthere\u2028\r\n‚Üí Lack of incentive to make popular \u2028\r\n‚Üí Language barriers \r\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \r\nbuildable?, open dev. history?, requirements documentation? \r\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!\r\n\r\nB7. Queue - but better for the student / TA society\r\n‚Ä¢ Requirements analysis regarding social and individual sustainability effects \r\nof Queue \r\n‚Ä¢ Other EIP / TUD used software also possible: e.g., Answers EWI \r\n‚Ä¢ Non-technical project ‚Üí proper process (workshops? Interviews?) & rich \r\ndescription of outcomes focus of grading\r\nhttps://eip.pages.ewi.tudelft.nl/eip-website/queue.html\r\n\r\nC1. Compare energy consumption of docker images for \r\nML workloads.\r\n‚Ä¢ Similar to what we have seen in the lectures but for ML-specific workloads. \r\n‚Ä¢ We can reuse existing experiment replication packages.\r\n22\r\n\r\nC2. Plugin to visualize Hugging Face carbon emissions.\r\n‚Ä¢ https://huggingface.co/blog/leaderboard-emissions-\r\nanalysis \r\n‚Ä¢\r\nYoo, Taewon, et al. ""Visualizing the Carbon Intensity of Machine Learning Inference for Image Analysis on TensorFlow Hub.""\r\n\r\nC3. Plugin for ChatGPT\r\n‚Ä¢ Users seldom know how much carbon they are emitting when they interact \r\nwith chat GPT. \r\n‚Ä¢ Let‚Äôs make it transparent to the users. Browser plugin?\r\n24\r\nCO2\r\n\r\nC4. NutriScore for software libraries\r\n25\r\n‚Ä¢ NutriScore labels are not perfect but they are a good starting point! \r\n‚Ä¢ What if we could do the same thing for the energy efficiency of software. \r\n‚Ä¢ (Also open to individual or social sustainability) \r\n‚Ä¢ This work can be scoped in particular domains/ecossystems/use cases. \r\n‚Ä¢ Libraries for stats? ML? Web Dev? Cloud?\r\n\r\nC5. Add energy-awareness to existing software\r\n26\r\n‚Ä¢ Streamlit, Notebooks, JSFiddle, \r\nPyScript, zsh, etc. \r\n‚Ä¢\r\n\r\nC6 - Green Shift Left\r\n‚Ä¢ Estimate energy efficiency using static code analysis. \r\n‚Ä¢ We don‚Äôt need an accurate value. \r\n‚Ä¢ It is useful to know which code is more likely to \r\nintroduce energy hotspots and that should be \r\nreviewed with more attention. \r\n‚Ä¢ Can be scoped to a particular domain (react, php, data \r\nscience, web, etc., etc.)', '‚Ä¢RQ3: Can we verify the \r\norigin of energy \r\nconsumption differences by \r\nrecreating the workload \r\nbehavior closely?\r\n37\r\n\r\nTracing\r\n‚Ä¢ Find libc function running at the end of the benchmark \r\n‚Ä¢ Tracing: Capture calls made to libc \r\n‚Ä¢ Introduces non-linear overhead\r\n38\r\n\r\nSynchronization\r\n‚Ä¢ Tracing slows down execution and increase energy consumption \r\n‚Ä¢ Run separately and synchronize with logs\r\n39\r\n\r\nTracing Analysis\r\n40\r\n\r\nTracing Analysis\r\n41\r\n\r\nBenchmarking memcpy\r\n‚Ä¢ Copy bytes from one part of memory to \r\nanother \r\n‚Ä¢ Depending on function parameters, different \r\nassembly-level optimizations \r\n‚Ä¢ Some not included in musl\r\n42\r\n\r\nBenchmarking memcpy\r\n‚Ä¢ Copy 4 bytes from fixed \r\npointer to moving pointer \r\n‚Ä¢ (100,300,500,600) x 1M \r\nrequests \r\n‚Ä¢  15% more power and 3X time\r\n43\r\n\r\nConclusions\r\n‚Ä¢ Significant difference in energy consumption for memcpy \r\n‚Ä¢ 8.6% difference for Redis workload and 13% in our benchmark \r\n‚Ä¢ musl trades performance for a smaller codebase \r\n‚Ä¢ No official documentation \r\n‚Ä¢ No awareness about energy performance\r\n44\r\n\r\n5. Energy Efficiency vs Code \r\nQuality\r\n\r\nMeasuring Maintainability\r\n‚Ä¢ According to ISO/IEC 25010, Maintainability is ‚Äúthe degree of \r\neffectiveness and efficiency with which a software product or \r\nsystem can be modified to improve it, correct it or adapt it to \r\nchanges in environment, and in requirements‚Äù \r\n‚Ä¢ We use the code analysis tool Better Code Hub to assess \r\nmaintainability \r\n‚Ä¢ Better Code Hub maps the ISO/IEC 25010 standard on \r\nmaintainability into a set of guidelines derived from static analysis\r\n46\r\n\r\nMaintainability of Energy Changes\r\n‚Ä¢ What is the impact of making energy-oriented code changes on \r\nthe maintainability of mobile apps? \r\nMaintainability \r\nDifference \r\nvE-2\r\nvE-1\r\nvE\r\nEnergy \r\nCommit\r\nvE+1\r\nM(vE-1)\r\nM(vE)\r\nParent \r\nCommit\r\n‚àÜM\r\n47\r\n\r\nThreshold Marks\r\n48\r\n\r\nBetter Code Hub\r\nMaintainability\r\nCombine\r\ndatasets\r\nEnergy\r\nCommits\r\nBaseline\r\nCommits\r\nBao et al. \r\n(2015)\r\nMoura et al. \r\n(2016)\r\nCruz et al. \r\n(2018)\r\nCruz et al. \r\n(2019)\r\nEnergy Code Changes \r\nDataset\r\n539 commits\u2028\r\nfrom 306 mobile apps\r\n539 baseline commits\u2028\r\nfrom 306 mobile apps\r\n49\r\n\r\nImpact of energy changes on \r\nmaintainability\r\n50\r\n\r\nWhich energy \r\npatterns are more \r\nlikely to affect \r\nmaintainability?\r\n51\r\n\r\nTypical maintainability issue I\r\nhttps://github.com/einmalfel/PodListen/commit/2ed5a65\r\n4 changed files with 28 additions and 0 deletions.\r\n‚Ä¶\r\n‚Ä¶\r\n52\r\n\r\nTypical maintainability issue II\r\nhttps://github.com/mozilla/MozStumbler/commit/6ea0268\r\n5 changed files with 66 additions and 14 deletions.\r\n53\r\n\r\n54', '‚Ä¢ By using money cost instead of carbon cost, they have more data available.\r\n26\r\n\r\nVirtual Cluster Capacity (VCC)\r\n‚Ä¢ If the forecast of VCC fails it shift flexible workload more than expected.  \r\n‚Ä¢ This happens because the amount of workload forecasted was below the \r\nworkload needed, and VCC was ‚Äúaggressively‚Äù low. \r\n‚Ä¢ The systems fall back to the real cluster capacity for 1 week until results \r\nstart being realistic again.\r\n27\r\n\r\nNext steps\r\n‚Ä¢ They will consider spatial flexibility. \r\n‚Ä¢ I.e., tasks that can be shifted over time and over space. \r\n‚Ä¢ It needs to factor in relocation overheads, though.\r\n28\r\n\r\nCritical questions\r\n‚Ä¢ Who defines what is flexible and inflexible? \r\n‚Ä¢ How do you estimate the CPU load of a given task?\r\n29\r\n\r\nEnergy Regression Testing\r\n‚ÜíEnergy?\r\nGreener? Greener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\n\r\nE-compare\r\nGithub Actions\r\n‚ûú https://koenhagen.github.io/E-Compare/\r\n\r\nEnergy Regression Testing \r\n\r\n4. Debugging Energy with \r\nDocker Images\r\n\r\nUnveiling the Energy Vampires \r\nA methodology for debugging Software \r\nEnergy Consumption\r\n ‚úÖ ICSE 2025\r\n\r\nData Centers and Docker\r\n‚Ä¢ Containers are the most popular way to deploy apps into the cloud \r\n‚Ä¢ Base image is an important choice when building an image \r\n‚Ä¢ Criteria \r\n‚Ä¢ Linux distribution and binaries \r\n‚Ä¢ Image size \r\n‚Ä¢ Energy?\r\n35\r\n\r\nRedis energy consumption\r\n‚Ä¢ Ubuntu/Alpine base images have different energy consumption for Redis\r\n36\r\n\r\nRedis Energy Consumption\r\n‚Ä¢RQ1: What is the difference \r\nin energy consumption \r\nbetween glibc and musl? \r\n‚Ä¢RQ2: Can we use tracing \r\nto compare energy \r\nconsumption in shared \r\nlibraries? \r\n‚Ä¢RQ3: Can we verify the \r\norigin of energy \r\nconsumption differences by \r\nrecreating the workload \r\nbehavior closely?\r\n37\r\n\r\nTracing\r\n‚Ä¢ Find libc function running at the end of the benchmark \r\n‚Ä¢ Tracing: Capture calls made to libc \r\n‚Ä¢ Introduces non-linear overhead\r\n38\r\n\r\nSynchronization\r\n‚Ä¢ Tracing slows down execution and increase energy consumption \r\n‚Ä¢ Run separately and synchronize with logs\r\n39\r\n\r\nTracing Analysis\r\n40\r\n\r\nTracing Analysis\r\n41\r\n\r\nBenchmarking memcpy\r\n‚Ä¢ Copy bytes from one part of memory to \r\nanother \r\n‚Ä¢ Depending on function parameters, different \r\nassembly-level optimizations \r\n‚Ä¢ Some not included in musl\r\n42\r\n\r\nBenchmarking memcpy\r\n‚Ä¢ Copy 4 bytes from fixed \r\npointer to moving pointer \r\n‚Ä¢ (100,300,500,600) x 1M \r\nrequests \r\n‚Ä¢  15% more power and 3X time\r\n43\r\n\r\nConclusions\r\n‚Ä¢ Significant difference in energy consumption for memcpy \r\n‚Ä¢ 8.6% difference for Redis workload and 13% in our benchmark \r\n‚Ä¢ musl trades performance for a smaller codebase \r\n‚Ä¢ No official documentation \r\n‚Ä¢ No awareness about energy performance\r\n44\r\n\r\n5. Energy Efficiency vs Code \r\nQuality\r\n\r\nMeasuring Maintainability\r\n‚Ä¢ According to ISO/IEC 25010, Maintainability is ‚Äúthe degree of \r\neffectiveness and efficiency with which a software product or \r\nsystem can be modified to improve it, correct it or adapt it to \r\nchanges in environment, and in requirements‚Äù \r\n‚Ä¢ We use the code analysis tool Better Code Hub to assess \r\nmaintainability \r\n‚Ä¢ Better Code Hub maps the ISO/IEC 25010 standard on \r\nmaintainability into a set of guidelines derived from static analysis\r\n46\r\n\r\nMaintainability of Energy Changes\r\n‚Ä¢ What is the impact of making energy-oriented code changes on \r\nthe maintainability of mobile apps?', 'google.com/view/energy-efficiency-languages\r\n21\r\nAna Radovanovic ÃÅ, Ross Koningstein, Ian Schneider, Bokan \r\nChen, Alexandre Duarte, Binz Roy, Diyue Xiao, Maya \r\nHaridasan, Patrick Hung, Nick Care, Saurav Talukdar, Eric \r\nMullen, Kendal Smith, MariEllen Cottman, and Walfredo Cirne \r\n\r\n\r\n‚Ä¢ Google‚Äôs Carbon-Intelligent Computing System (CICS) \r\n‚Ä¢ Main idea: use carbon-intensity data to shift datacenter jobs in time \r\n‚Ä¢ Typically, job schedulers use a metric of cluster capacity to schedule a job in \r\na particular cluster. \r\n‚Ä¢ CICS overrides this metric with the virtual capacity curve (VCC) that \r\nfactors in Carbon intensity \r\n‚Ä¢ When a new job comes in, the scheduler estimates its CPU load and power \r\nusage and assigns it to a cluster if the VCC is not exceeded.\r\n23\r\n\r\n‚Ä¢ Jobs are divided between flexible and inflexible. \r\n‚Ä¢ Flexible load is considered shapeable/shiftable as long as its total daily \r\ncompute (CPU) demand is preserved \r\n‚Ä¢ The system needs to consider that, while running a job, the virtual capacity \r\ncurve (VCC) might drop. Hence, this job should not start in the first place. \r\n‚Ä¢ They forecast VCC for the next day\r\n24\r\n\r\n\r\nVirtual Cluster Capacity (VCC)\r\n‚Ä¢ Aims at reducing the peak load at carbon intensive hours but in total it should allow for the \r\nsome amount of daily computation! \r\n‚Ä¢ Considers Carbon intensity \r\n‚Ä¢ Using data from electricityMap.org \r\n‚Ä¢ It does not use carbon intensity directly.\u2028\r\nCarbon intensity is converted to a cost (kgCO2 -> $$) \r\n‚Ä¢ This way, they can factor in other metrics that can also be converted to money. E.g., the \r\ncost saved by preventing peak load \r\n‚Ä¢ Peak workload entails extra cost at the infrastructure level (e.g., control faclities‚Äô \r\ntemperature). \r\n‚Ä¢ By using money cost instead of carbon cost, they have more data available.\r\n26\r\n\r\nVirtual Cluster Capacity (VCC)\r\n‚Ä¢ If the forecast of VCC fails it shift flexible workload more than expected.  \r\n‚Ä¢ This happens because the amount of workload forecasted was below the \r\nworkload needed, and VCC was ‚Äúaggressively‚Äù low. \r\n‚Ä¢ The systems fall back to the real cluster capacity for 1 week until results \r\nstart being realistic again.\r\n27\r\n\r\nNext steps\r\n‚Ä¢ They will consider spatial flexibility. \r\n‚Ä¢ I.e., tasks that can be shifted over time and over space. \r\n‚Ä¢ It needs to factor in relocation overheads, though.\r\n28\r\n\r\nCritical questions\r\n‚Ä¢ Who defines what is flexible and inflexible? \r\n‚Ä¢ How do you estimate the CPU load of a given task?\r\n29\r\n\r\nEnergy Regression Testing\r\n‚ÜíEnergy?\r\nGreener? Greener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\n\r\nE-compare\r\nGithub Actions\r\n‚ûú https://koenhagen.github.io/E-Compare/\r\n\r\nEnergy Regression Testing \r\n\r\n4. Debugging Energy with \r\nDocker Images\r\n\r\nUnveiling the Energy Vampires \r\nA methodology for debugging Software \r\nEnergy Consumption\r\n ‚úÖ ICSE 2025\r\n\r\nData Centers and Docker\r\n‚Ä¢ Containers are the most popular way to deploy apps into the cloud \r\n‚Ä¢ Base image is an important choice when building an image \r\n‚Ä¢ Criteria \r\n‚Ä¢ Linux distribution and binaries \r\n‚Ä¢ Image size \r\n‚Ä¢ Energy?\r\n35\r\n\r\nRedis energy consumption\r\n‚Ä¢ Ubuntu/Alpine base images have different energy consumption for Redis\r\n36\r\n\r\nRedis Energy Consumption\r\n‚Ä¢RQ1: What is the difference \r\nin energy consumption \r\nbetween glibc and musl? \r\n‚Ä¢RQ2: Can we use tracing \r\nto compare energy \r\nconsumption in shared \r\nlibraries?', '‚Ä¢ Deadline April 4.\r\n6\r\n\r\nStrategy\r\n‚Ä¢ Week 0 \r\n‚Ä¢ Decide project idea (today) \r\n‚Ä¢ Define steering meeting schedule \r\n‚Ä¢ Create working document of the \r\narticle: Problem statement and solution \r\nproposal! \r\n‚Ä¢ Define and assign tasks for each week. \r\n‚Ä¢ Week 1 \r\n‚Ä¢ Implementation \r\n‚Ä¢ Agreements with supervisor. \r\n‚Ä¢ Week 2 \r\n‚Ä¢ Implementation \r\n‚Ä¢ Week 3 \r\n‚Ä¢ Implementation, Full draft of article, \r\ndissemination. \r\n‚Ä¢ Week 4 \r\n‚Ä¢ Final refinements \r\n‚Ä¢ Prepare presentation\r\n7\r\n\r\nProject ideas\r\n‚Ä¢ A1. Prototype cross-machine comparable benchmarks \r\n‚Ä¢ A2. Add energy metrics to LMstudio/Ollama \r\n‚Ä¢ A3. Visualizations built-in with EnergiBridge \r\n‚Ä¢ A4. Service-based version of EnergiBridge\r\n\r\nProject ideas\r\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \r\n‚Ä¢ B2. Study test generation energy consumption \r\n‚Ä¢ B3. Energy profiling of static analysis tools \r\n‚Ä¢ B4. Detailed energy profiling of build pipelines \r\n‚Ä¢ B5. Tool supporting SusAF workshop / process \r\n‚Ä¢ B6. Dataset of government-developed OS software \r\n‚Ä¢ B7. Queue - but better for the student / TA society\r\nQuality Assurance & Testing\r\nSocial & Individual \u2028\r\nSustainability\r\n\r\nProject ideas\r\n‚Ä¢ C1. Compare energy consumption of docker images for ML workloads. \r\n‚Ä¢ C2. Create a plugin to visualize Hugging Face carbon emissions in detail. \r\n‚Ä¢ C3. Plugin for ChatGPT (footprint per chat window) \r\n‚Ä¢ C4. NutriScore for software libraries. \r\n‚Ä¢ C5. Add energy-awareness to existing software \r\n‚Ä¢ C6. Green Shift Left \r\n‚Ä¢ C7. Education for Sustainable SE\r\n\r\nA1. Prototype cross-machine comparable benchmarks\r\n‚Ä¢ Energy-usage comparisons require running both baseline + software on the \r\nsame machine ‚Üí limits how extensive our experiments can be \r\n‚Ä¢ Research community is in need of benchmarks that make energy \r\nmeasurements comparable even if executed on different machines \r\n‚Ä¢ Focus on a single task or model (i.e. computing vision, classification)\r\n\r\nA2. Adding energy metrics to LMstudio/Ollama\r\n‚Ä¢ Make energy consumption visible to users \r\nwithin local chat-interface for LLMs \r\n‚Ä¢ LMstudio/Ollama are tools for easy \r\ndeployment of LLMs \r\n‚Ä¢ Do not show energy metrics \r\n‚Ä¢ Add energy metrics to LMstudio-python \r\nor Ollama\r\nhttps://lmstudio.ai/\r\n\r\nA3. Visualizations built-in with EnergiBridge\r\n‚Ä¢ EnergiBridge simplifies energy measurement, but analysis & visualization is \r\nstill left to the user \r\n‚Ä¢ Extend the tool with well-chosen visualizations and analyses directly from the \r\nprovided data\r\n\r\nA4. Service-based version of EnergiBridge\r\n‚Ä¢ Simplify interaction & setup with EnergiBridge \r\n‚Ä¢ Service that runs independently, start/stop signals over RPC to manage \r\nexperiments \r\n‚Ä¢ Potential: create EnergiBridge interface for other prog. lang\r\n\r\nB1. Measure energy consumption of single JUnit tests\r\n‚Ä¢ We‚Äôd like to identify energy anti patterns in unit tests \r\n‚Ä¢ As a first step, we need tooling to measure and compare the energy \r\nconsumption of single unit tests \r\n‚Ä¢ Ideally including preliminary analysis looking at potential reasons for high-\r\nenergy-consuming tests\r\n\r\nB2. Study test generation energy consumption\r\n‚Ä¢ Automatic test generation mainly focuses on making strong test suites \r\n‚Ä¢ Do different techniques and configurations impact the energy consumption \r\nduring generation? \r\n‚Ä¢ Preferably focus on non-LLM test generation methods (EvoSuite, Pyguin, \r\nDSpot)\r\n\r\nB3. Detailed energy profiling of build pipelines\r\n‚Ä¢ Automatic builds have become a cornerstone of quality assurance.', ""‚Ä¢ Our question: Can we save energy with alternative approaches? \r\n‚Ä¢ We studied Grid Search, Random Search and Bayesian \r\nOptimisation.\r\n27\r\nTim's MSc Thesis, 2022 \r\nAccepted at CAIN‚Äô23\r\n\r\n\r\nResults\r\n29\r\nConclusions? \r\n‚Ä¢ Bayesian converges faster. \r\n‚Ä¢ No clear winner between Grid and Random\r\n\r\nDeepSeekMoE\r\n30\r\nPreprint at ArXiv, 2024 https://arxiv.org/pdf/\r\n2401.06066\r\n\r\nMixture of Experts\r\n‚Ä¢ Llama3.1 has 405B parameters, DeepSeek V3 671B \r\n‚Ä¢ Yet DeepSeek has quicker inference times and claims less energy \r\nconsumption (?) \r\n‚Ä¢ Divide the model into smaller blocks of experts \r\n‚Ä¢ Tokens get routed to certain experts based on the query \r\n‚Ä¢ Only part of the network is active during inference \r\n‚Ä¢ DeepSeek claims only 37B out of 671B parameters get active\r\n31\r\n\r\nDeepSeekMoE\r\n32\r\n\r\nDeepSeekMoE\r\n33\r\n‚Ä¢ Comparable performance to \r\nLLaMA2 7B effectively using \r\nless half the parameters \r\n‚Ä¢ Less computational power \r\n‚Ä¢ Problems (?) \r\n‚Ä¢ Still need to load all the \r\nparameters \r\n‚Ä¢ High memory -> high \r\nembodied carbon\r\n\r\nGreen AI at FacebookMeta\r\n34\r\nSustainable AI: Environmental Implications, \r\nChallenges and Opportunities (2022)\r\n\r\nCarbon footprint mapped to the AI lifecycle\r\n‚Ä¢ There are 4 main overarching stages where carbon emissions need to be isolated: data \r\ncollection, experimentation, training, inference. \r\n‚Ä¢ At Facebook, recommendation systems split energy consumption evenly between \r\ntraining and inference; text translation models have a 35%/65% split. (Operational cost) \r\n‚Ä¢ Operational/embodied cost split: 30%/70%\r\n35\r\n\r\nOpen issues according to Meta\r\n‚Ä¢ A vast portion of projects only use GPUs at 30%.\u2028\r\nShould be higher to attenuate embodied carbon.\r\n36\r\nBased on 10K AI projects\r\n\r\nData Jan\r\nInformed Adaptation\r\nData Feb\r\nData Mar\r\nData Apr\r\nData May\r\n‚Ä¶\r\n~Data Dec\r\n~Data Dec\r\nData Jan\r\nData Feb\r\nData Mar\r\nData Apr\r\nData May\r\n‚Ä¶\r\nModel update Model update Model update\r\nCheck if \r\ndata change\r\nCheck if \r\ndata change\r\nCheck if \r\ndata change\r\nModel update\r\nBlind Adaptation\r\nThe AI Model will be \r\nupdated fewer times and \r\nonly when necessary.\r\nKnow when to retrain models\r\nNeither too early nor too late\r\n37\r\nAdaptation Techniques\r\n?\r\n\r\nGreen Architectural Tactics for ML-Enabled \r\nSystem\r\n38\r\nICSE-SEIS 2024\r\n\r\nArchitectural tactics\r\n39\r\n\r\nData-centric\r\n40\r\n‚Ä¢ Reduce data size \r\n‚Ä¢ Sampling \r\n‚Ä¢ Dimensionality reduction \r\n‚Ä¢ Quantization\r\n\r\nAlgorithm Design\r\n41\r\n‚Ä¢ Carefully select your algorithm \r\n‚Ä¢ You don‚Äôt need the fanciest \r\ntechniques\r\n\r\nModel Optimization\r\n42\r\n‚Ä¢ Add energy to training parameters \r\n‚Ä¢ Reduce FLOPs \r\n‚Ä¢ Pruning, sparsity \r\n‚Ä¢  Take advantage of existing models\r\n\r\nModel Training\r\n43\r\n‚Ä¢ Quantization\r\n‚Ä¢ SAVE TRAINING PROGRESS\r\n\r\nModel Deployment\r\n44\r\n‚Ä¢ Distributed deployment \r\n‚Ä¢ Energy efficient hardware and \r\nconfigurations\r\n\r\nModel Management\r\n45\r\n‚Ä¢ Reuse the model as much as possible \r\n\r\nRethinking the Architecture: Spiking Neural Networks\r\n46\r\n\r\nRethinking the Architecture: Spiking Neural Networks\r\n47\r\n\r\nSELF Lab\r\n48\r\n\r\nrecap"", '‚Ä¢ Improve parameter-tuning strategy.\r\n11\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ We need benchmarks. \r\n‚Ä¢ AllenAI leaderboard\u2028\r\nhttps://leaderboard.allenai.org \r\n‚Ä¢ No carbon metrics, yet \r\n‚Ä¢ Report comparable proxies for energy \r\nconsumption. \r\n‚Ä¢ ‚ö† Learning algorithms behave in a non-\r\ndeterministic \r\n‚Ä¢ ‚ö† Different data-points lead to different \r\nenergy consumption\r\n12\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ Reporting measured energy consumption \r\n‚Ä¢ + Accurate \r\n‚Ä¢ + Easy to map to carbon emissions \r\n‚Ä¢ - Hard to measure \r\n‚Ä¢ - Low replicability \r\n‚Ä¢ Reporting time / estimation based on time & hardware \r\n‚Ä¢ + Easy to measure \r\n‚Ä¢ + Correlates with energy consumption in most cases. \r\n‚Ä¢ -  Difficult to compare with measurements from other setups \r\n‚Ä¢ E.g., floating point operations (FPOs) (?) \r\n‚Ä¢ + comparable across different setups \r\n‚Ä¢ + cheap \r\n‚Ä¢ - does not factor in memory energy consumption \r\n‚Ä¢ - does not reflect carbon emissions\r\n13\r\n\r\nData-centric AI\r\n\r\nData-centric AI\r\n‚Ä¢ Emerging discipline that deals with systematically engineering data to build AI \r\nsystems. \r\n‚Ä¢ Shift from improving the training strategy to improving the data. \r\n‚Ä¢ It is better to have small but reliable datasets than large but noisy \r\ndatasets. \r\n‚Ä¢ => Improve data collection, data labelling, and data preprocessing. \r\n‚Ä¢ More about data-centric AI by Andrew Ng:\u2028\r\nhttps://www.youtube.com/watch?v=06-AZXmwHjo\r\n15\r\n\r\n\r\nGreen Data-centric AI\r\n‚Ä¢ How do different ML algorithms compare \r\nin terms of energy consumption? \r\n‚Ä¢ How does number of rows relate to the \r\nenergy consumption of ML models? \r\n‚Ä¢ How does number of features relate to \r\nthe energy consumption of ML models? \r\n‚Ä¢ What is the impact of reducing data in the \r\nperformance of the model? \r\n‚Ä¢ Method -> results -> discussion\r\n17\r\n\r\nMethod\r\n‚Ä¢ Single object of study: natural language model to detect spam messages. \r\n‚Ä¢ 6 machine learning algorithms: SVM, Decision Tree, KNN, Random Forrest, \r\nAdaBoost, Bagging Classifier. \r\n‚Ä¢ Reduce the number of rows. 10%, 20%, .., 100% \r\n‚Ä¢ Stratified random sampling (?) \r\n‚Ä¢ Reduce the number of features. 10%, 20%, .., 100% \r\n‚Ä¢ Feature importance metric based on the Chi-Square Test (Chi2) \r\n‚Ä¢ Estimate energy consumption using a RAPL-based tool. (?)\r\n18\r\n\r\n‚Ä¢ Repeat 30 times \r\n‚Ä¢ Fix random seeds \r\n‚Ä¢ ‚Ä¶ \r\n‚Ä¢ Data was not Normal => tailed Normal distribution.\r\n19\r\n(?)\r\n\r\nResults: energy consumption of algorithms\r\n\r\nResults: energy vs data shape\r\n\r\nResults: performance vs data shape\r\n\r\nDiscussion\r\n‚Ä¢ Other data properties should be investigated. \r\n‚Ä¢ E.g., data types \r\n‚Ä¢ Reporting energy data is essential. It can lead to different model selection \r\nwithout hindering model performance. \r\n‚Ä¢ There is a big opportunity in Model and Data Simplification.\r\n23\r\n\r\nData/Model Simplification\r\n‚Ä¢ (?) \r\n‚Ä¢ Data selection \r\n‚Ä¢ Data quantisation. Posit? \r\n‚Ä¢ Data distillation \r\n‚Ä¢ Coreset extraction (?) \r\n‚Ä¢ Model distillation \r\n‚Ä¢ Model quantisation \r\n‚Ä¢ Model pruning \r\n‚Ä¢ ‚Ä¶\r\n24\r\n\r\nPosit vs Float\r\nMore about this: https://spectrum.ieee.org/floating-point-numbers-posits-processor\r\nBetter for DL use cases\r\n\r\nHow can we tune \r\nlearning \r\nparameters \r\nefficiently?\r\n\r\nHyper parameter tuning\r\n‚Ä¢ When training an ML model, there are several parameters that need to be \r\ntuned. \r\n‚Ä¢ E.g., in SVM we have the Regularization parameter C, the kernel function, \r\nthe degree of the kernel function, and depending on the case, many other. \r\n‚Ä¢ The common approach revolves around grid search.', '8. Green AI\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nLu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\nCarolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl\r\n\r\n- Overview of Green AI \r\n- Large language models \r\n- Green data-centric AI \r\n- Model simplification \r\n- Hyper parameter tuning \r\n- Mixture of Experts and DeepSeek \r\n- Green AI at Meta \r\n\r\nAI\r\n‚Ä¢ Artificial Intelligence (AI) is the branch of computer science that deals with \r\nautomating tasks that typically require human intelligence. \r\n‚Ä¢ In the past years AI has been widely applied across different domains.\u2028\r\nE.g., health care, transportation, finance. \r\n‚Ä¢ To deploy AI systems, we test them against benchmarks (or validation sets). \r\n‚Ä¢ The goal is to outperform the previous existing models. \r\n‚Ä¢ E.g., in Machine Learning we usually resort to accuracy metrics. The \r\nhighest the accuracy, the better the model.\r\n3\r\n\r\nSince 2012, the amount of computing used for AI \r\ntraining has been doubling every 6 months\r\n‚Ä¢ https://epoch.ai/blog/compute-trends\r\n4\r\n\r\n‚Ä¢ To create better AI systems we are currently adding \r\n‚Ä¢ More data \r\n‚Ä¢ More experiments \r\n‚Ä¢ Larger models\r\n5\r\n\r\nThe Equation of Red AI\r\nCost(R) ‚àùE¬∑D¬∑H\r\nCost of a single (E)xample\r\nSize of (D)ataset\r\nNumber of (H)yperparameters\r\nBy Schwartz et al. (2020)\r\n\r\nIssues of Red AI\r\n‚Ä¢ High costs (hardware, electricity, data access, etc.) \r\n‚Ä¢ Limited reproducibility.  \r\n‚Ä¢ Energy consumption. \r\n‚Ä¢ Carbon emissions. \r\n‚Ä¢ SMEs can hardly be competitive. \r\n‚Ä¢ Groundbreaking AI research is mostly done by tech giants.\r\n7\r\n\r\nA few examples of Red AI\r\n‚Ä¢ Google‚Äôs BERT-large \r\n‚Ä¢ 350 million features \r\n‚Ä¢ Trained for 2.5 days using 512 TPU chips, costing $60K+ \r\n‚Ä¢ Open-GPT3 (now GPT-4/o1) \r\n‚Ä¢ 550 tonnes CO2-eq (Patterson, 2021) \r\n‚Ä¢ 175 billion features \r\n‚Ä¢ API is open but no-pretrained model is available \r\n‚Ä¢ AlphaGo \r\n‚Ä¢ 1920 CPUs, 280 GPUs, costing $35M\r\n8\r\n\r\nRed AI in Large Language Models (LLMs)\r\n‚Ä¢ OPT by Meta reports 75 tons CO2-eq (1/7 of OpenGPT‚Äôs footprint).\u2028\r\n(Also 175billion params) \r\n‚Ä¢ However, Llama 3 reported 2,290 tons of CO2-eq (7.7M GPU hours \r\ntraining ) \r\n‚Ä¢ Open science: release includes both the pretrained models and the code \r\nneeded to train and use them. \r\n‚Ä¢ DeepSeek-V3 claims ‚Äúonly‚Äù 2.78M GPU hours \r\n‚Ä¢ Bloom by Huggingface reports 25 tons, 51 when considering embodied \r\nand operational carbon footprint. (176billion params)\r\n9\r\n\r\nRed AI\r\nAccuracy: 0.999999999\r\nGreen AI\r\n‚Ä¢ Energy \r\n‚Ä¢ Time \r\n‚Ä¢ Reproducibility \r\n‚Ä¢ Reusage\r\n\r\nHow can we adopt Green AI\r\n‚Ä¢ Check whether AI is needed. \r\n‚Ä¢ Select green datacenters. \r\n‚Ä¢ Run on low carbon intensity hours. \r\n‚Ä¢ Opt for GPU-optimised solutions (?) \r\n‚Ä¢ Opt for low-power hardware (e.g., Nvidia Jetson boards) \r\n‚Ä¢ Or GPUs that provide energy metrics (e.g., NVIDIA GPUs via the nvidia-smi tool) \r\n‚Ä¢ Report energy/carbon metrics (e.g., embed in MLFlow?)', 'Lu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\n10. Project 2\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nCarolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl\r\n\r\n1. Goal/assignment \r\n2. Deliverables \r\n3. Strategy \r\n4. Ideas\r\n\r\nAssignment\r\n‚Ä¢ Goal: Solve a Sustainable Software Engineering problem. \r\n‚Ä¢ Identify 1 problem that should be fixed to help enabling sustainability in \r\nthe software engineering industry/community. \r\n‚Ä¢ Propose a solution. A tool, framework, guidelines, etc. \r\n‚Ä¢ Implementation. \r\n‚Ä¢ Validation. (Depending on the idea) \r\n‚Ä¢ Dissemination/social impact. (Solution should be open source, welcome \r\ncontributors, post on social media? Tool website? Available in a package \r\nmanager?)\r\n3\r\n\r\nDeliverables\r\n‚Ä¢ Paper-like article. (Min 4 pages, max 10) \r\n‚Ä¢ Online git repo with open source codebase and/or replication package. \r\n‚Ä¢ Presentation: 5 min + 5min Q&A\r\n4\r\n\r\nArticle\r\n‚Ä¢ Different projects will have different expectations -> Make agreements with \r\nyour coach. \r\n‚Ä¢ Some projects are more technical and some projects more theoretical. \r\n‚Ä¢ Common requirements: \r\n‚Ä¢ Motivation, formulation of the problem being addressed, etc. \r\n‚Ä¢ Description of the solution. \r\n‚Ä¢ Validation of the solution (if applicable -> discuss with coach) \r\n‚Ä¢ Discussion of the solution. (Including limitations)\r\n5\r\n\r\nStrategy\r\n‚Ä¢ Starting next week, there are no lectures  \r\n‚Ä¢ Steering meetings from week 5 till week 9 (either online or in person).  \r\n‚Ä¢ 1 steering meeting per week. (4+1 sprints) \r\n‚Ä¢ Every week, you need to plan different tasks and assignments. \r\n‚Ä¢ Deadline April 4.\r\n6\r\n\r\nStrategy\r\n‚Ä¢ Week 0 \r\n‚Ä¢ Decide project idea (today) \r\n‚Ä¢ Define steering meeting schedule \r\n‚Ä¢ Create working document of the \r\narticle: Problem statement and solution \r\nproposal! \r\n‚Ä¢ Define and assign tasks for each week. \r\n‚Ä¢ Week 1 \r\n‚Ä¢ Implementation \r\n‚Ä¢ Agreements with supervisor. \r\n‚Ä¢ Week 2 \r\n‚Ä¢ Implementation \r\n‚Ä¢ Week 3 \r\n‚Ä¢ Implementation, Full draft of article, \r\ndissemination. \r\n‚Ä¢ Week 4 \r\n‚Ä¢ Final refinements \r\n‚Ä¢ Prepare presentation\r\n7\r\n\r\nProject ideas\r\n‚Ä¢ A1. Prototype cross-machine comparable benchmarks \r\n‚Ä¢ A2. Add energy metrics to LMstudio/Ollama \r\n‚Ä¢ A3. Visualizations built-in with EnergiBridge \r\n‚Ä¢ A4. Service-based version of EnergiBridge\r\n\r\nProject ideas\r\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \r\n‚Ä¢ B2. Study test generation energy consumption \r\n‚Ä¢ B3. Energy profiling of static analysis tools \r\n‚Ä¢ B4. Detailed energy profiling of build pipelines \r\n‚Ä¢ B5. Tool supporting SusAF workshop / process \r\n‚Ä¢ B6. Dataset of government-developed OS software \r\n‚Ä¢ B7. Queue - but better for the student / TA society\r\nQuality Assurance & Testing\r\nSocial & Individual \u2028\r\nSustainability\r\n\r\nProject ideas\r\n‚Ä¢ C1. Compare energy consumption of docker images for ML workloads. \r\n‚Ä¢ C2. Create a plugin to visualize Hugging Face carbon emissions in detail. \r\n‚Ä¢ C3. Plugin for ChatGPT (footprint per chat window) \r\n‚Ä¢ C4. NutriScore for software libraries. \r\n‚Ä¢ C5. Add energy-awareness to existing software \r\n‚Ä¢ C6. Green Shift Left \r\n‚Ä¢ C7. Education for Sustainable SE\r\n\r\nA1.', 'Lu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\n7. Green SE ‚Äì Research\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nCarolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl\r\n\r\n1. Energy patterns for mobile apps \r\n2. Carbon-aware datacenters \r\n3. Energy Regression Testing \r\n4. Debugging Energy with Docker images \r\n5. Energy Efficiency vs Code Quality \r\n\r\n‚Ä¢ While learning about these works, try to be critical about them and find their \r\npitfalls.\r\n3\r\n\r\n‚Ä¢ We have seen that measuring energy consumption is not trivial \r\n‚Ä¢ It is not practical considering that developers have other priorities above \r\nenergy efficiency \r\n‚Ä¢ At the same time, every now and then there are some efforts to improve \r\nenergy efficiency in some cases. This is time consuming and requires \r\nexpertise. \r\n‚Ä¢ How can we reuse these efforts?\r\n4\r\n\r\nEnergy Patterns for Mobile \r\nApps\r\nhttps://tqrg.github.io/energy-patterns/\r\n\r\nMethodology\r\n5. Catalog of Energy Patterns\r\n22 \r\npatterns\r\nF-droid\r\nCurated Lists\r\n1. App Collection\r\n1783 \r\napps\r\n3. Manual Refinement of Subjects of \r\nInterest\r\n1563 \r\nchanges\r\n4. Thematic Analysis\r\n431 \r\nreusable \r\nchanges\r\n2. Collect Changes With Potential Interest\r\n/.*(energy|power|battery).*/\r\n6028 \r\nchanges\r\n\r\nThematic Analysis\r\n1. Familiarization with data \r\n2. Generating initial labels \r\n3. Reviewing themes\r\n4. Defining and naming themes\r\n\r\n‚Ä¢ Energy Pattern: design pattern to improve energy efficiency.. \r\n‚Ä¢ 22 energy patterns. \r\n‚Ä¢ Each pattern is described by Context, Solution, Example, References from \r\nliterature, and Occurences (links to code changes from git repositories).\r\n8\r\n\r\nhttps://tqrg.github.io/energy-patterns\r\n\r\nDark UI Colors \r\nProvide a dark UI color theme to \r\nsave battery on devices with \r\nAMOLED screens.\r\n‚Ä¢ Context: [‚Ä¶] Apps that require heavy usage of screen can \r\nhave a substantial negative impact on battery life. \r\n‚Ä¢ Solution: Provide a UI theme with dark background colors. [‚Ä¶]\r\n‚Ä¢ Example: In a reading app, provide a theme with a dark \r\nbackground using light colors to display text. [‚Ä¶] \r\n10\r\n\r\nDark UI Colors \r\nProvide a dark UI color theme to \r\nsave battery on devices with \r\nAMOLED screens.\r\n‚Ä¢ Context: [‚Ä¶] Apps that require heavy usage of screen can \r\nhave a substantial negative impact on battery life. \r\n‚Ä¢ Solution: Provide a UI theme with dark background colors. [‚Ä¶]\r\n‚Ä¢ Example: In a reading app, provide a theme with a dark \r\nbackground using light colors to display text. [‚Ä¶] \r\n11\r\n\r\nDynamic Retry Delay\r\n‚Ä¢ Context: [‚Ä¶] In a mobile app, when a given resource is \r\nunavailable, the app will unnecessarily try to connect the resource \r\nfor a number of times, leading to unnecessary power consumption. \r\n‚Ä¢ Solution: Increase retry interval after each failed connection. [‚Ä¶]\r\n‚Ä¢ Example: Consider a mobile app that provides a news feed and \r\nthe app is not able to reach the server to collect updates. [‚Ä¶] use \r\nthe Fibonacci series to increase the time between attempts.\r\nWhenever an attempt to access a \r\nresource fails, increase the time \r\ninterval before retrying.\r\n12\r\n\r\nBatch Operations \r\n‚Ä¢ Context: Executing operations separately leads to extraneous \r\ntail energy consumptions  \r\n‚Ä¢ Solution: Bundle multiple operations in a single one. [‚Ä¶]\r\n‚Ä¢ Example: Use system provided APIs to schedule background \r\ntasks. These APIs, guarantee that device will exit sleep mode \r\nonly when there is a reasonable amount of work to do or when a \r\ngiven task is urgent.', '‚Ä¢ Groundbreaking AI research is mostly done by tech giants.\r\n7\r\n\r\nA few examples of Red AI\r\n‚Ä¢ Google‚Äôs BERT-large \r\n‚Ä¢ 350 million features \r\n‚Ä¢ Trained for 2.5 days using 512 TPU chips, costing $60K+ \r\n‚Ä¢ Open-GPT3 (now GPT-4/o1) \r\n‚Ä¢ 550 tonnes CO2-eq (Patterson, 2021) \r\n‚Ä¢ 175 billion features \r\n‚Ä¢ API is open but no-pretrained model is available \r\n‚Ä¢ AlphaGo \r\n‚Ä¢ 1920 CPUs, 280 GPUs, costing $35M\r\n8\r\n\r\nRed AI in Large Language Models (LLMs)\r\n‚Ä¢ OPT by Meta reports 75 tons CO2-eq (1/7 of OpenGPT‚Äôs footprint).\u2028\r\n(Also 175billion params) \r\n‚Ä¢ However, Llama 3 reported 2,290 tons of CO2-eq (7.7M GPU hours \r\ntraining ) \r\n‚Ä¢ Open science: release includes both the pretrained models and the code \r\nneeded to train and use them. \r\n‚Ä¢ DeepSeek-V3 claims ‚Äúonly‚Äù 2.78M GPU hours \r\n‚Ä¢ Bloom by Huggingface reports 25 tons, 51 when considering embodied \r\nand operational carbon footprint. (176billion params)\r\n9\r\n\r\nRed AI\r\nAccuracy: 0.999999999\r\nGreen AI\r\n‚Ä¢ Energy \r\n‚Ä¢ Time \r\n‚Ä¢ Reproducibility \r\n‚Ä¢ Reusage\r\n\r\nHow can we adopt Green AI\r\n‚Ä¢ Check whether AI is needed. \r\n‚Ä¢ Select green datacenters. \r\n‚Ä¢ Run on low carbon intensity hours. \r\n‚Ä¢ Opt for GPU-optimised solutions (?) \r\n‚Ä¢ Opt for low-power hardware (e.g., Nvidia Jetson boards) \r\n‚Ä¢ Or GPUs that provide energy metrics (e.g., NVIDIA GPUs via the nvidia-smi tool) \r\n‚Ä¢ Report energy/carbon metrics (e.g., embed in MLFlow?) \r\n‚Ä¢ Use pre-trained models (Transfer Learning) \r\n‚Ä¢ Preprocess dataset to reduce size. \r\n‚Ä¢ Improve parameter-tuning strategy.\r\n11\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ We need benchmarks. \r\n‚Ä¢ AllenAI leaderboard\u2028\r\nhttps://leaderboard.allenai.org \r\n‚Ä¢ No carbon metrics, yet \r\n‚Ä¢ Report comparable proxies for energy \r\nconsumption. \r\n‚Ä¢ ‚ö† Learning algorithms behave in a non-\r\ndeterministic \r\n‚Ä¢ ‚ö† Different data-points lead to different \r\nenergy consumption\r\n12\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ Reporting measured energy consumption \r\n‚Ä¢ + Accurate \r\n‚Ä¢ + Easy to map to carbon emissions \r\n‚Ä¢ - Hard to measure \r\n‚Ä¢ - Low replicability \r\n‚Ä¢ Reporting time / estimation based on time & hardware \r\n‚Ä¢ + Easy to measure \r\n‚Ä¢ + Correlates with energy consumption in most cases. \r\n‚Ä¢ -  Difficult to compare with measurements from other setups \r\n‚Ä¢ E.g., floating point operations (FPOs) (?) \r\n‚Ä¢ + comparable across different setups \r\n‚Ä¢ + cheap \r\n‚Ä¢ - does not factor in memory energy consumption \r\n‚Ä¢ - does not reflect carbon emissions\r\n13\r\n\r\nData-centric AI\r\n\r\nData-centric AI\r\n‚Ä¢ Emerging discipline that deals with systematically engineering data to build AI \r\nsystems. \r\n‚Ä¢ Shift from improving the training strategy to improving the data. \r\n‚Ä¢ It is better to have small but reliable datasets than large but noisy \r\ndatasets. \r\n‚Ä¢ => Improve data collection, data labelling, and data preprocessing. \r\n‚Ä¢ More about data-centric AI by Andrew Ng:\u2028\r\nhttps://www.youtube.com/watch?v=06-AZXmwHjo\r\n15\r\n\r\n\r\nGreen Data-centric AI\r\n‚Ä¢ How do different ML algorithms compare \r\nin terms of energy consumption? \r\n‚Ä¢ How does number of rows relate to the \r\nenergy consumption of ML models? \r\n‚Ä¢ How does number of features relate to \r\nthe energy consumption of ML models? \r\n‚Ä¢ What is the impact of reducing data in the \r\nperformance of the model?', 'computing vision, classification)\r\n\r\nA2. Adding energy metrics to LMstudio/Ollama\r\n‚Ä¢ Make energy consumption visible to users \r\nwithin local chat-interface for LLMs \r\n‚Ä¢ LMstudio/Ollama are tools for easy \r\ndeployment of LLMs \r\n‚Ä¢ Do not show energy metrics \r\n‚Ä¢ Add energy metrics to LMstudio-python \r\nor Ollama\r\nhttps://lmstudio.ai/\r\n\r\nA3. Visualizations built-in with EnergiBridge\r\n‚Ä¢ EnergiBridge simplifies energy measurement, but analysis & visualization is \r\nstill left to the user \r\n‚Ä¢ Extend the tool with well-chosen visualizations and analyses directly from the \r\nprovided data\r\n\r\nA4. Service-based version of EnergiBridge\r\n‚Ä¢ Simplify interaction & setup with EnergiBridge \r\n‚Ä¢ Service that runs independently, start/stop signals over RPC to manage \r\nexperiments \r\n‚Ä¢ Potential: create EnergiBridge interface for other prog. lang\r\n\r\nB1. Measure energy consumption of single JUnit tests\r\n‚Ä¢ We‚Äôd like to identify energy anti patterns in unit tests \r\n‚Ä¢ As a first step, we need tooling to measure and compare the energy \r\nconsumption of single unit tests \r\n‚Ä¢ Ideally including preliminary analysis looking at potential reasons for high-\r\nenergy-consuming tests\r\n\r\nB2. Study test generation energy consumption\r\n‚Ä¢ Automatic test generation mainly focuses on making strong test suites \r\n‚Ä¢ Do different techniques and configurations impact the energy consumption \r\nduring generation? \r\n‚Ä¢ Preferably focus on non-LLM test generation methods (EvoSuite, Pyguin, \r\nDSpot)\r\n\r\nB3. Detailed energy profiling of build pipelines\r\n‚Ä¢ Automatic builds have become a cornerstone of quality assurance. But how \r\nmuch energy do they even consume? \r\n‚Ä¢ Create a tool that reports on the energy consumed during the (different stages \r\nof the) whole build (compile, build, test, package, ‚Ä¶) \r\n‚Ä¢ Should be integrated with build system(s), making setup for developers easy \r\n‚Ä¢ For local setup (to enable true energy measurements)\r\n\r\nB4. Energy profiling of static analysis tools\r\n‚Ä¢ What is the energy consumption of a ""typical run"" for a few OSS projects? \r\n‚Ä¢ Does the type of analysis matter? Are certain analysis more expensive? Does \r\nthe number of rules that are activated in a static analysis tool important for the \r\nenergy consumption? \r\n‚Ä¢ Differences between static analysis tools [lower priority]\r\n\r\nB5. Tool supporting SusAF workshop / process\r\n‚Ä¢ Lead engineers through process & questions \r\n‚Ä¢ Interface to create & document the two diagrams \r\n‚Ä¢ (!) Should be easy to start using & set up \r\n‚Ä¢ You may also create a simplified version / \u2028\r\nyour favorite sustainability framework\r\nEnvironmental\r\nEconomic\r\nTechnical\r\nIndividual\r\nSocial\r\nImmediate\r\nEnabling\r\nStructural\r\nAirbnb\r\ngreater \r\nearnings\r\nincrease \r\nin rents\r\ngentrification\r\ngreater racial \r\ndisparities\r\nrent \r\nrooms\r\n5\r\n1\r\n3\r\n4\r\n2\r\n \r\n \r\n \r\n \r\n \r\n \r\nVery \r\nunlikely \r\nVery \r\nlikely \r\n\r\nB6. Dataset of government-developed OS software\r\n‚Ä¢ Governments develop & use software for supporting society\u2028\r\nOpen-source development & policies are on the rise \r\n‚Ä¢ But studying government software is difficult b/c we don‚Äôt know what is out \r\nthere\u2028\r\n‚Üí Lack of incentive to make popular \u2028\r\n‚Üí Language barriers \r\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \r\nbuildable?, open dev. history?, requirements documentation? \r\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!\r\n\r\nB7. Queue - but better for the student / TA society\r\n‚Ä¢ Requirements analysis regarding social and individual sustainability effects \r\nof Queue \r\n‚Ä¢ Other EIP / TUD used software also possible: e.g., Answers EWI \r\n‚Ä¢ Non-technical project ‚Üí proper process (workshops?', ""‚Ä¢ 6 machine learning algorithms: SVM, Decision Tree, KNN, Random Forrest, \r\nAdaBoost, Bagging Classifier. \r\n‚Ä¢ Reduce the number of rows. 10%, 20%, .., 100% \r\n‚Ä¢ Stratified random sampling (?) \r\n‚Ä¢ Reduce the number of features. 10%, 20%, .., 100% \r\n‚Ä¢ Feature importance metric based on the Chi-Square Test (Chi2) \r\n‚Ä¢ Estimate energy consumption using a RAPL-based tool. (?)\r\n18\r\n\r\n‚Ä¢ Repeat 30 times \r\n‚Ä¢ Fix random seeds \r\n‚Ä¢ ‚Ä¶ \r\n‚Ä¢ Data was not Normal => tailed Normal distribution.\r\n19\r\n(?)\r\n\r\nResults: energy consumption of algorithms\r\n\r\nResults: energy vs data shape\r\n\r\nResults: performance vs data shape\r\n\r\nDiscussion\r\n‚Ä¢ Other data properties should be investigated. \r\n‚Ä¢ E.g., data types \r\n‚Ä¢ Reporting energy data is essential. It can lead to different model selection \r\nwithout hindering model performance. \r\n‚Ä¢ There is a big opportunity in Model and Data Simplification.\r\n23\r\n\r\nData/Model Simplification\r\n‚Ä¢ (?) \r\n‚Ä¢ Data selection \r\n‚Ä¢ Data quantisation. Posit? \r\n‚Ä¢ Data distillation \r\n‚Ä¢ Coreset extraction (?) \r\n‚Ä¢ Model distillation \r\n‚Ä¢ Model quantisation \r\n‚Ä¢ Model pruning \r\n‚Ä¢ ‚Ä¶\r\n24\r\n\r\nPosit vs Float\r\nMore about this: https://spectrum.ieee.org/floating-point-numbers-posits-processor\r\nBetter for DL use cases\r\n\r\nHow can we tune \r\nlearning \r\nparameters \r\nefficiently?\r\n\r\nHyper parameter tuning\r\n‚Ä¢ When training an ML model, there are several parameters that need to be \r\ntuned. \r\n‚Ä¢ E.g., in SVM we have the Regularization parameter C, the kernel function, \r\nthe degree of the kernel function, and depending on the case, many other. \r\n‚Ä¢ The common approach revolves around grid search. The user provides a \r\nsequence of possible values for each parameter and the pipeline runs all \r\npossible combinations. \r\n‚Ä¢ Our question: Can we save energy with alternative approaches? \r\n‚Ä¢ We studied Grid Search, Random Search and Bayesian \r\nOptimisation.\r\n27\r\nTim's MSc Thesis, 2022 \r\nAccepted at CAIN‚Äô23\r\n\r\n\r\nResults\r\n29\r\nConclusions? \r\n‚Ä¢ Bayesian converges faster. \r\n‚Ä¢ No clear winner between Grid and Random\r\n\r\nDeepSeekMoE\r\n30\r\nPreprint at ArXiv, 2024 https://arxiv.org/pdf/\r\n2401.06066\r\n\r\nMixture of Experts\r\n‚Ä¢ Llama3.1 has 405B parameters, DeepSeek V3 671B \r\n‚Ä¢ Yet DeepSeek has quicker inference times and claims less energy \r\nconsumption (?) \r\n‚Ä¢ Divide the model into smaller blocks of experts \r\n‚Ä¢ Tokens get routed to certain experts based on the query \r\n‚Ä¢ Only part of the network is active during inference \r\n‚Ä¢ DeepSeek claims only 37B out of 671B parameters get active\r\n31\r\n\r\nDeepSeekMoE\r\n32\r\n\r\nDeepSeekMoE\r\n33\r\n‚Ä¢ Comparable performance to \r\nLLaMA2 7B effectively using \r\nless half the parameters \r\n‚Ä¢ Less computational power \r\n‚Ä¢ Problems (?) \r\n‚Ä¢ Still need to load all the \r\nparameters \r\n‚Ä¢ High memory -> high \r\nembodied carbon\r\n\r\nGreen AI at FacebookMeta\r\n34\r\nSustainable AI: Environmental Implications, \r\nChallenges and Opportunities (2022)\r\n\r\nCarbon footprint mapped to the AI lifecycle\r\n‚Ä¢ There are 4 main overarching stages where carbon emissions need to be isolated: data \r\ncollection, experimentation, training, inference. \r\n‚Ä¢ At Facebook, recommendation systems split energy consumption evenly between \r\ntraining and inference; text translation models have a 35%/65% split. (Operational cost) \r\n‚Ä¢ Operational/embodied cost split: 30%/70%\r\n35\r\n\r\nOpen issues according to Meta\r\n‚Ä¢ A vast portion of projects only use GPUs at 30%.\u2028\r\nShould be higher to attenuate embodied carbon."", ""Unless there‚Äôs a \r\ngood reason. \r\n‚Ä¢ E.g., somewhere amongst the 30 executions, \r\nthere might be 1 or 2 that failed to finish due \r\nto some unexpected error. \r\n‚Ä¢ (It happens and that‚Äôs ok!)‚Äì consequently, \r\nthe execution is shorter and spends less \r\nenergy ‚Äì falsely appearing as more \r\nenergy efficient. \r\n‚Ä¢ If data is not Normal there might be some \r\nissues affecting the measurements that \r\nmight be ruining results. It is important to \r\ninvestigate this.\r\n16\r\n\r\nEnergy data is not normal. Why?\r\n‚Ä¢ It might be caused by one of the following reasons: \r\n‚Ä¢ There was an error in some of the executions. If not detected and fixed it \r\nmight ruin results. \r\n‚Ä¢ Your tests are not fully replicable or are not deterministic. Quite frequent \r\nwhen you have internet requests or random-based algorithms. \r\n‚Ä¢ There is an unusual task being run by the system during some experiments. \r\n‚Ä¢ The computer entered a different power mode. \r\n‚Ä¢ External physical conditions have changed. E.g., someone opened a \r\nwindow.\r\n17\r\n\r\nEnergy data is not normal. How to fix?\r\n‚Ä¢ We have 2+1 options: \r\n1. Remove outliers. If there are only a few points that deviate from the normal \r\ndistribution, it is okay to simply remove them. \r\n‚Ä¢ Use the z-score outlier removal. (?) \r\n‚Ä¢ Remove all data points that deviate from the mean more than 3 standard \r\ndeviations: \r\n \r\n2. Fix the issue and rerun experiments. \r\n3. Conclude that nothing can be done about it and data will never be normal. (e.g., \r\nin AI, executions are rarely deterministic). ‚ö† Only after ruling out the previous \r\npoints.\r\n| ¬Øx ‚àíx| > 3s\r\n18\r\n\r\nHow do we know whether data is Normal?\r\n‚Ä¢ Visualise distribution shape: violin plots, histograms, density plot.\u2028\r\n \r\n‚Ä¢ Shapiro-Wilk test.\u2028\r\ndata is not normal;\u2028\r\nwe are not sure but it is okay to assume that data is \r\nnormal.\r\np-value < 0.05 ‚áí\r\np-value ‚â•0.05 ‚áí\r\n19\r\n\r\nAfter having all data ready, which artefact \r\nis more energy efficient(?) \r\nFirst approach: compare sample means. \r\n‚ö† assuming normal distribution\r\n\r\nStatistical significance\r\n‚Ä¢ Even if, on average, one artefact has lower \r\nenergy consumption than other,  it might be just \r\na random difference. \r\n‚Ä¢ When we extract a sample from a normal \r\ndistribution it will never be the exact same \r\n‚Ä¢ Statistical significance tests help you \r\nunderstand the differences in the average are \r\nconclusive/significant or inconclusive/\r\ninsignificant.\r\n21\r\n‚ö† assuming normal distribution\r\n\r\nStatistical significance test\r\n‚Ä¢ Two-sided parametric test Welch‚Äôs t-test. \r\n‚Ä¢ Less known alternative to student‚Äôs t-test.\r\n22\r\nWelch‚Äôs t-test in Python\r\nfrom scipy.stats import ttest_ind \r\n_,pvalue = ttest_ind(sample_a, sample_b, \r\n                     equal_var=False, \r\n                     alternative='two-sided')\r\n(?)\r\n‚ö† assuming normal distribution\r\n\r\nEffect Size analysis\r\n‚Ä¢ Now that we know that results are statistically significant we need to \r\nmeasure the difference between the two samples. \r\n‚Ä¢ Mean difference: \r\n \r\n‚Ä¢ Percent change: \r\n \r\n‚Ä¢ Cohen‚Äôs d (informal definition: mean difference normalized by a combined \r\nstandard deviation): \r\nŒî¬Øx\r\nxB ‚àíxA\r\nxA\r\n√ó 100 % = Œî¬Øx\r\nxA\r\n√ó 100 %\r\nŒî¬Øx\r\n1\r\n2\r\ns21 + s22\r\n23\r\n‚ö† assuming normal distribution\r\n\r\nImagine that version A spends 70J and \r\nversion B spends 69J with a \r\n."", 'Carbon-free giants\r\n‚Ä¢ Google, Microsoft, Meta/Facebook want to be carbon free by 2030 \r\n‚Ä¢ Carbon free is different from carbon neutral \r\n‚Ä¢ Green IT experts are needed to meet these goals\r\n23\r\n\r\n\r\nRebound effect*\r\n‚Ä¢ Energy consumption decreases ‚Üì‚Üì but demand also increases ‚Üë‚Üë. \r\n‚Ä¢ *a.k.a. Jevons Paradox in economics; Downs‚ÄìThomson paradox in\xa0mobility.\r\nEnergy per prompt\r\nPrompts\r\n100\r\n80\r\n30\r\n38\r\nChat \r\nGPT\r\n‚ÄúEnergy-efficient‚Äù \r\nChat GPT\r\n0\r\n\r\nIs sustainability an\u2028\r\nethical issue?\r\n‚Ä¢ Climate change is more likely to affect the \r\npoorest countries. \r\n‚Ä¢ Less financial resources to adapt \r\n‚Ä¢ Climate-impact does not necessarily affect \r\npolluting countries. \r\n‚Ä¢ Poorest countries have contributed less to the \r\nclimate change. \r\n‚Ä¢ We need to figure out how to do more using \r\nless resources.\r\n26\r\n\r\nMorality ‚â† Moralising\r\n‚Ä¢ We should not use climate action as a \r\nshaming weapon \r\n‚Ä¢ Climate action should be agnostic of political \r\nviews, ideology, social status, etc. \r\n‚Ä¢ We need everyone to take action!\r\n27\r\n\r\nWhy?\r\n‚Ä¢ Throughout your career you might: \r\n‚Ä¢ Design/maintain/contract data centers \r\n‚Ä¢ Set up operations/devops \r\n‚Ä¢ Develop AI for IoT devices \r\n‚Ä¢ Be the next CEO/CTO of a software company \r\n‚Ä¢ Sustainability can be your main role: \r\n‚Ä¢ Green Software Developer \r\n‚Ä¢ Sustainability Consultant \r\n‚Ä¢ Green Advocate  \r\n‚Ä¢ Founder of a Green Tech startup (B2B?)\r\n28\r\n\r\nFormat of classes\r\n‚Ä¢ In-person. \r\n‚Ä¢ Collegerama recordings. \r\n‚Ä¢ Lectures and Labs. \r\n‚Ä¢ Guest lectures. \r\n‚Ä¢ Steering meetings (after week 5, new schedule)\r\n29\r\n\r\nFormat of classes\r\n‚Ä¢ There‚Äôs no exam in this course. It‚Äôs more important that we learn how to \r\ndiscuss this topic and come up with new ideas than learning all the theory. \r\nCritical thinking over checkboxes. \r\n‚Ä¢ Mix of content and discussion \r\n‚Ä¢ Ultimately, the lectures aim to give you food for thought and the necessary \r\nknowledge to excel in Project 2. (We will talk about it later)\r\n30\r\n\r\nhttps://luiscruz.github.io/course_sustainableSE/\r\n31\r\nContent of the course üëá\r\n\r\n32\r\nhttps://mattermost.tudelft.nl/signup_user_complete/?id=1nj9tk6usjf8xmsws8wpq3s5uy&md=link&sbr=su\r\n\r\nProject 1\r\n‚Ä¢ Goal: Measure the energy consumption of software applications. \r\n‚Ä¢ Approach: energy measurement tools; use case testing. \r\n‚Ä¢ Deliverable: blog-style report (approx. 2500 words) \r\n‚Ä¢ Deadline: Week 3, Feb 28, 2025 \r\n‚Ä¢ Group size: 4‚Äì5\r\n33\r\n\r\nProject 2\r\n‚Ä¢ Goal: Create a solution/tool/technique that helps building green software. (You \r\ncan come up with your own idea or choose one from a list of suggestions). \r\n‚Ä¢ Approach: open-source software development; literature review. \r\n‚Ä¢ Deliverable: library/tool/app; paper; presentation. \r\n‚Ä¢ Two deadlines:\u2028\r\n1. Paper and software: Week 8, April 4, 2025\u2028\r\n2. Presentation: Week 9, April 11, 2025 \r\n‚Ä¢ Group size: 4‚Äì5\r\n34\r\n\r\nGuest Lectures\r\nNergis T√∂men \r\nComputer Vision lab | TU Delft \r\nWeek 4, Wed, Mar 5, 2025\r\n35\r\n\r\nCommunity \r\nHow to get involved?', 'Carolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nLu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\n1. Intro Class\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl\r\n\r\n1. Intro to Sustainable SE \r\n2. Intro to the course\r\n2\r\n\r\nof the electricity consumed worldwide \r\nby 2040 will stem from ICT\r\n14%\r\n\r\n4\r\nhttps://xkcd.com/1007/\r\n\r\nBuzz words\r\n‚Ä¢ Eco-friendly \r\n‚Ä¢ Climate change, action, adaption \r\n‚Ä¢ Energy efficiency \r\n‚Ä¢ Environmental-responsible \r\n‚Ä¢ Carbon-neutral; Climate-neutral; Net zero \r\n‚Ä¢ Carbon-offsetting \r\n‚Ä¢ Carbon-free \r\n‚Ä¢ Clean technology \r\n‚Ä¢ E-waste\r\n5\r\n\r\nhttps://www.menti.com/uns9d89kzn\r\nWhat is Sustainable \r\nSoftware Engineering?\r\n?\r\n6\r\n\r\nSustainable Software \r\nEngineering is‚Ä¶\r\n7\r\n‚Ä¶the discipline that studies the process of creating software systems that are able \r\nto create value in the long term without hindering its surrounding environment.\r\n\r\n8\r\nEconomical\r\nSocial\r\nTechnical\r\nIndividual\r\nEnvironmental\r\nSustainable\r\nSoftware\r\nEngineering\r\n‚≠ê\r\nTechnical\u2028\r\n‚öô\r\nEconomical\u2028\r\nüí∞\r\nSocial\u2028\r\nüë©üíºüë®üíºüë©üíºüë©üíº\r\nIndividual\u2028\r\nüë©üíª\r\nEnvironmental\u2028\r\nüå±\r\nSustainable\u2028\r\nSoftware \r\nEngineering\r\n\r\nEconomical\r\n‚Ä¢ Focused on assets, capital and added value\u2028\r\n(wealth creation, prosperity, profitability, capital \r\ninvestment, income, etc.) \r\n‚Ä¢ Nr of customers  \r\n‚Ä¢ Man-day-rate estimate \r\n‚Ä¢ Next round of funding \r\n‚Ä¢ Meet requirements in the contract\r\n9\r\n\r\nTechnical\r\n‚Ä¢ Longevity of information, systems, and infrastructure and their \r\nadequate evolution with changing surrounding conditions. \r\n‚Ä¢ Examples: \r\n‚Ä¢ Technical Debt \r\n‚Ä¢ Does it scale? \r\n‚Ä¢ Software testing \r\n‚Ä¢ Bus-factor \r\n‚Ä¢ Data integrity \r\n‚Ä¢ Innovation \r\n‚Ä¢ ‚Ä¶\r\n10\r\n\r\nIndividual\r\n‚Ä¢ Well-being of the individuals in an organisation.\u2028\r\nNote that it also includes how well individuals interact \r\nwith each other within the org. \r\n‚Ä¢ Examples: \r\n‚Ä¢ mental and physical well-being \r\n‚Ä¢ self-respect \r\n‚Ä¢ education/skills \r\n‚Ä¢ career development \r\n‚Ä¢ ‚Ä¶\r\n11\r\n\r\nSocial\r\n‚Ä¢ concerned with societal communities (groups of people, \r\norganisations) and the factors that erode trust in society. \r\n‚Ä¢ Examples: \r\n‚Ä¢ Social equity \r\n‚Ä¢ Justice \r\n‚Ä¢ Employment \r\n‚Ä¢ Democracy \r\n‚Ä¢ ‚Ä¶ \r\n‚Ä¢ Also includes compliance with policies and regulations \r\n12\r\n\r\nEnvironmental Sustainability\r\n‚Ä¢ the branch of Software Engineering that studies \r\nthe development of software that has minimal \r\nimpact in our planet throughout its whole \r\nlifecycle. \r\n‚Ä¢ Looking at software at different levels: \r\n‚Ä¢ Developing, Using, Serving, ‚Ä¶ \r\n‚Ä¢ Also includes e-waste. \r\n‚Ä¢ Almost identical to Green Software. (?)\r\n13\r\nBordallo II\r\n\r\nGreen Software\r\n‚Ä¢ Sustainability and energy efficiency. \r\n‚Ä¢ Building energy-efficient software is important also from a \r\ntechnical sustainability POV. \r\n‚Ä¢ Smartphones, smart wearables, IoT devices, etc. run on limited \r\npower resources. \r\n‚Ä¢ Developing software to these devices require energy-efficiency \r\ntesting and improvement. \r\n‚Ä¢ It also leads to environmental sustainability (e.g., less battery \r\ncycles) \r\n‚Ä¢ Important for UX (e.g., no need to walk around with power banks)\r\n14\r\n\r\nhttps://www.menti.com/uns9d89kzn\r\nWhat is the sustainability \r\ndimension you are most \r\ninterested in?\r\n?', '‚Ä¢ Comparing different programming languages is not an easy task. \r\n‚Ä¢ They differ in many mechanisms: \r\n‚Ä¢ Interpreted vs Compiled \r\n‚Ä¢ Optimisations at the compiler level \r\n‚Ä¢ Virtual machine \r\n‚Ä¢ Garbage collector \r\n‚Ä¢ Available libraries\r\n30\r\n\r\nResearch Questions\r\n‚Ä¢ Can we compare the energy efficiency of software languages?  \r\n‚Ä¢ Is the faster language always the most energy efficient? \r\n‚Ä¢ How does memory usage relate to energy consumption? (We don‚Äôt cover this one) \r\n‚Ä¢ Can we automatically decide what is the best programming language \r\nconsidering energy, time, and memory usage?  \r\n‚Ä¢ How do the results of our energy consumption analysis of programming \r\nlanguages gathered from rigorous performance benchmarking solutions \r\ncompare to results of average day-to-day solutions? \u2028\r\n31\r\n\r\nMethodology\r\n\r\nThe Computer Language Benchmarks Game \r\n‚Ä¢ https://benchmarksgame-team.pages.debian.net/benchmarksgame/\r\n33\r\n\r\nProblems in the Computer Language Benchmarks Game\r\n34\r\n\r\n‚Ä¢ 27 Programming languages across different paradigms  \r\n‚Ä¢ Functional (e.g., Ocaml, F#, Haskell) \r\n‚Ä¢ Imperative (e.g., C, Go, Python) \r\n‚Ä¢ Object-oriented (e.g., C++, C#, Java) \r\n‚Ä¢ Scripting (or interpretative) (e.g., JavaScript, Python, Ruby) \r\n‚Ä¢ (These are not mutual exclusive) \r\n‚Ä¢ Intel RAPL‚Äôs C library to measure energy consumption\r\n35\r\n\r\n‚Ä¢ Execute each benchmark solution 10 times. \r\n‚Ä¢ Collect energy data and timestamps. \r\n‚Ä¢ Two-minute interval between executions\r\n36\r\n\r\n\r\n\r\n\r\nCritical thinking\r\n‚Ä¢ There is no doubt this is an excellent study. Yet, as any excellent study, there‚Äôs \r\na lot we can discuss and criticise constructively. \r\n‚Ä¢ What kind of issues you see in drawing conclusions from such a table of \r\nresults? \r\n‚Ä¢ Is the benchmark representative of the most common usage behaviour? \r\n‚Ä¢ Are the implemented solutions representative? \r\n‚Ä¢ Does it make sense to use the average to compare energy consumption \r\nacross different problems? \r\n‚Ä¢ ‚Ä¶\r\n40\r\n\r\nReproducing with Rosetta Code \r\n‚Ä¢ Rosetta Code is a programming chrestomathy repository \r\n \r\n‚Ä¢ 900 usecases/tasks solved across 700 different programming languages \r\n‚Ä¢ Purpose: if you know a programming language we can easily learn how the \r\nsame task is solved in a language you are not familiar with.\r\n41\r\n(?)\r\n\r\n\r\n\r\nRevisiting Research Questions\r\n‚Ä¢ Can we compare the energy efficiency of software languages?  \r\n‚Ä¢ Is the faster language always the most energy efficient? \r\n‚Ä¢ How does memory usage relate to energy consumption?  \r\n‚Ä¢ Can we automatically decide what is the best programming language considering \r\nenergy, time, and memory usage?  \r\n‚Ä¢ How do the results of our energy consumption analysis of programming \r\nlanguages gathered from rigorous performance benchmarking solutions \r\ncompare to results of average day-to-day solutions?  \r\n‚Ä¢ What would happen if we cherry picked the tasks?\u2028\r\n44\r\n\r\n\r\nLu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\n3. Scientific Guide for Reliable \r\nEnergy Experiments\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nCarolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl', 'p-value = 0.04\r\nOn average, version B spent less energy than version A  ‚Äî  ‚úÖ \r\nThere is statistical significance ‚Äî  ‚úÖ \r\nEffect size, percent-change is ‚âà1% ‚Äî ü§î \r\n‚ö† Do we care?\r\n(?)\r\n\r\nPractical Significance\r\n‚Ä¢ Depending on the case, a 2% improvement might be either wonderful or completely \r\nuseless. \r\n‚Ä¢ Effect size analyses help assess practical significance but might not be enough. \r\n‚Ä¢ A critical discussion always needs to be performed. Consider context and explain in what \r\nsense the effect size might be relevant. \r\n‚Ä¢ E.g.: \r\n‚Ä¢  to improve 2% in energy efficiency the code will be less readable or the user \r\nexperience is not so appealing. \r\n‚Ä¢ A particular method improves 2% but it will only be used 1% of the time. \r\n‚Ä¢ There is no particular metric or structure, but this kind of critical analysis is very important.\r\n25\r\n\r\nWhat if data is not Normal?\r\nSame approach but different tests/metrics!\r\n\r\nNon-normal data\r\n‚Ä¢ Statistical significance: non-parametric test (?) \r\n‚Ä¢ Mann-Whitney U test. Instead of looking at standard deviation or mean, it orders \r\nsamples and compares with each other. \r\n‚Ä¢ Less power than parametric-tests (?) \r\n‚Ä¢ Effect size \r\n‚Ä¢ Median difference: \r\n \r\n‚Ä¢ Percentage of pairs supporting a conclusion\u2028\r\n(i.e., # pairs where version A > version B/ total pairs) \r\n‚Ä¢ Common language effect size: \r\nŒîM\r\nU1\r\nN1N2\r\n27\r\n\r\nRecap\r\nImpossible to \r\nfix but \r\nexplainable.\r\n\r\nEnergy Efficiency Across \r\nProgramming Languages\r\nhttps://sites.google.com/view/energy-efficiency-languages\r\n29\r\nRui Pereira, Marco Couto, Francisco Ribeiro, Rui Rua, J√°come \r\nCunha, Jo√£o Paulo Fernandes, and Jo√£o Saraiva\r\n\r\n‚Ä¢ Is a faster programming language also more energy efficient? \r\n‚Ä¢ Comparing different programming languages is not an easy task. \r\n‚Ä¢ They differ in many mechanisms: \r\n‚Ä¢ Interpreted vs Compiled \r\n‚Ä¢ Optimisations at the compiler level \r\n‚Ä¢ Virtual machine \r\n‚Ä¢ Garbage collector \r\n‚Ä¢ Available libraries\r\n30\r\n\r\nResearch Questions\r\n‚Ä¢ Can we compare the energy efficiency of software languages?  \r\n‚Ä¢ Is the faster language always the most energy efficient? \r\n‚Ä¢ How does memory usage relate to energy consumption? (We don‚Äôt cover this one) \r\n‚Ä¢ Can we automatically decide what is the best programming language \r\nconsidering energy, time, and memory usage?  \r\n‚Ä¢ How do the results of our energy consumption analysis of programming \r\nlanguages gathered from rigorous performance benchmarking solutions \r\ncompare to results of average day-to-day solutions? \u2028\r\n31\r\n\r\nMethodology\r\n\r\nThe Computer Language Benchmarks Game \r\n‚Ä¢ https://benchmarksgame-team.pages.debian.net/benchmarksgame/\r\n33\r\n\r\nProblems in the Computer Language Benchmarks Game\r\n34\r\n\r\n‚Ä¢ 27 Programming languages across different paradigms  \r\n‚Ä¢ Functional (e.g., Ocaml, F#, Haskell) \r\n‚Ä¢ Imperative (e.g., C, Go, Python) \r\n‚Ä¢ Object-oriented (e.g., C++, C#, Java) \r\n‚Ä¢ Scripting (or interpretative) (e.g., JavaScript, Python, Ruby) \r\n‚Ä¢ (These are not mutual exclusive) \r\n‚Ä¢ Intel RAPL‚Äôs C library to measure energy consumption\r\n35\r\n\r\n‚Ä¢ Execute each benchmark solution 10 times. \r\n‚Ä¢ Collect energy data and timestamps. \r\n‚Ä¢ Two-minute interval between executions\r\n36\r\n\r\n\r\n\r\n\r\nCritical thinking\r\n‚Ä¢ There is no doubt this is an excellent study. Yet, as any excellent study, there‚Äôs \r\na lot we can discuss and criticise constructively. \r\n‚Ä¢ What kind of issues you see in drawing conclusions from such a table of \r\nresults?', '‚Ä¢ In a scientific project, the magic number is 30.\r\n7\r\n\r\n\r\nRest ‚è∏\r\n‚Ä¢ It is common practice to do a pause/sleep between executions/\r\nmeasurements. \r\n‚Ä¢ Prevent tail energy consumption from previous measurements. ? \r\n‚Ä¢ Prevent collateral tasks of previous measurement from affecting the next \r\nmeasurement. \r\n‚Ä¢ There is no golden rule but one minute should be enough. It can be more or \r\nless depending on your hardware or the duration of your energy test.\r\n9\r\n\r\nt\r\nP\r\nTail Energy Consumption\r\n\r\nShuffle üîÄ\r\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \r\nit is impossible to control all of them. \r\n‚Ä¢ If you run 30 executions for version A and another batch for version B: \r\n‚Ä¢ External conditions that change over time will have a different bias in \r\nthe 2 versions (e.g., room temperature changes). \r\n‚Ä¢ If you shuffle, you reduce this risk.\r\n11\r\n\r\nKeep it cool üå°\r\n‚Ä¢ Always make sure there is a stable room temperature. \r\n‚Ä¢ Tricky because, some times, experiments may have to run over a few days. \r\n‚Ä¢ If you cannot control room temperature: collect temperature data and filter \r\nout measurements where the room temperature is clearly deviating.\r\n12\r\n\r\nAutomate Executions ü§ñ\r\n‚Ä¢ (Already mentioned in the previous classes) \r\n‚Ä¢ One cannot run 30 shuffled experiments per version without automation‚Ä¶\r\n13\r\n\r\nData analysis\r\n14\r\n\r\n1. Exploratory Analysis\r\n‚Ä¢ Plot the data and inspect outliers or \r\nunexpected biases. \r\n‚Ä¢ Violin+box plots are usually handy. (?) \r\n‚Ä¢ It‚Äôs a nice way of combining the 30 \r\nexperiments, and of showing \r\ndescriptive statistics. (?) \r\n‚Ä¢ Shows the shape of the distribution \r\nof the data.\r\n15\r\n\r\n1. Exploratory Analysis (II)\r\n‚Ä¢ Data should be Normal. Unless there‚Äôs a \r\ngood reason. \r\n‚Ä¢ E.g., somewhere amongst the 30 executions, \r\nthere might be 1 or 2 that failed to finish due \r\nto some unexpected error. \r\n‚Ä¢ (It happens and that‚Äôs ok!)‚Äì consequently, \r\nthe execution is shorter and spends less \r\nenergy ‚Äì falsely appearing as more \r\nenergy efficient. \r\n‚Ä¢ If data is not Normal there might be some \r\nissues affecting the measurements that \r\nmight be ruining results. It is important to \r\ninvestigate this.\r\n16\r\n\r\nEnergy data is not normal. Why?\r\n‚Ä¢ It might be caused by one of the following reasons: \r\n‚Ä¢ There was an error in some of the executions. If not detected and fixed it \r\nmight ruin results. \r\n‚Ä¢ Your tests are not fully replicable or are not deterministic. Quite frequent \r\nwhen you have internet requests or random-based algorithms. \r\n‚Ä¢ There is an unusual task being run by the system during some experiments. \r\n‚Ä¢ The computer entered a different power mode. \r\n‚Ä¢ External physical conditions have changed. E.g., someone opened a \r\nwindow.\r\n17\r\n\r\nEnergy data is not normal. How to fix?\r\n‚Ä¢ We have 2+1 options: \r\n1. Remove outliers. If there are only a few points that deviate from the normal \r\ndistribution, it is okay to simply remove them. \r\n‚Ä¢ Use the z-score outlier removal. (?) \r\n‚Ä¢ Remove all data points that deviate from the mean more than 3 standard \r\ndeviations: \r\n \r\n2. Fix the issue and rerun experiments. \r\n3. Conclude that nothing can be done about it and data will never be normal. (e.g., \r\nin AI, executions are rarely deterministic). ‚ö† Only after ruling out the previous \r\npoints.\r\n| ¬Øx ‚àíx| > 3s\r\n18\r\n\r\nHow do we know whether data is Normal?']","['<1-hop>\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy eÔ¨Éciency using static code analysis.\n‚Ä¢ We don‚Äôt need an accurate value.\n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.\n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27', '<2-hop>\n\nWhy?\n‚Ä¢ Throughout your career you might:\n‚Ä¢ Design/maintain/contract data centers\n‚Ä¢ Set up operations/devops\n‚Ä¢ Develop AI for IoT devices\n‚Ä¢ Be the next CEO/CTO of a software company\n‚Ä¢ Sustainability can be your main role:\n‚Ä¢ Green Software Developer\n‚Ä¢ Sustainability Consultant\n‚Ä¢ Green Advocate \n‚Ä¢ Founder of a Green Tech startup (B2B?)\n28']","Static code analysis in data science can contribute to the development of more sustainable data centers by identifying and optimizing code that may lead to energy inefficiencies. By using static code analysis tools, developers can estimate energy efficiency and pinpoint code segments that are likely to introduce energy hotspots. This allows for targeted code reviews and optimizations, which can reduce the overall energy consumption of software running in data centers. This approach aligns with the ""Green Shift Left"" strategy, which emphasizes early detection and correction of potential energy inefficiencies in the software development lifecycle. By improving the energy efficiency of software, data centers can operate more sustainably, reducing their carbon footprint and energy costs.","Static code analysis in data science can contribute to the development of more sustainable data centers by estimating energy efficiency and identifying potential energy hotspots within the code. This approach allows developers to focus on reviewing code segments that are more likely to introduce inefficiencies, thereby optimizing resource usage. By integrating such practices, especially in domains like data science, developers can help create more sustainable solutions, which aligns with broader career goals in sustainability, such as designing or maintaining energy-efficient data centers.",0.5740384615269807,1.0,1.0,0.89,,0.986006221560618
How can static code analysis in data science projects help in designing more sustainablility-focused data centers?,"['Interviews?) & rich \r\ndescription of outcomes focus of grading\r\nhttps://eip.pages.ewi.tudelft.nl/eip-website/queue.html\r\n\r\nC1. Compare energy consumption of docker images for \r\nML workloads.\r\n‚Ä¢ Similar to what we have seen in the lectures but for ML-specific workloads. \r\n‚Ä¢ We can reuse existing experiment replication packages.\r\n22\r\n\r\nC2. Plugin to visualize Hugging Face carbon emissions.\r\n‚Ä¢ https://huggingface.co/blog/leaderboard-emissions-\r\nanalysis \r\n‚Ä¢\r\nYoo, Taewon, et al. ""Visualizing the Carbon Intensity of Machine Learning Inference for Image Analysis on TensorFlow Hub.""\r\n\r\nC3. Plugin for ChatGPT\r\n‚Ä¢ Users seldom know how much carbon they are emitting when they interact \r\nwith chat GPT. \r\n‚Ä¢ Let‚Äôs make it transparent to the users. Browser plugin?\r\n24\r\nCO2\r\n\r\nC4. NutriScore for software libraries\r\n25\r\n‚Ä¢ NutriScore labels are not perfect but they are a good starting point! \r\n‚Ä¢ What if we could do the same thing for the energy efficiency of software. \r\n‚Ä¢ (Also open to individual or social sustainability) \r\n‚Ä¢ This work can be scoped in particular domains/ecossystems/use cases. \r\n‚Ä¢ Libraries for stats? ML? Web Dev? Cloud?\r\n\r\nC5. Add energy-awareness to existing software\r\n26\r\n‚Ä¢ Streamlit, Notebooks, JSFiddle, \r\nPyScript, zsh, etc. \r\n‚Ä¢\r\n\r\nC6 - Green Shift Left\r\n‚Ä¢ Estimate energy efficiency using static code analysis. \r\n‚Ä¢ We don‚Äôt need an accurate value. \r\n‚Ä¢ It is useful to know which code is more likely to \r\nintroduce energy hotspots and that should be \r\nreviewed with more attention. \r\n‚Ä¢ Can be scoped to a particular domain (react, php, data \r\nscience, web, etc., etc.)\r\n27\r\n\r\nC7 - Education\r\n‚Ä¢ Educational game for Software \r\nSustainability practices \r\n‚Ä¢ Purpose: use within software teams to \r\ndiscuss or learn about different sustainable \r\nIT practices: at the organisation level, \r\nsoftware, etc.\r\n28\r\nhttps://github.com/OttoKaaij/Ticket-To-Sustainability/?tab=readme-ov-file\r\n\r\nProject ideas (old)\r\n‚Ä¢ Plugin from EnergiBridge (GUI, report generator, python library, etc.) \r\n‚Ä¢ Plugin for ChatGPT (carbon emissions per chat window) \r\n‚Ä¢ Seamless measurements for AI libraries \r\n‚Ä¢ Energy patterns for Green AI \r\n‚Ä¢ Sustainable SW dev gamification \r\n‚Ä¢ Sustainability auditor for AI projects \r\n‚Ä¢ Energy Profiling of screen colour filter tools (or display settings) \r\n‚Ä¢ ‚Ä¶ you can also propose yours!\r\n\r\nhttps://edu.nl/64gpk\r\nedu.nl/64gpk', 'Energy profiling of static analysis tools\r\n‚Ä¢ What is the energy consumption of a ""typical run"" for a few OSS projects? \r\n‚Ä¢ Does the type of analysis matter? Are certain analysis more expensive? Does \r\nthe number of rules that are activated in a static analysis tool important for the \r\nenergy consumption? \r\n‚Ä¢ Differences between static analysis tools [lower priority]\r\n\r\nB5. Tool supporting SusAF workshop / process\r\n‚Ä¢ Lead engineers through process & questions \r\n‚Ä¢ Interface to create & document the two diagrams \r\n‚Ä¢ (!) Should be easy to start using & set up \r\n‚Ä¢ You may also create a simplified version / \u2028\r\nyour favorite sustainability framework\r\nEnvironmental\r\nEconomic\r\nTechnical\r\nIndividual\r\nSocial\r\nImmediate\r\nEnabling\r\nStructural\r\nAirbnb\r\ngreater \r\nearnings\r\nincrease \r\nin rents\r\ngentrification\r\ngreater racial \r\ndisparities\r\nrent \r\nrooms\r\n5\r\n1\r\n3\r\n4\r\n2\r\n \r\n \r\n \r\n \r\n \r\n \r\nVery \r\nunlikely \r\nVery \r\nlikely \r\n\r\nB6. Dataset of government-developed OS software\r\n‚Ä¢ Governments develop & use software for supporting society\u2028\r\nOpen-source development & policies are on the rise \r\n‚Ä¢ But studying government software is difficult b/c we don‚Äôt know what is out \r\nthere\u2028\r\n‚Üí Lack of incentive to make popular \u2028\r\n‚Üí Language barriers \r\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \r\nbuildable?, open dev. history?, requirements documentation? \r\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!\r\n\r\nB7. Queue - but better for the student / TA society\r\n‚Ä¢ Requirements analysis regarding social and individual sustainability effects \r\nof Queue \r\n‚Ä¢ Other EIP / TUD used software also possible: e.g., Answers EWI \r\n‚Ä¢ Non-technical project ‚Üí proper process (workshops? Interviews?) & rich \r\ndescription of outcomes focus of grading\r\nhttps://eip.pages.ewi.tudelft.nl/eip-website/queue.html\r\n\r\nC1. Compare energy consumption of docker images for \r\nML workloads.\r\n‚Ä¢ Similar to what we have seen in the lectures but for ML-specific workloads. \r\n‚Ä¢ We can reuse existing experiment replication packages.\r\n22\r\n\r\nC2. Plugin to visualize Hugging Face carbon emissions.\r\n‚Ä¢ https://huggingface.co/blog/leaderboard-emissions-\r\nanalysis \r\n‚Ä¢\r\nYoo, Taewon, et al. ""Visualizing the Carbon Intensity of Machine Learning Inference for Image Analysis on TensorFlow Hub.""\r\n\r\nC3. Plugin for ChatGPT\r\n‚Ä¢ Users seldom know how much carbon they are emitting when they interact \r\nwith chat GPT. \r\n‚Ä¢ Let‚Äôs make it transparent to the users. Browser plugin?\r\n24\r\nCO2\r\n\r\nC4. NutriScore for software libraries\r\n25\r\n‚Ä¢ NutriScore labels are not perfect but they are a good starting point! \r\n‚Ä¢ What if we could do the same thing for the energy efficiency of software. \r\n‚Ä¢ (Also open to individual or social sustainability) \r\n‚Ä¢ This work can be scoped in particular domains/ecossystems/use cases. \r\n‚Ä¢ Libraries for stats? ML? Web Dev? Cloud?\r\n\r\nC5. Add energy-awareness to existing software\r\n26\r\n‚Ä¢ Streamlit, Notebooks, JSFiddle, \r\nPyScript, zsh, etc. \r\n‚Ä¢\r\n\r\nC6 - Green Shift Left\r\n‚Ä¢ Estimate energy efficiency using static code analysis. \r\n‚Ä¢ We don‚Äôt need an accurate value. \r\n‚Ä¢ It is useful to know which code is more likely to \r\nintroduce energy hotspots and that should be \r\nreviewed with more attention. \r\n‚Ä¢ Can be scoped to a particular domain (react, php, data \r\nscience, web, etc., etc.)', '‚Ä¢RQ3: Can we verify the \r\norigin of energy \r\nconsumption differences by \r\nrecreating the workload \r\nbehavior closely?\r\n37\r\n\r\nTracing\r\n‚Ä¢ Find libc function running at the end of the benchmark \r\n‚Ä¢ Tracing: Capture calls made to libc \r\n‚Ä¢ Introduces non-linear overhead\r\n38\r\n\r\nSynchronization\r\n‚Ä¢ Tracing slows down execution and increase energy consumption \r\n‚Ä¢ Run separately and synchronize with logs\r\n39\r\n\r\nTracing Analysis\r\n40\r\n\r\nTracing Analysis\r\n41\r\n\r\nBenchmarking memcpy\r\n‚Ä¢ Copy bytes from one part of memory to \r\nanother \r\n‚Ä¢ Depending on function parameters, different \r\nassembly-level optimizations \r\n‚Ä¢ Some not included in musl\r\n42\r\n\r\nBenchmarking memcpy\r\n‚Ä¢ Copy 4 bytes from fixed \r\npointer to moving pointer \r\n‚Ä¢ (100,300,500,600) x 1M \r\nrequests \r\n‚Ä¢  15% more power and 3X time\r\n43\r\n\r\nConclusions\r\n‚Ä¢ Significant difference in energy consumption for memcpy \r\n‚Ä¢ 8.6% difference for Redis workload and 13% in our benchmark \r\n‚Ä¢ musl trades performance for a smaller codebase \r\n‚Ä¢ No official documentation \r\n‚Ä¢ No awareness about energy performance\r\n44\r\n\r\n5. Energy Efficiency vs Code \r\nQuality\r\n\r\nMeasuring Maintainability\r\n‚Ä¢ According to ISO/IEC 25010, Maintainability is ‚Äúthe degree of \r\neffectiveness and efficiency with which a software product or \r\nsystem can be modified to improve it, correct it or adapt it to \r\nchanges in environment, and in requirements‚Äù \r\n‚Ä¢ We use the code analysis tool Better Code Hub to assess \r\nmaintainability \r\n‚Ä¢ Better Code Hub maps the ISO/IEC 25010 standard on \r\nmaintainability into a set of guidelines derived from static analysis\r\n46\r\n\r\nMaintainability of Energy Changes\r\n‚Ä¢ What is the impact of making energy-oriented code changes on \r\nthe maintainability of mobile apps? \r\nMaintainability \r\nDifference \r\nvE-2\r\nvE-1\r\nvE\r\nEnergy \r\nCommit\r\nvE+1\r\nM(vE-1)\r\nM(vE)\r\nParent \r\nCommit\r\n‚àÜM\r\n47\r\n\r\nThreshold Marks\r\n48\r\n\r\nBetter Code Hub\r\nMaintainability\r\nCombine\r\ndatasets\r\nEnergy\r\nCommits\r\nBaseline\r\nCommits\r\nBao et al. \r\n(2015)\r\nMoura et al. \r\n(2016)\r\nCruz et al. \r\n(2018)\r\nCruz et al. \r\n(2019)\r\nEnergy Code Changes \r\nDataset\r\n539 commits\u2028\r\nfrom 306 mobile apps\r\n539 baseline commits\u2028\r\nfrom 306 mobile apps\r\n49\r\n\r\nImpact of energy changes on \r\nmaintainability\r\n50\r\n\r\nWhich energy \r\npatterns are more \r\nlikely to affect \r\nmaintainability?\r\n51\r\n\r\nTypical maintainability issue I\r\nhttps://github.com/einmalfel/PodListen/commit/2ed5a65\r\n4 changed files with 28 additions and 0 deletions.\r\n‚Ä¶\r\n‚Ä¶\r\n52\r\n\r\nTypical maintainability issue II\r\nhttps://github.com/mozilla/MozStumbler/commit/6ea0268\r\n5 changed files with 66 additions and 14 deletions.\r\n53\r\n\r\n54', '‚Ä¢ By using money cost instead of carbon cost, they have more data available.\r\n26\r\n\r\nVirtual Cluster Capacity (VCC)\r\n‚Ä¢ If the forecast of VCC fails it shift flexible workload more than expected.  \r\n‚Ä¢ This happens because the amount of workload forecasted was below the \r\nworkload needed, and VCC was ‚Äúaggressively‚Äù low. \r\n‚Ä¢ The systems fall back to the real cluster capacity for 1 week until results \r\nstart being realistic again.\r\n27\r\n\r\nNext steps\r\n‚Ä¢ They will consider spatial flexibility. \r\n‚Ä¢ I.e., tasks that can be shifted over time and over space. \r\n‚Ä¢ It needs to factor in relocation overheads, though.\r\n28\r\n\r\nCritical questions\r\n‚Ä¢ Who defines what is flexible and inflexible? \r\n‚Ä¢ How do you estimate the CPU load of a given task?\r\n29\r\n\r\nEnergy Regression Testing\r\n‚ÜíEnergy?\r\nGreener? Greener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\n\r\nE-compare\r\nGithub Actions\r\n‚ûú https://koenhagen.github.io/E-Compare/\r\n\r\nEnergy Regression Testing \r\n\r\n4. Debugging Energy with \r\nDocker Images\r\n\r\nUnveiling the Energy Vampires \r\nA methodology for debugging Software \r\nEnergy Consumption\r\n ‚úÖ ICSE 2025\r\n\r\nData Centers and Docker\r\n‚Ä¢ Containers are the most popular way to deploy apps into the cloud \r\n‚Ä¢ Base image is an important choice when building an image \r\n‚Ä¢ Criteria \r\n‚Ä¢ Linux distribution and binaries \r\n‚Ä¢ Image size \r\n‚Ä¢ Energy?\r\n35\r\n\r\nRedis energy consumption\r\n‚Ä¢ Ubuntu/Alpine base images have different energy consumption for Redis\r\n36\r\n\r\nRedis Energy Consumption\r\n‚Ä¢RQ1: What is the difference \r\nin energy consumption \r\nbetween glibc and musl? \r\n‚Ä¢RQ2: Can we use tracing \r\nto compare energy \r\nconsumption in shared \r\nlibraries? \r\n‚Ä¢RQ3: Can we verify the \r\norigin of energy \r\nconsumption differences by \r\nrecreating the workload \r\nbehavior closely?\r\n37\r\n\r\nTracing\r\n‚Ä¢ Find libc function running at the end of the benchmark \r\n‚Ä¢ Tracing: Capture calls made to libc \r\n‚Ä¢ Introduces non-linear overhead\r\n38\r\n\r\nSynchronization\r\n‚Ä¢ Tracing slows down execution and increase energy consumption \r\n‚Ä¢ Run separately and synchronize with logs\r\n39\r\n\r\nTracing Analysis\r\n40\r\n\r\nTracing Analysis\r\n41\r\n\r\nBenchmarking memcpy\r\n‚Ä¢ Copy bytes from one part of memory to \r\nanother \r\n‚Ä¢ Depending on function parameters, different \r\nassembly-level optimizations \r\n‚Ä¢ Some not included in musl\r\n42\r\n\r\nBenchmarking memcpy\r\n‚Ä¢ Copy 4 bytes from fixed \r\npointer to moving pointer \r\n‚Ä¢ (100,300,500,600) x 1M \r\nrequests \r\n‚Ä¢  15% more power and 3X time\r\n43\r\n\r\nConclusions\r\n‚Ä¢ Significant difference in energy consumption for memcpy \r\n‚Ä¢ 8.6% difference for Redis workload and 13% in our benchmark \r\n‚Ä¢ musl trades performance for a smaller codebase \r\n‚Ä¢ No official documentation \r\n‚Ä¢ No awareness about energy performance\r\n44\r\n\r\n5. Energy Efficiency vs Code \r\nQuality\r\n\r\nMeasuring Maintainability\r\n‚Ä¢ According to ISO/IEC 25010, Maintainability is ‚Äúthe degree of \r\neffectiveness and efficiency with which a software product or \r\nsystem can be modified to improve it, correct it or adapt it to \r\nchanges in environment, and in requirements‚Äù \r\n‚Ä¢ We use the code analysis tool Better Code Hub to assess \r\nmaintainability \r\n‚Ä¢ Better Code Hub maps the ISO/IEC 25010 standard on \r\nmaintainability into a set of guidelines derived from static analysis\r\n46\r\n\r\nMaintainability of Energy Changes\r\n‚Ä¢ What is the impact of making energy-oriented code changes on \r\nthe maintainability of mobile apps?', '‚Ä¢ Deadline April 4.\r\n6\r\n\r\nStrategy\r\n‚Ä¢ Week 0 \r\n‚Ä¢ Decide project idea (today) \r\n‚Ä¢ Define steering meeting schedule \r\n‚Ä¢ Create working document of the \r\narticle: Problem statement and solution \r\nproposal! \r\n‚Ä¢ Define and assign tasks for each week. \r\n‚Ä¢ Week 1 \r\n‚Ä¢ Implementation \r\n‚Ä¢ Agreements with supervisor. \r\n‚Ä¢ Week 2 \r\n‚Ä¢ Implementation \r\n‚Ä¢ Week 3 \r\n‚Ä¢ Implementation, Full draft of article, \r\ndissemination. \r\n‚Ä¢ Week 4 \r\n‚Ä¢ Final refinements \r\n‚Ä¢ Prepare presentation\r\n7\r\n\r\nProject ideas\r\n‚Ä¢ A1. Prototype cross-machine comparable benchmarks \r\n‚Ä¢ A2. Add energy metrics to LMstudio/Ollama \r\n‚Ä¢ A3. Visualizations built-in with EnergiBridge \r\n‚Ä¢ A4. Service-based version of EnergiBridge\r\n\r\nProject ideas\r\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \r\n‚Ä¢ B2. Study test generation energy consumption \r\n‚Ä¢ B3. Energy profiling of static analysis tools \r\n‚Ä¢ B4. Detailed energy profiling of build pipelines \r\n‚Ä¢ B5. Tool supporting SusAF workshop / process \r\n‚Ä¢ B6. Dataset of government-developed OS software \r\n‚Ä¢ B7. Queue - but better for the student / TA society\r\nQuality Assurance & Testing\r\nSocial & Individual \u2028\r\nSustainability\r\n\r\nProject ideas\r\n‚Ä¢ C1. Compare energy consumption of docker images for ML workloads. \r\n‚Ä¢ C2. Create a plugin to visualize Hugging Face carbon emissions in detail. \r\n‚Ä¢ C3. Plugin for ChatGPT (footprint per chat window) \r\n‚Ä¢ C4. NutriScore for software libraries. \r\n‚Ä¢ C5. Add energy-awareness to existing software \r\n‚Ä¢ C6. Green Shift Left \r\n‚Ä¢ C7. Education for Sustainable SE\r\n\r\nA1. Prototype cross-machine comparable benchmarks\r\n‚Ä¢ Energy-usage comparisons require running both baseline + software on the \r\nsame machine ‚Üí limits how extensive our experiments can be \r\n‚Ä¢ Research community is in need of benchmarks that make energy \r\nmeasurements comparable even if executed on different machines \r\n‚Ä¢ Focus on a single task or model (i.e. computing vision, classification)\r\n\r\nA2. Adding energy metrics to LMstudio/Ollama\r\n‚Ä¢ Make energy consumption visible to users \r\nwithin local chat-interface for LLMs \r\n‚Ä¢ LMstudio/Ollama are tools for easy \r\ndeployment of LLMs \r\n‚Ä¢ Do not show energy metrics \r\n‚Ä¢ Add energy metrics to LMstudio-python \r\nor Ollama\r\nhttps://lmstudio.ai/\r\n\r\nA3. Visualizations built-in with EnergiBridge\r\n‚Ä¢ EnergiBridge simplifies energy measurement, but analysis & visualization is \r\nstill left to the user \r\n‚Ä¢ Extend the tool with well-chosen visualizations and analyses directly from the \r\nprovided data\r\n\r\nA4. Service-based version of EnergiBridge\r\n‚Ä¢ Simplify interaction & setup with EnergiBridge \r\n‚Ä¢ Service that runs independently, start/stop signals over RPC to manage \r\nexperiments \r\n‚Ä¢ Potential: create EnergiBridge interface for other prog. lang\r\n\r\nB1. Measure energy consumption of single JUnit tests\r\n‚Ä¢ We‚Äôd like to identify energy anti patterns in unit tests \r\n‚Ä¢ As a first step, we need tooling to measure and compare the energy \r\nconsumption of single unit tests \r\n‚Ä¢ Ideally including preliminary analysis looking at potential reasons for high-\r\nenergy-consuming tests\r\n\r\nB2. Study test generation energy consumption\r\n‚Ä¢ Automatic test generation mainly focuses on making strong test suites \r\n‚Ä¢ Do different techniques and configurations impact the energy consumption \r\nduring generation? \r\n‚Ä¢ Preferably focus on non-LLM test generation methods (EvoSuite, Pyguin, \r\nDSpot)\r\n\r\nB3. Detailed energy profiling of build pipelines\r\n‚Ä¢ Automatic builds have become a cornerstone of quality assurance.', 'google.com/view/energy-efficiency-languages\r\n21\r\nAna Radovanovic ÃÅ, Ross Koningstein, Ian Schneider, Bokan \r\nChen, Alexandre Duarte, Binz Roy, Diyue Xiao, Maya \r\nHaridasan, Patrick Hung, Nick Care, Saurav Talukdar, Eric \r\nMullen, Kendal Smith, MariEllen Cottman, and Walfredo Cirne \r\n\r\n\r\n‚Ä¢ Google‚Äôs Carbon-Intelligent Computing System (CICS) \r\n‚Ä¢ Main idea: use carbon-intensity data to shift datacenter jobs in time \r\n‚Ä¢ Typically, job schedulers use a metric of cluster capacity to schedule a job in \r\na particular cluster. \r\n‚Ä¢ CICS overrides this metric with the virtual capacity curve (VCC) that \r\nfactors in Carbon intensity \r\n‚Ä¢ When a new job comes in, the scheduler estimates its CPU load and power \r\nusage and assigns it to a cluster if the VCC is not exceeded.\r\n23\r\n\r\n‚Ä¢ Jobs are divided between flexible and inflexible. \r\n‚Ä¢ Flexible load is considered shapeable/shiftable as long as its total daily \r\ncompute (CPU) demand is preserved \r\n‚Ä¢ The system needs to consider that, while running a job, the virtual capacity \r\ncurve (VCC) might drop. Hence, this job should not start in the first place. \r\n‚Ä¢ They forecast VCC for the next day\r\n24\r\n\r\n\r\nVirtual Cluster Capacity (VCC)\r\n‚Ä¢ Aims at reducing the peak load at carbon intensive hours but in total it should allow for the \r\nsome amount of daily computation! \r\n‚Ä¢ Considers Carbon intensity \r\n‚Ä¢ Using data from electricityMap.org \r\n‚Ä¢ It does not use carbon intensity directly.\u2028\r\nCarbon intensity is converted to a cost (kgCO2 -> $$) \r\n‚Ä¢ This way, they can factor in other metrics that can also be converted to money. E.g., the \r\ncost saved by preventing peak load \r\n‚Ä¢ Peak workload entails extra cost at the infrastructure level (e.g., control faclities‚Äô \r\ntemperature). \r\n‚Ä¢ By using money cost instead of carbon cost, they have more data available.\r\n26\r\n\r\nVirtual Cluster Capacity (VCC)\r\n‚Ä¢ If the forecast of VCC fails it shift flexible workload more than expected.  \r\n‚Ä¢ This happens because the amount of workload forecasted was below the \r\nworkload needed, and VCC was ‚Äúaggressively‚Äù low. \r\n‚Ä¢ The systems fall back to the real cluster capacity for 1 week until results \r\nstart being realistic again.\r\n27\r\n\r\nNext steps\r\n‚Ä¢ They will consider spatial flexibility. \r\n‚Ä¢ I.e., tasks that can be shifted over time and over space. \r\n‚Ä¢ It needs to factor in relocation overheads, though.\r\n28\r\n\r\nCritical questions\r\n‚Ä¢ Who defines what is flexible and inflexible? \r\n‚Ä¢ How do you estimate the CPU load of a given task?\r\n29\r\n\r\nEnergy Regression Testing\r\n‚ÜíEnergy?\r\nGreener? Greener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\n\r\nE-compare\r\nGithub Actions\r\n‚ûú https://koenhagen.github.io/E-Compare/\r\n\r\nEnergy Regression Testing \r\n\r\n4. Debugging Energy with \r\nDocker Images\r\n\r\nUnveiling the Energy Vampires \r\nA methodology for debugging Software \r\nEnergy Consumption\r\n ‚úÖ ICSE 2025\r\n\r\nData Centers and Docker\r\n‚Ä¢ Containers are the most popular way to deploy apps into the cloud \r\n‚Ä¢ Base image is an important choice when building an image \r\n‚Ä¢ Criteria \r\n‚Ä¢ Linux distribution and binaries \r\n‚Ä¢ Image size \r\n‚Ä¢ Energy?\r\n35\r\n\r\nRedis energy consumption\r\n‚Ä¢ Ubuntu/Alpine base images have different energy consumption for Redis\r\n36\r\n\r\nRedis Energy Consumption\r\n‚Ä¢RQ1: What is the difference \r\nin energy consumption \r\nbetween glibc and musl? \r\n‚Ä¢RQ2: Can we use tracing \r\nto compare energy \r\nconsumption in shared \r\nlibraries?', 'Lu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\n10. Project 2\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nCarolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl\r\n\r\n1. Goal/assignment \r\n2. Deliverables \r\n3. Strategy \r\n4. Ideas\r\n\r\nAssignment\r\n‚Ä¢ Goal: Solve a Sustainable Software Engineering problem. \r\n‚Ä¢ Identify 1 problem that should be fixed to help enabling sustainability in \r\nthe software engineering industry/community. \r\n‚Ä¢ Propose a solution. A tool, framework, guidelines, etc. \r\n‚Ä¢ Implementation. \r\n‚Ä¢ Validation. (Depending on the idea) \r\n‚Ä¢ Dissemination/social impact. (Solution should be open source, welcome \r\ncontributors, post on social media? Tool website? Available in a package \r\nmanager?)\r\n3\r\n\r\nDeliverables\r\n‚Ä¢ Paper-like article. (Min 4 pages, max 10) \r\n‚Ä¢ Online git repo with open source codebase and/or replication package. \r\n‚Ä¢ Presentation: 5 min + 5min Q&A\r\n4\r\n\r\nArticle\r\n‚Ä¢ Different projects will have different expectations -> Make agreements with \r\nyour coach. \r\n‚Ä¢ Some projects are more technical and some projects more theoretical. \r\n‚Ä¢ Common requirements: \r\n‚Ä¢ Motivation, formulation of the problem being addressed, etc. \r\n‚Ä¢ Description of the solution. \r\n‚Ä¢ Validation of the solution (if applicable -> discuss with coach) \r\n‚Ä¢ Discussion of the solution. (Including limitations)\r\n5\r\n\r\nStrategy\r\n‚Ä¢ Starting next week, there are no lectures  \r\n‚Ä¢ Steering meetings from week 5 till week 9 (either online or in person).  \r\n‚Ä¢ 1 steering meeting per week. (4+1 sprints) \r\n‚Ä¢ Every week, you need to plan different tasks and assignments. \r\n‚Ä¢ Deadline April 4.\r\n6\r\n\r\nStrategy\r\n‚Ä¢ Week 0 \r\n‚Ä¢ Decide project idea (today) \r\n‚Ä¢ Define steering meeting schedule \r\n‚Ä¢ Create working document of the \r\narticle: Problem statement and solution \r\nproposal! \r\n‚Ä¢ Define and assign tasks for each week. \r\n‚Ä¢ Week 1 \r\n‚Ä¢ Implementation \r\n‚Ä¢ Agreements with supervisor. \r\n‚Ä¢ Week 2 \r\n‚Ä¢ Implementation \r\n‚Ä¢ Week 3 \r\n‚Ä¢ Implementation, Full draft of article, \r\ndissemination. \r\n‚Ä¢ Week 4 \r\n‚Ä¢ Final refinements \r\n‚Ä¢ Prepare presentation\r\n7\r\n\r\nProject ideas\r\n‚Ä¢ A1. Prototype cross-machine comparable benchmarks \r\n‚Ä¢ A2. Add energy metrics to LMstudio/Ollama \r\n‚Ä¢ A3. Visualizations built-in with EnergiBridge \r\n‚Ä¢ A4. Service-based version of EnergiBridge\r\n\r\nProject ideas\r\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \r\n‚Ä¢ B2. Study test generation energy consumption \r\n‚Ä¢ B3. Energy profiling of static analysis tools \r\n‚Ä¢ B4. Detailed energy profiling of build pipelines \r\n‚Ä¢ B5. Tool supporting SusAF workshop / process \r\n‚Ä¢ B6. Dataset of government-developed OS software \r\n‚Ä¢ B7. Queue - but better for the student / TA society\r\nQuality Assurance & Testing\r\nSocial & Individual \u2028\r\nSustainability\r\n\r\nProject ideas\r\n‚Ä¢ C1. Compare energy consumption of docker images for ML workloads. \r\n‚Ä¢ C2. Create a plugin to visualize Hugging Face carbon emissions in detail. \r\n‚Ä¢ C3. Plugin for ChatGPT (footprint per chat window) \r\n‚Ä¢ C4. NutriScore for software libraries. \r\n‚Ä¢ C5. Add energy-awareness to existing software \r\n‚Ä¢ C6. Green Shift Left \r\n‚Ä¢ C7. Education for Sustainable SE\r\n\r\nA1.', ""‚Ä¢ Our question: Can we save energy with alternative approaches? \r\n‚Ä¢ We studied Grid Search, Random Search and Bayesian \r\nOptimisation.\r\n27\r\nTim's MSc Thesis, 2022 \r\nAccepted at CAIN‚Äô23\r\n\r\n\r\nResults\r\n29\r\nConclusions? \r\n‚Ä¢ Bayesian converges faster. \r\n‚Ä¢ No clear winner between Grid and Random\r\n\r\nDeepSeekMoE\r\n30\r\nPreprint at ArXiv, 2024 https://arxiv.org/pdf/\r\n2401.06066\r\n\r\nMixture of Experts\r\n‚Ä¢ Llama3.1 has 405B parameters, DeepSeek V3 671B \r\n‚Ä¢ Yet DeepSeek has quicker inference times and claims less energy \r\nconsumption (?) \r\n‚Ä¢ Divide the model into smaller blocks of experts \r\n‚Ä¢ Tokens get routed to certain experts based on the query \r\n‚Ä¢ Only part of the network is active during inference \r\n‚Ä¢ DeepSeek claims only 37B out of 671B parameters get active\r\n31\r\n\r\nDeepSeekMoE\r\n32\r\n\r\nDeepSeekMoE\r\n33\r\n‚Ä¢ Comparable performance to \r\nLLaMA2 7B effectively using \r\nless half the parameters \r\n‚Ä¢ Less computational power \r\n‚Ä¢ Problems (?) \r\n‚Ä¢ Still need to load all the \r\nparameters \r\n‚Ä¢ High memory -> high \r\nembodied carbon\r\n\r\nGreen AI at FacebookMeta\r\n34\r\nSustainable AI: Environmental Implications, \r\nChallenges and Opportunities (2022)\r\n\r\nCarbon footprint mapped to the AI lifecycle\r\n‚Ä¢ There are 4 main overarching stages where carbon emissions need to be isolated: data \r\ncollection, experimentation, training, inference. \r\n‚Ä¢ At Facebook, recommendation systems split energy consumption evenly between \r\ntraining and inference; text translation models have a 35%/65% split. (Operational cost) \r\n‚Ä¢ Operational/embodied cost split: 30%/70%\r\n35\r\n\r\nOpen issues according to Meta\r\n‚Ä¢ A vast portion of projects only use GPUs at 30%.\u2028\r\nShould be higher to attenuate embodied carbon.\r\n36\r\nBased on 10K AI projects\r\n\r\nData Jan\r\nInformed Adaptation\r\nData Feb\r\nData Mar\r\nData Apr\r\nData May\r\n‚Ä¶\r\n~Data Dec\r\n~Data Dec\r\nData Jan\r\nData Feb\r\nData Mar\r\nData Apr\r\nData May\r\n‚Ä¶\r\nModel update Model update Model update\r\nCheck if \r\ndata change\r\nCheck if \r\ndata change\r\nCheck if \r\ndata change\r\nModel update\r\nBlind Adaptation\r\nThe AI Model will be \r\nupdated fewer times and \r\nonly when necessary.\r\nKnow when to retrain models\r\nNeither too early nor too late\r\n37\r\nAdaptation Techniques\r\n?\r\n\r\nGreen Architectural Tactics for ML-Enabled \r\nSystem\r\n38\r\nICSE-SEIS 2024\r\n\r\nArchitectural tactics\r\n39\r\n\r\nData-centric\r\n40\r\n‚Ä¢ Reduce data size \r\n‚Ä¢ Sampling \r\n‚Ä¢ Dimensionality reduction \r\n‚Ä¢ Quantization\r\n\r\nAlgorithm Design\r\n41\r\n‚Ä¢ Carefully select your algorithm \r\n‚Ä¢ You don‚Äôt need the fanciest \r\ntechniques\r\n\r\nModel Optimization\r\n42\r\n‚Ä¢ Add energy to training parameters \r\n‚Ä¢ Reduce FLOPs \r\n‚Ä¢ Pruning, sparsity \r\n‚Ä¢  Take advantage of existing models\r\n\r\nModel Training\r\n43\r\n‚Ä¢ Quantization\r\n‚Ä¢ SAVE TRAINING PROGRESS\r\n\r\nModel Deployment\r\n44\r\n‚Ä¢ Distributed deployment \r\n‚Ä¢ Energy efficient hardware and \r\nconfigurations\r\n\r\nModel Management\r\n45\r\n‚Ä¢ Reuse the model as much as possible \r\n\r\nRethinking the Architecture: Spiking Neural Networks\r\n46\r\n\r\nRethinking the Architecture: Spiking Neural Networks\r\n47\r\n\r\nSELF Lab\r\n48\r\n\r\nrecap"", 'Lu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\n7. Green SE ‚Äì Research\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nCarolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl\r\n\r\n1. Energy patterns for mobile apps \r\n2. Carbon-aware datacenters \r\n3. Energy Regression Testing \r\n4. Debugging Energy with Docker images \r\n5. Energy Efficiency vs Code Quality \r\n\r\n‚Ä¢ While learning about these works, try to be critical about them and find their \r\npitfalls.\r\n3\r\n\r\n‚Ä¢ We have seen that measuring energy consumption is not trivial \r\n‚Ä¢ It is not practical considering that developers have other priorities above \r\nenergy efficiency \r\n‚Ä¢ At the same time, every now and then there are some efforts to improve \r\nenergy efficiency in some cases. This is time consuming and requires \r\nexpertise. \r\n‚Ä¢ How can we reuse these efforts?\r\n4\r\n\r\nEnergy Patterns for Mobile \r\nApps\r\nhttps://tqrg.github.io/energy-patterns/\r\n\r\nMethodology\r\n5. Catalog of Energy Patterns\r\n22 \r\npatterns\r\nF-droid\r\nCurated Lists\r\n1. App Collection\r\n1783 \r\napps\r\n3. Manual Refinement of Subjects of \r\nInterest\r\n1563 \r\nchanges\r\n4. Thematic Analysis\r\n431 \r\nreusable \r\nchanges\r\n2. Collect Changes With Potential Interest\r\n/.*(energy|power|battery).*/\r\n6028 \r\nchanges\r\n\r\nThematic Analysis\r\n1. Familiarization with data \r\n2. Generating initial labels \r\n3. Reviewing themes\r\n4. Defining and naming themes\r\n\r\n‚Ä¢ Energy Pattern: design pattern to improve energy efficiency.. \r\n‚Ä¢ 22 energy patterns. \r\n‚Ä¢ Each pattern is described by Context, Solution, Example, References from \r\nliterature, and Occurences (links to code changes from git repositories).\r\n8\r\n\r\nhttps://tqrg.github.io/energy-patterns\r\n\r\nDark UI Colors \r\nProvide a dark UI color theme to \r\nsave battery on devices with \r\nAMOLED screens.\r\n‚Ä¢ Context: [‚Ä¶] Apps that require heavy usage of screen can \r\nhave a substantial negative impact on battery life. \r\n‚Ä¢ Solution: Provide a UI theme with dark background colors. [‚Ä¶]\r\n‚Ä¢ Example: In a reading app, provide a theme with a dark \r\nbackground using light colors to display text. [‚Ä¶] \r\n10\r\n\r\nDark UI Colors \r\nProvide a dark UI color theme to \r\nsave battery on devices with \r\nAMOLED screens.\r\n‚Ä¢ Context: [‚Ä¶] Apps that require heavy usage of screen can \r\nhave a substantial negative impact on battery life. \r\n‚Ä¢ Solution: Provide a UI theme with dark background colors. [‚Ä¶]\r\n‚Ä¢ Example: In a reading app, provide a theme with a dark \r\nbackground using light colors to display text. [‚Ä¶] \r\n11\r\n\r\nDynamic Retry Delay\r\n‚Ä¢ Context: [‚Ä¶] In a mobile app, when a given resource is \r\nunavailable, the app will unnecessarily try to connect the resource \r\nfor a number of times, leading to unnecessary power consumption. \r\n‚Ä¢ Solution: Increase retry interval after each failed connection. [‚Ä¶]\r\n‚Ä¢ Example: Consider a mobile app that provides a news feed and \r\nthe app is not able to reach the server to collect updates. [‚Ä¶] use \r\nthe Fibonacci series to increase the time between attempts.\r\nWhenever an attempt to access a \r\nresource fails, increase the time \r\ninterval before retrying.\r\n12\r\n\r\nBatch Operations \r\n‚Ä¢ Context: Executing operations separately leads to extraneous \r\ntail energy consumptions  \r\n‚Ä¢ Solution: Bundle multiple operations in a single one. [‚Ä¶]\r\n‚Ä¢ Example: Use system provided APIs to schedule background \r\ntasks. These APIs, guarantee that device will exit sleep mode \r\nonly when there is a reasonable amount of work to do or when a \r\ngiven task is urgent.', '8. Green AI\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nLu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\nCarolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl\r\n\r\n- Overview of Green AI \r\n- Large language models \r\n- Green data-centric AI \r\n- Model simplification \r\n- Hyper parameter tuning \r\n- Mixture of Experts and DeepSeek \r\n- Green AI at Meta \r\n\r\nAI\r\n‚Ä¢ Artificial Intelligence (AI) is the branch of computer science that deals with \r\nautomating tasks that typically require human intelligence. \r\n‚Ä¢ In the past years AI has been widely applied across different domains.\u2028\r\nE.g., health care, transportation, finance. \r\n‚Ä¢ To deploy AI systems, we test them against benchmarks (or validation sets). \r\n‚Ä¢ The goal is to outperform the previous existing models. \r\n‚Ä¢ E.g., in Machine Learning we usually resort to accuracy metrics. The \r\nhighest the accuracy, the better the model.\r\n3\r\n\r\nSince 2012, the amount of computing used for AI \r\ntraining has been doubling every 6 months\r\n‚Ä¢ https://epoch.ai/blog/compute-trends\r\n4\r\n\r\n‚Ä¢ To create better AI systems we are currently adding \r\n‚Ä¢ More data \r\n‚Ä¢ More experiments \r\n‚Ä¢ Larger models\r\n5\r\n\r\nThe Equation of Red AI\r\nCost(R) ‚àùE¬∑D¬∑H\r\nCost of a single (E)xample\r\nSize of (D)ataset\r\nNumber of (H)yperparameters\r\nBy Schwartz et al. (2020)\r\n\r\nIssues of Red AI\r\n‚Ä¢ High costs (hardware, electricity, data access, etc.) \r\n‚Ä¢ Limited reproducibility.  \r\n‚Ä¢ Energy consumption. \r\n‚Ä¢ Carbon emissions. \r\n‚Ä¢ SMEs can hardly be competitive. \r\n‚Ä¢ Groundbreaking AI research is mostly done by tech giants.\r\n7\r\n\r\nA few examples of Red AI\r\n‚Ä¢ Google‚Äôs BERT-large \r\n‚Ä¢ 350 million features \r\n‚Ä¢ Trained for 2.5 days using 512 TPU chips, costing $60K+ \r\n‚Ä¢ Open-GPT3 (now GPT-4/o1) \r\n‚Ä¢ 550 tonnes CO2-eq (Patterson, 2021) \r\n‚Ä¢ 175 billion features \r\n‚Ä¢ API is open but no-pretrained model is available \r\n‚Ä¢ AlphaGo \r\n‚Ä¢ 1920 CPUs, 280 GPUs, costing $35M\r\n8\r\n\r\nRed AI in Large Language Models (LLMs)\r\n‚Ä¢ OPT by Meta reports 75 tons CO2-eq (1/7 of OpenGPT‚Äôs footprint).\u2028\r\n(Also 175billion params) \r\n‚Ä¢ However, Llama 3 reported 2,290 tons of CO2-eq (7.7M GPU hours \r\ntraining ) \r\n‚Ä¢ Open science: release includes both the pretrained models and the code \r\nneeded to train and use them. \r\n‚Ä¢ DeepSeek-V3 claims ‚Äúonly‚Äù 2.78M GPU hours \r\n‚Ä¢ Bloom by Huggingface reports 25 tons, 51 when considering embodied \r\nand operational carbon footprint. (176billion params)\r\n9\r\n\r\nRed AI\r\nAccuracy: 0.999999999\r\nGreen AI\r\n‚Ä¢ Energy \r\n‚Ä¢ Time \r\n‚Ä¢ Reproducibility \r\n‚Ä¢ Reusage\r\n\r\nHow can we adopt Green AI\r\n‚Ä¢ Check whether AI is needed. \r\n‚Ä¢ Select green datacenters. \r\n‚Ä¢ Run on low carbon intensity hours. \r\n‚Ä¢ Opt for GPU-optimised solutions (?) \r\n‚Ä¢ Opt for low-power hardware (e.g., Nvidia Jetson boards) \r\n‚Ä¢ Or GPUs that provide energy metrics (e.g., NVIDIA GPUs via the nvidia-smi tool) \r\n‚Ä¢ Report energy/carbon metrics (e.g., embed in MLFlow?)', '‚Ä¢ Groundbreaking AI research is mostly done by tech giants.\r\n7\r\n\r\nA few examples of Red AI\r\n‚Ä¢ Google‚Äôs BERT-large \r\n‚Ä¢ 350 million features \r\n‚Ä¢ Trained for 2.5 days using 512 TPU chips, costing $60K+ \r\n‚Ä¢ Open-GPT3 (now GPT-4/o1) \r\n‚Ä¢ 550 tonnes CO2-eq (Patterson, 2021) \r\n‚Ä¢ 175 billion features \r\n‚Ä¢ API is open but no-pretrained model is available \r\n‚Ä¢ AlphaGo \r\n‚Ä¢ 1920 CPUs, 280 GPUs, costing $35M\r\n8\r\n\r\nRed AI in Large Language Models (LLMs)\r\n‚Ä¢ OPT by Meta reports 75 tons CO2-eq (1/7 of OpenGPT‚Äôs footprint).\u2028\r\n(Also 175billion params) \r\n‚Ä¢ However, Llama 3 reported 2,290 tons of CO2-eq (7.7M GPU hours \r\ntraining ) \r\n‚Ä¢ Open science: release includes both the pretrained models and the code \r\nneeded to train and use them. \r\n‚Ä¢ DeepSeek-V3 claims ‚Äúonly‚Äù 2.78M GPU hours \r\n‚Ä¢ Bloom by Huggingface reports 25 tons, 51 when considering embodied \r\nand operational carbon footprint. (176billion params)\r\n9\r\n\r\nRed AI\r\nAccuracy: 0.999999999\r\nGreen AI\r\n‚Ä¢ Energy \r\n‚Ä¢ Time \r\n‚Ä¢ Reproducibility \r\n‚Ä¢ Reusage\r\n\r\nHow can we adopt Green AI\r\n‚Ä¢ Check whether AI is needed. \r\n‚Ä¢ Select green datacenters. \r\n‚Ä¢ Run on low carbon intensity hours. \r\n‚Ä¢ Opt for GPU-optimised solutions (?) \r\n‚Ä¢ Opt for low-power hardware (e.g., Nvidia Jetson boards) \r\n‚Ä¢ Or GPUs that provide energy metrics (e.g., NVIDIA GPUs via the nvidia-smi tool) \r\n‚Ä¢ Report energy/carbon metrics (e.g., embed in MLFlow?) \r\n‚Ä¢ Use pre-trained models (Transfer Learning) \r\n‚Ä¢ Preprocess dataset to reduce size. \r\n‚Ä¢ Improve parameter-tuning strategy.\r\n11\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ We need benchmarks. \r\n‚Ä¢ AllenAI leaderboard\u2028\r\nhttps://leaderboard.allenai.org \r\n‚Ä¢ No carbon metrics, yet \r\n‚Ä¢ Report comparable proxies for energy \r\nconsumption. \r\n‚Ä¢ ‚ö† Learning algorithms behave in a non-\r\ndeterministic \r\n‚Ä¢ ‚ö† Different data-points lead to different \r\nenergy consumption\r\n12\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ Reporting measured energy consumption \r\n‚Ä¢ + Accurate \r\n‚Ä¢ + Easy to map to carbon emissions \r\n‚Ä¢ - Hard to measure \r\n‚Ä¢ - Low replicability \r\n‚Ä¢ Reporting time / estimation based on time & hardware \r\n‚Ä¢ + Easy to measure \r\n‚Ä¢ + Correlates with energy consumption in most cases. \r\n‚Ä¢ -  Difficult to compare with measurements from other setups \r\n‚Ä¢ E.g., floating point operations (FPOs) (?) \r\n‚Ä¢ + comparable across different setups \r\n‚Ä¢ + cheap \r\n‚Ä¢ - does not factor in memory energy consumption \r\n‚Ä¢ - does not reflect carbon emissions\r\n13\r\n\r\nData-centric AI\r\n\r\nData-centric AI\r\n‚Ä¢ Emerging discipline that deals with systematically engineering data to build AI \r\nsystems. \r\n‚Ä¢ Shift from improving the training strategy to improving the data. \r\n‚Ä¢ It is better to have small but reliable datasets than large but noisy \r\ndatasets. \r\n‚Ä¢ => Improve data collection, data labelling, and data preprocessing. \r\n‚Ä¢ More about data-centric AI by Andrew Ng:\u2028\r\nhttps://www.youtube.com/watch?v=06-AZXmwHjo\r\n15\r\n\r\n\r\nGreen Data-centric AI\r\n‚Ä¢ How do different ML algorithms compare \r\nin terms of energy consumption? \r\n‚Ä¢ How does number of rows relate to the \r\nenergy consumption of ML models? \r\n‚Ä¢ How does number of features relate to \r\nthe energy consumption of ML models? \r\n‚Ä¢ What is the impact of reducing data in the \r\nperformance of the model?', '‚Ä¢ Improve parameter-tuning strategy.\r\n11\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ We need benchmarks. \r\n‚Ä¢ AllenAI leaderboard\u2028\r\nhttps://leaderboard.allenai.org \r\n‚Ä¢ No carbon metrics, yet \r\n‚Ä¢ Report comparable proxies for energy \r\nconsumption. \r\n‚Ä¢ ‚ö† Learning algorithms behave in a non-\r\ndeterministic \r\n‚Ä¢ ‚ö† Different data-points lead to different \r\nenergy consumption\r\n12\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ Reporting measured energy consumption \r\n‚Ä¢ + Accurate \r\n‚Ä¢ + Easy to map to carbon emissions \r\n‚Ä¢ - Hard to measure \r\n‚Ä¢ - Low replicability \r\n‚Ä¢ Reporting time / estimation based on time & hardware \r\n‚Ä¢ + Easy to measure \r\n‚Ä¢ + Correlates with energy consumption in most cases. \r\n‚Ä¢ -  Difficult to compare with measurements from other setups \r\n‚Ä¢ E.g., floating point operations (FPOs) (?) \r\n‚Ä¢ + comparable across different setups \r\n‚Ä¢ + cheap \r\n‚Ä¢ - does not factor in memory energy consumption \r\n‚Ä¢ - does not reflect carbon emissions\r\n13\r\n\r\nData-centric AI\r\n\r\nData-centric AI\r\n‚Ä¢ Emerging discipline that deals with systematically engineering data to build AI \r\nsystems. \r\n‚Ä¢ Shift from improving the training strategy to improving the data. \r\n‚Ä¢ It is better to have small but reliable datasets than large but noisy \r\ndatasets. \r\n‚Ä¢ => Improve data collection, data labelling, and data preprocessing. \r\n‚Ä¢ More about data-centric AI by Andrew Ng:\u2028\r\nhttps://www.youtube.com/watch?v=06-AZXmwHjo\r\n15\r\n\r\n\r\nGreen Data-centric AI\r\n‚Ä¢ How do different ML algorithms compare \r\nin terms of energy consumption? \r\n‚Ä¢ How does number of rows relate to the \r\nenergy consumption of ML models? \r\n‚Ä¢ How does number of features relate to \r\nthe energy consumption of ML models? \r\n‚Ä¢ What is the impact of reducing data in the \r\nperformance of the model? \r\n‚Ä¢ Method -> results -> discussion\r\n17\r\n\r\nMethod\r\n‚Ä¢ Single object of study: natural language model to detect spam messages. \r\n‚Ä¢ 6 machine learning algorithms: SVM, Decision Tree, KNN, Random Forrest, \r\nAdaBoost, Bagging Classifier. \r\n‚Ä¢ Reduce the number of rows. 10%, 20%, .., 100% \r\n‚Ä¢ Stratified random sampling (?) \r\n‚Ä¢ Reduce the number of features. 10%, 20%, .., 100% \r\n‚Ä¢ Feature importance metric based on the Chi-Square Test (Chi2) \r\n‚Ä¢ Estimate energy consumption using a RAPL-based tool. (?)\r\n18\r\n\r\n‚Ä¢ Repeat 30 times \r\n‚Ä¢ Fix random seeds \r\n‚Ä¢ ‚Ä¶ \r\n‚Ä¢ Data was not Normal => tailed Normal distribution.\r\n19\r\n(?)\r\n\r\nResults: energy consumption of algorithms\r\n\r\nResults: energy vs data shape\r\n\r\nResults: performance vs data shape\r\n\r\nDiscussion\r\n‚Ä¢ Other data properties should be investigated. \r\n‚Ä¢ E.g., data types \r\n‚Ä¢ Reporting energy data is essential. It can lead to different model selection \r\nwithout hindering model performance. \r\n‚Ä¢ There is a big opportunity in Model and Data Simplification.\r\n23\r\n\r\nData/Model Simplification\r\n‚Ä¢ (?) \r\n‚Ä¢ Data selection \r\n‚Ä¢ Data quantisation. Posit? \r\n‚Ä¢ Data distillation \r\n‚Ä¢ Coreset extraction (?) \r\n‚Ä¢ Model distillation \r\n‚Ä¢ Model quantisation \r\n‚Ä¢ Model pruning \r\n‚Ä¢ ‚Ä¶\r\n24\r\n\r\nPosit vs Float\r\nMore about this: https://spectrum.ieee.org/floating-point-numbers-posits-processor\r\nBetter for DL use cases\r\n\r\nHow can we tune \r\nlearning \r\nparameters \r\nefficiently?\r\n\r\nHyper parameter tuning\r\n‚Ä¢ When training an ML model, there are several parameters that need to be \r\ntuned. \r\n‚Ä¢ E.g., in SVM we have the Regularization parameter C, the kernel function, \r\nthe degree of the kernel function, and depending on the case, many other. \r\n‚Ä¢ The common approach revolves around grid search.', 'computing vision, classification)\r\n\r\nA2. Adding energy metrics to LMstudio/Ollama\r\n‚Ä¢ Make energy consumption visible to users \r\nwithin local chat-interface for LLMs \r\n‚Ä¢ LMstudio/Ollama are tools for easy \r\ndeployment of LLMs \r\n‚Ä¢ Do not show energy metrics \r\n‚Ä¢ Add energy metrics to LMstudio-python \r\nor Ollama\r\nhttps://lmstudio.ai/\r\n\r\nA3. Visualizations built-in with EnergiBridge\r\n‚Ä¢ EnergiBridge simplifies energy measurement, but analysis & visualization is \r\nstill left to the user \r\n‚Ä¢ Extend the tool with well-chosen visualizations and analyses directly from the \r\nprovided data\r\n\r\nA4. Service-based version of EnergiBridge\r\n‚Ä¢ Simplify interaction & setup with EnergiBridge \r\n‚Ä¢ Service that runs independently, start/stop signals over RPC to manage \r\nexperiments \r\n‚Ä¢ Potential: create EnergiBridge interface for other prog. lang\r\n\r\nB1. Measure energy consumption of single JUnit tests\r\n‚Ä¢ We‚Äôd like to identify energy anti patterns in unit tests \r\n‚Ä¢ As a first step, we need tooling to measure and compare the energy \r\nconsumption of single unit tests \r\n‚Ä¢ Ideally including preliminary analysis looking at potential reasons for high-\r\nenergy-consuming tests\r\n\r\nB2. Study test generation energy consumption\r\n‚Ä¢ Automatic test generation mainly focuses on making strong test suites \r\n‚Ä¢ Do different techniques and configurations impact the energy consumption \r\nduring generation? \r\n‚Ä¢ Preferably focus on non-LLM test generation methods (EvoSuite, Pyguin, \r\nDSpot)\r\n\r\nB3. Detailed energy profiling of build pipelines\r\n‚Ä¢ Automatic builds have become a cornerstone of quality assurance. But how \r\nmuch energy do they even consume? \r\n‚Ä¢ Create a tool that reports on the energy consumed during the (different stages \r\nof the) whole build (compile, build, test, package, ‚Ä¶) \r\n‚Ä¢ Should be integrated with build system(s), making setup for developers easy \r\n‚Ä¢ For local setup (to enable true energy measurements)\r\n\r\nB4. Energy profiling of static analysis tools\r\n‚Ä¢ What is the energy consumption of a ""typical run"" for a few OSS projects? \r\n‚Ä¢ Does the type of analysis matter? Are certain analysis more expensive? Does \r\nthe number of rules that are activated in a static analysis tool important for the \r\nenergy consumption? \r\n‚Ä¢ Differences between static analysis tools [lower priority]\r\n\r\nB5. Tool supporting SusAF workshop / process\r\n‚Ä¢ Lead engineers through process & questions \r\n‚Ä¢ Interface to create & document the two diagrams \r\n‚Ä¢ (!) Should be easy to start using & set up \r\n‚Ä¢ You may also create a simplified version / \u2028\r\nyour favorite sustainability framework\r\nEnvironmental\r\nEconomic\r\nTechnical\r\nIndividual\r\nSocial\r\nImmediate\r\nEnabling\r\nStructural\r\nAirbnb\r\ngreater \r\nearnings\r\nincrease \r\nin rents\r\ngentrification\r\ngreater racial \r\ndisparities\r\nrent \r\nrooms\r\n5\r\n1\r\n3\r\n4\r\n2\r\n \r\n \r\n \r\n \r\n \r\n \r\nVery \r\nunlikely \r\nVery \r\nlikely \r\n\r\nB6. Dataset of government-developed OS software\r\n‚Ä¢ Governments develop & use software for supporting society\u2028\r\nOpen-source development & policies are on the rise \r\n‚Ä¢ But studying government software is difficult b/c we don‚Äôt know what is out \r\nthere\u2028\r\n‚Üí Lack of incentive to make popular \u2028\r\n‚Üí Language barriers \r\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \r\nbuildable?, open dev. history?, requirements documentation? \r\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!\r\n\r\nB7. Queue - but better for the student / TA society\r\n‚Ä¢ Requirements analysis regarding social and individual sustainability effects \r\nof Queue \r\n‚Ä¢ Other EIP / TUD used software also possible: e.g., Answers EWI \r\n‚Ä¢ Non-technical project ‚Üí proper process (workshops?', 'Carbon-free giants\r\n‚Ä¢ Google, Microsoft, Meta/Facebook want to be carbon free by 2030 \r\n‚Ä¢ Carbon free is different from carbon neutral \r\n‚Ä¢ Green IT experts are needed to meet these goals\r\n23\r\n\r\n\r\nRebound effect*\r\n‚Ä¢ Energy consumption decreases ‚Üì‚Üì but demand also increases ‚Üë‚Üë. \r\n‚Ä¢ *a.k.a. Jevons Paradox in economics; Downs‚ÄìThomson paradox in\xa0mobility.\r\nEnergy per prompt\r\nPrompts\r\n100\r\n80\r\n30\r\n38\r\nChat \r\nGPT\r\n‚ÄúEnergy-efficient‚Äù \r\nChat GPT\r\n0\r\n\r\nIs sustainability an\u2028\r\nethical issue?\r\n‚Ä¢ Climate change is more likely to affect the \r\npoorest countries. \r\n‚Ä¢ Less financial resources to adapt \r\n‚Ä¢ Climate-impact does not necessarily affect \r\npolluting countries. \r\n‚Ä¢ Poorest countries have contributed less to the \r\nclimate change. \r\n‚Ä¢ We need to figure out how to do more using \r\nless resources.\r\n26\r\n\r\nMorality ‚â† Moralising\r\n‚Ä¢ We should not use climate action as a \r\nshaming weapon \r\n‚Ä¢ Climate action should be agnostic of political \r\nviews, ideology, social status, etc. \r\n‚Ä¢ We need everyone to take action!\r\n27\r\n\r\nWhy?\r\n‚Ä¢ Throughout your career you might: \r\n‚Ä¢ Design/maintain/contract data centers \r\n‚Ä¢ Set up operations/devops \r\n‚Ä¢ Develop AI for IoT devices \r\n‚Ä¢ Be the next CEO/CTO of a software company \r\n‚Ä¢ Sustainability can be your main role: \r\n‚Ä¢ Green Software Developer \r\n‚Ä¢ Sustainability Consultant \r\n‚Ä¢ Green Advocate  \r\n‚Ä¢ Founder of a Green Tech startup (B2B?)\r\n28\r\n\r\nFormat of classes\r\n‚Ä¢ In-person. \r\n‚Ä¢ Collegerama recordings. \r\n‚Ä¢ Lectures and Labs. \r\n‚Ä¢ Guest lectures. \r\n‚Ä¢ Steering meetings (after week 5, new schedule)\r\n29\r\n\r\nFormat of classes\r\n‚Ä¢ There‚Äôs no exam in this course. It‚Äôs more important that we learn how to \r\ndiscuss this topic and come up with new ideas than learning all the theory. \r\nCritical thinking over checkboxes. \r\n‚Ä¢ Mix of content and discussion \r\n‚Ä¢ Ultimately, the lectures aim to give you food for thought and the necessary \r\nknowledge to excel in Project 2. (We will talk about it later)\r\n30\r\n\r\nhttps://luiscruz.github.io/course_sustainableSE/\r\n31\r\nContent of the course üëá\r\n\r\n32\r\nhttps://mattermost.tudelft.nl/signup_user_complete/?id=1nj9tk6usjf8xmsws8wpq3s5uy&md=link&sbr=su\r\n\r\nProject 1\r\n‚Ä¢ Goal: Measure the energy consumption of software applications. \r\n‚Ä¢ Approach: energy measurement tools; use case testing. \r\n‚Ä¢ Deliverable: blog-style report (approx. 2500 words) \r\n‚Ä¢ Deadline: Week 3, Feb 28, 2025 \r\n‚Ä¢ Group size: 4‚Äì5\r\n33\r\n\r\nProject 2\r\n‚Ä¢ Goal: Create a solution/tool/technique that helps building green software. (You \r\ncan come up with your own idea or choose one from a list of suggestions). \r\n‚Ä¢ Approach: open-source software development; literature review. \r\n‚Ä¢ Deliverable: library/tool/app; paper; presentation. \r\n‚Ä¢ Two deadlines:\u2028\r\n1. Paper and software: Week 8, April 4, 2025\u2028\r\n2. Presentation: Week 9, April 11, 2025 \r\n‚Ä¢ Group size: 4‚Äì5\r\n34\r\n\r\nGuest Lectures\r\nNergis T√∂men \r\nComputer Vision lab | TU Delft \r\nWeek 4, Wed, Mar 5, 2025\r\n35\r\n\r\nCommunity \r\nHow to get involved?', ""‚Ä¢ 6 machine learning algorithms: SVM, Decision Tree, KNN, Random Forrest, \r\nAdaBoost, Bagging Classifier. \r\n‚Ä¢ Reduce the number of rows. 10%, 20%, .., 100% \r\n‚Ä¢ Stratified random sampling (?) \r\n‚Ä¢ Reduce the number of features. 10%, 20%, .., 100% \r\n‚Ä¢ Feature importance metric based on the Chi-Square Test (Chi2) \r\n‚Ä¢ Estimate energy consumption using a RAPL-based tool. (?)\r\n18\r\n\r\n‚Ä¢ Repeat 30 times \r\n‚Ä¢ Fix random seeds \r\n‚Ä¢ ‚Ä¶ \r\n‚Ä¢ Data was not Normal => tailed Normal distribution.\r\n19\r\n(?)\r\n\r\nResults: energy consumption of algorithms\r\n\r\nResults: energy vs data shape\r\n\r\nResults: performance vs data shape\r\n\r\nDiscussion\r\n‚Ä¢ Other data properties should be investigated. \r\n‚Ä¢ E.g., data types \r\n‚Ä¢ Reporting energy data is essential. It can lead to different model selection \r\nwithout hindering model performance. \r\n‚Ä¢ There is a big opportunity in Model and Data Simplification.\r\n23\r\n\r\nData/Model Simplification\r\n‚Ä¢ (?) \r\n‚Ä¢ Data selection \r\n‚Ä¢ Data quantisation. Posit? \r\n‚Ä¢ Data distillation \r\n‚Ä¢ Coreset extraction (?) \r\n‚Ä¢ Model distillation \r\n‚Ä¢ Model quantisation \r\n‚Ä¢ Model pruning \r\n‚Ä¢ ‚Ä¶\r\n24\r\n\r\nPosit vs Float\r\nMore about this: https://spectrum.ieee.org/floating-point-numbers-posits-processor\r\nBetter for DL use cases\r\n\r\nHow can we tune \r\nlearning \r\nparameters \r\nefficiently?\r\n\r\nHyper parameter tuning\r\n‚Ä¢ When training an ML model, there are several parameters that need to be \r\ntuned. \r\n‚Ä¢ E.g., in SVM we have the Regularization parameter C, the kernel function, \r\nthe degree of the kernel function, and depending on the case, many other. \r\n‚Ä¢ The common approach revolves around grid search. The user provides a \r\nsequence of possible values for each parameter and the pipeline runs all \r\npossible combinations. \r\n‚Ä¢ Our question: Can we save energy with alternative approaches? \r\n‚Ä¢ We studied Grid Search, Random Search and Bayesian \r\nOptimisation.\r\n27\r\nTim's MSc Thesis, 2022 \r\nAccepted at CAIN‚Äô23\r\n\r\n\r\nResults\r\n29\r\nConclusions? \r\n‚Ä¢ Bayesian converges faster. \r\n‚Ä¢ No clear winner between Grid and Random\r\n\r\nDeepSeekMoE\r\n30\r\nPreprint at ArXiv, 2024 https://arxiv.org/pdf/\r\n2401.06066\r\n\r\nMixture of Experts\r\n‚Ä¢ Llama3.1 has 405B parameters, DeepSeek V3 671B \r\n‚Ä¢ Yet DeepSeek has quicker inference times and claims less energy \r\nconsumption (?) \r\n‚Ä¢ Divide the model into smaller blocks of experts \r\n‚Ä¢ Tokens get routed to certain experts based on the query \r\n‚Ä¢ Only part of the network is active during inference \r\n‚Ä¢ DeepSeek claims only 37B out of 671B parameters get active\r\n31\r\n\r\nDeepSeekMoE\r\n32\r\n\r\nDeepSeekMoE\r\n33\r\n‚Ä¢ Comparable performance to \r\nLLaMA2 7B effectively using \r\nless half the parameters \r\n‚Ä¢ Less computational power \r\n‚Ä¢ Problems (?) \r\n‚Ä¢ Still need to load all the \r\nparameters \r\n‚Ä¢ High memory -> high \r\nembodied carbon\r\n\r\nGreen AI at FacebookMeta\r\n34\r\nSustainable AI: Environmental Implications, \r\nChallenges and Opportunities (2022)\r\n\r\nCarbon footprint mapped to the AI lifecycle\r\n‚Ä¢ There are 4 main overarching stages where carbon emissions need to be isolated: data \r\ncollection, experimentation, training, inference. \r\n‚Ä¢ At Facebook, recommendation systems split energy consumption evenly between \r\ntraining and inference; text translation models have a 35%/65% split. (Operational cost) \r\n‚Ä¢ Operational/embodied cost split: 30%/70%\r\n35\r\n\r\nOpen issues according to Meta\r\n‚Ä¢ A vast portion of projects only use GPUs at 30%.\u2028\r\nShould be higher to attenuate embodied carbon."", ""Unless there‚Äôs a \r\ngood reason. \r\n‚Ä¢ E.g., somewhere amongst the 30 executions, \r\nthere might be 1 or 2 that failed to finish due \r\nto some unexpected error. \r\n‚Ä¢ (It happens and that‚Äôs ok!)‚Äì consequently, \r\nthe execution is shorter and spends less \r\nenergy ‚Äì falsely appearing as more \r\nenergy efficient. \r\n‚Ä¢ If data is not Normal there might be some \r\nissues affecting the measurements that \r\nmight be ruining results. It is important to \r\ninvestigate this.\r\n16\r\n\r\nEnergy data is not normal. Why?\r\n‚Ä¢ It might be caused by one of the following reasons: \r\n‚Ä¢ There was an error in some of the executions. If not detected and fixed it \r\nmight ruin results. \r\n‚Ä¢ Your tests are not fully replicable or are not deterministic. Quite frequent \r\nwhen you have internet requests or random-based algorithms. \r\n‚Ä¢ There is an unusual task being run by the system during some experiments. \r\n‚Ä¢ The computer entered a different power mode. \r\n‚Ä¢ External physical conditions have changed. E.g., someone opened a \r\nwindow.\r\n17\r\n\r\nEnergy data is not normal. How to fix?\r\n‚Ä¢ We have 2+1 options: \r\n1. Remove outliers. If there are only a few points that deviate from the normal \r\ndistribution, it is okay to simply remove them. \r\n‚Ä¢ Use the z-score outlier removal. (?) \r\n‚Ä¢ Remove all data points that deviate from the mean more than 3 standard \r\ndeviations: \r\n \r\n2. Fix the issue and rerun experiments. \r\n3. Conclude that nothing can be done about it and data will never be normal. (e.g., \r\nin AI, executions are rarely deterministic). ‚ö† Only after ruling out the previous \r\npoints.\r\n| ¬Øx ‚àíx| > 3s\r\n18\r\n\r\nHow do we know whether data is Normal?\r\n‚Ä¢ Visualise distribution shape: violin plots, histograms, density plot.\u2028\r\n \r\n‚Ä¢ Shapiro-Wilk test.\u2028\r\ndata is not normal;\u2028\r\nwe are not sure but it is okay to assume that data is \r\nnormal.\r\np-value < 0.05 ‚áí\r\np-value ‚â•0.05 ‚áí\r\n19\r\n\r\nAfter having all data ready, which artefact \r\nis more energy efficient(?) \r\nFirst approach: compare sample means. \r\n‚ö† assuming normal distribution\r\n\r\nStatistical significance\r\n‚Ä¢ Even if, on average, one artefact has lower \r\nenergy consumption than other,  it might be just \r\na random difference. \r\n‚Ä¢ When we extract a sample from a normal \r\ndistribution it will never be the exact same \r\n‚Ä¢ Statistical significance tests help you \r\nunderstand the differences in the average are \r\nconclusive/significant or inconclusive/\r\ninsignificant.\r\n21\r\n‚ö† assuming normal distribution\r\n\r\nStatistical significance test\r\n‚Ä¢ Two-sided parametric test Welch‚Äôs t-test. \r\n‚Ä¢ Less known alternative to student‚Äôs t-test.\r\n22\r\nWelch‚Äôs t-test in Python\r\nfrom scipy.stats import ttest_ind \r\n_,pvalue = ttest_ind(sample_a, sample_b, \r\n                     equal_var=False, \r\n                     alternative='two-sided')\r\n(?)\r\n‚ö† assuming normal distribution\r\n\r\nEffect Size analysis\r\n‚Ä¢ Now that we know that results are statistically significant we need to \r\nmeasure the difference between the two samples. \r\n‚Ä¢ Mean difference: \r\n \r\n‚Ä¢ Percent change: \r\n \r\n‚Ä¢ Cohen‚Äôs d (informal definition: mean difference normalized by a combined \r\nstandard deviation): \r\nŒî¬Øx\r\nxB ‚àíxA\r\nxA\r\n√ó 100 % = Œî¬Øx\r\nxA\r\n√ó 100 %\r\nŒî¬Øx\r\n1\r\n2\r\ns21 + s22\r\n23\r\n‚ö† assuming normal distribution\r\n\r\nImagine that version A spends 70J and \r\nversion B spends 69J with a \r\n."", 'Carolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nLu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\n1. Intro Class\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl\r\n\r\n1. Intro to Sustainable SE \r\n2. Intro to the course\r\n2\r\n\r\nof the electricity consumed worldwide \r\nby 2040 will stem from ICT\r\n14%\r\n\r\n4\r\nhttps://xkcd.com/1007/\r\n\r\nBuzz words\r\n‚Ä¢ Eco-friendly \r\n‚Ä¢ Climate change, action, adaption \r\n‚Ä¢ Energy efficiency \r\n‚Ä¢ Environmental-responsible \r\n‚Ä¢ Carbon-neutral; Climate-neutral; Net zero \r\n‚Ä¢ Carbon-offsetting \r\n‚Ä¢ Carbon-free \r\n‚Ä¢ Clean technology \r\n‚Ä¢ E-waste\r\n5\r\n\r\nhttps://www.menti.com/uns9d89kzn\r\nWhat is Sustainable \r\nSoftware Engineering?\r\n?\r\n6\r\n\r\nSustainable Software \r\nEngineering is‚Ä¶\r\n7\r\n‚Ä¶the discipline that studies the process of creating software systems that are able \r\nto create value in the long term without hindering its surrounding environment.\r\n\r\n8\r\nEconomical\r\nSocial\r\nTechnical\r\nIndividual\r\nEnvironmental\r\nSustainable\r\nSoftware\r\nEngineering\r\n‚≠ê\r\nTechnical\u2028\r\n‚öô\r\nEconomical\u2028\r\nüí∞\r\nSocial\u2028\r\nüë©üíºüë®üíºüë©üíºüë©üíº\r\nIndividual\u2028\r\nüë©üíª\r\nEnvironmental\u2028\r\nüå±\r\nSustainable\u2028\r\nSoftware \r\nEngineering\r\n\r\nEconomical\r\n‚Ä¢ Focused on assets, capital and added value\u2028\r\n(wealth creation, prosperity, profitability, capital \r\ninvestment, income, etc.) \r\n‚Ä¢ Nr of customers  \r\n‚Ä¢ Man-day-rate estimate \r\n‚Ä¢ Next round of funding \r\n‚Ä¢ Meet requirements in the contract\r\n9\r\n\r\nTechnical\r\n‚Ä¢ Longevity of information, systems, and infrastructure and their \r\nadequate evolution with changing surrounding conditions. \r\n‚Ä¢ Examples: \r\n‚Ä¢ Technical Debt \r\n‚Ä¢ Does it scale? \r\n‚Ä¢ Software testing \r\n‚Ä¢ Bus-factor \r\n‚Ä¢ Data integrity \r\n‚Ä¢ Innovation \r\n‚Ä¢ ‚Ä¶\r\n10\r\n\r\nIndividual\r\n‚Ä¢ Well-being of the individuals in an organisation.\u2028\r\nNote that it also includes how well individuals interact \r\nwith each other within the org. \r\n‚Ä¢ Examples: \r\n‚Ä¢ mental and physical well-being \r\n‚Ä¢ self-respect \r\n‚Ä¢ education/skills \r\n‚Ä¢ career development \r\n‚Ä¢ ‚Ä¶\r\n11\r\n\r\nSocial\r\n‚Ä¢ concerned with societal communities (groups of people, \r\norganisations) and the factors that erode trust in society. \r\n‚Ä¢ Examples: \r\n‚Ä¢ Social equity \r\n‚Ä¢ Justice \r\n‚Ä¢ Employment \r\n‚Ä¢ Democracy \r\n‚Ä¢ ‚Ä¶ \r\n‚Ä¢ Also includes compliance with policies and regulations \r\n12\r\n\r\nEnvironmental Sustainability\r\n‚Ä¢ the branch of Software Engineering that studies \r\nthe development of software that has minimal \r\nimpact in our planet throughout its whole \r\nlifecycle. \r\n‚Ä¢ Looking at software at different levels: \r\n‚Ä¢ Developing, Using, Serving, ‚Ä¶ \r\n‚Ä¢ Also includes e-waste. \r\n‚Ä¢ Almost identical to Green Software. (?)\r\n13\r\nBordallo II\r\n\r\nGreen Software\r\n‚Ä¢ Sustainability and energy efficiency. \r\n‚Ä¢ Building energy-efficient software is important also from a \r\ntechnical sustainability POV. \r\n‚Ä¢ Smartphones, smart wearables, IoT devices, etc. run on limited \r\npower resources. \r\n‚Ä¢ Developing software to these devices require energy-efficiency \r\ntesting and improvement. \r\n‚Ä¢ It also leads to environmental sustainability (e.g., less battery \r\ncycles) \r\n‚Ä¢ Important for UX (e.g., no need to walk around with power banks)\r\n14\r\n\r\nhttps://www.menti.com/uns9d89kzn\r\nWhat is the sustainability \r\ndimension you are most \r\ninterested in?\r\n?', '‚Ä¢ Comparing different programming languages is not an easy task. \r\n‚Ä¢ They differ in many mechanisms: \r\n‚Ä¢ Interpreted vs Compiled \r\n‚Ä¢ Optimisations at the compiler level \r\n‚Ä¢ Virtual machine \r\n‚Ä¢ Garbage collector \r\n‚Ä¢ Available libraries\r\n30\r\n\r\nResearch Questions\r\n‚Ä¢ Can we compare the energy efficiency of software languages?  \r\n‚Ä¢ Is the faster language always the most energy efficient? \r\n‚Ä¢ How does memory usage relate to energy consumption? (We don‚Äôt cover this one) \r\n‚Ä¢ Can we automatically decide what is the best programming language \r\nconsidering energy, time, and memory usage?  \r\n‚Ä¢ How do the results of our energy consumption analysis of programming \r\nlanguages gathered from rigorous performance benchmarking solutions \r\ncompare to results of average day-to-day solutions? \u2028\r\n31\r\n\r\nMethodology\r\n\r\nThe Computer Language Benchmarks Game \r\n‚Ä¢ https://benchmarksgame-team.pages.debian.net/benchmarksgame/\r\n33\r\n\r\nProblems in the Computer Language Benchmarks Game\r\n34\r\n\r\n‚Ä¢ 27 Programming languages across different paradigms  \r\n‚Ä¢ Functional (e.g., Ocaml, F#, Haskell) \r\n‚Ä¢ Imperative (e.g., C, Go, Python) \r\n‚Ä¢ Object-oriented (e.g., C++, C#, Java) \r\n‚Ä¢ Scripting (or interpretative) (e.g., JavaScript, Python, Ruby) \r\n‚Ä¢ (These are not mutual exclusive) \r\n‚Ä¢ Intel RAPL‚Äôs C library to measure energy consumption\r\n35\r\n\r\n‚Ä¢ Execute each benchmark solution 10 times. \r\n‚Ä¢ Collect energy data and timestamps. \r\n‚Ä¢ Two-minute interval between executions\r\n36\r\n\r\n\r\n\r\n\r\nCritical thinking\r\n‚Ä¢ There is no doubt this is an excellent study. Yet, as any excellent study, there‚Äôs \r\na lot we can discuss and criticise constructively. \r\n‚Ä¢ What kind of issues you see in drawing conclusions from such a table of \r\nresults? \r\n‚Ä¢ Is the benchmark representative of the most common usage behaviour? \r\n‚Ä¢ Are the implemented solutions representative? \r\n‚Ä¢ Does it make sense to use the average to compare energy consumption \r\nacross different problems? \r\n‚Ä¢ ‚Ä¶\r\n40\r\n\r\nReproducing with Rosetta Code \r\n‚Ä¢ Rosetta Code is a programming chrestomathy repository \r\n \r\n‚Ä¢ 900 usecases/tasks solved across 700 different programming languages \r\n‚Ä¢ Purpose: if you know a programming language we can easily learn how the \r\nsame task is solved in a language you are not familiar with.\r\n41\r\n(?)\r\n\r\n\r\n\r\nRevisiting Research Questions\r\n‚Ä¢ Can we compare the energy efficiency of software languages?  \r\n‚Ä¢ Is the faster language always the most energy efficient? \r\n‚Ä¢ How does memory usage relate to energy consumption?  \r\n‚Ä¢ Can we automatically decide what is the best programming language considering \r\nenergy, time, and memory usage?  \r\n‚Ä¢ How do the results of our energy consumption analysis of programming \r\nlanguages gathered from rigorous performance benchmarking solutions \r\ncompare to results of average day-to-day solutions?  \r\n‚Ä¢ What would happen if we cherry picked the tasks?\u2028\r\n44\r\n\r\n\r\nLu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\n3. Scientific Guide for Reliable \r\nEnergy Experiments\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nCarolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl', '‚Ä¢ Examples: \r\n‚Ä¢ Technical Debt \r\n‚Ä¢ Does it scale? \r\n‚Ä¢ Software testing \r\n‚Ä¢ Bus-factor \r\n‚Ä¢ Data integrity \r\n‚Ä¢ Innovation \r\n‚Ä¢ ‚Ä¶\r\n10\r\n\r\nIndividual\r\n‚Ä¢ Well-being of the individuals in an organisation.\u2028\r\nNote that it also includes how well individuals interact \r\nwith each other within the org. \r\n‚Ä¢ Examples: \r\n‚Ä¢ mental and physical well-being \r\n‚Ä¢ self-respect \r\n‚Ä¢ education/skills \r\n‚Ä¢ career development \r\n‚Ä¢ ‚Ä¶\r\n11\r\n\r\nSocial\r\n‚Ä¢ concerned with societal communities (groups of people, \r\norganisations) and the factors that erode trust in society. \r\n‚Ä¢ Examples: \r\n‚Ä¢ Social equity \r\n‚Ä¢ Justice \r\n‚Ä¢ Employment \r\n‚Ä¢ Democracy \r\n‚Ä¢ ‚Ä¶ \r\n‚Ä¢ Also includes compliance with policies and regulations \r\n12\r\n\r\nEnvironmental Sustainability\r\n‚Ä¢ the branch of Software Engineering that studies \r\nthe development of software that has minimal \r\nimpact in our planet throughout its whole \r\nlifecycle. \r\n‚Ä¢ Looking at software at different levels: \r\n‚Ä¢ Developing, Using, Serving, ‚Ä¶ \r\n‚Ä¢ Also includes e-waste. \r\n‚Ä¢ Almost identical to Green Software. (?)\r\n13\r\nBordallo II\r\n\r\nGreen Software\r\n‚Ä¢ Sustainability and energy efficiency. \r\n‚Ä¢ Building energy-efficient software is important also from a \r\ntechnical sustainability POV. \r\n‚Ä¢ Smartphones, smart wearables, IoT devices, etc. run on limited \r\npower resources. \r\n‚Ä¢ Developing software to these devices require energy-efficiency \r\ntesting and improvement. \r\n‚Ä¢ It also leads to environmental sustainability (e.g., less battery \r\ncycles) \r\n‚Ä¢ Important for UX (e.g., no need to walk around with power banks)\r\n14\r\n\r\nhttps://www.menti.com/uns9d89kzn\r\nWhat is the sustainability \r\ndimension you are most \r\ninterested in?\r\n?\r\n15\r\n\r\nEconomical sustainability tops the environment\r\n‚Ä¢ In general, a software project will not survive if it‚Äôs not economical \r\nsustainable \r\n‚Ä¢ Yet, a project can survive even if it is not environmental sustainable \r\n‚Ä¢ The mindset is changing! \r\n‚Ä¢ Software consumers have started to worry about the climate impact \r\nof their behaviour as users. \r\n‚Ä¢ Being environmentally sustainable is now an important competitive \r\nfactor \r\n‚Ä¢ Marketing teams are already using all eco-friendly labels. Technical \r\nteams are not there yet, though. \r\n‚Ä¢ It‚Äôs easier said than done!\r\n$\r\n16\r\n\r\nGreen Washing\r\n‚Ä¢ Deceptively use marketing techniques to \r\nclaim being eco-friendly. \r\n‚Ä¢ Opting for green-coloured designs. \r\n‚Ä¢ Red/orange is usually perceived as \r\ntasty. \r\n‚Ä¢ Green is perceived as eco-friendly. \r\n‚Ä¢ The VW case. (?)\r\n17\r\n\r\nThe VW scandal\r\nGreenwashing\r\n‚Ä¢ Used software to cheat on vehicle emissions \r\ntests. \r\n‚Ä¢ The vehicle‚Äôs software could detect whether they \r\nwere being tested, changing the performance \r\naccordingly to improve results. \r\n‚Ä¢ Affected 11M cars worldwide, 8M in Europe.\r\n18\r\n\r\nHow can we drive sustainability \r\nin the SE industry?\r\n\r\nGreen Procurement\r\n‚Ä¢ Customers decide on providers that share their values \r\n‚Ä¢ This is currently the main trigger reason why organisations \r\nworry about Sustainability and Green Software. \r\n‚Ä¢ Examples of green procurement: \r\n‚Ä¢ Customers that only buy green services/products \r\n‚Ä¢ Companies that only use green providers \r\n‚Ä¢ Developers that only work for green companies \r\n‚Ä¢ Green procurement makes environmental sustainability \r\nessential for economical sustainability.\r\n20\r\n\r\nSustainability via compliance\r\n‚Ä¢ EU wants to be carbon neutral by 2030 \r\n‚Ä¢ This also affects the ICT sector. Estimated to impact \r\n14% of the global carbon footprint by 2040. \r\n‚Ä¢ Some initiatives are already being negotiated. \r\n‚Ä¢ Extending the smartphone lifetime to 7 years. \r\n‚Ä¢ Right-to-repair movement. https://repair.eu \r\n‚Ä¢ Making IT services relying on clean energy more \r\naccessible (e.g., less taxes).\r\n21\r\n\r\nSoftware for Sustainability \r\n‚Ä¢ We are not covering it in this course.', 'CO2eq =\r\n‚àë\r\ng‚ààGHG\r\n(GWPg ‚ãÖmg)\r\n23\r\nCO2eq = GWPCO2 ‚ãÖmCO2 + GWPCH4 ‚ãÖmCH4 + GWPN2O ‚ãÖmN2O\r\n= 1 √ó 1000 + 21 √ó 20 + 310 √ó 5\r\n= 2670kgCO2eq\r\n\r\nNote: \r\n- 100-GWP is only an estimation;  \r\n- different sources reveal different estimations; \r\n- there is also the 20-GWP and the 500-GWP. \r\nI use this source: Foster et al. (2017) Changes in Atmospheric Constituents and in Radiative Forcing  \r\nhttps://archive.ipcc.ch/pdf/assessment-report/ar4/wg1/ar4-wg1-chapter2.pdf \r\n\r\nCarbon credits (quick detour)\r\n‚Ä¢ Strategy used to regulate allowed emissions and to make carbon emission \r\nrights tradable. \r\n‚Ä¢ Each entity (e.g., company/country) has a budget of carbon credits. \r\n‚Ä¢ Entities can buy carbon credits from other entities when they are over budget. \r\n‚Ä¢ In the case of companies, carbon credits can only be bought from GHG \r\nmitigation projects. \r\n‚Ä¢ 1 carbon credit = 1 tonne CO2-eq  \r\n‚Ä¢ Consequence: the price of carbon credits is rising and carbon trading is \r\nstarting to be interesting for investors.\r\n25\r\n\r\nWhen should we use Carbon vs Energy?\r\n‚Ä¢ Energy/Power is more useful at the software usecase level. \r\n‚Ä¢ Carbon is more useful at the infrastructure level (e.g., datacenter) or at the \r\nproject level (e.g., the impact of developing a full software project). \r\n‚Ä¢ Choose your metrics wisely ;)\r\n26\r\n\r\n‚Ä¢ Carbon emissions ‚úÖ \r\n‚Ä¢ How do we go from energy consumption to carbon consumption?\r\n27\r\n\r\nCarbon intensity\r\n‚Ä¢ How much carbon is emitted per kWh of electricity consumed. \r\n‚Ä¢ The common unit: \r\n ü§∑ \r\n‚Ä¢ E.g.,  gas-based power plants emit less carbon than coal-based plants. \r\n‚Ä¢ The power grid is a mix between different sources of electricity ‚Äì different \r\nlocations have different carbon intensity.\r\ngCO2eq/kWh\r\n28\r\n\r\nhttps://app.electricitymaps.com/map\r\n\r\nBy Asim Hussain: https://principles.green/principles/carbon-intensity/\r\nüìù Reducing software energy consumption can help reduce the carbon intensity. Why?\r\n\r\nOne would expect zero carbon intensity from solar-\r\npanels or wind farms, but that‚Äôs not the case.\r\n‚ö†\r\n?\r\n\r\nMarginal Power Plant\r\n‚Ä¢ Renewable-based power plants cannot adapt to demand. \r\n‚Ä¢ When demand is higher than the existing power in the electricity grid, we \r\nneed a power plant that is able to scale up to that demand. \r\n‚Ä¢ This is usually done by fossil-based power plants. They are called the \r\nmarginal power plants. \r\n‚Ä¢ The problem is that marginal power plants do not scale down to zero. \r\n‚Ä¢ There is always a minimum carbon that needs to be emitted, even if there is \r\na lot of renewable energy in the grid.\r\n32\r\n\r\nBy Asim Hussain: https://principles.green/principles/carbon-intensity/\r\nHow could we fix this?\r\nWhat‚Äôs the problem here?\r\n\r\nMarginal Carbon Intensity\r\n‚Ä¢ Increase or decrease in carbon emissions in the electrical grid, in response \r\nto an infinitesimal increase/decrease in power demand/supply.\r\n\r\nFrom: ‚ÄúLiterature Review: On the effectiveness of a Marginal Carbon Intensity Signal ‚Äú\r\n\r\nWhy is marginal carbon intensity \r\nrelevant for software?\r\n‚Ä¢ Tip: consider a task scheduler in a datacenter.']","['<1-hop>\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy eÔ¨Éciency using static code analysis.\n‚Ä¢ We don‚Äôt need an accurate value.\n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.\n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27', '<2-hop>\n\nWhy?\n‚Ä¢ Throughout your career you might:\n‚Ä¢ Design/maintain/contract data centers\n‚Ä¢ Set up operations/devops\n‚Ä¢ Develop AI for IoT devices\n‚Ä¢ Be the next CEO/CTO of a software company\n‚Ä¢ Sustainability can be your main role:\n‚Ä¢ Green Software Developer\n‚Ä¢ Sustainability Consultant\n‚Ä¢ Green Advocate \n‚Ä¢ Founder of a Green Tech startup (B2B?)\n28', '<1-hop>\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy eÔ¨Éciency using static code analysis.\n‚Ä¢ We don‚Äôt need an accurate value.\n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.\n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27', '<2-hop>\n\nWhy?\n‚Ä¢ Throughout your career you might:\n‚Ä¢ Design/maintain/contract data centers\n‚Ä¢ Set up operations/devops\n‚Ä¢ Develop AI for IoT devices\n‚Ä¢ Be the next CEO/CTO of a software company\n‚Ä¢ Sustainability can be your main role:\n‚Ä¢ Green Software Developer\n‚Ä¢ Sustainability Consultant\n‚Ä¢ Green Advocate \n‚Ä¢ Founder of a Green Tech startup (B2B?)\n28', '<1-hop>\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy eÔ¨Éciency using static code analysis.\n‚Ä¢ We don‚Äôt need an accurate value.\n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.\n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27', '<2-hop>\n\nWhy?\n‚Ä¢ Throughout your career you might:\n‚Ä¢ Design/maintain/contract data centers\n‚Ä¢ Set up operations/devops\n‚Ä¢ Develop AI for IoT devices\n‚Ä¢ Be the next CEO/CTO of a software company\n‚Ä¢ Sustainability can be your main role:\n‚Ä¢ Green Software Developer\n‚Ä¢ Sustainability Consultant\n‚Ä¢ Green Advocate \n‚Ä¢ Founder of a Green Tech startup (B2B?)\n28']","Static code analysis in data science projects can help design more sustainability-focused data centers by identifying code that is likely to introduce energy hotspots. By estimating energy efficiency using static code analysis, developers can pinpoint parts of the code that consume more energy and should be reviewed with more attention (Source: C6 - Green Shift Left). This proactive approach allows for optimizing code to be more energy-efficient, which in turn can reduce the overall energy consumption of data centers. By minimizing energy-intensive operations and improving code efficiency, data centers can operate more sustainably, reducing their carbon footprint and operational costs.","Static code analysis in data science projects can help in designing more sustainablility-focused data centers by identifying energy hotspots in the code. This allows developers to review and optimize code that may contribute to higher energy consumption, thereby supporting the development of more efficient and sustainable data centers.",0.7997431140174033,1.0,1.0,0.83,,0.9702480976101024
How does the use of static code analysis in data science projects contribute to the design and optimization of more sustanable data centers?,"['Interviews?) & rich \r\ndescription of outcomes focus of grading\r\nhttps://eip.pages.ewi.tudelft.nl/eip-website/queue.html\r\n\r\nC1. Compare energy consumption of docker images for \r\nML workloads.\r\n‚Ä¢ Similar to what we have seen in the lectures but for ML-specific workloads. \r\n‚Ä¢ We can reuse existing experiment replication packages.\r\n22\r\n\r\nC2. Plugin to visualize Hugging Face carbon emissions.\r\n‚Ä¢ https://huggingface.co/blog/leaderboard-emissions-\r\nanalysis \r\n‚Ä¢\r\nYoo, Taewon, et al. ""Visualizing the Carbon Intensity of Machine Learning Inference for Image Analysis on TensorFlow Hub.""\r\n\r\nC3. Plugin for ChatGPT\r\n‚Ä¢ Users seldom know how much carbon they are emitting when they interact \r\nwith chat GPT. \r\n‚Ä¢ Let‚Äôs make it transparent to the users. Browser plugin?\r\n24\r\nCO2\r\n\r\nC4. NutriScore for software libraries\r\n25\r\n‚Ä¢ NutriScore labels are not perfect but they are a good starting point! \r\n‚Ä¢ What if we could do the same thing for the energy efficiency of software. \r\n‚Ä¢ (Also open to individual or social sustainability) \r\n‚Ä¢ This work can be scoped in particular domains/ecossystems/use cases. \r\n‚Ä¢ Libraries for stats? ML? Web Dev? Cloud?\r\n\r\nC5. Add energy-awareness to existing software\r\n26\r\n‚Ä¢ Streamlit, Notebooks, JSFiddle, \r\nPyScript, zsh, etc. \r\n‚Ä¢\r\n\r\nC6 - Green Shift Left\r\n‚Ä¢ Estimate energy efficiency using static code analysis. \r\n‚Ä¢ We don‚Äôt need an accurate value. \r\n‚Ä¢ It is useful to know which code is more likely to \r\nintroduce energy hotspots and that should be \r\nreviewed with more attention. \r\n‚Ä¢ Can be scoped to a particular domain (react, php, data \r\nscience, web, etc., etc.)\r\n27\r\n\r\nC7 - Education\r\n‚Ä¢ Educational game for Software \r\nSustainability practices \r\n‚Ä¢ Purpose: use within software teams to \r\ndiscuss or learn about different sustainable \r\nIT practices: at the organisation level, \r\nsoftware, etc.\r\n28\r\nhttps://github.com/OttoKaaij/Ticket-To-Sustainability/?tab=readme-ov-file\r\n\r\nProject ideas (old)\r\n‚Ä¢ Plugin from EnergiBridge (GUI, report generator, python library, etc.) \r\n‚Ä¢ Plugin for ChatGPT (carbon emissions per chat window) \r\n‚Ä¢ Seamless measurements for AI libraries \r\n‚Ä¢ Energy patterns for Green AI \r\n‚Ä¢ Sustainable SW dev gamification \r\n‚Ä¢ Sustainability auditor for AI projects \r\n‚Ä¢ Energy Profiling of screen colour filter tools (or display settings) \r\n‚Ä¢ ‚Ä¶ you can also propose yours!\r\n\r\nhttps://edu.nl/64gpk\r\nedu.nl/64gpk', 'Energy profiling of static analysis tools\r\n‚Ä¢ What is the energy consumption of a ""typical run"" for a few OSS projects? \r\n‚Ä¢ Does the type of analysis matter? Are certain analysis more expensive? Does \r\nthe number of rules that are activated in a static analysis tool important for the \r\nenergy consumption? \r\n‚Ä¢ Differences between static analysis tools [lower priority]\r\n\r\nB5. Tool supporting SusAF workshop / process\r\n‚Ä¢ Lead engineers through process & questions \r\n‚Ä¢ Interface to create & document the two diagrams \r\n‚Ä¢ (!) Should be easy to start using & set up \r\n‚Ä¢ You may also create a simplified version / \u2028\r\nyour favorite sustainability framework\r\nEnvironmental\r\nEconomic\r\nTechnical\r\nIndividual\r\nSocial\r\nImmediate\r\nEnabling\r\nStructural\r\nAirbnb\r\ngreater \r\nearnings\r\nincrease \r\nin rents\r\ngentrification\r\ngreater racial \r\ndisparities\r\nrent \r\nrooms\r\n5\r\n1\r\n3\r\n4\r\n2\r\n \r\n \r\n \r\n \r\n \r\n \r\nVery \r\nunlikely \r\nVery \r\nlikely \r\n\r\nB6. Dataset of government-developed OS software\r\n‚Ä¢ Governments develop & use software for supporting society\u2028\r\nOpen-source development & policies are on the rise \r\n‚Ä¢ But studying government software is difficult b/c we don‚Äôt know what is out \r\nthere\u2028\r\n‚Üí Lack of incentive to make popular \u2028\r\n‚Üí Language barriers \r\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \r\nbuildable?, open dev. history?, requirements documentation? \r\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!\r\n\r\nB7. Queue - but better for the student / TA society\r\n‚Ä¢ Requirements analysis regarding social and individual sustainability effects \r\nof Queue \r\n‚Ä¢ Other EIP / TUD used software also possible: e.g., Answers EWI \r\n‚Ä¢ Non-technical project ‚Üí proper process (workshops? Interviews?) & rich \r\ndescription of outcomes focus of grading\r\nhttps://eip.pages.ewi.tudelft.nl/eip-website/queue.html\r\n\r\nC1. Compare energy consumption of docker images for \r\nML workloads.\r\n‚Ä¢ Similar to what we have seen in the lectures but for ML-specific workloads. \r\n‚Ä¢ We can reuse existing experiment replication packages.\r\n22\r\n\r\nC2. Plugin to visualize Hugging Face carbon emissions.\r\n‚Ä¢ https://huggingface.co/blog/leaderboard-emissions-\r\nanalysis \r\n‚Ä¢\r\nYoo, Taewon, et al. ""Visualizing the Carbon Intensity of Machine Learning Inference for Image Analysis on TensorFlow Hub.""\r\n\r\nC3. Plugin for ChatGPT\r\n‚Ä¢ Users seldom know how much carbon they are emitting when they interact \r\nwith chat GPT. \r\n‚Ä¢ Let‚Äôs make it transparent to the users. Browser plugin?\r\n24\r\nCO2\r\n\r\nC4. NutriScore for software libraries\r\n25\r\n‚Ä¢ NutriScore labels are not perfect but they are a good starting point! \r\n‚Ä¢ What if we could do the same thing for the energy efficiency of software. \r\n‚Ä¢ (Also open to individual or social sustainability) \r\n‚Ä¢ This work can be scoped in particular domains/ecossystems/use cases. \r\n‚Ä¢ Libraries for stats? ML? Web Dev? Cloud?\r\n\r\nC5. Add energy-awareness to existing software\r\n26\r\n‚Ä¢ Streamlit, Notebooks, JSFiddle, \r\nPyScript, zsh, etc. \r\n‚Ä¢\r\n\r\nC6 - Green Shift Left\r\n‚Ä¢ Estimate energy efficiency using static code analysis. \r\n‚Ä¢ We don‚Äôt need an accurate value. \r\n‚Ä¢ It is useful to know which code is more likely to \r\nintroduce energy hotspots and that should be \r\nreviewed with more attention. \r\n‚Ä¢ Can be scoped to a particular domain (react, php, data \r\nscience, web, etc., etc.)', '‚Ä¢RQ3: Can we verify the \r\norigin of energy \r\nconsumption differences by \r\nrecreating the workload \r\nbehavior closely?\r\n37\r\n\r\nTracing\r\n‚Ä¢ Find libc function running at the end of the benchmark \r\n‚Ä¢ Tracing: Capture calls made to libc \r\n‚Ä¢ Introduces non-linear overhead\r\n38\r\n\r\nSynchronization\r\n‚Ä¢ Tracing slows down execution and increase energy consumption \r\n‚Ä¢ Run separately and synchronize with logs\r\n39\r\n\r\nTracing Analysis\r\n40\r\n\r\nTracing Analysis\r\n41\r\n\r\nBenchmarking memcpy\r\n‚Ä¢ Copy bytes from one part of memory to \r\nanother \r\n‚Ä¢ Depending on function parameters, different \r\nassembly-level optimizations \r\n‚Ä¢ Some not included in musl\r\n42\r\n\r\nBenchmarking memcpy\r\n‚Ä¢ Copy 4 bytes from fixed \r\npointer to moving pointer \r\n‚Ä¢ (100,300,500,600) x 1M \r\nrequests \r\n‚Ä¢  15% more power and 3X time\r\n43\r\n\r\nConclusions\r\n‚Ä¢ Significant difference in energy consumption for memcpy \r\n‚Ä¢ 8.6% difference for Redis workload and 13% in our benchmark \r\n‚Ä¢ musl trades performance for a smaller codebase \r\n‚Ä¢ No official documentation \r\n‚Ä¢ No awareness about energy performance\r\n44\r\n\r\n5. Energy Efficiency vs Code \r\nQuality\r\n\r\nMeasuring Maintainability\r\n‚Ä¢ According to ISO/IEC 25010, Maintainability is ‚Äúthe degree of \r\neffectiveness and efficiency with which a software product or \r\nsystem can be modified to improve it, correct it or adapt it to \r\nchanges in environment, and in requirements‚Äù \r\n‚Ä¢ We use the code analysis tool Better Code Hub to assess \r\nmaintainability \r\n‚Ä¢ Better Code Hub maps the ISO/IEC 25010 standard on \r\nmaintainability into a set of guidelines derived from static analysis\r\n46\r\n\r\nMaintainability of Energy Changes\r\n‚Ä¢ What is the impact of making energy-oriented code changes on \r\nthe maintainability of mobile apps? \r\nMaintainability \r\nDifference \r\nvE-2\r\nvE-1\r\nvE\r\nEnergy \r\nCommit\r\nvE+1\r\nM(vE-1)\r\nM(vE)\r\nParent \r\nCommit\r\n‚àÜM\r\n47\r\n\r\nThreshold Marks\r\n48\r\n\r\nBetter Code Hub\r\nMaintainability\r\nCombine\r\ndatasets\r\nEnergy\r\nCommits\r\nBaseline\r\nCommits\r\nBao et al. \r\n(2015)\r\nMoura et al. \r\n(2016)\r\nCruz et al. \r\n(2018)\r\nCruz et al. \r\n(2019)\r\nEnergy Code Changes \r\nDataset\r\n539 commits\u2028\r\nfrom 306 mobile apps\r\n539 baseline commits\u2028\r\nfrom 306 mobile apps\r\n49\r\n\r\nImpact of energy changes on \r\nmaintainability\r\n50\r\n\r\nWhich energy \r\npatterns are more \r\nlikely to affect \r\nmaintainability?\r\n51\r\n\r\nTypical maintainability issue I\r\nhttps://github.com/einmalfel/PodListen/commit/2ed5a65\r\n4 changed files with 28 additions and 0 deletions.\r\n‚Ä¶\r\n‚Ä¶\r\n52\r\n\r\nTypical maintainability issue II\r\nhttps://github.com/mozilla/MozStumbler/commit/6ea0268\r\n5 changed files with 66 additions and 14 deletions.\r\n53\r\n\r\n54', '‚Ä¢ By using money cost instead of carbon cost, they have more data available.\r\n26\r\n\r\nVirtual Cluster Capacity (VCC)\r\n‚Ä¢ If the forecast of VCC fails it shift flexible workload more than expected.  \r\n‚Ä¢ This happens because the amount of workload forecasted was below the \r\nworkload needed, and VCC was ‚Äúaggressively‚Äù low. \r\n‚Ä¢ The systems fall back to the real cluster capacity for 1 week until results \r\nstart being realistic again.\r\n27\r\n\r\nNext steps\r\n‚Ä¢ They will consider spatial flexibility. \r\n‚Ä¢ I.e., tasks that can be shifted over time and over space. \r\n‚Ä¢ It needs to factor in relocation overheads, though.\r\n28\r\n\r\nCritical questions\r\n‚Ä¢ Who defines what is flexible and inflexible? \r\n‚Ä¢ How do you estimate the CPU load of a given task?\r\n29\r\n\r\nEnergy Regression Testing\r\n‚ÜíEnergy?\r\nGreener? Greener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\n\r\nE-compare\r\nGithub Actions\r\n‚ûú https://koenhagen.github.io/E-Compare/\r\n\r\nEnergy Regression Testing \r\n\r\n4. Debugging Energy with \r\nDocker Images\r\n\r\nUnveiling the Energy Vampires \r\nA methodology for debugging Software \r\nEnergy Consumption\r\n ‚úÖ ICSE 2025\r\n\r\nData Centers and Docker\r\n‚Ä¢ Containers are the most popular way to deploy apps into the cloud \r\n‚Ä¢ Base image is an important choice when building an image \r\n‚Ä¢ Criteria \r\n‚Ä¢ Linux distribution and binaries \r\n‚Ä¢ Image size \r\n‚Ä¢ Energy?\r\n35\r\n\r\nRedis energy consumption\r\n‚Ä¢ Ubuntu/Alpine base images have different energy consumption for Redis\r\n36\r\n\r\nRedis Energy Consumption\r\n‚Ä¢RQ1: What is the difference \r\nin energy consumption \r\nbetween glibc and musl? \r\n‚Ä¢RQ2: Can we use tracing \r\nto compare energy \r\nconsumption in shared \r\nlibraries? \r\n‚Ä¢RQ3: Can we verify the \r\norigin of energy \r\nconsumption differences by \r\nrecreating the workload \r\nbehavior closely?\r\n37\r\n\r\nTracing\r\n‚Ä¢ Find libc function running at the end of the benchmark \r\n‚Ä¢ Tracing: Capture calls made to libc \r\n‚Ä¢ Introduces non-linear overhead\r\n38\r\n\r\nSynchronization\r\n‚Ä¢ Tracing slows down execution and increase energy consumption \r\n‚Ä¢ Run separately and synchronize with logs\r\n39\r\n\r\nTracing Analysis\r\n40\r\n\r\nTracing Analysis\r\n41\r\n\r\nBenchmarking memcpy\r\n‚Ä¢ Copy bytes from one part of memory to \r\nanother \r\n‚Ä¢ Depending on function parameters, different \r\nassembly-level optimizations \r\n‚Ä¢ Some not included in musl\r\n42\r\n\r\nBenchmarking memcpy\r\n‚Ä¢ Copy 4 bytes from fixed \r\npointer to moving pointer \r\n‚Ä¢ (100,300,500,600) x 1M \r\nrequests \r\n‚Ä¢  15% more power and 3X time\r\n43\r\n\r\nConclusions\r\n‚Ä¢ Significant difference in energy consumption for memcpy \r\n‚Ä¢ 8.6% difference for Redis workload and 13% in our benchmark \r\n‚Ä¢ musl trades performance for a smaller codebase \r\n‚Ä¢ No official documentation \r\n‚Ä¢ No awareness about energy performance\r\n44\r\n\r\n5. Energy Efficiency vs Code \r\nQuality\r\n\r\nMeasuring Maintainability\r\n‚Ä¢ According to ISO/IEC 25010, Maintainability is ‚Äúthe degree of \r\neffectiveness and efficiency with which a software product or \r\nsystem can be modified to improve it, correct it or adapt it to \r\nchanges in environment, and in requirements‚Äù \r\n‚Ä¢ We use the code analysis tool Better Code Hub to assess \r\nmaintainability \r\n‚Ä¢ Better Code Hub maps the ISO/IEC 25010 standard on \r\nmaintainability into a set of guidelines derived from static analysis\r\n46\r\n\r\nMaintainability of Energy Changes\r\n‚Ä¢ What is the impact of making energy-oriented code changes on \r\nthe maintainability of mobile apps?', '‚Ä¢ Deadline April 4.\r\n6\r\n\r\nStrategy\r\n‚Ä¢ Week 0 \r\n‚Ä¢ Decide project idea (today) \r\n‚Ä¢ Define steering meeting schedule \r\n‚Ä¢ Create working document of the \r\narticle: Problem statement and solution \r\nproposal! \r\n‚Ä¢ Define and assign tasks for each week. \r\n‚Ä¢ Week 1 \r\n‚Ä¢ Implementation \r\n‚Ä¢ Agreements with supervisor. \r\n‚Ä¢ Week 2 \r\n‚Ä¢ Implementation \r\n‚Ä¢ Week 3 \r\n‚Ä¢ Implementation, Full draft of article, \r\ndissemination. \r\n‚Ä¢ Week 4 \r\n‚Ä¢ Final refinements \r\n‚Ä¢ Prepare presentation\r\n7\r\n\r\nProject ideas\r\n‚Ä¢ A1. Prototype cross-machine comparable benchmarks \r\n‚Ä¢ A2. Add energy metrics to LMstudio/Ollama \r\n‚Ä¢ A3. Visualizations built-in with EnergiBridge \r\n‚Ä¢ A4. Service-based version of EnergiBridge\r\n\r\nProject ideas\r\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \r\n‚Ä¢ B2. Study test generation energy consumption \r\n‚Ä¢ B3. Energy profiling of static analysis tools \r\n‚Ä¢ B4. Detailed energy profiling of build pipelines \r\n‚Ä¢ B5. Tool supporting SusAF workshop / process \r\n‚Ä¢ B6. Dataset of government-developed OS software \r\n‚Ä¢ B7. Queue - but better for the student / TA society\r\nQuality Assurance & Testing\r\nSocial & Individual \u2028\r\nSustainability\r\n\r\nProject ideas\r\n‚Ä¢ C1. Compare energy consumption of docker images for ML workloads. \r\n‚Ä¢ C2. Create a plugin to visualize Hugging Face carbon emissions in detail. \r\n‚Ä¢ C3. Plugin for ChatGPT (footprint per chat window) \r\n‚Ä¢ C4. NutriScore for software libraries. \r\n‚Ä¢ C5. Add energy-awareness to existing software \r\n‚Ä¢ C6. Green Shift Left \r\n‚Ä¢ C7. Education for Sustainable SE\r\n\r\nA1. Prototype cross-machine comparable benchmarks\r\n‚Ä¢ Energy-usage comparisons require running both baseline + software on the \r\nsame machine ‚Üí limits how extensive our experiments can be \r\n‚Ä¢ Research community is in need of benchmarks that make energy \r\nmeasurements comparable even if executed on different machines \r\n‚Ä¢ Focus on a single task or model (i.e. computing vision, classification)\r\n\r\nA2. Adding energy metrics to LMstudio/Ollama\r\n‚Ä¢ Make energy consumption visible to users \r\nwithin local chat-interface for LLMs \r\n‚Ä¢ LMstudio/Ollama are tools for easy \r\ndeployment of LLMs \r\n‚Ä¢ Do not show energy metrics \r\n‚Ä¢ Add energy metrics to LMstudio-python \r\nor Ollama\r\nhttps://lmstudio.ai/\r\n\r\nA3. Visualizations built-in with EnergiBridge\r\n‚Ä¢ EnergiBridge simplifies energy measurement, but analysis & visualization is \r\nstill left to the user \r\n‚Ä¢ Extend the tool with well-chosen visualizations and analyses directly from the \r\nprovided data\r\n\r\nA4. Service-based version of EnergiBridge\r\n‚Ä¢ Simplify interaction & setup with EnergiBridge \r\n‚Ä¢ Service that runs independently, start/stop signals over RPC to manage \r\nexperiments \r\n‚Ä¢ Potential: create EnergiBridge interface for other prog. lang\r\n\r\nB1. Measure energy consumption of single JUnit tests\r\n‚Ä¢ We‚Äôd like to identify energy anti patterns in unit tests \r\n‚Ä¢ As a first step, we need tooling to measure and compare the energy \r\nconsumption of single unit tests \r\n‚Ä¢ Ideally including preliminary analysis looking at potential reasons for high-\r\nenergy-consuming tests\r\n\r\nB2. Study test generation energy consumption\r\n‚Ä¢ Automatic test generation mainly focuses on making strong test suites \r\n‚Ä¢ Do different techniques and configurations impact the energy consumption \r\nduring generation? \r\n‚Ä¢ Preferably focus on non-LLM test generation methods (EvoSuite, Pyguin, \r\nDSpot)\r\n\r\nB3. Detailed energy profiling of build pipelines\r\n‚Ä¢ Automatic builds have become a cornerstone of quality assurance.', ""‚Ä¢ Our question: Can we save energy with alternative approaches? \r\n‚Ä¢ We studied Grid Search, Random Search and Bayesian \r\nOptimisation.\r\n27\r\nTim's MSc Thesis, 2022 \r\nAccepted at CAIN‚Äô23\r\n\r\n\r\nResults\r\n29\r\nConclusions? \r\n‚Ä¢ Bayesian converges faster. \r\n‚Ä¢ No clear winner between Grid and Random\r\n\r\nDeepSeekMoE\r\n30\r\nPreprint at ArXiv, 2024 https://arxiv.org/pdf/\r\n2401.06066\r\n\r\nMixture of Experts\r\n‚Ä¢ Llama3.1 has 405B parameters, DeepSeek V3 671B \r\n‚Ä¢ Yet DeepSeek has quicker inference times and claims less energy \r\nconsumption (?) \r\n‚Ä¢ Divide the model into smaller blocks of experts \r\n‚Ä¢ Tokens get routed to certain experts based on the query \r\n‚Ä¢ Only part of the network is active during inference \r\n‚Ä¢ DeepSeek claims only 37B out of 671B parameters get active\r\n31\r\n\r\nDeepSeekMoE\r\n32\r\n\r\nDeepSeekMoE\r\n33\r\n‚Ä¢ Comparable performance to \r\nLLaMA2 7B effectively using \r\nless half the parameters \r\n‚Ä¢ Less computational power \r\n‚Ä¢ Problems (?) \r\n‚Ä¢ Still need to load all the \r\nparameters \r\n‚Ä¢ High memory -> high \r\nembodied carbon\r\n\r\nGreen AI at FacebookMeta\r\n34\r\nSustainable AI: Environmental Implications, \r\nChallenges and Opportunities (2022)\r\n\r\nCarbon footprint mapped to the AI lifecycle\r\n‚Ä¢ There are 4 main overarching stages where carbon emissions need to be isolated: data \r\ncollection, experimentation, training, inference. \r\n‚Ä¢ At Facebook, recommendation systems split energy consumption evenly between \r\ntraining and inference; text translation models have a 35%/65% split. (Operational cost) \r\n‚Ä¢ Operational/embodied cost split: 30%/70%\r\n35\r\n\r\nOpen issues according to Meta\r\n‚Ä¢ A vast portion of projects only use GPUs at 30%.\u2028\r\nShould be higher to attenuate embodied carbon.\r\n36\r\nBased on 10K AI projects\r\n\r\nData Jan\r\nInformed Adaptation\r\nData Feb\r\nData Mar\r\nData Apr\r\nData May\r\n‚Ä¶\r\n~Data Dec\r\n~Data Dec\r\nData Jan\r\nData Feb\r\nData Mar\r\nData Apr\r\nData May\r\n‚Ä¶\r\nModel update Model update Model update\r\nCheck if \r\ndata change\r\nCheck if \r\ndata change\r\nCheck if \r\ndata change\r\nModel update\r\nBlind Adaptation\r\nThe AI Model will be \r\nupdated fewer times and \r\nonly when necessary.\r\nKnow when to retrain models\r\nNeither too early nor too late\r\n37\r\nAdaptation Techniques\r\n?\r\n\r\nGreen Architectural Tactics for ML-Enabled \r\nSystem\r\n38\r\nICSE-SEIS 2024\r\n\r\nArchitectural tactics\r\n39\r\n\r\nData-centric\r\n40\r\n‚Ä¢ Reduce data size \r\n‚Ä¢ Sampling \r\n‚Ä¢ Dimensionality reduction \r\n‚Ä¢ Quantization\r\n\r\nAlgorithm Design\r\n41\r\n‚Ä¢ Carefully select your algorithm \r\n‚Ä¢ You don‚Äôt need the fanciest \r\ntechniques\r\n\r\nModel Optimization\r\n42\r\n‚Ä¢ Add energy to training parameters \r\n‚Ä¢ Reduce FLOPs \r\n‚Ä¢ Pruning, sparsity \r\n‚Ä¢  Take advantage of existing models\r\n\r\nModel Training\r\n43\r\n‚Ä¢ Quantization\r\n‚Ä¢ SAVE TRAINING PROGRESS\r\n\r\nModel Deployment\r\n44\r\n‚Ä¢ Distributed deployment \r\n‚Ä¢ Energy efficient hardware and \r\nconfigurations\r\n\r\nModel Management\r\n45\r\n‚Ä¢ Reuse the model as much as possible \r\n\r\nRethinking the Architecture: Spiking Neural Networks\r\n46\r\n\r\nRethinking the Architecture: Spiking Neural Networks\r\n47\r\n\r\nSELF Lab\r\n48\r\n\r\nrecap"", 'Lu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\n10. Project 2\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nCarolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl\r\n\r\n1. Goal/assignment \r\n2. Deliverables \r\n3. Strategy \r\n4. Ideas\r\n\r\nAssignment\r\n‚Ä¢ Goal: Solve a Sustainable Software Engineering problem. \r\n‚Ä¢ Identify 1 problem that should be fixed to help enabling sustainability in \r\nthe software engineering industry/community. \r\n‚Ä¢ Propose a solution. A tool, framework, guidelines, etc. \r\n‚Ä¢ Implementation. \r\n‚Ä¢ Validation. (Depending on the idea) \r\n‚Ä¢ Dissemination/social impact. (Solution should be open source, welcome \r\ncontributors, post on social media? Tool website? Available in a package \r\nmanager?)\r\n3\r\n\r\nDeliverables\r\n‚Ä¢ Paper-like article. (Min 4 pages, max 10) \r\n‚Ä¢ Online git repo with open source codebase and/or replication package. \r\n‚Ä¢ Presentation: 5 min + 5min Q&A\r\n4\r\n\r\nArticle\r\n‚Ä¢ Different projects will have different expectations -> Make agreements with \r\nyour coach. \r\n‚Ä¢ Some projects are more technical and some projects more theoretical. \r\n‚Ä¢ Common requirements: \r\n‚Ä¢ Motivation, formulation of the problem being addressed, etc. \r\n‚Ä¢ Description of the solution. \r\n‚Ä¢ Validation of the solution (if applicable -> discuss with coach) \r\n‚Ä¢ Discussion of the solution. (Including limitations)\r\n5\r\n\r\nStrategy\r\n‚Ä¢ Starting next week, there are no lectures  \r\n‚Ä¢ Steering meetings from week 5 till week 9 (either online or in person).  \r\n‚Ä¢ 1 steering meeting per week. (4+1 sprints) \r\n‚Ä¢ Every week, you need to plan different tasks and assignments. \r\n‚Ä¢ Deadline April 4.\r\n6\r\n\r\nStrategy\r\n‚Ä¢ Week 0 \r\n‚Ä¢ Decide project idea (today) \r\n‚Ä¢ Define steering meeting schedule \r\n‚Ä¢ Create working document of the \r\narticle: Problem statement and solution \r\nproposal! \r\n‚Ä¢ Define and assign tasks for each week. \r\n‚Ä¢ Week 1 \r\n‚Ä¢ Implementation \r\n‚Ä¢ Agreements with supervisor. \r\n‚Ä¢ Week 2 \r\n‚Ä¢ Implementation \r\n‚Ä¢ Week 3 \r\n‚Ä¢ Implementation, Full draft of article, \r\ndissemination. \r\n‚Ä¢ Week 4 \r\n‚Ä¢ Final refinements \r\n‚Ä¢ Prepare presentation\r\n7\r\n\r\nProject ideas\r\n‚Ä¢ A1. Prototype cross-machine comparable benchmarks \r\n‚Ä¢ A2. Add energy metrics to LMstudio/Ollama \r\n‚Ä¢ A3. Visualizations built-in with EnergiBridge \r\n‚Ä¢ A4. Service-based version of EnergiBridge\r\n\r\nProject ideas\r\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \r\n‚Ä¢ B2. Study test generation energy consumption \r\n‚Ä¢ B3. Energy profiling of static analysis tools \r\n‚Ä¢ B4. Detailed energy profiling of build pipelines \r\n‚Ä¢ B5. Tool supporting SusAF workshop / process \r\n‚Ä¢ B6. Dataset of government-developed OS software \r\n‚Ä¢ B7. Queue - but better for the student / TA society\r\nQuality Assurance & Testing\r\nSocial & Individual \u2028\r\nSustainability\r\n\r\nProject ideas\r\n‚Ä¢ C1. Compare energy consumption of docker images for ML workloads. \r\n‚Ä¢ C2. Create a plugin to visualize Hugging Face carbon emissions in detail. \r\n‚Ä¢ C3. Plugin for ChatGPT (footprint per chat window) \r\n‚Ä¢ C4. NutriScore for software libraries. \r\n‚Ä¢ C5. Add energy-awareness to existing software \r\n‚Ä¢ C6. Green Shift Left \r\n‚Ä¢ C7. Education for Sustainable SE\r\n\r\nA1.', 'google.com/view/energy-efficiency-languages\r\n21\r\nAna Radovanovic ÃÅ, Ross Koningstein, Ian Schneider, Bokan \r\nChen, Alexandre Duarte, Binz Roy, Diyue Xiao, Maya \r\nHaridasan, Patrick Hung, Nick Care, Saurav Talukdar, Eric \r\nMullen, Kendal Smith, MariEllen Cottman, and Walfredo Cirne \r\n\r\n\r\n‚Ä¢ Google‚Äôs Carbon-Intelligent Computing System (CICS) \r\n‚Ä¢ Main idea: use carbon-intensity data to shift datacenter jobs in time \r\n‚Ä¢ Typically, job schedulers use a metric of cluster capacity to schedule a job in \r\na particular cluster. \r\n‚Ä¢ CICS overrides this metric with the virtual capacity curve (VCC) that \r\nfactors in Carbon intensity \r\n‚Ä¢ When a new job comes in, the scheduler estimates its CPU load and power \r\nusage and assigns it to a cluster if the VCC is not exceeded.\r\n23\r\n\r\n‚Ä¢ Jobs are divided between flexible and inflexible. \r\n‚Ä¢ Flexible load is considered shapeable/shiftable as long as its total daily \r\ncompute (CPU) demand is preserved \r\n‚Ä¢ The system needs to consider that, while running a job, the virtual capacity \r\ncurve (VCC) might drop. Hence, this job should not start in the first place. \r\n‚Ä¢ They forecast VCC for the next day\r\n24\r\n\r\n\r\nVirtual Cluster Capacity (VCC)\r\n‚Ä¢ Aims at reducing the peak load at carbon intensive hours but in total it should allow for the \r\nsome amount of daily computation! \r\n‚Ä¢ Considers Carbon intensity \r\n‚Ä¢ Using data from electricityMap.org \r\n‚Ä¢ It does not use carbon intensity directly.\u2028\r\nCarbon intensity is converted to a cost (kgCO2 -> $$) \r\n‚Ä¢ This way, they can factor in other metrics that can also be converted to money. E.g., the \r\ncost saved by preventing peak load \r\n‚Ä¢ Peak workload entails extra cost at the infrastructure level (e.g., control faclities‚Äô \r\ntemperature). \r\n‚Ä¢ By using money cost instead of carbon cost, they have more data available.\r\n26\r\n\r\nVirtual Cluster Capacity (VCC)\r\n‚Ä¢ If the forecast of VCC fails it shift flexible workload more than expected.  \r\n‚Ä¢ This happens because the amount of workload forecasted was below the \r\nworkload needed, and VCC was ‚Äúaggressively‚Äù low. \r\n‚Ä¢ The systems fall back to the real cluster capacity for 1 week until results \r\nstart being realistic again.\r\n27\r\n\r\nNext steps\r\n‚Ä¢ They will consider spatial flexibility. \r\n‚Ä¢ I.e., tasks that can be shifted over time and over space. \r\n‚Ä¢ It needs to factor in relocation overheads, though.\r\n28\r\n\r\nCritical questions\r\n‚Ä¢ Who defines what is flexible and inflexible? \r\n‚Ä¢ How do you estimate the CPU load of a given task?\r\n29\r\n\r\nEnergy Regression Testing\r\n‚ÜíEnergy?\r\nGreener? Greener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\n\r\nE-compare\r\nGithub Actions\r\n‚ûú https://koenhagen.github.io/E-Compare/\r\n\r\nEnergy Regression Testing \r\n\r\n4. Debugging Energy with \r\nDocker Images\r\n\r\nUnveiling the Energy Vampires \r\nA methodology for debugging Software \r\nEnergy Consumption\r\n ‚úÖ ICSE 2025\r\n\r\nData Centers and Docker\r\n‚Ä¢ Containers are the most popular way to deploy apps into the cloud \r\n‚Ä¢ Base image is an important choice when building an image \r\n‚Ä¢ Criteria \r\n‚Ä¢ Linux distribution and binaries \r\n‚Ä¢ Image size \r\n‚Ä¢ Energy?\r\n35\r\n\r\nRedis energy consumption\r\n‚Ä¢ Ubuntu/Alpine base images have different energy consumption for Redis\r\n36\r\n\r\nRedis Energy Consumption\r\n‚Ä¢RQ1: What is the difference \r\nin energy consumption \r\nbetween glibc and musl? \r\n‚Ä¢RQ2: Can we use tracing \r\nto compare energy \r\nconsumption in shared \r\nlibraries?', '‚Ä¢ Improve parameter-tuning strategy.\r\n11\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ We need benchmarks. \r\n‚Ä¢ AllenAI leaderboard\u2028\r\nhttps://leaderboard.allenai.org \r\n‚Ä¢ No carbon metrics, yet \r\n‚Ä¢ Report comparable proxies for energy \r\nconsumption. \r\n‚Ä¢ ‚ö† Learning algorithms behave in a non-\r\ndeterministic \r\n‚Ä¢ ‚ö† Different data-points lead to different \r\nenergy consumption\r\n12\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ Reporting measured energy consumption \r\n‚Ä¢ + Accurate \r\n‚Ä¢ + Easy to map to carbon emissions \r\n‚Ä¢ - Hard to measure \r\n‚Ä¢ - Low replicability \r\n‚Ä¢ Reporting time / estimation based on time & hardware \r\n‚Ä¢ + Easy to measure \r\n‚Ä¢ + Correlates with energy consumption in most cases. \r\n‚Ä¢ -  Difficult to compare with measurements from other setups \r\n‚Ä¢ E.g., floating point operations (FPOs) (?) \r\n‚Ä¢ + comparable across different setups \r\n‚Ä¢ + cheap \r\n‚Ä¢ - does not factor in memory energy consumption \r\n‚Ä¢ - does not reflect carbon emissions\r\n13\r\n\r\nData-centric AI\r\n\r\nData-centric AI\r\n‚Ä¢ Emerging discipline that deals with systematically engineering data to build AI \r\nsystems. \r\n‚Ä¢ Shift from improving the training strategy to improving the data. \r\n‚Ä¢ It is better to have small but reliable datasets than large but noisy \r\ndatasets. \r\n‚Ä¢ => Improve data collection, data labelling, and data preprocessing. \r\n‚Ä¢ More about data-centric AI by Andrew Ng:\u2028\r\nhttps://www.youtube.com/watch?v=06-AZXmwHjo\r\n15\r\n\r\n\r\nGreen Data-centric AI\r\n‚Ä¢ How do different ML algorithms compare \r\nin terms of energy consumption? \r\n‚Ä¢ How does number of rows relate to the \r\nenergy consumption of ML models? \r\n‚Ä¢ How does number of features relate to \r\nthe energy consumption of ML models? \r\n‚Ä¢ What is the impact of reducing data in the \r\nperformance of the model? \r\n‚Ä¢ Method -> results -> discussion\r\n17\r\n\r\nMethod\r\n‚Ä¢ Single object of study: natural language model to detect spam messages. \r\n‚Ä¢ 6 machine learning algorithms: SVM, Decision Tree, KNN, Random Forrest, \r\nAdaBoost, Bagging Classifier. \r\n‚Ä¢ Reduce the number of rows. 10%, 20%, .., 100% \r\n‚Ä¢ Stratified random sampling (?) \r\n‚Ä¢ Reduce the number of features. 10%, 20%, .., 100% \r\n‚Ä¢ Feature importance metric based on the Chi-Square Test (Chi2) \r\n‚Ä¢ Estimate energy consumption using a RAPL-based tool. (?)\r\n18\r\n\r\n‚Ä¢ Repeat 30 times \r\n‚Ä¢ Fix random seeds \r\n‚Ä¢ ‚Ä¶ \r\n‚Ä¢ Data was not Normal => tailed Normal distribution.\r\n19\r\n(?)\r\n\r\nResults: energy consumption of algorithms\r\n\r\nResults: energy vs data shape\r\n\r\nResults: performance vs data shape\r\n\r\nDiscussion\r\n‚Ä¢ Other data properties should be investigated. \r\n‚Ä¢ E.g., data types \r\n‚Ä¢ Reporting energy data is essential. It can lead to different model selection \r\nwithout hindering model performance. \r\n‚Ä¢ There is a big opportunity in Model and Data Simplification.\r\n23\r\n\r\nData/Model Simplification\r\n‚Ä¢ (?) \r\n‚Ä¢ Data selection \r\n‚Ä¢ Data quantisation. Posit? \r\n‚Ä¢ Data distillation \r\n‚Ä¢ Coreset extraction (?) \r\n‚Ä¢ Model distillation \r\n‚Ä¢ Model quantisation \r\n‚Ä¢ Model pruning \r\n‚Ä¢ ‚Ä¶\r\n24\r\n\r\nPosit vs Float\r\nMore about this: https://spectrum.ieee.org/floating-point-numbers-posits-processor\r\nBetter for DL use cases\r\n\r\nHow can we tune \r\nlearning \r\nparameters \r\nefficiently?\r\n\r\nHyper parameter tuning\r\n‚Ä¢ When training an ML model, there are several parameters that need to be \r\ntuned. \r\n‚Ä¢ E.g., in SVM we have the Regularization parameter C, the kernel function, \r\nthe degree of the kernel function, and depending on the case, many other. \r\n‚Ä¢ The common approach revolves around grid search.', '8. Green AI\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nLu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\nCarolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl\r\n\r\n- Overview of Green AI \r\n- Large language models \r\n- Green data-centric AI \r\n- Model simplification \r\n- Hyper parameter tuning \r\n- Mixture of Experts and DeepSeek \r\n- Green AI at Meta \r\n\r\nAI\r\n‚Ä¢ Artificial Intelligence (AI) is the branch of computer science that deals with \r\nautomating tasks that typically require human intelligence. \r\n‚Ä¢ In the past years AI has been widely applied across different domains.\u2028\r\nE.g., health care, transportation, finance. \r\n‚Ä¢ To deploy AI systems, we test them against benchmarks (or validation sets). \r\n‚Ä¢ The goal is to outperform the previous existing models. \r\n‚Ä¢ E.g., in Machine Learning we usually resort to accuracy metrics. The \r\nhighest the accuracy, the better the model.\r\n3\r\n\r\nSince 2012, the amount of computing used for AI \r\ntraining has been doubling every 6 months\r\n‚Ä¢ https://epoch.ai/blog/compute-trends\r\n4\r\n\r\n‚Ä¢ To create better AI systems we are currently adding \r\n‚Ä¢ More data \r\n‚Ä¢ More experiments \r\n‚Ä¢ Larger models\r\n5\r\n\r\nThe Equation of Red AI\r\nCost(R) ‚àùE¬∑D¬∑H\r\nCost of a single (E)xample\r\nSize of (D)ataset\r\nNumber of (H)yperparameters\r\nBy Schwartz et al. (2020)\r\n\r\nIssues of Red AI\r\n‚Ä¢ High costs (hardware, electricity, data access, etc.) \r\n‚Ä¢ Limited reproducibility.  \r\n‚Ä¢ Energy consumption. \r\n‚Ä¢ Carbon emissions. \r\n‚Ä¢ SMEs can hardly be competitive. \r\n‚Ä¢ Groundbreaking AI research is mostly done by tech giants.\r\n7\r\n\r\nA few examples of Red AI\r\n‚Ä¢ Google‚Äôs BERT-large \r\n‚Ä¢ 350 million features \r\n‚Ä¢ Trained for 2.5 days using 512 TPU chips, costing $60K+ \r\n‚Ä¢ Open-GPT3 (now GPT-4/o1) \r\n‚Ä¢ 550 tonnes CO2-eq (Patterson, 2021) \r\n‚Ä¢ 175 billion features \r\n‚Ä¢ API is open but no-pretrained model is available \r\n‚Ä¢ AlphaGo \r\n‚Ä¢ 1920 CPUs, 280 GPUs, costing $35M\r\n8\r\n\r\nRed AI in Large Language Models (LLMs)\r\n‚Ä¢ OPT by Meta reports 75 tons CO2-eq (1/7 of OpenGPT‚Äôs footprint).\u2028\r\n(Also 175billion params) \r\n‚Ä¢ However, Llama 3 reported 2,290 tons of CO2-eq (7.7M GPU hours \r\ntraining ) \r\n‚Ä¢ Open science: release includes both the pretrained models and the code \r\nneeded to train and use them. \r\n‚Ä¢ DeepSeek-V3 claims ‚Äúonly‚Äù 2.78M GPU hours \r\n‚Ä¢ Bloom by Huggingface reports 25 tons, 51 when considering embodied \r\nand operational carbon footprint. (176billion params)\r\n9\r\n\r\nRed AI\r\nAccuracy: 0.999999999\r\nGreen AI\r\n‚Ä¢ Energy \r\n‚Ä¢ Time \r\n‚Ä¢ Reproducibility \r\n‚Ä¢ Reusage\r\n\r\nHow can we adopt Green AI\r\n‚Ä¢ Check whether AI is needed. \r\n‚Ä¢ Select green datacenters. \r\n‚Ä¢ Run on low carbon intensity hours. \r\n‚Ä¢ Opt for GPU-optimised solutions (?) \r\n‚Ä¢ Opt for low-power hardware (e.g., Nvidia Jetson boards) \r\n‚Ä¢ Or GPUs that provide energy metrics (e.g., NVIDIA GPUs via the nvidia-smi tool) \r\n‚Ä¢ Report energy/carbon metrics (e.g., embed in MLFlow?)', 'Lu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\n7. Green SE ‚Äì Research\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nCarolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl\r\n\r\n1. Energy patterns for mobile apps \r\n2. Carbon-aware datacenters \r\n3. Energy Regression Testing \r\n4. Debugging Energy with Docker images \r\n5. Energy Efficiency vs Code Quality \r\n\r\n‚Ä¢ While learning about these works, try to be critical about them and find their \r\npitfalls.\r\n3\r\n\r\n‚Ä¢ We have seen that measuring energy consumption is not trivial \r\n‚Ä¢ It is not practical considering that developers have other priorities above \r\nenergy efficiency \r\n‚Ä¢ At the same time, every now and then there are some efforts to improve \r\nenergy efficiency in some cases. This is time consuming and requires \r\nexpertise. \r\n‚Ä¢ How can we reuse these efforts?\r\n4\r\n\r\nEnergy Patterns for Mobile \r\nApps\r\nhttps://tqrg.github.io/energy-patterns/\r\n\r\nMethodology\r\n5. Catalog of Energy Patterns\r\n22 \r\npatterns\r\nF-droid\r\nCurated Lists\r\n1. App Collection\r\n1783 \r\napps\r\n3. Manual Refinement of Subjects of \r\nInterest\r\n1563 \r\nchanges\r\n4. Thematic Analysis\r\n431 \r\nreusable \r\nchanges\r\n2. Collect Changes With Potential Interest\r\n/.*(energy|power|battery).*/\r\n6028 \r\nchanges\r\n\r\nThematic Analysis\r\n1. Familiarization with data \r\n2. Generating initial labels \r\n3. Reviewing themes\r\n4. Defining and naming themes\r\n\r\n‚Ä¢ Energy Pattern: design pattern to improve energy efficiency.. \r\n‚Ä¢ 22 energy patterns. \r\n‚Ä¢ Each pattern is described by Context, Solution, Example, References from \r\nliterature, and Occurences (links to code changes from git repositories).\r\n8\r\n\r\nhttps://tqrg.github.io/energy-patterns\r\n\r\nDark UI Colors \r\nProvide a dark UI color theme to \r\nsave battery on devices with \r\nAMOLED screens.\r\n‚Ä¢ Context: [‚Ä¶] Apps that require heavy usage of screen can \r\nhave a substantial negative impact on battery life. \r\n‚Ä¢ Solution: Provide a UI theme with dark background colors. [‚Ä¶]\r\n‚Ä¢ Example: In a reading app, provide a theme with a dark \r\nbackground using light colors to display text. [‚Ä¶] \r\n10\r\n\r\nDark UI Colors \r\nProvide a dark UI color theme to \r\nsave battery on devices with \r\nAMOLED screens.\r\n‚Ä¢ Context: [‚Ä¶] Apps that require heavy usage of screen can \r\nhave a substantial negative impact on battery life. \r\n‚Ä¢ Solution: Provide a UI theme with dark background colors. [‚Ä¶]\r\n‚Ä¢ Example: In a reading app, provide a theme with a dark \r\nbackground using light colors to display text. [‚Ä¶] \r\n11\r\n\r\nDynamic Retry Delay\r\n‚Ä¢ Context: [‚Ä¶] In a mobile app, when a given resource is \r\nunavailable, the app will unnecessarily try to connect the resource \r\nfor a number of times, leading to unnecessary power consumption. \r\n‚Ä¢ Solution: Increase retry interval after each failed connection. [‚Ä¶]\r\n‚Ä¢ Example: Consider a mobile app that provides a news feed and \r\nthe app is not able to reach the server to collect updates. [‚Ä¶] use \r\nthe Fibonacci series to increase the time between attempts.\r\nWhenever an attempt to access a \r\nresource fails, increase the time \r\ninterval before retrying.\r\n12\r\n\r\nBatch Operations \r\n‚Ä¢ Context: Executing operations separately leads to extraneous \r\ntail energy consumptions  \r\n‚Ä¢ Solution: Bundle multiple operations in a single one. [‚Ä¶]\r\n‚Ä¢ Example: Use system provided APIs to schedule background \r\ntasks. These APIs, guarantee that device will exit sleep mode \r\nonly when there is a reasonable amount of work to do or when a \r\ngiven task is urgent.', 'computing vision, classification)\r\n\r\nA2. Adding energy metrics to LMstudio/Ollama\r\n‚Ä¢ Make energy consumption visible to users \r\nwithin local chat-interface for LLMs \r\n‚Ä¢ LMstudio/Ollama are tools for easy \r\ndeployment of LLMs \r\n‚Ä¢ Do not show energy metrics \r\n‚Ä¢ Add energy metrics to LMstudio-python \r\nor Ollama\r\nhttps://lmstudio.ai/\r\n\r\nA3. Visualizations built-in with EnergiBridge\r\n‚Ä¢ EnergiBridge simplifies energy measurement, but analysis & visualization is \r\nstill left to the user \r\n‚Ä¢ Extend the tool with well-chosen visualizations and analyses directly from the \r\nprovided data\r\n\r\nA4. Service-based version of EnergiBridge\r\n‚Ä¢ Simplify interaction & setup with EnergiBridge \r\n‚Ä¢ Service that runs independently, start/stop signals over RPC to manage \r\nexperiments \r\n‚Ä¢ Potential: create EnergiBridge interface for other prog. lang\r\n\r\nB1. Measure energy consumption of single JUnit tests\r\n‚Ä¢ We‚Äôd like to identify energy anti patterns in unit tests \r\n‚Ä¢ As a first step, we need tooling to measure and compare the energy \r\nconsumption of single unit tests \r\n‚Ä¢ Ideally including preliminary analysis looking at potential reasons for high-\r\nenergy-consuming tests\r\n\r\nB2. Study test generation energy consumption\r\n‚Ä¢ Automatic test generation mainly focuses on making strong test suites \r\n‚Ä¢ Do different techniques and configurations impact the energy consumption \r\nduring generation? \r\n‚Ä¢ Preferably focus on non-LLM test generation methods (EvoSuite, Pyguin, \r\nDSpot)\r\n\r\nB3. Detailed energy profiling of build pipelines\r\n‚Ä¢ Automatic builds have become a cornerstone of quality assurance. But how \r\nmuch energy do they even consume? \r\n‚Ä¢ Create a tool that reports on the energy consumed during the (different stages \r\nof the) whole build (compile, build, test, package, ‚Ä¶) \r\n‚Ä¢ Should be integrated with build system(s), making setup for developers easy \r\n‚Ä¢ For local setup (to enable true energy measurements)\r\n\r\nB4. Energy profiling of static analysis tools\r\n‚Ä¢ What is the energy consumption of a ""typical run"" for a few OSS projects? \r\n‚Ä¢ Does the type of analysis matter? Are certain analysis more expensive? Does \r\nthe number of rules that are activated in a static analysis tool important for the \r\nenergy consumption? \r\n‚Ä¢ Differences between static analysis tools [lower priority]\r\n\r\nB5. Tool supporting SusAF workshop / process\r\n‚Ä¢ Lead engineers through process & questions \r\n‚Ä¢ Interface to create & document the two diagrams \r\n‚Ä¢ (!) Should be easy to start using & set up \r\n‚Ä¢ You may also create a simplified version / \u2028\r\nyour favorite sustainability framework\r\nEnvironmental\r\nEconomic\r\nTechnical\r\nIndividual\r\nSocial\r\nImmediate\r\nEnabling\r\nStructural\r\nAirbnb\r\ngreater \r\nearnings\r\nincrease \r\nin rents\r\ngentrification\r\ngreater racial \r\ndisparities\r\nrent \r\nrooms\r\n5\r\n1\r\n3\r\n4\r\n2\r\n \r\n \r\n \r\n \r\n \r\n \r\nVery \r\nunlikely \r\nVery \r\nlikely \r\n\r\nB6. Dataset of government-developed OS software\r\n‚Ä¢ Governments develop & use software for supporting society\u2028\r\nOpen-source development & policies are on the rise \r\n‚Ä¢ But studying government software is difficult b/c we don‚Äôt know what is out \r\nthere\u2028\r\n‚Üí Lack of incentive to make popular \u2028\r\n‚Üí Language barriers \r\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \r\nbuildable?, open dev. history?, requirements documentation? \r\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!\r\n\r\nB7. Queue - but better for the student / TA society\r\n‚Ä¢ Requirements analysis regarding social and individual sustainability effects \r\nof Queue \r\n‚Ä¢ Other EIP / TUD used software also possible: e.g., Answers EWI \r\n‚Ä¢ Non-technical project ‚Üí proper process (workshops?', '‚Ä¢ Groundbreaking AI research is mostly done by tech giants.\r\n7\r\n\r\nA few examples of Red AI\r\n‚Ä¢ Google‚Äôs BERT-large \r\n‚Ä¢ 350 million features \r\n‚Ä¢ Trained for 2.5 days using 512 TPU chips, costing $60K+ \r\n‚Ä¢ Open-GPT3 (now GPT-4/o1) \r\n‚Ä¢ 550 tonnes CO2-eq (Patterson, 2021) \r\n‚Ä¢ 175 billion features \r\n‚Ä¢ API is open but no-pretrained model is available \r\n‚Ä¢ AlphaGo \r\n‚Ä¢ 1920 CPUs, 280 GPUs, costing $35M\r\n8\r\n\r\nRed AI in Large Language Models (LLMs)\r\n‚Ä¢ OPT by Meta reports 75 tons CO2-eq (1/7 of OpenGPT‚Äôs footprint).\u2028\r\n(Also 175billion params) \r\n‚Ä¢ However, Llama 3 reported 2,290 tons of CO2-eq (7.7M GPU hours \r\ntraining ) \r\n‚Ä¢ Open science: release includes both the pretrained models and the code \r\nneeded to train and use them. \r\n‚Ä¢ DeepSeek-V3 claims ‚Äúonly‚Äù 2.78M GPU hours \r\n‚Ä¢ Bloom by Huggingface reports 25 tons, 51 when considering embodied \r\nand operational carbon footprint. (176billion params)\r\n9\r\n\r\nRed AI\r\nAccuracy: 0.999999999\r\nGreen AI\r\n‚Ä¢ Energy \r\n‚Ä¢ Time \r\n‚Ä¢ Reproducibility \r\n‚Ä¢ Reusage\r\n\r\nHow can we adopt Green AI\r\n‚Ä¢ Check whether AI is needed. \r\n‚Ä¢ Select green datacenters. \r\n‚Ä¢ Run on low carbon intensity hours. \r\n‚Ä¢ Opt for GPU-optimised solutions (?) \r\n‚Ä¢ Opt for low-power hardware (e.g., Nvidia Jetson boards) \r\n‚Ä¢ Or GPUs that provide energy metrics (e.g., NVIDIA GPUs via the nvidia-smi tool) \r\n‚Ä¢ Report energy/carbon metrics (e.g., embed in MLFlow?) \r\n‚Ä¢ Use pre-trained models (Transfer Learning) \r\n‚Ä¢ Preprocess dataset to reduce size. \r\n‚Ä¢ Improve parameter-tuning strategy.\r\n11\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ We need benchmarks. \r\n‚Ä¢ AllenAI leaderboard\u2028\r\nhttps://leaderboard.allenai.org \r\n‚Ä¢ No carbon metrics, yet \r\n‚Ä¢ Report comparable proxies for energy \r\nconsumption. \r\n‚Ä¢ ‚ö† Learning algorithms behave in a non-\r\ndeterministic \r\n‚Ä¢ ‚ö† Different data-points lead to different \r\nenergy consumption\r\n12\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ Reporting measured energy consumption \r\n‚Ä¢ + Accurate \r\n‚Ä¢ + Easy to map to carbon emissions \r\n‚Ä¢ - Hard to measure \r\n‚Ä¢ - Low replicability \r\n‚Ä¢ Reporting time / estimation based on time & hardware \r\n‚Ä¢ + Easy to measure \r\n‚Ä¢ + Correlates with energy consumption in most cases. \r\n‚Ä¢ -  Difficult to compare with measurements from other setups \r\n‚Ä¢ E.g., floating point operations (FPOs) (?) \r\n‚Ä¢ + comparable across different setups \r\n‚Ä¢ + cheap \r\n‚Ä¢ - does not factor in memory energy consumption \r\n‚Ä¢ - does not reflect carbon emissions\r\n13\r\n\r\nData-centric AI\r\n\r\nData-centric AI\r\n‚Ä¢ Emerging discipline that deals with systematically engineering data to build AI \r\nsystems. \r\n‚Ä¢ Shift from improving the training strategy to improving the data. \r\n‚Ä¢ It is better to have small but reliable datasets than large but noisy \r\ndatasets. \r\n‚Ä¢ => Improve data collection, data labelling, and data preprocessing. \r\n‚Ä¢ More about data-centric AI by Andrew Ng:\u2028\r\nhttps://www.youtube.com/watch?v=06-AZXmwHjo\r\n15\r\n\r\n\r\nGreen Data-centric AI\r\n‚Ä¢ How do different ML algorithms compare \r\nin terms of energy consumption? \r\n‚Ä¢ How does number of rows relate to the \r\nenergy consumption of ML models? \r\n‚Ä¢ How does number of features relate to \r\nthe energy consumption of ML models? \r\n‚Ä¢ What is the impact of reducing data in the \r\nperformance of the model?', ""‚Ä¢ 6 machine learning algorithms: SVM, Decision Tree, KNN, Random Forrest, \r\nAdaBoost, Bagging Classifier. \r\n‚Ä¢ Reduce the number of rows. 10%, 20%, .., 100% \r\n‚Ä¢ Stratified random sampling (?) \r\n‚Ä¢ Reduce the number of features. 10%, 20%, .., 100% \r\n‚Ä¢ Feature importance metric based on the Chi-Square Test (Chi2) \r\n‚Ä¢ Estimate energy consumption using a RAPL-based tool. (?)\r\n18\r\n\r\n‚Ä¢ Repeat 30 times \r\n‚Ä¢ Fix random seeds \r\n‚Ä¢ ‚Ä¶ \r\n‚Ä¢ Data was not Normal => tailed Normal distribution.\r\n19\r\n(?)\r\n\r\nResults: energy consumption of algorithms\r\n\r\nResults: energy vs data shape\r\n\r\nResults: performance vs data shape\r\n\r\nDiscussion\r\n‚Ä¢ Other data properties should be investigated. \r\n‚Ä¢ E.g., data types \r\n‚Ä¢ Reporting energy data is essential. It can lead to different model selection \r\nwithout hindering model performance. \r\n‚Ä¢ There is a big opportunity in Model and Data Simplification.\r\n23\r\n\r\nData/Model Simplification\r\n‚Ä¢ (?) \r\n‚Ä¢ Data selection \r\n‚Ä¢ Data quantisation. Posit? \r\n‚Ä¢ Data distillation \r\n‚Ä¢ Coreset extraction (?) \r\n‚Ä¢ Model distillation \r\n‚Ä¢ Model quantisation \r\n‚Ä¢ Model pruning \r\n‚Ä¢ ‚Ä¶\r\n24\r\n\r\nPosit vs Float\r\nMore about this: https://spectrum.ieee.org/floating-point-numbers-posits-processor\r\nBetter for DL use cases\r\n\r\nHow can we tune \r\nlearning \r\nparameters \r\nefficiently?\r\n\r\nHyper parameter tuning\r\n‚Ä¢ When training an ML model, there are several parameters that need to be \r\ntuned. \r\n‚Ä¢ E.g., in SVM we have the Regularization parameter C, the kernel function, \r\nthe degree of the kernel function, and depending on the case, many other. \r\n‚Ä¢ The common approach revolves around grid search. The user provides a \r\nsequence of possible values for each parameter and the pipeline runs all \r\npossible combinations. \r\n‚Ä¢ Our question: Can we save energy with alternative approaches? \r\n‚Ä¢ We studied Grid Search, Random Search and Bayesian \r\nOptimisation.\r\n27\r\nTim's MSc Thesis, 2022 \r\nAccepted at CAIN‚Äô23\r\n\r\n\r\nResults\r\n29\r\nConclusions? \r\n‚Ä¢ Bayesian converges faster. \r\n‚Ä¢ No clear winner between Grid and Random\r\n\r\nDeepSeekMoE\r\n30\r\nPreprint at ArXiv, 2024 https://arxiv.org/pdf/\r\n2401.06066\r\n\r\nMixture of Experts\r\n‚Ä¢ Llama3.1 has 405B parameters, DeepSeek V3 671B \r\n‚Ä¢ Yet DeepSeek has quicker inference times and claims less energy \r\nconsumption (?) \r\n‚Ä¢ Divide the model into smaller blocks of experts \r\n‚Ä¢ Tokens get routed to certain experts based on the query \r\n‚Ä¢ Only part of the network is active during inference \r\n‚Ä¢ DeepSeek claims only 37B out of 671B parameters get active\r\n31\r\n\r\nDeepSeekMoE\r\n32\r\n\r\nDeepSeekMoE\r\n33\r\n‚Ä¢ Comparable performance to \r\nLLaMA2 7B effectively using \r\nless half the parameters \r\n‚Ä¢ Less computational power \r\n‚Ä¢ Problems (?) \r\n‚Ä¢ Still need to load all the \r\nparameters \r\n‚Ä¢ High memory -> high \r\nembodied carbon\r\n\r\nGreen AI at FacebookMeta\r\n34\r\nSustainable AI: Environmental Implications, \r\nChallenges and Opportunities (2022)\r\n\r\nCarbon footprint mapped to the AI lifecycle\r\n‚Ä¢ There are 4 main overarching stages where carbon emissions need to be isolated: data \r\ncollection, experimentation, training, inference. \r\n‚Ä¢ At Facebook, recommendation systems split energy consumption evenly between \r\ntraining and inference; text translation models have a 35%/65% split. (Operational cost) \r\n‚Ä¢ Operational/embodied cost split: 30%/70%\r\n35\r\n\r\nOpen issues according to Meta\r\n‚Ä¢ A vast portion of projects only use GPUs at 30%.\u2028\r\nShould be higher to attenuate embodied carbon."", 'p-value = 0.04\r\nOn average, version B spent less energy than version A  ‚Äî  ‚úÖ \r\nThere is statistical significance ‚Äî  ‚úÖ \r\nEffect size, percent-change is ‚âà1% ‚Äî ü§î \r\n‚ö† Do we care?\r\n(?)\r\n\r\nPractical Significance\r\n‚Ä¢ Depending on the case, a 2% improvement might be either wonderful or completely \r\nuseless. \r\n‚Ä¢ Effect size analyses help assess practical significance but might not be enough. \r\n‚Ä¢ A critical discussion always needs to be performed. Consider context and explain in what \r\nsense the effect size might be relevant. \r\n‚Ä¢ E.g.: \r\n‚Ä¢  to improve 2% in energy efficiency the code will be less readable or the user \r\nexperience is not so appealing. \r\n‚Ä¢ A particular method improves 2% but it will only be used 1% of the time. \r\n‚Ä¢ There is no particular metric or structure, but this kind of critical analysis is very important.\r\n25\r\n\r\nWhat if data is not Normal?\r\nSame approach but different tests/metrics!\r\n\r\nNon-normal data\r\n‚Ä¢ Statistical significance: non-parametric test (?) \r\n‚Ä¢ Mann-Whitney U test. Instead of looking at standard deviation or mean, it orders \r\nsamples and compares with each other. \r\n‚Ä¢ Less power than parametric-tests (?) \r\n‚Ä¢ Effect size \r\n‚Ä¢ Median difference: \r\n \r\n‚Ä¢ Percentage of pairs supporting a conclusion\u2028\r\n(i.e., # pairs where version A > version B/ total pairs) \r\n‚Ä¢ Common language effect size: \r\nŒîM\r\nU1\r\nN1N2\r\n27\r\n\r\nRecap\r\nImpossible to \r\nfix but \r\nexplainable.\r\n\r\nEnergy Efficiency Across \r\nProgramming Languages\r\nhttps://sites.google.com/view/energy-efficiency-languages\r\n29\r\nRui Pereira, Marco Couto, Francisco Ribeiro, Rui Rua, J√°come \r\nCunha, Jo√£o Paulo Fernandes, and Jo√£o Saraiva\r\n\r\n‚Ä¢ Is a faster programming language also more energy efficient? \r\n‚Ä¢ Comparing different programming languages is not an easy task. \r\n‚Ä¢ They differ in many mechanisms: \r\n‚Ä¢ Interpreted vs Compiled \r\n‚Ä¢ Optimisations at the compiler level \r\n‚Ä¢ Virtual machine \r\n‚Ä¢ Garbage collector \r\n‚Ä¢ Available libraries\r\n30\r\n\r\nResearch Questions\r\n‚Ä¢ Can we compare the energy efficiency of software languages?  \r\n‚Ä¢ Is the faster language always the most energy efficient? \r\n‚Ä¢ How does memory usage relate to energy consumption? (We don‚Äôt cover this one) \r\n‚Ä¢ Can we automatically decide what is the best programming language \r\nconsidering energy, time, and memory usage?  \r\n‚Ä¢ How do the results of our energy consumption analysis of programming \r\nlanguages gathered from rigorous performance benchmarking solutions \r\ncompare to results of average day-to-day solutions? \u2028\r\n31\r\n\r\nMethodology\r\n\r\nThe Computer Language Benchmarks Game \r\n‚Ä¢ https://benchmarksgame-team.pages.debian.net/benchmarksgame/\r\n33\r\n\r\nProblems in the Computer Language Benchmarks Game\r\n34\r\n\r\n‚Ä¢ 27 Programming languages across different paradigms  \r\n‚Ä¢ Functional (e.g., Ocaml, F#, Haskell) \r\n‚Ä¢ Imperative (e.g., C, Go, Python) \r\n‚Ä¢ Object-oriented (e.g., C++, C#, Java) \r\n‚Ä¢ Scripting (or interpretative) (e.g., JavaScript, Python, Ruby) \r\n‚Ä¢ (These are not mutual exclusive) \r\n‚Ä¢ Intel RAPL‚Äôs C library to measure energy consumption\r\n35\r\n\r\n‚Ä¢ Execute each benchmark solution 10 times. \r\n‚Ä¢ Collect energy data and timestamps. \r\n‚Ä¢ Two-minute interval between executions\r\n36\r\n\r\n\r\n\r\n\r\nCritical thinking\r\n‚Ä¢ There is no doubt this is an excellent study. Yet, as any excellent study, there‚Äôs \r\na lot we can discuss and criticise constructively. \r\n‚Ä¢ What kind of issues you see in drawing conclusions from such a table of \r\nresults?', 'Carolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nLu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\n1. Intro Class\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl\r\n\r\n1. Intro to Sustainable SE \r\n2. Intro to the course\r\n2\r\n\r\nof the electricity consumed worldwide \r\nby 2040 will stem from ICT\r\n14%\r\n\r\n4\r\nhttps://xkcd.com/1007/\r\n\r\nBuzz words\r\n‚Ä¢ Eco-friendly \r\n‚Ä¢ Climate change, action, adaption \r\n‚Ä¢ Energy efficiency \r\n‚Ä¢ Environmental-responsible \r\n‚Ä¢ Carbon-neutral; Climate-neutral; Net zero \r\n‚Ä¢ Carbon-offsetting \r\n‚Ä¢ Carbon-free \r\n‚Ä¢ Clean technology \r\n‚Ä¢ E-waste\r\n5\r\n\r\nhttps://www.menti.com/uns9d89kzn\r\nWhat is Sustainable \r\nSoftware Engineering?\r\n?\r\n6\r\n\r\nSustainable Software \r\nEngineering is‚Ä¶\r\n7\r\n‚Ä¶the discipline that studies the process of creating software systems that are able \r\nto create value in the long term without hindering its surrounding environment.\r\n\r\n8\r\nEconomical\r\nSocial\r\nTechnical\r\nIndividual\r\nEnvironmental\r\nSustainable\r\nSoftware\r\nEngineering\r\n‚≠ê\r\nTechnical\u2028\r\n‚öô\r\nEconomical\u2028\r\nüí∞\r\nSocial\u2028\r\nüë©üíºüë®üíºüë©üíºüë©üíº\r\nIndividual\u2028\r\nüë©üíª\r\nEnvironmental\u2028\r\nüå±\r\nSustainable\u2028\r\nSoftware \r\nEngineering\r\n\r\nEconomical\r\n‚Ä¢ Focused on assets, capital and added value\u2028\r\n(wealth creation, prosperity, profitability, capital \r\ninvestment, income, etc.) \r\n‚Ä¢ Nr of customers  \r\n‚Ä¢ Man-day-rate estimate \r\n‚Ä¢ Next round of funding \r\n‚Ä¢ Meet requirements in the contract\r\n9\r\n\r\nTechnical\r\n‚Ä¢ Longevity of information, systems, and infrastructure and their \r\nadequate evolution with changing surrounding conditions. \r\n‚Ä¢ Examples: \r\n‚Ä¢ Technical Debt \r\n‚Ä¢ Does it scale? \r\n‚Ä¢ Software testing \r\n‚Ä¢ Bus-factor \r\n‚Ä¢ Data integrity \r\n‚Ä¢ Innovation \r\n‚Ä¢ ‚Ä¶\r\n10\r\n\r\nIndividual\r\n‚Ä¢ Well-being of the individuals in an organisation.\u2028\r\nNote that it also includes how well individuals interact \r\nwith each other within the org. \r\n‚Ä¢ Examples: \r\n‚Ä¢ mental and physical well-being \r\n‚Ä¢ self-respect \r\n‚Ä¢ education/skills \r\n‚Ä¢ career development \r\n‚Ä¢ ‚Ä¶\r\n11\r\n\r\nSocial\r\n‚Ä¢ concerned with societal communities (groups of people, \r\norganisations) and the factors that erode trust in society. \r\n‚Ä¢ Examples: \r\n‚Ä¢ Social equity \r\n‚Ä¢ Justice \r\n‚Ä¢ Employment \r\n‚Ä¢ Democracy \r\n‚Ä¢ ‚Ä¶ \r\n‚Ä¢ Also includes compliance with policies and regulations \r\n12\r\n\r\nEnvironmental Sustainability\r\n‚Ä¢ the branch of Software Engineering that studies \r\nthe development of software that has minimal \r\nimpact in our planet throughout its whole \r\nlifecycle. \r\n‚Ä¢ Looking at software at different levels: \r\n‚Ä¢ Developing, Using, Serving, ‚Ä¶ \r\n‚Ä¢ Also includes e-waste. \r\n‚Ä¢ Almost identical to Green Software. (?)\r\n13\r\nBordallo II\r\n\r\nGreen Software\r\n‚Ä¢ Sustainability and energy efficiency. \r\n‚Ä¢ Building energy-efficient software is important also from a \r\ntechnical sustainability POV. \r\n‚Ä¢ Smartphones, smart wearables, IoT devices, etc. run on limited \r\npower resources. \r\n‚Ä¢ Developing software to these devices require energy-efficiency \r\ntesting and improvement. \r\n‚Ä¢ It also leads to environmental sustainability (e.g., less battery \r\ncycles) \r\n‚Ä¢ Important for UX (e.g., no need to walk around with power banks)\r\n14\r\n\r\nhttps://www.menti.com/uns9d89kzn\r\nWhat is the sustainability \r\ndimension you are most \r\ninterested in?\r\n?', '‚Ä¢ Comparing different programming languages is not an easy task. \r\n‚Ä¢ They differ in many mechanisms: \r\n‚Ä¢ Interpreted vs Compiled \r\n‚Ä¢ Optimisations at the compiler level \r\n‚Ä¢ Virtual machine \r\n‚Ä¢ Garbage collector \r\n‚Ä¢ Available libraries\r\n30\r\n\r\nResearch Questions\r\n‚Ä¢ Can we compare the energy efficiency of software languages?  \r\n‚Ä¢ Is the faster language always the most energy efficient? \r\n‚Ä¢ How does memory usage relate to energy consumption? (We don‚Äôt cover this one) \r\n‚Ä¢ Can we automatically decide what is the best programming language \r\nconsidering energy, time, and memory usage?  \r\n‚Ä¢ How do the results of our energy consumption analysis of programming \r\nlanguages gathered from rigorous performance benchmarking solutions \r\ncompare to results of average day-to-day solutions? \u2028\r\n31\r\n\r\nMethodology\r\n\r\nThe Computer Language Benchmarks Game \r\n‚Ä¢ https://benchmarksgame-team.pages.debian.net/benchmarksgame/\r\n33\r\n\r\nProblems in the Computer Language Benchmarks Game\r\n34\r\n\r\n‚Ä¢ 27 Programming languages across different paradigms  \r\n‚Ä¢ Functional (e.g., Ocaml, F#, Haskell) \r\n‚Ä¢ Imperative (e.g., C, Go, Python) \r\n‚Ä¢ Object-oriented (e.g., C++, C#, Java) \r\n‚Ä¢ Scripting (or interpretative) (e.g., JavaScript, Python, Ruby) \r\n‚Ä¢ (These are not mutual exclusive) \r\n‚Ä¢ Intel RAPL‚Äôs C library to measure energy consumption\r\n35\r\n\r\n‚Ä¢ Execute each benchmark solution 10 times. \r\n‚Ä¢ Collect energy data and timestamps. \r\n‚Ä¢ Two-minute interval between executions\r\n36\r\n\r\n\r\n\r\n\r\nCritical thinking\r\n‚Ä¢ There is no doubt this is an excellent study. Yet, as any excellent study, there‚Äôs \r\na lot we can discuss and criticise constructively. \r\n‚Ä¢ What kind of issues you see in drawing conclusions from such a table of \r\nresults? \r\n‚Ä¢ Is the benchmark representative of the most common usage behaviour? \r\n‚Ä¢ Are the implemented solutions representative? \r\n‚Ä¢ Does it make sense to use the average to compare energy consumption \r\nacross different problems? \r\n‚Ä¢ ‚Ä¶\r\n40\r\n\r\nReproducing with Rosetta Code \r\n‚Ä¢ Rosetta Code is a programming chrestomathy repository \r\n \r\n‚Ä¢ 900 usecases/tasks solved across 700 different programming languages \r\n‚Ä¢ Purpose: if you know a programming language we can easily learn how the \r\nsame task is solved in a language you are not familiar with.\r\n41\r\n(?)\r\n\r\n\r\n\r\nRevisiting Research Questions\r\n‚Ä¢ Can we compare the energy efficiency of software languages?  \r\n‚Ä¢ Is the faster language always the most energy efficient? \r\n‚Ä¢ How does memory usage relate to energy consumption?  \r\n‚Ä¢ Can we automatically decide what is the best programming language considering \r\nenergy, time, and memory usage?  \r\n‚Ä¢ How do the results of our energy consumption analysis of programming \r\nlanguages gathered from rigorous performance benchmarking solutions \r\ncompare to results of average day-to-day solutions?  \r\n‚Ä¢ What would happen if we cherry picked the tasks?\u2028\r\n44\r\n\r\n\r\nLu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\n3. Scientific Guide for Reliable \r\nEnergy Experiments\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nCarolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl', ""‚Ä¢ Visualise distribution shape: violin plots, histograms, density plot.\u2028\r\n \r\n‚Ä¢ Shapiro-Wilk test.\u2028\r\ndata is not normal;\u2028\r\nwe are not sure but it is okay to assume that data is \r\nnormal.\r\np-value < 0.05 ‚áí\r\np-value ‚â•0.05 ‚áí\r\n19\r\n\r\nAfter having all data ready, which artefact \r\nis more energy efficient(?) \r\nFirst approach: compare sample means. \r\n‚ö† assuming normal distribution\r\n\r\nStatistical significance\r\n‚Ä¢ Even if, on average, one artefact has lower \r\nenergy consumption than other,  it might be just \r\na random difference. \r\n‚Ä¢ When we extract a sample from a normal \r\ndistribution it will never be the exact same \r\n‚Ä¢ Statistical significance tests help you \r\nunderstand the differences in the average are \r\nconclusive/significant or inconclusive/\r\ninsignificant.\r\n21\r\n‚ö† assuming normal distribution\r\n\r\nStatistical significance test\r\n‚Ä¢ Two-sided parametric test Welch‚Äôs t-test. \r\n‚Ä¢ Less known alternative to student‚Äôs t-test.\r\n22\r\nWelch‚Äôs t-test in Python\r\nfrom scipy.stats import ttest_ind \r\n_,pvalue = ttest_ind(sample_a, sample_b, \r\n                     equal_var=False, \r\n                     alternative='two-sided')\r\n(?)\r\n‚ö† assuming normal distribution\r\n\r\nEffect Size analysis\r\n‚Ä¢ Now that we know that results are statistically significant we need to \r\nmeasure the difference between the two samples. \r\n‚Ä¢ Mean difference: \r\n \r\n‚Ä¢ Percent change: \r\n \r\n‚Ä¢ Cohen‚Äôs d (informal definition: mean difference normalized by a combined \r\nstandard deviation): \r\nŒî¬Øx\r\nxB ‚àíxA\r\nxA\r\n√ó 100 % = Œî¬Øx\r\nxA\r\n√ó 100 %\r\nŒî¬Øx\r\n1\r\n2\r\ns21 + s22\r\n23\r\n‚ö† assuming normal distribution\r\n\r\nImagine that version A spends 70J and \r\nversion B spends 69J with a \r\n.\r\np-value = 0.04\r\nOn average, version B spent less energy than version A  ‚Äî  ‚úÖ \r\nThere is statistical significance ‚Äî  ‚úÖ \r\nEffect size, percent-change is ‚âà1% ‚Äî ü§î \r\n‚ö† Do we care?\r\n(?)\r\n\r\nPractical Significance\r\n‚Ä¢ Depending on the case, a 2% improvement might be either wonderful or completely \r\nuseless. \r\n‚Ä¢ Effect size analyses help assess practical significance but might not be enough. \r\n‚Ä¢ A critical discussion always needs to be performed. Consider context and explain in what \r\nsense the effect size might be relevant. \r\n‚Ä¢ E.g.: \r\n‚Ä¢  to improve 2% in energy efficiency the code will be less readable or the user \r\nexperience is not so appealing. \r\n‚Ä¢ A particular method improves 2% but it will only be used 1% of the time. \r\n‚Ä¢ There is no particular metric or structure, but this kind of critical analysis is very important.\r\n25\r\n\r\nWhat if data is not Normal?\r\nSame approach but different tests/metrics!\r\n\r\nNon-normal data\r\n‚Ä¢ Statistical significance: non-parametric test (?) \r\n‚Ä¢ Mann-Whitney U test. Instead of looking at standard deviation or mean, it orders \r\nsamples and compares with each other. \r\n‚Ä¢ Less power than parametric-tests (?) \r\n‚Ä¢ Effect size \r\n‚Ä¢ Median difference: \r\n \r\n‚Ä¢ Percentage of pairs supporting a conclusion\u2028\r\n(i.e., # pairs where version A > version B/ total pairs) \r\n‚Ä¢ Common language effect size: \r\nŒîM\r\nU1\r\nN1N2\r\n27\r\n\r\nRecap\r\nImpossible to \r\nfix but \r\nexplainable."", 'Carbon-free giants\r\n‚Ä¢ Google, Microsoft, Meta/Facebook want to be carbon free by 2030 \r\n‚Ä¢ Carbon free is different from carbon neutral \r\n‚Ä¢ Green IT experts are needed to meet these goals\r\n23\r\n\r\n\r\nRebound effect*\r\n‚Ä¢ Energy consumption decreases ‚Üì‚Üì but demand also increases ‚Üë‚Üë. \r\n‚Ä¢ *a.k.a. Jevons Paradox in economics; Downs‚ÄìThomson paradox in\xa0mobility.\r\nEnergy per prompt\r\nPrompts\r\n100\r\n80\r\n30\r\n38\r\nChat \r\nGPT\r\n‚ÄúEnergy-efficient‚Äù \r\nChat GPT\r\n0\r\n\r\nIs sustainability an\u2028\r\nethical issue?\r\n‚Ä¢ Climate change is more likely to affect the \r\npoorest countries. \r\n‚Ä¢ Less financial resources to adapt \r\n‚Ä¢ Climate-impact does not necessarily affect \r\npolluting countries. \r\n‚Ä¢ Poorest countries have contributed less to the \r\nclimate change. \r\n‚Ä¢ We need to figure out how to do more using \r\nless resources.\r\n26\r\n\r\nMorality ‚â† Moralising\r\n‚Ä¢ We should not use climate action as a \r\nshaming weapon \r\n‚Ä¢ Climate action should be agnostic of political \r\nviews, ideology, social status, etc. \r\n‚Ä¢ We need everyone to take action!\r\n27\r\n\r\nWhy?\r\n‚Ä¢ Throughout your career you might: \r\n‚Ä¢ Design/maintain/contract data centers \r\n‚Ä¢ Set up operations/devops \r\n‚Ä¢ Develop AI for IoT devices \r\n‚Ä¢ Be the next CEO/CTO of a software company \r\n‚Ä¢ Sustainability can be your main role: \r\n‚Ä¢ Green Software Developer \r\n‚Ä¢ Sustainability Consultant \r\n‚Ä¢ Green Advocate  \r\n‚Ä¢ Founder of a Green Tech startup (B2B?)\r\n28\r\n\r\nFormat of classes\r\n‚Ä¢ In-person. \r\n‚Ä¢ Collegerama recordings. \r\n‚Ä¢ Lectures and Labs. \r\n‚Ä¢ Guest lectures. \r\n‚Ä¢ Steering meetings (after week 5, new schedule)\r\n29\r\n\r\nFormat of classes\r\n‚Ä¢ There‚Äôs no exam in this course. It‚Äôs more important that we learn how to \r\ndiscuss this topic and come up with new ideas than learning all the theory. \r\nCritical thinking over checkboxes. \r\n‚Ä¢ Mix of content and discussion \r\n‚Ä¢ Ultimately, the lectures aim to give you food for thought and the necessary \r\nknowledge to excel in Project 2. (We will talk about it later)\r\n30\r\n\r\nhttps://luiscruz.github.io/course_sustainableSE/\r\n31\r\nContent of the course üëá\r\n\r\n32\r\nhttps://mattermost.tudelft.nl/signup_user_complete/?id=1nj9tk6usjf8xmsws8wpq3s5uy&md=link&sbr=su\r\n\r\nProject 1\r\n‚Ä¢ Goal: Measure the energy consumption of software applications. \r\n‚Ä¢ Approach: energy measurement tools; use case testing. \r\n‚Ä¢ Deliverable: blog-style report (approx. 2500 words) \r\n‚Ä¢ Deadline: Week 3, Feb 28, 2025 \r\n‚Ä¢ Group size: 4‚Äì5\r\n33\r\n\r\nProject 2\r\n‚Ä¢ Goal: Create a solution/tool/technique that helps building green software. (You \r\ncan come up with your own idea or choose one from a list of suggestions). \r\n‚Ä¢ Approach: open-source software development; literature review. \r\n‚Ä¢ Deliverable: library/tool/app; paper; presentation. \r\n‚Ä¢ Two deadlines:\u2028\r\n1. Paper and software: Week 8, April 4, 2025\u2028\r\n2. Presentation: Week 9, April 11, 2025 \r\n‚Ä¢ Group size: 4‚Äì5\r\n34\r\n\r\nGuest Lectures\r\nNergis T√∂men \r\nComputer Vision lab | TU Delft \r\nWeek 4, Wed, Mar 5, 2025\r\n35\r\n\r\nCommunity \r\nHow to get involved?', '‚Ä¢ Examples: \r\n‚Ä¢ Technical Debt \r\n‚Ä¢ Does it scale? \r\n‚Ä¢ Software testing \r\n‚Ä¢ Bus-factor \r\n‚Ä¢ Data integrity \r\n‚Ä¢ Innovation \r\n‚Ä¢ ‚Ä¶\r\n10\r\n\r\nIndividual\r\n‚Ä¢ Well-being of the individuals in an organisation.\u2028\r\nNote that it also includes how well individuals interact \r\nwith each other within the org. \r\n‚Ä¢ Examples: \r\n‚Ä¢ mental and physical well-being \r\n‚Ä¢ self-respect \r\n‚Ä¢ education/skills \r\n‚Ä¢ career development \r\n‚Ä¢ ‚Ä¶\r\n11\r\n\r\nSocial\r\n‚Ä¢ concerned with societal communities (groups of people, \r\norganisations) and the factors that erode trust in society. \r\n‚Ä¢ Examples: \r\n‚Ä¢ Social equity \r\n‚Ä¢ Justice \r\n‚Ä¢ Employment \r\n‚Ä¢ Democracy \r\n‚Ä¢ ‚Ä¶ \r\n‚Ä¢ Also includes compliance with policies and regulations \r\n12\r\n\r\nEnvironmental Sustainability\r\n‚Ä¢ the branch of Software Engineering that studies \r\nthe development of software that has minimal \r\nimpact in our planet throughout its whole \r\nlifecycle. \r\n‚Ä¢ Looking at software at different levels: \r\n‚Ä¢ Developing, Using, Serving, ‚Ä¶ \r\n‚Ä¢ Also includes e-waste. \r\n‚Ä¢ Almost identical to Green Software. (?)\r\n13\r\nBordallo II\r\n\r\nGreen Software\r\n‚Ä¢ Sustainability and energy efficiency. \r\n‚Ä¢ Building energy-efficient software is important also from a \r\ntechnical sustainability POV. \r\n‚Ä¢ Smartphones, smart wearables, IoT devices, etc. run on limited \r\npower resources. \r\n‚Ä¢ Developing software to these devices require energy-efficiency \r\ntesting and improvement. \r\n‚Ä¢ It also leads to environmental sustainability (e.g., less battery \r\ncycles) \r\n‚Ä¢ Important for UX (e.g., no need to walk around with power banks)\r\n14\r\n\r\nhttps://www.menti.com/uns9d89kzn\r\nWhat is the sustainability \r\ndimension you are most \r\ninterested in?\r\n?\r\n15\r\n\r\nEconomical sustainability tops the environment\r\n‚Ä¢ In general, a software project will not survive if it‚Äôs not economical \r\nsustainable \r\n‚Ä¢ Yet, a project can survive even if it is not environmental sustainable \r\n‚Ä¢ The mindset is changing! \r\n‚Ä¢ Software consumers have started to worry about the climate impact \r\nof their behaviour as users. \r\n‚Ä¢ Being environmentally sustainable is now an important competitive \r\nfactor \r\n‚Ä¢ Marketing teams are already using all eco-friendly labels. Technical \r\nteams are not there yet, though. \r\n‚Ä¢ It‚Äôs easier said than done!\r\n$\r\n16\r\n\r\nGreen Washing\r\n‚Ä¢ Deceptively use marketing techniques to \r\nclaim being eco-friendly. \r\n‚Ä¢ Opting for green-coloured designs. \r\n‚Ä¢ Red/orange is usually perceived as \r\ntasty. \r\n‚Ä¢ Green is perceived as eco-friendly. \r\n‚Ä¢ The VW case. (?)\r\n17\r\n\r\nThe VW scandal\r\nGreenwashing\r\n‚Ä¢ Used software to cheat on vehicle emissions \r\ntests. \r\n‚Ä¢ The vehicle‚Äôs software could detect whether they \r\nwere being tested, changing the performance \r\naccordingly to improve results. \r\n‚Ä¢ Affected 11M cars worldwide, 8M in Europe.\r\n18\r\n\r\nHow can we drive sustainability \r\nin the SE industry?\r\n\r\nGreen Procurement\r\n‚Ä¢ Customers decide on providers that share their values \r\n‚Ä¢ This is currently the main trigger reason why organisations \r\nworry about Sustainability and Green Software. \r\n‚Ä¢ Examples of green procurement: \r\n‚Ä¢ Customers that only buy green services/products \r\n‚Ä¢ Companies that only use green providers \r\n‚Ä¢ Developers that only work for green companies \r\n‚Ä¢ Green procurement makes environmental sustainability \r\nessential for economical sustainability.\r\n20\r\n\r\nSustainability via compliance\r\n‚Ä¢ EU wants to be carbon neutral by 2030 \r\n‚Ä¢ This also affects the ICT sector. Estimated to impact \r\n14% of the global carbon footprint by 2040. \r\n‚Ä¢ Some initiatives are already being negotiated. \r\n‚Ä¢ Extending the smartphone lifetime to 7 years. \r\n‚Ä¢ Right-to-repair movement. https://repair.eu \r\n‚Ä¢ Making IT services relying on clean energy more \r\naccessible (e.g., less taxes).\r\n21\r\n\r\nSoftware for Sustainability \r\n‚Ä¢ We are not covering it in this course.']","['<1-hop>\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy eÔ¨Éciency using static code analysis.\n‚Ä¢ We don‚Äôt need an accurate value.\n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.\n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27', '<2-hop>\n\nWhy?\n‚Ä¢ Throughout your career you might:\n‚Ä¢ Design/maintain/contract data centers\n‚Ä¢ Set up operations/devops\n‚Ä¢ Develop AI for IoT devices\n‚Ä¢ Be the next CEO/CTO of a software company\n‚Ä¢ Sustainability can be your main role:\n‚Ä¢ Green Software Developer\n‚Ä¢ Sustainability Consultant\n‚Ä¢ Green Advocate \n‚Ä¢ Founder of a Green Tech startup (B2B?)\n28', '<1-hop>\n\nC6 - Green Shift Left\n‚Ä¢ Estimate energy eÔ¨Éciency using static code analysis.\n‚Ä¢ We don‚Äôt need an accurate value.\n‚Ä¢ It is useful to know which code is more likely to \nintroduce energy hotspots and that should be \nreviewed with more attention.\n‚Ä¢ Can be scoped to a particular domain (react, php, data \nscience, web, etc., etc.)\n27', '<2-hop>\n\nWhy?\n‚Ä¢ Throughout your career you might:\n‚Ä¢ Design/maintain/contract data centers\n‚Ä¢ Set up operations/devops\n‚Ä¢ Develop AI for IoT devices\n‚Ä¢ Be the next CEO/CTO of a software company\n‚Ä¢ Sustainability can be your main role:\n‚Ä¢ Green Software Developer\n‚Ä¢ Sustainability Consultant\n‚Ä¢ Green Advocate \n‚Ä¢ Founder of a Green Tech startup (B2B?)\n28']","The sources provided do not directly address the use of static code analysis in data science projects for designing and optimizing more sustainable data centers. However, I can provide some insights based on general knowledge.

Static code analysis can contribute to the sustainability of data centers by identifying inefficient code that may lead to higher energy consumption. By optimizing code for energy efficiency, data centers can reduce their overall power usage, which is a significant factor in their environmental impact. This can involve detecting energy hotspots in the code that require more computational resources and optimizing them to be more efficient. Additionally, static code analysis can help ensure that software is scalable and maintainable, which can lead to longer software lifecycles and less frequent need for resource-intensive updates or replacements. This contributes to the sustainability of data centers by reducing the need for additional hardware and the associated energy consumption.","The use of static code analysis in data science projects contributes to the design and optimization of more sustainable data centers by identifying energy hotspots within the code. This process allows developers to focus on reviewing and optimizing sections of code that are more likely to introduce energy inefficiencies. By doing so, it supports the broader goal of creating more energy-efficient systems, which is crucial for the sustainable operation of data centers. This approach aligns with the growing need for green software development practices, where professionals can play roles such as green software developers or sustainability consultants, ensuring that energy efficiency is a key consideration throughout the software lifecycle.",0.99999999995,1.0,,0.4,,0.9794771422599027
How reduce risk and reduce size in software engineering?,"['8. Green AI\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nLu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\nCarolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl\r\n\r\n- Overview of Green AI \r\n- Large language models \r\n- Green data-centric AI \r\n- Model simplification \r\n- Hyper parameter tuning \r\n- Mixture of Experts and DeepSeek \r\n- Green AI at Meta \r\n\r\nAI\r\n‚Ä¢ Artificial Intelligence (AI) is the branch of computer science that deals with \r\nautomating tasks that typically require human intelligence. \r\n‚Ä¢ In the past years AI has been widely applied across different domains.\u2028\r\nE.g., health care, transportation, finance. \r\n‚Ä¢ To deploy AI systems, we test them against benchmarks (or validation sets). \r\n‚Ä¢ The goal is to outperform the previous existing models. \r\n‚Ä¢ E.g., in Machine Learning we usually resort to accuracy metrics. The \r\nhighest the accuracy, the better the model.\r\n3\r\n\r\nSince 2012, the amount of computing used for AI \r\ntraining has been doubling every 6 months\r\n‚Ä¢ https://epoch.ai/blog/compute-trends\r\n4\r\n\r\n‚Ä¢ To create better AI systems we are currently adding \r\n‚Ä¢ More data \r\n‚Ä¢ More experiments \r\n‚Ä¢ Larger models\r\n5\r\n\r\nThe Equation of Red AI\r\nCost(R) ‚àùE¬∑D¬∑H\r\nCost of a single (E)xample\r\nSize of (D)ataset\r\nNumber of (H)yperparameters\r\nBy Schwartz et al. (2020)\r\n\r\nIssues of Red AI\r\n‚Ä¢ High costs (hardware, electricity, data access, etc.) \r\n‚Ä¢ Limited reproducibility.  \r\n‚Ä¢ Energy consumption. \r\n‚Ä¢ Carbon emissions. \r\n‚Ä¢ SMEs can hardly be competitive. \r\n‚Ä¢ Groundbreaking AI research is mostly done by tech giants.\r\n7\r\n\r\nA few examples of Red AI\r\n‚Ä¢ Google‚Äôs BERT-large \r\n‚Ä¢ 350 million features \r\n‚Ä¢ Trained for 2.5 days using 512 TPU chips, costing $60K+ \r\n‚Ä¢ Open-GPT3 (now GPT-4/o1) \r\n‚Ä¢ 550 tonnes CO2-eq (Patterson, 2021) \r\n‚Ä¢ 175 billion features \r\n‚Ä¢ API is open but no-pretrained model is available \r\n‚Ä¢ AlphaGo \r\n‚Ä¢ 1920 CPUs, 280 GPUs, costing $35M\r\n8\r\n\r\nRed AI in Large Language Models (LLMs)\r\n‚Ä¢ OPT by Meta reports 75 tons CO2-eq (1/7 of OpenGPT‚Äôs footprint).\u2028\r\n(Also 175billion params) \r\n‚Ä¢ However, Llama 3 reported 2,290 tons of CO2-eq (7.7M GPU hours \r\ntraining ) \r\n‚Ä¢ Open science: release includes both the pretrained models and the code \r\nneeded to train and use them. \r\n‚Ä¢ DeepSeek-V3 claims ‚Äúonly‚Äù 2.78M GPU hours \r\n‚Ä¢ Bloom by Huggingface reports 25 tons, 51 when considering embodied \r\nand operational carbon footprint. (176billion params)\r\n9\r\n\r\nRed AI\r\nAccuracy: 0.999999999\r\nGreen AI\r\n‚Ä¢ Energy \r\n‚Ä¢ Time \r\n‚Ä¢ Reproducibility \r\n‚Ä¢ Reusage\r\n\r\nHow can we adopt Green AI\r\n‚Ä¢ Check whether AI is needed. \r\n‚Ä¢ Select green datacenters. \r\n‚Ä¢ Run on low carbon intensity hours. \r\n‚Ä¢ Opt for GPU-optimised solutions (?) \r\n‚Ä¢ Opt for low-power hardware (e.g., Nvidia Jetson boards) \r\n‚Ä¢ Or GPUs that provide energy metrics (e.g., NVIDIA GPUs via the nvidia-smi tool) \r\n‚Ä¢ Report energy/carbon metrics (e.g., embed in MLFlow?)', ""‚Ä¢ Our question: Can we save energy with alternative approaches? \r\n‚Ä¢ We studied Grid Search, Random Search and Bayesian \r\nOptimisation.\r\n27\r\nTim's MSc Thesis, 2022 \r\nAccepted at CAIN‚Äô23\r\n\r\n\r\nResults\r\n29\r\nConclusions? \r\n‚Ä¢ Bayesian converges faster. \r\n‚Ä¢ No clear winner between Grid and Random\r\n\r\nDeepSeekMoE\r\n30\r\nPreprint at ArXiv, 2024 https://arxiv.org/pdf/\r\n2401.06066\r\n\r\nMixture of Experts\r\n‚Ä¢ Llama3.1 has 405B parameters, DeepSeek V3 671B \r\n‚Ä¢ Yet DeepSeek has quicker inference times and claims less energy \r\nconsumption (?) \r\n‚Ä¢ Divide the model into smaller blocks of experts \r\n‚Ä¢ Tokens get routed to certain experts based on the query \r\n‚Ä¢ Only part of the network is active during inference \r\n‚Ä¢ DeepSeek claims only 37B out of 671B parameters get active\r\n31\r\n\r\nDeepSeekMoE\r\n32\r\n\r\nDeepSeekMoE\r\n33\r\n‚Ä¢ Comparable performance to \r\nLLaMA2 7B effectively using \r\nless half the parameters \r\n‚Ä¢ Less computational power \r\n‚Ä¢ Problems (?) \r\n‚Ä¢ Still need to load all the \r\nparameters \r\n‚Ä¢ High memory -> high \r\nembodied carbon\r\n\r\nGreen AI at FacebookMeta\r\n34\r\nSustainable AI: Environmental Implications, \r\nChallenges and Opportunities (2022)\r\n\r\nCarbon footprint mapped to the AI lifecycle\r\n‚Ä¢ There are 4 main overarching stages where carbon emissions need to be isolated: data \r\ncollection, experimentation, training, inference. \r\n‚Ä¢ At Facebook, recommendation systems split energy consumption evenly between \r\ntraining and inference; text translation models have a 35%/65% split. (Operational cost) \r\n‚Ä¢ Operational/embodied cost split: 30%/70%\r\n35\r\n\r\nOpen issues according to Meta\r\n‚Ä¢ A vast portion of projects only use GPUs at 30%.\u2028\r\nShould be higher to attenuate embodied carbon.\r\n36\r\nBased on 10K AI projects\r\n\r\nData Jan\r\nInformed Adaptation\r\nData Feb\r\nData Mar\r\nData Apr\r\nData May\r\n‚Ä¶\r\n~Data Dec\r\n~Data Dec\r\nData Jan\r\nData Feb\r\nData Mar\r\nData Apr\r\nData May\r\n‚Ä¶\r\nModel update Model update Model update\r\nCheck if \r\ndata change\r\nCheck if \r\ndata change\r\nCheck if \r\ndata change\r\nModel update\r\nBlind Adaptation\r\nThe AI Model will be \r\nupdated fewer times and \r\nonly when necessary.\r\nKnow when to retrain models\r\nNeither too early nor too late\r\n37\r\nAdaptation Techniques\r\n?\r\n\r\nGreen Architectural Tactics for ML-Enabled \r\nSystem\r\n38\r\nICSE-SEIS 2024\r\n\r\nArchitectural tactics\r\n39\r\n\r\nData-centric\r\n40\r\n‚Ä¢ Reduce data size \r\n‚Ä¢ Sampling \r\n‚Ä¢ Dimensionality reduction \r\n‚Ä¢ Quantization\r\n\r\nAlgorithm Design\r\n41\r\n‚Ä¢ Carefully select your algorithm \r\n‚Ä¢ You don‚Äôt need the fanciest \r\ntechniques\r\n\r\nModel Optimization\r\n42\r\n‚Ä¢ Add energy to training parameters \r\n‚Ä¢ Reduce FLOPs \r\n‚Ä¢ Pruning, sparsity \r\n‚Ä¢  Take advantage of existing models\r\n\r\nModel Training\r\n43\r\n‚Ä¢ Quantization\r\n‚Ä¢ SAVE TRAINING PROGRESS\r\n\r\nModel Deployment\r\n44\r\n‚Ä¢ Distributed deployment \r\n‚Ä¢ Energy efficient hardware and \r\nconfigurations\r\n\r\nModel Management\r\n45\r\n‚Ä¢ Reuse the model as much as possible \r\n\r\nRethinking the Architecture: Spiking Neural Networks\r\n46\r\n\r\nRethinking the Architecture: Spiking Neural Networks\r\n47\r\n\r\nSELF Lab\r\n48\r\n\r\nrecap"", 'Lu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\n7. Green SE ‚Äì Research\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nCarolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl\r\n\r\n1. Energy patterns for mobile apps \r\n2. Carbon-aware datacenters \r\n3. Energy Regression Testing \r\n4. Debugging Energy with Docker images \r\n5. Energy Efficiency vs Code Quality \r\n\r\n‚Ä¢ While learning about these works, try to be critical about them and find their \r\npitfalls.\r\n3\r\n\r\n‚Ä¢ We have seen that measuring energy consumption is not trivial \r\n‚Ä¢ It is not practical considering that developers have other priorities above \r\nenergy efficiency \r\n‚Ä¢ At the same time, every now and then there are some efforts to improve \r\nenergy efficiency in some cases. This is time consuming and requires \r\nexpertise. \r\n‚Ä¢ How can we reuse these efforts?\r\n4\r\n\r\nEnergy Patterns for Mobile \r\nApps\r\nhttps://tqrg.github.io/energy-patterns/\r\n\r\nMethodology\r\n5. Catalog of Energy Patterns\r\n22 \r\npatterns\r\nF-droid\r\nCurated Lists\r\n1. App Collection\r\n1783 \r\napps\r\n3. Manual Refinement of Subjects of \r\nInterest\r\n1563 \r\nchanges\r\n4. Thematic Analysis\r\n431 \r\nreusable \r\nchanges\r\n2. Collect Changes With Potential Interest\r\n/.*(energy|power|battery).*/\r\n6028 \r\nchanges\r\n\r\nThematic Analysis\r\n1. Familiarization with data \r\n2. Generating initial labels \r\n3. Reviewing themes\r\n4. Defining and naming themes\r\n\r\n‚Ä¢ Energy Pattern: design pattern to improve energy efficiency.. \r\n‚Ä¢ 22 energy patterns. \r\n‚Ä¢ Each pattern is described by Context, Solution, Example, References from \r\nliterature, and Occurences (links to code changes from git repositories).\r\n8\r\n\r\nhttps://tqrg.github.io/energy-patterns\r\n\r\nDark UI Colors \r\nProvide a dark UI color theme to \r\nsave battery on devices with \r\nAMOLED screens.\r\n‚Ä¢ Context: [‚Ä¶] Apps that require heavy usage of screen can \r\nhave a substantial negative impact on battery life. \r\n‚Ä¢ Solution: Provide a UI theme with dark background colors. [‚Ä¶]\r\n‚Ä¢ Example: In a reading app, provide a theme with a dark \r\nbackground using light colors to display text. [‚Ä¶] \r\n10\r\n\r\nDark UI Colors \r\nProvide a dark UI color theme to \r\nsave battery on devices with \r\nAMOLED screens.\r\n‚Ä¢ Context: [‚Ä¶] Apps that require heavy usage of screen can \r\nhave a substantial negative impact on battery life. \r\n‚Ä¢ Solution: Provide a UI theme with dark background colors. [‚Ä¶]\r\n‚Ä¢ Example: In a reading app, provide a theme with a dark \r\nbackground using light colors to display text. [‚Ä¶] \r\n11\r\n\r\nDynamic Retry Delay\r\n‚Ä¢ Context: [‚Ä¶] In a mobile app, when a given resource is \r\nunavailable, the app will unnecessarily try to connect the resource \r\nfor a number of times, leading to unnecessary power consumption. \r\n‚Ä¢ Solution: Increase retry interval after each failed connection. [‚Ä¶]\r\n‚Ä¢ Example: Consider a mobile app that provides a news feed and \r\nthe app is not able to reach the server to collect updates. [‚Ä¶] use \r\nthe Fibonacci series to increase the time between attempts.\r\nWhenever an attempt to access a \r\nresource fails, increase the time \r\ninterval before retrying.\r\n12\r\n\r\nBatch Operations \r\n‚Ä¢ Context: Executing operations separately leads to extraneous \r\ntail energy consumptions  \r\n‚Ä¢ Solution: Bundle multiple operations in a single one. [‚Ä¶]\r\n‚Ä¢ Example: Use system provided APIs to schedule background \r\ntasks. These APIs, guarantee that device will exit sleep mode \r\nonly when there is a reasonable amount of work to do or when a \r\ngiven task is urgent.', '[‚Ä¶]\r\n13\r\n\r\nAvoid Extraneous Graphics and \r\nAnimations  \r\n‚Ä¢ Context: Mobile apps that feature impressive graphics \r\nand animations. [‚Ä¶] \r\n‚Ä¢ Solution: Study the importance of graphics and \r\nanimations to the user experience and reduce them when \r\napplicable. [‚Ä¶]\r\n‚Ä¢ Example: Resort to low frame rates for animations when \r\npossible. \r\nDespite being important to improve user experience, graphics \r\nand animations are battery intensive and should be used with \r\nmoderation.  \r\n14\r\n\r\nEnergy Patterns are \r\nmore Frequent\r\nin Android Apps\r\n\r\nExample case: Nextcloud\r\nFOSS\r\n\r\nExample case: Nextcloud\r\n‚Ä¢ Users complain that sometimes they go on a trip and  Nextcloud drains their \r\nbattery. Users consider uninstalling the app when battery life is essential. \r\n‚Ä¢ File sync can be energy-greedy. Send large files to the server, long 3G/4G data connections. \r\n‚Ä¢ It is mostly used for backup. No real-time collaboration is needed. \r\n‚Ä¢ Energy requirements vary depending on context and user. Some days you really \r\nneed all the battery you can get. \r\n‚Ä¢ https://github.com/nextcloud/android/commit/\r\n8bc432027e0d33e8043cf40192203203a40ca29c\r\nSolutions?\r\n17\r\n\r\nExample case: K-9 mail\r\n18\r\n\r\nExample case: K-9 mail\r\n19\r\nSolutions?\r\n‚Ä¢ Some users noticed that K-9 mail was spending more energy than usual. üôâ \r\n‚Ä¢ A user that was having issues with a personal mail server  noticed that K-9 \r\nmail was the one of the most energy-greedy apps. IMAP IDLE protocol for real-time \r\nnotifications. \r\n‚Ä¢ When a connection is not possible, the app automatically retries later. \r\n‚Ä¢ https://github.com/k9mail/k-9/commit/\r\n86f3b28f79509d1a4d613eb39f60603e08579ea3\r\n\r\nEcoAndroid\r\n‚Ä¢ Plugin for IntelliJ (Android Studio) \r\n‚Ä¢ Dynamic Retry Delay \r\n‚Ä¢ Push Over Poll \r\n‚Ä¢ Reduce Size \r\n‚Ä¢ Cache \r\n‚Ä¢ Avoid Graphics and Animations\r\n20\r\n\r\nCarbon-Aware Computing for \r\nDatacenters \r\nhttps://sites.google.com/view/energy-efficiency-languages\r\n21\r\nAna Radovanovic ÃÅ, Ross Koningstein, Ian Schneider, Bokan \r\nChen, Alexandre Duarte, Binz Roy, Diyue Xiao, Maya \r\nHaridasan, Patrick Hung, Nick Care, Saurav Talukdar, Eric \r\nMullen, Kendal Smith, MariEllen Cottman, and Walfredo Cirne \r\n\r\n\r\n‚Ä¢ Google‚Äôs Carbon-Intelligent Computing System (CICS) \r\n‚Ä¢ Main idea: use carbon-intensity data to shift datacenter jobs in time \r\n‚Ä¢ Typically, job schedulers use a metric of cluster capacity to schedule a job in \r\na particular cluster. \r\n‚Ä¢ CICS overrides this metric with the virtual capacity curve (VCC) that \r\nfactors in Carbon intensity \r\n‚Ä¢ When a new job comes in, the scheduler estimates its CPU load and power \r\nusage and assigns it to a cluster if the VCC is not exceeded.\r\n23\r\n\r\n‚Ä¢ Jobs are divided between flexible and inflexible. \r\n‚Ä¢ Flexible load is considered shapeable/shiftable as long as its total daily \r\ncompute (CPU) demand is preserved \r\n‚Ä¢ The system needs to consider that, while running a job, the virtual capacity \r\ncurve (VCC) might drop. Hence, this job should not start in the first place. \r\n‚Ä¢ They forecast VCC for the next day\r\n24\r\n\r\n\r\nVirtual Cluster Capacity (VCC)\r\n‚Ä¢ Aims at reducing the peak load at carbon intensive hours but in total it should allow for the \r\nsome amount of daily computation!', '‚Ä¢ Groundbreaking AI research is mostly done by tech giants.\r\n7\r\n\r\nA few examples of Red AI\r\n‚Ä¢ Google‚Äôs BERT-large \r\n‚Ä¢ 350 million features \r\n‚Ä¢ Trained for 2.5 days using 512 TPU chips, costing $60K+ \r\n‚Ä¢ Open-GPT3 (now GPT-4/o1) \r\n‚Ä¢ 550 tonnes CO2-eq (Patterson, 2021) \r\n‚Ä¢ 175 billion features \r\n‚Ä¢ API is open but no-pretrained model is available \r\n‚Ä¢ AlphaGo \r\n‚Ä¢ 1920 CPUs, 280 GPUs, costing $35M\r\n8\r\n\r\nRed AI in Large Language Models (LLMs)\r\n‚Ä¢ OPT by Meta reports 75 tons CO2-eq (1/7 of OpenGPT‚Äôs footprint).\u2028\r\n(Also 175billion params) \r\n‚Ä¢ However, Llama 3 reported 2,290 tons of CO2-eq (7.7M GPU hours \r\ntraining ) \r\n‚Ä¢ Open science: release includes both the pretrained models and the code \r\nneeded to train and use them. \r\n‚Ä¢ DeepSeek-V3 claims ‚Äúonly‚Äù 2.78M GPU hours \r\n‚Ä¢ Bloom by Huggingface reports 25 tons, 51 when considering embodied \r\nand operational carbon footprint. (176billion params)\r\n9\r\n\r\nRed AI\r\nAccuracy: 0.999999999\r\nGreen AI\r\n‚Ä¢ Energy \r\n‚Ä¢ Time \r\n‚Ä¢ Reproducibility \r\n‚Ä¢ Reusage\r\n\r\nHow can we adopt Green AI\r\n‚Ä¢ Check whether AI is needed. \r\n‚Ä¢ Select green datacenters. \r\n‚Ä¢ Run on low carbon intensity hours. \r\n‚Ä¢ Opt for GPU-optimised solutions (?) \r\n‚Ä¢ Opt for low-power hardware (e.g., Nvidia Jetson boards) \r\n‚Ä¢ Or GPUs that provide energy metrics (e.g., NVIDIA GPUs via the nvidia-smi tool) \r\n‚Ä¢ Report energy/carbon metrics (e.g., embed in MLFlow?) \r\n‚Ä¢ Use pre-trained models (Transfer Learning) \r\n‚Ä¢ Preprocess dataset to reduce size. \r\n‚Ä¢ Improve parameter-tuning strategy.\r\n11\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ We need benchmarks. \r\n‚Ä¢ AllenAI leaderboard\u2028\r\nhttps://leaderboard.allenai.org \r\n‚Ä¢ No carbon metrics, yet \r\n‚Ä¢ Report comparable proxies for energy \r\nconsumption. \r\n‚Ä¢ ‚ö† Learning algorithms behave in a non-\r\ndeterministic \r\n‚Ä¢ ‚ö† Different data-points lead to different \r\nenergy consumption\r\n12\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ Reporting measured energy consumption \r\n‚Ä¢ + Accurate \r\n‚Ä¢ + Easy to map to carbon emissions \r\n‚Ä¢ - Hard to measure \r\n‚Ä¢ - Low replicability \r\n‚Ä¢ Reporting time / estimation based on time & hardware \r\n‚Ä¢ + Easy to measure \r\n‚Ä¢ + Correlates with energy consumption in most cases. \r\n‚Ä¢ -  Difficult to compare with measurements from other setups \r\n‚Ä¢ E.g., floating point operations (FPOs) (?) \r\n‚Ä¢ + comparable across different setups \r\n‚Ä¢ + cheap \r\n‚Ä¢ - does not factor in memory energy consumption \r\n‚Ä¢ - does not reflect carbon emissions\r\n13\r\n\r\nData-centric AI\r\n\r\nData-centric AI\r\n‚Ä¢ Emerging discipline that deals with systematically engineering data to build AI \r\nsystems. \r\n‚Ä¢ Shift from improving the training strategy to improving the data. \r\n‚Ä¢ It is better to have small but reliable datasets than large but noisy \r\ndatasets. \r\n‚Ä¢ => Improve data collection, data labelling, and data preprocessing. \r\n‚Ä¢ More about data-centric AI by Andrew Ng:\u2028\r\nhttps://www.youtube.com/watch?v=06-AZXmwHjo\r\n15\r\n\r\n\r\nGreen Data-centric AI\r\n‚Ä¢ How do different ML algorithms compare \r\nin terms of energy consumption? \r\n‚Ä¢ How does number of rows relate to the \r\nenergy consumption of ML models? \r\n‚Ä¢ How does number of features relate to \r\nthe energy consumption of ML models? \r\n‚Ä¢ What is the impact of reducing data in the \r\nperformance of the model?', ""‚Ä¢ 6 machine learning algorithms: SVM, Decision Tree, KNN, Random Forrest, \r\nAdaBoost, Bagging Classifier. \r\n‚Ä¢ Reduce the number of rows. 10%, 20%, .., 100% \r\n‚Ä¢ Stratified random sampling (?) \r\n‚Ä¢ Reduce the number of features. 10%, 20%, .., 100% \r\n‚Ä¢ Feature importance metric based on the Chi-Square Test (Chi2) \r\n‚Ä¢ Estimate energy consumption using a RAPL-based tool. (?)\r\n18\r\n\r\n‚Ä¢ Repeat 30 times \r\n‚Ä¢ Fix random seeds \r\n‚Ä¢ ‚Ä¶ \r\n‚Ä¢ Data was not Normal => tailed Normal distribution.\r\n19\r\n(?)\r\n\r\nResults: energy consumption of algorithms\r\n\r\nResults: energy vs data shape\r\n\r\nResults: performance vs data shape\r\n\r\nDiscussion\r\n‚Ä¢ Other data properties should be investigated. \r\n‚Ä¢ E.g., data types \r\n‚Ä¢ Reporting energy data is essential. It can lead to different model selection \r\nwithout hindering model performance. \r\n‚Ä¢ There is a big opportunity in Model and Data Simplification.\r\n23\r\n\r\nData/Model Simplification\r\n‚Ä¢ (?) \r\n‚Ä¢ Data selection \r\n‚Ä¢ Data quantisation. Posit? \r\n‚Ä¢ Data distillation \r\n‚Ä¢ Coreset extraction (?) \r\n‚Ä¢ Model distillation \r\n‚Ä¢ Model quantisation \r\n‚Ä¢ Model pruning \r\n‚Ä¢ ‚Ä¶\r\n24\r\n\r\nPosit vs Float\r\nMore about this: https://spectrum.ieee.org/floating-point-numbers-posits-processor\r\nBetter for DL use cases\r\n\r\nHow can we tune \r\nlearning \r\nparameters \r\nefficiently?\r\n\r\nHyper parameter tuning\r\n‚Ä¢ When training an ML model, there are several parameters that need to be \r\ntuned. \r\n‚Ä¢ E.g., in SVM we have the Regularization parameter C, the kernel function, \r\nthe degree of the kernel function, and depending on the case, many other. \r\n‚Ä¢ The common approach revolves around grid search. The user provides a \r\nsequence of possible values for each parameter and the pipeline runs all \r\npossible combinations. \r\n‚Ä¢ Our question: Can we save energy with alternative approaches? \r\n‚Ä¢ We studied Grid Search, Random Search and Bayesian \r\nOptimisation.\r\n27\r\nTim's MSc Thesis, 2022 \r\nAccepted at CAIN‚Äô23\r\n\r\n\r\nResults\r\n29\r\nConclusions? \r\n‚Ä¢ Bayesian converges faster. \r\n‚Ä¢ No clear winner between Grid and Random\r\n\r\nDeepSeekMoE\r\n30\r\nPreprint at ArXiv, 2024 https://arxiv.org/pdf/\r\n2401.06066\r\n\r\nMixture of Experts\r\n‚Ä¢ Llama3.1 has 405B parameters, DeepSeek V3 671B \r\n‚Ä¢ Yet DeepSeek has quicker inference times and claims less energy \r\nconsumption (?) \r\n‚Ä¢ Divide the model into smaller blocks of experts \r\n‚Ä¢ Tokens get routed to certain experts based on the query \r\n‚Ä¢ Only part of the network is active during inference \r\n‚Ä¢ DeepSeek claims only 37B out of 671B parameters get active\r\n31\r\n\r\nDeepSeekMoE\r\n32\r\n\r\nDeepSeekMoE\r\n33\r\n‚Ä¢ Comparable performance to \r\nLLaMA2 7B effectively using \r\nless half the parameters \r\n‚Ä¢ Less computational power \r\n‚Ä¢ Problems (?) \r\n‚Ä¢ Still need to load all the \r\nparameters \r\n‚Ä¢ High memory -> high \r\nembodied carbon\r\n\r\nGreen AI at FacebookMeta\r\n34\r\nSustainable AI: Environmental Implications, \r\nChallenges and Opportunities (2022)\r\n\r\nCarbon footprint mapped to the AI lifecycle\r\n‚Ä¢ There are 4 main overarching stages where carbon emissions need to be isolated: data \r\ncollection, experimentation, training, inference. \r\n‚Ä¢ At Facebook, recommendation systems split energy consumption evenly between \r\ntraining and inference; text translation models have a 35%/65% split. (Operational cost) \r\n‚Ä¢ Operational/embodied cost split: 30%/70%\r\n35\r\n\r\nOpen issues according to Meta\r\n‚Ä¢ A vast portion of projects only use GPUs at 30%.\u2028\r\nShould be higher to attenuate embodied carbon."", '‚Ä¢ In a scientific project, the magic number is 30.\r\n7\r\n\r\n\r\nRest ‚è∏\r\n‚Ä¢ It is common practice to do a pause/sleep between executions/\r\nmeasurements. \r\n‚Ä¢ Prevent tail energy consumption from previous measurements. ? \r\n‚Ä¢ Prevent collateral tasks of previous measurement from affecting the next \r\nmeasurement. \r\n‚Ä¢ There is no golden rule but one minute should be enough. It can be more or \r\nless depending on your hardware or the duration of your energy test.\r\n9\r\n\r\nt\r\nP\r\nTail Energy Consumption\r\n\r\nShuffle üîÄ\r\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \r\nit is impossible to control all of them. \r\n‚Ä¢ If you run 30 executions for version A and another batch for version B: \r\n‚Ä¢ External conditions that change over time will have a different bias in \r\nthe 2 versions (e.g., room temperature changes). \r\n‚Ä¢ If you shuffle, you reduce this risk.\r\n11\r\n\r\nKeep it cool üå°\r\n‚Ä¢ Always make sure there is a stable room temperature. \r\n‚Ä¢ Tricky because, some times, experiments may have to run over a few days. \r\n‚Ä¢ If you cannot control room temperature: collect temperature data and filter \r\nout measurements where the room temperature is clearly deviating.\r\n12\r\n\r\nAutomate Executions ü§ñ\r\n‚Ä¢ (Already mentioned in the previous classes) \r\n‚Ä¢ One cannot run 30 shuffled experiments per version without automation‚Ä¶\r\n13\r\n\r\nData analysis\r\n14\r\n\r\n1. Exploratory Analysis\r\n‚Ä¢ Plot the data and inspect outliers or \r\nunexpected biases. \r\n‚Ä¢ Violin+box plots are usually handy. (?) \r\n‚Ä¢ It‚Äôs a nice way of combining the 30 \r\nexperiments, and of showing \r\ndescriptive statistics. (?) \r\n‚Ä¢ Shows the shape of the distribution \r\nof the data.\r\n15\r\n\r\n1. Exploratory Analysis (II)\r\n‚Ä¢ Data should be Normal. Unless there‚Äôs a \r\ngood reason. \r\n‚Ä¢ E.g., somewhere amongst the 30 executions, \r\nthere might be 1 or 2 that failed to finish due \r\nto some unexpected error. \r\n‚Ä¢ (It happens and that‚Äôs ok!)‚Äì consequently, \r\nthe execution is shorter and spends less \r\nenergy ‚Äì falsely appearing as more \r\nenergy efficient. \r\n‚Ä¢ If data is not Normal there might be some \r\nissues affecting the measurements that \r\nmight be ruining results. It is important to \r\ninvestigate this.\r\n16\r\n\r\nEnergy data is not normal. Why?\r\n‚Ä¢ It might be caused by one of the following reasons: \r\n‚Ä¢ There was an error in some of the executions. If not detected and fixed it \r\nmight ruin results. \r\n‚Ä¢ Your tests are not fully replicable or are not deterministic. Quite frequent \r\nwhen you have internet requests or random-based algorithms. \r\n‚Ä¢ There is an unusual task being run by the system during some experiments. \r\n‚Ä¢ The computer entered a different power mode. \r\n‚Ä¢ External physical conditions have changed. E.g., someone opened a \r\nwindow.\r\n17\r\n\r\nEnergy data is not normal. How to fix?\r\n‚Ä¢ We have 2+1 options: \r\n1. Remove outliers. If there are only a few points that deviate from the normal \r\ndistribution, it is okay to simply remove them. \r\n‚Ä¢ Use the z-score outlier removal. (?) \r\n‚Ä¢ Remove all data points that deviate from the mean more than 3 standard \r\ndeviations: \r\n \r\n2. Fix the issue and rerun experiments. \r\n3. Conclude that nothing can be done about it and data will never be normal. (e.g., \r\nin AI, executions are rarely deterministic). ‚ö† Only after ruling out the previous \r\npoints.\r\n| ¬Øx ‚àíx| > 3s\r\n18\r\n\r\nHow do we know whether data is Normal?', '‚Ä¢ By using money cost instead of carbon cost, they have more data available.\r\n26\r\n\r\nVirtual Cluster Capacity (VCC)\r\n‚Ä¢ If the forecast of VCC fails it shift flexible workload more than expected.  \r\n‚Ä¢ This happens because the amount of workload forecasted was below the \r\nworkload needed, and VCC was ‚Äúaggressively‚Äù low. \r\n‚Ä¢ The systems fall back to the real cluster capacity for 1 week until results \r\nstart being realistic again.\r\n27\r\n\r\nNext steps\r\n‚Ä¢ They will consider spatial flexibility. \r\n‚Ä¢ I.e., tasks that can be shifted over time and over space. \r\n‚Ä¢ It needs to factor in relocation overheads, though.\r\n28\r\n\r\nCritical questions\r\n‚Ä¢ Who defines what is flexible and inflexible? \r\n‚Ä¢ How do you estimate the CPU load of a given task?\r\n29\r\n\r\nEnergy Regression Testing\r\n‚ÜíEnergy?\r\nGreener? Greener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\n\r\nE-compare\r\nGithub Actions\r\n‚ûú https://koenhagen.github.io/E-Compare/\r\n\r\nEnergy Regression Testing \r\n\r\n4. Debugging Energy with \r\nDocker Images\r\n\r\nUnveiling the Energy Vampires \r\nA methodology for debugging Software \r\nEnergy Consumption\r\n ‚úÖ ICSE 2025\r\n\r\nData Centers and Docker\r\n‚Ä¢ Containers are the most popular way to deploy apps into the cloud \r\n‚Ä¢ Base image is an important choice when building an image \r\n‚Ä¢ Criteria \r\n‚Ä¢ Linux distribution and binaries \r\n‚Ä¢ Image size \r\n‚Ä¢ Energy?\r\n35\r\n\r\nRedis energy consumption\r\n‚Ä¢ Ubuntu/Alpine base images have different energy consumption for Redis\r\n36\r\n\r\nRedis Energy Consumption\r\n‚Ä¢RQ1: What is the difference \r\nin energy consumption \r\nbetween glibc and musl? \r\n‚Ä¢RQ2: Can we use tracing \r\nto compare energy \r\nconsumption in shared \r\nlibraries? \r\n‚Ä¢RQ3: Can we verify the \r\norigin of energy \r\nconsumption differences by \r\nrecreating the workload \r\nbehavior closely?\r\n37\r\n\r\nTracing\r\n‚Ä¢ Find libc function running at the end of the benchmark \r\n‚Ä¢ Tracing: Capture calls made to libc \r\n‚Ä¢ Introduces non-linear overhead\r\n38\r\n\r\nSynchronization\r\n‚Ä¢ Tracing slows down execution and increase energy consumption \r\n‚Ä¢ Run separately and synchronize with logs\r\n39\r\n\r\nTracing Analysis\r\n40\r\n\r\nTracing Analysis\r\n41\r\n\r\nBenchmarking memcpy\r\n‚Ä¢ Copy bytes from one part of memory to \r\nanother \r\n‚Ä¢ Depending on function parameters, different \r\nassembly-level optimizations \r\n‚Ä¢ Some not included in musl\r\n42\r\n\r\nBenchmarking memcpy\r\n‚Ä¢ Copy 4 bytes from fixed \r\npointer to moving pointer \r\n‚Ä¢ (100,300,500,600) x 1M \r\nrequests \r\n‚Ä¢  15% more power and 3X time\r\n43\r\n\r\nConclusions\r\n‚Ä¢ Significant difference in energy consumption for memcpy \r\n‚Ä¢ 8.6% difference for Redis workload and 13% in our benchmark \r\n‚Ä¢ musl trades performance for a smaller codebase \r\n‚Ä¢ No official documentation \r\n‚Ä¢ No awareness about energy performance\r\n44\r\n\r\n5. Energy Efficiency vs Code \r\nQuality\r\n\r\nMeasuring Maintainability\r\n‚Ä¢ According to ISO/IEC 25010, Maintainability is ‚Äúthe degree of \r\neffectiveness and efficiency with which a software product or \r\nsystem can be modified to improve it, correct it or adapt it to \r\nchanges in environment, and in requirements‚Äù \r\n‚Ä¢ We use the code analysis tool Better Code Hub to assess \r\nmaintainability \r\n‚Ä¢ Better Code Hub maps the ISO/IEC 25010 standard on \r\nmaintainability into a set of guidelines derived from static analysis\r\n46\r\n\r\nMaintainability of Energy Changes\r\n‚Ä¢ What is the impact of making energy-oriented code changes on \r\nthe maintainability of mobile apps?', 'google.com/view/energy-efficiency-languages\r\n21\r\nAna Radovanovic ÃÅ, Ross Koningstein, Ian Schneider, Bokan \r\nChen, Alexandre Duarte, Binz Roy, Diyue Xiao, Maya \r\nHaridasan, Patrick Hung, Nick Care, Saurav Talukdar, Eric \r\nMullen, Kendal Smith, MariEllen Cottman, and Walfredo Cirne \r\n\r\n\r\n‚Ä¢ Google‚Äôs Carbon-Intelligent Computing System (CICS) \r\n‚Ä¢ Main idea: use carbon-intensity data to shift datacenter jobs in time \r\n‚Ä¢ Typically, job schedulers use a metric of cluster capacity to schedule a job in \r\na particular cluster. \r\n‚Ä¢ CICS overrides this metric with the virtual capacity curve (VCC) that \r\nfactors in Carbon intensity \r\n‚Ä¢ When a new job comes in, the scheduler estimates its CPU load and power \r\nusage and assigns it to a cluster if the VCC is not exceeded.\r\n23\r\n\r\n‚Ä¢ Jobs are divided between flexible and inflexible. \r\n‚Ä¢ Flexible load is considered shapeable/shiftable as long as its total daily \r\ncompute (CPU) demand is preserved \r\n‚Ä¢ The system needs to consider that, while running a job, the virtual capacity \r\ncurve (VCC) might drop. Hence, this job should not start in the first place. \r\n‚Ä¢ They forecast VCC for the next day\r\n24\r\n\r\n\r\nVirtual Cluster Capacity (VCC)\r\n‚Ä¢ Aims at reducing the peak load at carbon intensive hours but in total it should allow for the \r\nsome amount of daily computation! \r\n‚Ä¢ Considers Carbon intensity \r\n‚Ä¢ Using data from electricityMap.org \r\n‚Ä¢ It does not use carbon intensity directly.\u2028\r\nCarbon intensity is converted to a cost (kgCO2 -> $$) \r\n‚Ä¢ This way, they can factor in other metrics that can also be converted to money. E.g., the \r\ncost saved by preventing peak load \r\n‚Ä¢ Peak workload entails extra cost at the infrastructure level (e.g., control faclities‚Äô \r\ntemperature). \r\n‚Ä¢ By using money cost instead of carbon cost, they have more data available.\r\n26\r\n\r\nVirtual Cluster Capacity (VCC)\r\n‚Ä¢ If the forecast of VCC fails it shift flexible workload more than expected.  \r\n‚Ä¢ This happens because the amount of workload forecasted was below the \r\nworkload needed, and VCC was ‚Äúaggressively‚Äù low. \r\n‚Ä¢ The systems fall back to the real cluster capacity for 1 week until results \r\nstart being realistic again.\r\n27\r\n\r\nNext steps\r\n‚Ä¢ They will consider spatial flexibility. \r\n‚Ä¢ I.e., tasks that can be shifted over time and over space. \r\n‚Ä¢ It needs to factor in relocation overheads, though.\r\n28\r\n\r\nCritical questions\r\n‚Ä¢ Who defines what is flexible and inflexible? \r\n‚Ä¢ How do you estimate the CPU load of a given task?\r\n29\r\n\r\nEnergy Regression Testing\r\n‚ÜíEnergy?\r\nGreener? Greener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\n\r\nE-compare\r\nGithub Actions\r\n‚ûú https://koenhagen.github.io/E-Compare/\r\n\r\nEnergy Regression Testing \r\n\r\n4. Debugging Energy with \r\nDocker Images\r\n\r\nUnveiling the Energy Vampires \r\nA methodology for debugging Software \r\nEnergy Consumption\r\n ‚úÖ ICSE 2025\r\n\r\nData Centers and Docker\r\n‚Ä¢ Containers are the most popular way to deploy apps into the cloud \r\n‚Ä¢ Base image is an important choice when building an image \r\n‚Ä¢ Criteria \r\n‚Ä¢ Linux distribution and binaries \r\n‚Ä¢ Image size \r\n‚Ä¢ Energy?\r\n35\r\n\r\nRedis energy consumption\r\n‚Ä¢ Ubuntu/Alpine base images have different energy consumption for Redis\r\n36\r\n\r\nRedis Energy Consumption\r\n‚Ä¢RQ1: What is the difference \r\nin energy consumption \r\nbetween glibc and musl? \r\n‚Ä¢RQ2: Can we use tracing \r\nto compare energy \r\nconsumption in shared \r\nlibraries?', '‚Ä¢ Deadline April 4.\r\n6\r\n\r\nStrategy\r\n‚Ä¢ Week 0 \r\n‚Ä¢ Decide project idea (today) \r\n‚Ä¢ Define steering meeting schedule \r\n‚Ä¢ Create working document of the \r\narticle: Problem statement and solution \r\nproposal! \r\n‚Ä¢ Define and assign tasks for each week. \r\n‚Ä¢ Week 1 \r\n‚Ä¢ Implementation \r\n‚Ä¢ Agreements with supervisor. \r\n‚Ä¢ Week 2 \r\n‚Ä¢ Implementation \r\n‚Ä¢ Week 3 \r\n‚Ä¢ Implementation, Full draft of article, \r\ndissemination. \r\n‚Ä¢ Week 4 \r\n‚Ä¢ Final refinements \r\n‚Ä¢ Prepare presentation\r\n7\r\n\r\nProject ideas\r\n‚Ä¢ A1. Prototype cross-machine comparable benchmarks \r\n‚Ä¢ A2. Add energy metrics to LMstudio/Ollama \r\n‚Ä¢ A3. Visualizations built-in with EnergiBridge \r\n‚Ä¢ A4. Service-based version of EnergiBridge\r\n\r\nProject ideas\r\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \r\n‚Ä¢ B2. Study test generation energy consumption \r\n‚Ä¢ B3. Energy profiling of static analysis tools \r\n‚Ä¢ B4. Detailed energy profiling of build pipelines \r\n‚Ä¢ B5. Tool supporting SusAF workshop / process \r\n‚Ä¢ B6. Dataset of government-developed OS software \r\n‚Ä¢ B7. Queue - but better for the student / TA society\r\nQuality Assurance & Testing\r\nSocial & Individual \u2028\r\nSustainability\r\n\r\nProject ideas\r\n‚Ä¢ C1. Compare energy consumption of docker images for ML workloads. \r\n‚Ä¢ C2. Create a plugin to visualize Hugging Face carbon emissions in detail. \r\n‚Ä¢ C3. Plugin for ChatGPT (footprint per chat window) \r\n‚Ä¢ C4. NutriScore for software libraries. \r\n‚Ä¢ C5. Add energy-awareness to existing software \r\n‚Ä¢ C6. Green Shift Left \r\n‚Ä¢ C7. Education for Sustainable SE\r\n\r\nA1. Prototype cross-machine comparable benchmarks\r\n‚Ä¢ Energy-usage comparisons require running both baseline + software on the \r\nsame machine ‚Üí limits how extensive our experiments can be \r\n‚Ä¢ Research community is in need of benchmarks that make energy \r\nmeasurements comparable even if executed on different machines \r\n‚Ä¢ Focus on a single task or model (i.e. computing vision, classification)\r\n\r\nA2. Adding energy metrics to LMstudio/Ollama\r\n‚Ä¢ Make energy consumption visible to users \r\nwithin local chat-interface for LLMs \r\n‚Ä¢ LMstudio/Ollama are tools for easy \r\ndeployment of LLMs \r\n‚Ä¢ Do not show energy metrics \r\n‚Ä¢ Add energy metrics to LMstudio-python \r\nor Ollama\r\nhttps://lmstudio.ai/\r\n\r\nA3. Visualizations built-in with EnergiBridge\r\n‚Ä¢ EnergiBridge simplifies energy measurement, but analysis & visualization is \r\nstill left to the user \r\n‚Ä¢ Extend the tool with well-chosen visualizations and analyses directly from the \r\nprovided data\r\n\r\nA4. Service-based version of EnergiBridge\r\n‚Ä¢ Simplify interaction & setup with EnergiBridge \r\n‚Ä¢ Service that runs independently, start/stop signals over RPC to manage \r\nexperiments \r\n‚Ä¢ Potential: create EnergiBridge interface for other prog. lang\r\n\r\nB1. Measure energy consumption of single JUnit tests\r\n‚Ä¢ We‚Äôd like to identify energy anti patterns in unit tests \r\n‚Ä¢ As a first step, we need tooling to measure and compare the energy \r\nconsumption of single unit tests \r\n‚Ä¢ Ideally including preliminary analysis looking at potential reasons for high-\r\nenergy-consuming tests\r\n\r\nB2. Study test generation energy consumption\r\n‚Ä¢ Automatic test generation mainly focuses on making strong test suites \r\n‚Ä¢ Do different techniques and configurations impact the energy consumption \r\nduring generation? \r\n‚Ä¢ Preferably focus on non-LLM test generation methods (EvoSuite, Pyguin, \r\nDSpot)\r\n\r\nB3. Detailed energy profiling of build pipelines\r\n‚Ä¢ Automatic builds have become a cornerstone of quality assurance.', 'Lu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\n3. Scientific Guide for Reliable \r\nEnergy Experiments\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nCarolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl\r\n\r\n1. Scientific guide for energy measurements \r\n2. Energy consumption data analysis \r\n\r\nEnergy tests are flaky\r\n‚Ä¢ Multiple runs might yield different results \r\n‚Ä¢ There are many confounding factors that need to be controlled/minimized.\r\n3\r\n?\r\n\r\nZen mode üßò\r\n‚Ä¢ Close all applications. \r\n‚Ä¢ Turn off notifications. \r\n‚Ä¢ Only the required hardware should be connected (avoid USB drives, external \r\ndisks, external displays, etc.). \r\n‚Ä¢ Kill unnecessary services running in the background (e.g., web server, file \r\nsharing, etc.). \r\n‚Ä¢ If you do not need an internet or intranet connection, switch off your network. \r\n‚Ä¢ Prefer cable over wireless ‚Äì the energy consumption from a cable connection \r\nis more stable than from a wireless connection.\r\n4\r\n\r\nFreeze and report your settings ü•∂\r\n‚Ä¢ Fix display brightness; switch off auto brightness \r\n‚Ä¢ If Wifi is on, it should always be on, connected to the same network/\r\nendpoint.‚Ä¶\r\n5\r\n\r\nWarm-up üì∂\r\n‚Ä¢ Energy consumption is highly affected by the temperature of your hardware. \r\n‚Ä¢ Higher the temperature -> higher the resistance of electrical conductors ->\u2028\r\n-> higher dissipation -> higher energy consumption \r\n‚Ä¢ The first execution will appear more efficient because the hardware is still \r\ncold. \r\n‚Ä¢ Run a CPU-intensive task before measuring energy consumption. E.g., \r\nFibonacci sequence. At least 1min; 5min recommended. \r\n‚Ä¢\r\n6\r\n\r\nRepeat üîÅ\r\n‚Ä¢ The best way to make sure a measurement is valid is by repeating it. \r\n‚Ä¢ In a scientific project, the magic number is 30.\r\n7\r\n\r\n\r\nRest ‚è∏\r\n‚Ä¢ It is common practice to do a pause/sleep between executions/\r\nmeasurements. \r\n‚Ä¢ Prevent tail energy consumption from previous measurements. ? \r\n‚Ä¢ Prevent collateral tasks of previous measurement from affecting the next \r\nmeasurement. \r\n‚Ä¢ There is no golden rule but one minute should be enough. It can be more or \r\nless depending on your hardware or the duration of your energy test.\r\n9\r\n\r\nt\r\nP\r\nTail Energy Consumption\r\n\r\nShuffle üîÄ\r\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \r\nit is impossible to control all of them. \r\n‚Ä¢ If you run 30 executions for version A and another batch for version B: \r\n‚Ä¢ External conditions that change over time will have a different bias in \r\nthe 2 versions (e.g., room temperature changes). \r\n‚Ä¢ If you shuffle, you reduce this risk.\r\n11\r\n\r\nKeep it cool üå°\r\n‚Ä¢ Always make sure there is a stable room temperature. \r\n‚Ä¢ Tricky because, some times, experiments may have to run over a few days. \r\n‚Ä¢ If you cannot control room temperature: collect temperature data and filter \r\nout measurements where the room temperature is clearly deviating.\r\n12\r\n\r\nAutomate Executions ü§ñ\r\n‚Ä¢ (Already mentioned in the previous classes) \r\n‚Ä¢ One cannot run 30 shuffled experiments per version without automation‚Ä¶\r\n13\r\n\r\nData analysis\r\n14\r\n\r\n1. Exploratory Analysis\r\n‚Ä¢ Plot the data and inspect outliers or \r\nunexpected biases. \r\n‚Ä¢ Violin+box plots are usually handy. (?) \r\n‚Ä¢ It‚Äôs a nice way of combining the 30 \r\nexperiments, and of showing \r\ndescriptive statistics. (?) \r\n‚Ä¢ Shows the shape of the distribution \r\nof the data.\r\n15\r\n\r\n1. Exploratory Analysis (II)\r\n‚Ä¢ Data should be Normal.', '‚Ä¢ Improve parameter-tuning strategy.\r\n11\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ We need benchmarks. \r\n‚Ä¢ AllenAI leaderboard\u2028\r\nhttps://leaderboard.allenai.org \r\n‚Ä¢ No carbon metrics, yet \r\n‚Ä¢ Report comparable proxies for energy \r\nconsumption. \r\n‚Ä¢ ‚ö† Learning algorithms behave in a non-\r\ndeterministic \r\n‚Ä¢ ‚ö† Different data-points lead to different \r\nenergy consumption\r\n12\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ Reporting measured energy consumption \r\n‚Ä¢ + Accurate \r\n‚Ä¢ + Easy to map to carbon emissions \r\n‚Ä¢ - Hard to measure \r\n‚Ä¢ - Low replicability \r\n‚Ä¢ Reporting time / estimation based on time & hardware \r\n‚Ä¢ + Easy to measure \r\n‚Ä¢ + Correlates with energy consumption in most cases. \r\n‚Ä¢ -  Difficult to compare with measurements from other setups \r\n‚Ä¢ E.g., floating point operations (FPOs) (?) \r\n‚Ä¢ + comparable across different setups \r\n‚Ä¢ + cheap \r\n‚Ä¢ - does not factor in memory energy consumption \r\n‚Ä¢ - does not reflect carbon emissions\r\n13\r\n\r\nData-centric AI\r\n\r\nData-centric AI\r\n‚Ä¢ Emerging discipline that deals with systematically engineering data to build AI \r\nsystems. \r\n‚Ä¢ Shift from improving the training strategy to improving the data. \r\n‚Ä¢ It is better to have small but reliable datasets than large but noisy \r\ndatasets. \r\n‚Ä¢ => Improve data collection, data labelling, and data preprocessing. \r\n‚Ä¢ More about data-centric AI by Andrew Ng:\u2028\r\nhttps://www.youtube.com/watch?v=06-AZXmwHjo\r\n15\r\n\r\n\r\nGreen Data-centric AI\r\n‚Ä¢ How do different ML algorithms compare \r\nin terms of energy consumption? \r\n‚Ä¢ How does number of rows relate to the \r\nenergy consumption of ML models? \r\n‚Ä¢ How does number of features relate to \r\nthe energy consumption of ML models? \r\n‚Ä¢ What is the impact of reducing data in the \r\nperformance of the model? \r\n‚Ä¢ Method -> results -> discussion\r\n17\r\n\r\nMethod\r\n‚Ä¢ Single object of study: natural language model to detect spam messages. \r\n‚Ä¢ 6 machine learning algorithms: SVM, Decision Tree, KNN, Random Forrest, \r\nAdaBoost, Bagging Classifier. \r\n‚Ä¢ Reduce the number of rows. 10%, 20%, .., 100% \r\n‚Ä¢ Stratified random sampling (?) \r\n‚Ä¢ Reduce the number of features. 10%, 20%, .., 100% \r\n‚Ä¢ Feature importance metric based on the Chi-Square Test (Chi2) \r\n‚Ä¢ Estimate energy consumption using a RAPL-based tool. (?)\r\n18\r\n\r\n‚Ä¢ Repeat 30 times \r\n‚Ä¢ Fix random seeds \r\n‚Ä¢ ‚Ä¶ \r\n‚Ä¢ Data was not Normal => tailed Normal distribution.\r\n19\r\n(?)\r\n\r\nResults: energy consumption of algorithms\r\n\r\nResults: energy vs data shape\r\n\r\nResults: performance vs data shape\r\n\r\nDiscussion\r\n‚Ä¢ Other data properties should be investigated. \r\n‚Ä¢ E.g., data types \r\n‚Ä¢ Reporting energy data is essential. It can lead to different model selection \r\nwithout hindering model performance. \r\n‚Ä¢ There is a big opportunity in Model and Data Simplification.\r\n23\r\n\r\nData/Model Simplification\r\n‚Ä¢ (?) \r\n‚Ä¢ Data selection \r\n‚Ä¢ Data quantisation. Posit? \r\n‚Ä¢ Data distillation \r\n‚Ä¢ Coreset extraction (?) \r\n‚Ä¢ Model distillation \r\n‚Ä¢ Model quantisation \r\n‚Ä¢ Model pruning \r\n‚Ä¢ ‚Ä¶\r\n24\r\n\r\nPosit vs Float\r\nMore about this: https://spectrum.ieee.org/floating-point-numbers-posits-processor\r\nBetter for DL use cases\r\n\r\nHow can we tune \r\nlearning \r\nparameters \r\nefficiently?\r\n\r\nHyper parameter tuning\r\n‚Ä¢ When training an ML model, there are several parameters that need to be \r\ntuned. \r\n‚Ä¢ E.g., in SVM we have the Regularization parameter C, the kernel function, \r\nthe degree of the kernel function, and depending on the case, many other. \r\n‚Ä¢ The common approach revolves around grid search.', 'Lu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\n10. Project 2\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nCarolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl\r\n\r\n1. Goal/assignment \r\n2. Deliverables \r\n3. Strategy \r\n4. Ideas\r\n\r\nAssignment\r\n‚Ä¢ Goal: Solve a Sustainable Software Engineering problem. \r\n‚Ä¢ Identify 1 problem that should be fixed to help enabling sustainability in \r\nthe software engineering industry/community. \r\n‚Ä¢ Propose a solution. A tool, framework, guidelines, etc. \r\n‚Ä¢ Implementation. \r\n‚Ä¢ Validation. (Depending on the idea) \r\n‚Ä¢ Dissemination/social impact. (Solution should be open source, welcome \r\ncontributors, post on social media? Tool website? Available in a package \r\nmanager?)\r\n3\r\n\r\nDeliverables\r\n‚Ä¢ Paper-like article. (Min 4 pages, max 10) \r\n‚Ä¢ Online git repo with open source codebase and/or replication package. \r\n‚Ä¢ Presentation: 5 min + 5min Q&A\r\n4\r\n\r\nArticle\r\n‚Ä¢ Different projects will have different expectations -> Make agreements with \r\nyour coach. \r\n‚Ä¢ Some projects are more technical and some projects more theoretical. \r\n‚Ä¢ Common requirements: \r\n‚Ä¢ Motivation, formulation of the problem being addressed, etc. \r\n‚Ä¢ Description of the solution. \r\n‚Ä¢ Validation of the solution (if applicable -> discuss with coach) \r\n‚Ä¢ Discussion of the solution. (Including limitations)\r\n5\r\n\r\nStrategy\r\n‚Ä¢ Starting next week, there are no lectures  \r\n‚Ä¢ Steering meetings from week 5 till week 9 (either online or in person).  \r\n‚Ä¢ 1 steering meeting per week. (4+1 sprints) \r\n‚Ä¢ Every week, you need to plan different tasks and assignments. \r\n‚Ä¢ Deadline April 4.\r\n6\r\n\r\nStrategy\r\n‚Ä¢ Week 0 \r\n‚Ä¢ Decide project idea (today) \r\n‚Ä¢ Define steering meeting schedule \r\n‚Ä¢ Create working document of the \r\narticle: Problem statement and solution \r\nproposal! \r\n‚Ä¢ Define and assign tasks for each week. \r\n‚Ä¢ Week 1 \r\n‚Ä¢ Implementation \r\n‚Ä¢ Agreements with supervisor. \r\n‚Ä¢ Week 2 \r\n‚Ä¢ Implementation \r\n‚Ä¢ Week 3 \r\n‚Ä¢ Implementation, Full draft of article, \r\ndissemination. \r\n‚Ä¢ Week 4 \r\n‚Ä¢ Final refinements \r\n‚Ä¢ Prepare presentation\r\n7\r\n\r\nProject ideas\r\n‚Ä¢ A1. Prototype cross-machine comparable benchmarks \r\n‚Ä¢ A2. Add energy metrics to LMstudio/Ollama \r\n‚Ä¢ A3. Visualizations built-in with EnergiBridge \r\n‚Ä¢ A4. Service-based version of EnergiBridge\r\n\r\nProject ideas\r\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \r\n‚Ä¢ B2. Study test generation energy consumption \r\n‚Ä¢ B3. Energy profiling of static analysis tools \r\n‚Ä¢ B4. Detailed energy profiling of build pipelines \r\n‚Ä¢ B5. Tool supporting SusAF workshop / process \r\n‚Ä¢ B6. Dataset of government-developed OS software \r\n‚Ä¢ B7. Queue - but better for the student / TA society\r\nQuality Assurance & Testing\r\nSocial & Individual \u2028\r\nSustainability\r\n\r\nProject ideas\r\n‚Ä¢ C1. Compare energy consumption of docker images for ML workloads. \r\n‚Ä¢ C2. Create a plugin to visualize Hugging Face carbon emissions in detail. \r\n‚Ä¢ C3. Plugin for ChatGPT (footprint per chat window) \r\n‚Ä¢ C4. NutriScore for software libraries. \r\n‚Ä¢ C5. Add energy-awareness to existing software \r\n‚Ä¢ C6. Green Shift Left \r\n‚Ä¢ C7. Education for Sustainable SE\r\n\r\nA1.', 'Energy profiling of static analysis tools\r\n‚Ä¢ What is the energy consumption of a ""typical run"" for a few OSS projects? \r\n‚Ä¢ Does the type of analysis matter? Are certain analysis more expensive? Does \r\nthe number of rules that are activated in a static analysis tool important for the \r\nenergy consumption? \r\n‚Ä¢ Differences between static analysis tools [lower priority]\r\n\r\nB5. Tool supporting SusAF workshop / process\r\n‚Ä¢ Lead engineers through process & questions \r\n‚Ä¢ Interface to create & document the two diagrams \r\n‚Ä¢ (!) Should be easy to start using & set up \r\n‚Ä¢ You may also create a simplified version / \u2028\r\nyour favorite sustainability framework\r\nEnvironmental\r\nEconomic\r\nTechnical\r\nIndividual\r\nSocial\r\nImmediate\r\nEnabling\r\nStructural\r\nAirbnb\r\ngreater \r\nearnings\r\nincrease \r\nin rents\r\ngentrification\r\ngreater racial \r\ndisparities\r\nrent \r\nrooms\r\n5\r\n1\r\n3\r\n4\r\n2\r\n \r\n \r\n \r\n \r\n \r\n \r\nVery \r\nunlikely \r\nVery \r\nlikely \r\n\r\nB6. Dataset of government-developed OS software\r\n‚Ä¢ Governments develop & use software for supporting society\u2028\r\nOpen-source development & policies are on the rise \r\n‚Ä¢ But studying government software is difficult b/c we don‚Äôt know what is out \r\nthere\u2028\r\n‚Üí Lack of incentive to make popular \u2028\r\n‚Üí Language barriers \r\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \r\nbuildable?, open dev. history?, requirements documentation? \r\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!\r\n\r\nB7. Queue - but better for the student / TA society\r\n‚Ä¢ Requirements analysis regarding social and individual sustainability effects \r\nof Queue \r\n‚Ä¢ Other EIP / TUD used software also possible: e.g., Answers EWI \r\n‚Ä¢ Non-technical project ‚Üí proper process (workshops? Interviews?) & rich \r\ndescription of outcomes focus of grading\r\nhttps://eip.pages.ewi.tudelft.nl/eip-website/queue.html\r\n\r\nC1. Compare energy consumption of docker images for \r\nML workloads.\r\n‚Ä¢ Similar to what we have seen in the lectures but for ML-specific workloads. \r\n‚Ä¢ We can reuse existing experiment replication packages.\r\n22\r\n\r\nC2. Plugin to visualize Hugging Face carbon emissions.\r\n‚Ä¢ https://huggingface.co/blog/leaderboard-emissions-\r\nanalysis \r\n‚Ä¢\r\nYoo, Taewon, et al. ""Visualizing the Carbon Intensity of Machine Learning Inference for Image Analysis on TensorFlow Hub.""\r\n\r\nC3. Plugin for ChatGPT\r\n‚Ä¢ Users seldom know how much carbon they are emitting when they interact \r\nwith chat GPT. \r\n‚Ä¢ Let‚Äôs make it transparent to the users. Browser plugin?\r\n24\r\nCO2\r\n\r\nC4. NutriScore for software libraries\r\n25\r\n‚Ä¢ NutriScore labels are not perfect but they are a good starting point! \r\n‚Ä¢ What if we could do the same thing for the energy efficiency of software. \r\n‚Ä¢ (Also open to individual or social sustainability) \r\n‚Ä¢ This work can be scoped in particular domains/ecossystems/use cases. \r\n‚Ä¢ Libraries for stats? ML? Web Dev? Cloud?\r\n\r\nC5. Add energy-awareness to existing software\r\n26\r\n‚Ä¢ Streamlit, Notebooks, JSFiddle, \r\nPyScript, zsh, etc. \r\n‚Ä¢\r\n\r\nC6 - Green Shift Left\r\n‚Ä¢ Estimate energy efficiency using static code analysis. \r\n‚Ä¢ We don‚Äôt need an accurate value. \r\n‚Ä¢ It is useful to know which code is more likely to \r\nintroduce energy hotspots and that should be \r\nreviewed with more attention. \r\n‚Ä¢ Can be scoped to a particular domain (react, php, data \r\nscience, web, etc., etc.)', ""Unless there‚Äôs a \r\ngood reason. \r\n‚Ä¢ E.g., somewhere amongst the 30 executions, \r\nthere might be 1 or 2 that failed to finish due \r\nto some unexpected error. \r\n‚Ä¢ (It happens and that‚Äôs ok!)‚Äì consequently, \r\nthe execution is shorter and spends less \r\nenergy ‚Äì falsely appearing as more \r\nenergy efficient. \r\n‚Ä¢ If data is not Normal there might be some \r\nissues affecting the measurements that \r\nmight be ruining results. It is important to \r\ninvestigate this.\r\n16\r\n\r\nEnergy data is not normal. Why?\r\n‚Ä¢ It might be caused by one of the following reasons: \r\n‚Ä¢ There was an error in some of the executions. If not detected and fixed it \r\nmight ruin results. \r\n‚Ä¢ Your tests are not fully replicable or are not deterministic. Quite frequent \r\nwhen you have internet requests or random-based algorithms. \r\n‚Ä¢ There is an unusual task being run by the system during some experiments. \r\n‚Ä¢ The computer entered a different power mode. \r\n‚Ä¢ External physical conditions have changed. E.g., someone opened a \r\nwindow.\r\n17\r\n\r\nEnergy data is not normal. How to fix?\r\n‚Ä¢ We have 2+1 options: \r\n1. Remove outliers. If there are only a few points that deviate from the normal \r\ndistribution, it is okay to simply remove them. \r\n‚Ä¢ Use the z-score outlier removal. (?) \r\n‚Ä¢ Remove all data points that deviate from the mean more than 3 standard \r\ndeviations: \r\n \r\n2. Fix the issue and rerun experiments. \r\n3. Conclude that nothing can be done about it and data will never be normal. (e.g., \r\nin AI, executions are rarely deterministic). ‚ö† Only after ruling out the previous \r\npoints.\r\n| ¬Øx ‚àíx| > 3s\r\n18\r\n\r\nHow do we know whether data is Normal?\r\n‚Ä¢ Visualise distribution shape: violin plots, histograms, density plot.\u2028\r\n \r\n‚Ä¢ Shapiro-Wilk test.\u2028\r\ndata is not normal;\u2028\r\nwe are not sure but it is okay to assume that data is \r\nnormal.\r\np-value < 0.05 ‚áí\r\np-value ‚â•0.05 ‚áí\r\n19\r\n\r\nAfter having all data ready, which artefact \r\nis more energy efficient(?) \r\nFirst approach: compare sample means. \r\n‚ö† assuming normal distribution\r\n\r\nStatistical significance\r\n‚Ä¢ Even if, on average, one artefact has lower \r\nenergy consumption than other,  it might be just \r\na random difference. \r\n‚Ä¢ When we extract a sample from a normal \r\ndistribution it will never be the exact same \r\n‚Ä¢ Statistical significance tests help you \r\nunderstand the differences in the average are \r\nconclusive/significant or inconclusive/\r\ninsignificant.\r\n21\r\n‚ö† assuming normal distribution\r\n\r\nStatistical significance test\r\n‚Ä¢ Two-sided parametric test Welch‚Äôs t-test. \r\n‚Ä¢ Less known alternative to student‚Äôs t-test.\r\n22\r\nWelch‚Äôs t-test in Python\r\nfrom scipy.stats import ttest_ind \r\n_,pvalue = ttest_ind(sample_a, sample_b, \r\n                     equal_var=False, \r\n                     alternative='two-sided')\r\n(?)\r\n‚ö† assuming normal distribution\r\n\r\nEffect Size analysis\r\n‚Ä¢ Now that we know that results are statistically significant we need to \r\nmeasure the difference between the two samples. \r\n‚Ä¢ Mean difference: \r\n \r\n‚Ä¢ Percent change: \r\n \r\n‚Ä¢ Cohen‚Äôs d (informal definition: mean difference normalized by a combined \r\nstandard deviation): \r\nŒî¬Øx\r\nxB ‚àíxA\r\nxA\r\n√ó 100 % = Œî¬Øx\r\nxA\r\n√ó 100 %\r\nŒî¬Øx\r\n1\r\n2\r\ns21 + s22\r\n23\r\n‚ö† assuming normal distribution\r\n\r\nImagine that version A spends 70J and \r\nversion B spends 69J with a \r\n."", '5. Green Software Metrics\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nLu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\nCarolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl\r\nSustainableSE 2025\r\n\r\nBitcoin example\r\n‚Ä¢ 1 bitcoin transaction is equivalent to more than 1.5 million VISA transactions. \r\n \r\n   \r\n \r\n‚Ä¢ Day-to-day metrics are easy to grasp \r\n‚Ä¢ If we say 8 gigajoules, it‚Äôs a bit more difficult to understand. \r\n‚Ä¢ These numbers keep changing (check it here: https://www.statista.com/\r\nstatistics/881541/bitcoin-energy-consumption-transaction-comparison-visa/)\r\n2\r\n\r\n3\r\n\r\n(Electrical) Energy\r\n‚Ä¢ Work required to move charged particles. \r\n‚Ä¢ Same concept but different perspective when talking about thermal, \r\nmechanical, or nuclear energy. \r\n‚Ä¢ Most common units: \r\n‚Ä¢ joule (J) -  recommended; scientific communications; metric from the \r\nInternational System of Units \r\n‚Ä¢ kilowatt-hour (kWh) - more common, e.g., used for household electricity \r\nconsumption\r\n4\r\n+q\r\n-q\r\nF\r\nF\r\n\r\nPower\r\n‚Ä¢ Amount of work being done per unit of time. \r\n‚Ä¢ Commonly measured in watts (W).\r\n5\r\n\r\n‚à´\r\ntf=9\r\nti=1\r\nP(t)dt\r\n\r\n‚à´\r\ntf=9\r\nti=1\r\nP(t)dt\r\n\r\nA = a + b\r\n2\r\nh\r\nMeasured Energy \r\nConsumption\r\n=\r\nPtn + Ptn+1\r\n2\r\n‚ãÖŒît = 3.5W + 2.0W\r\n2\r\n‚ãÖ1s = 2.75J\r\nA = ?\r\na\r\nb\r\nh\r\n\r\n‚à´\r\ntn\r\nt0\r\nP(t)dt ‚âàŒît\r\n2 [P(t0) + 2P(t1) + 2P(t2) + . . . + 2P(tn‚àí1) + P(tn)]\r\nMeasured Energy \r\nConsumption\r\n‚ö† Sometimes you cannot assume that the sampling interval (\r\n) is always the same. ‚ö†\r\nŒît\r\nTrapezoid Rule\r\n\r\nTrapezoid Rule in Python\r\nimport numpy as np \r\nenergy_consumption = np.trapz(power_sample, timestamps) \r\n\r\nAverage power\r\n‚Ä¢ Easy to convert to energy consumption \r\n‚Ä¢ Simply multiply by the elapsed time. \r\n‚Ä¢ (This is another reason to always collect time data along with energy \r\nmetrics.)\r\n11\r\nEnergy = Pavg¬∑Œît\r\n\r\nPower or Energy?\r\n‚Ä¢ Average power consumption makes sense when we report the \r\nconsumption of a continuous use case. E.g., reading an ebook in your \r\ncomputer. \r\n‚Ä¢ Energy consumption makes sense in one-off use cases. E.g., energy \r\nconsumption of a bitcoin transaction. \r\n‚ö†\r\n\r\nLearning activity\r\n‚Ä¢ Pair up with one colleague and discuss potential software use cases where \r\none should test energy efficiency. \r\n‚Ä¢ Choose one use case where energy consumption is the best metric to \r\ndiscuss/test energy efficiency. \r\n‚Ä¢ Choose one use case where average power consumption is the best \r\nmetric to discuss/test energy efficiency.\r\n13\r\n\r\nEnergy Delay Product (EDP)\r\n‚Ä¢ In some cases, to achieve less energy consumption, one simply runs the \r\nsoftware on a low power mode of the CPU. \r\n‚Ä¢ E.g., setting the CPU at a low frequency will make execution slow but more \r\nenergy-efficient. \r\n‚Ä¢ Energy consumption metric that penalizes slow runs \r\n \r\n \r\n‚Ä¢ Gives more importance to application runtime, with the goal of making both \r\nlow energy and fast runtime applications.', 'It‚Äôs more important that we learn how to \r\ndiscuss this topic and come up with new ideas than learning all the theory. \r\nCritical thinking over checkboxes. \r\n‚Ä¢ Mix of content and discussion \r\n‚Ä¢ Ultimately, the lectures aim to give you food for thought and the necessary \r\nknowledge to excel in Project 2. (We will talk about it later)\r\n30\r\n\r\nhttps://luiscruz.github.io/course_sustainableSE/\r\n31\r\nContent of the course üëá\r\n\r\n32\r\nhttps://mattermost.tudelft.nl/signup_user_complete/?id=1nj9tk6usjf8xmsws8wpq3s5uy&md=link&sbr=su\r\n\r\nProject 1\r\n‚Ä¢ Goal: Measure the energy consumption of software applications. \r\n‚Ä¢ Approach: energy measurement tools; use case testing. \r\n‚Ä¢ Deliverable: blog-style report (approx. 2500 words) \r\n‚Ä¢ Deadline: Week 3, Feb 28, 2025 \r\n‚Ä¢ Group size: 4‚Äì5\r\n33\r\n\r\nProject 2\r\n‚Ä¢ Goal: Create a solution/tool/technique that helps building green software. (You \r\ncan come up with your own idea or choose one from a list of suggestions). \r\n‚Ä¢ Approach: open-source software development; literature review. \r\n‚Ä¢ Deliverable: library/tool/app; paper; presentation. \r\n‚Ä¢ Two deadlines:\u2028\r\n1. Paper and software: Week 8, April 4, 2025\u2028\r\n2. Presentation: Week 9, April 11, 2025 \r\n‚Ä¢ Group size: 4‚Äì5\r\n34\r\n\r\nGuest Lectures\r\nNergis T√∂men \r\nComputer Vision lab | TU Delft \r\nWeek 4, Wed, Mar 5, 2025\r\n35\r\n\r\nCommunity \r\nHow to get involved?\r\n36\r\n\r\nGreen TU\r\n‚Ä¢ https://www.tudelft.nl/sustainability/get-\r\ninvolved/greentu \r\n‚Ä¢ Student organisation at the TU Delft devoted \r\nto stimulating sustainability in education, \r\nresearch, university operations and \r\ncommunity engagement.\r\n37\r\n\r\nClimateAction.tech\r\n‚Ä¢ Great community for outreach \r\n‚Ä¢ Based on Slack  \r\n‚Ä¢ Regular meetings, talks, social events \r\n‚Ä¢ You can join as a volunteer or simply to \r\nconnect to other techies \r\n‚Ä¢ Also good to for job hunting on green tech.\r\n38\r\n\r\nClimateAction.tech\r\n39\r\n\r\nBranch magazine\r\n‚Ä¢ Stay up-to-date on sustainable tech \r\n‚Ä¢ Creativity booster \r\n‚Ä¢ Carbon-aware UI \r\n‚Ä¢ https://branch.climateaction.tech üîó\r\n40\r\n\r\nThis is the fourth edition\r\n‚Ä¢ Any feedback is welcome! Email or DM!\r\n41\r\n\r\n42\r\n\r\nCarolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nLu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\n1. Intro Class\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl', 'Different \r\nscreen brightness, different results. \r\n‚Ä¢ You need to reduce tasks to the bare minimum: \r\n‚Ä¢ Set brightness to a fixed value; turn off notifications, kill all user-owned \r\nprocesses, turn off cellular data, bluetooth, location services, account \r\nsyncs; uninstall all unnecessary apps, etc.\r\n11\r\n\r\nWhen it comes to desktop/cloud software, the sources \r\nof noise are different but the same concerns apply. \r\n \r\nEach case is different ‚Äì think it through!\r\n‚ö†\r\n\r\nEnergy Profilers\r\n‚Ä¢ Simple setup! Quite reliable (if you choose the profiler wisely). \r\n‚Ä¢ Recently, they are starting to rely on internal power sensors. \r\n‚Ä¢ Still sensitive to noise from concurrent processes/tasks! ‚ö†\r\n13\r\n\r\nExamples of Energy Profilers\r\n\r\n15\r\nhttps://www.websitecarbon.com\r\n\r\n16\r\nhttps://mlco2.github.io/impact/\r\n\r\nIntel Power Monitor\r\n‚Ä¢ Install: https://software.intel.com/content/www/us/en/\r\ndevelop/articles/intel-power-gadget.html \r\n‚Ä¢ To collect: Logging > Log to File \r\n \r\n‚Ä¢ It will store a CSV file with all the collected power data. \r\n(File location is specified in the settings) \r\n‚Ä¢ Based on Intel RAPL. Works with Intel-based Windows \r\nand Macs. \r\n‚Ä¢ Alternative-twin for M1-based Macs: Mx Power Gadget.\u2028\r\nhttps://www.seense.com/menubarstats/mxpg/\r\n17\r\n‚ö† No longer supported by Intel ‚ö†  \r\n\r\n18\r\nüîó https://luiscruz.github.io/\r\n2021/07/20/measuring-energy.html\r\n(Missing Apple m1 tools: mxpg, powermetrics)\r\n\r\n19\r\nEnergiBridge\r\nhttps://github.com/tdurieux/energibridge\r\n> target/release/energibridge -o results.csv --summary sleep 10\r\n\r\nHands-on 1\r\n‚Ä¢ Install your energy profiler (EnergiBridge). \r\n‚Ä¢ Collect the energy data of using Coral BodyPix for 30 seconds.\u2028\r\nhttps://storage.googleapis.com/tfjs-models/demos/body-pix/index.html \r\n‚Ä¢ Report the total energy consumption. \r\n‚Ä¢ Extra-mile: \r\n‚Ä¢ Compare the energy consumption in different browsers. \r\n‚Ä¢ Check the spikes and drops in Power and Temperature.\r\n20\r\n\r\nRetrospection\r\nHands-on 1\r\n‚Ä¢ Are the measurements repeatable? \r\n‚Ä¢ What were the confounding factors? \r\n‚Ä¢ How can we automate this process?\r\n21\r\n\r\nEnergy testing\r\n(Different from energy monitoring)\r\n1. Create a reproducible scenario of the execution of your software. Preferably \r\nthis should be an automated script ‚Äì e.g., using a bash or python script. \r\n2. Execute the scenario in a version of your software. Use the energy profiler to \r\nmeasure the energy consumption. \r\n3. Improve your software in parts of the code that you suspect have low \r\nperformance. \r\n4. Execute the same scenario with the new version. Compare the energy data \r\nin this version with the previous one.\u2028\r\nEnergy is lower, test passes; energy is higher test fails.\r\n22\r\n\r\nHands-on 2\r\n‚Ä¢ Create a reproducible scenario. (Usually easier with command-line interfaces) \r\n‚Ä¢ Automatically start/stop energy profiling.\r\n23\r\n\r\nProject 1\r\n‚Ä¢ Deadline: March 1 \r\n‚Ä¢  Compare energy consumption in common software use cases. \r\n‚Ä¢ Examples: \r\n‚Ä¢ Different versions of the same app; \r\n‚Ä¢ Same use case but different apps \r\n‚Ä¢ Same version, same app, but different user settings (e.g., enable/disable GPU optimisation) \r\n‚Ä¢ Same version, same app, but different running environment \r\n‚Ä¢ Submission via PR (markdown). \r\n‚Ä¢ Blog-style report (markdown, approx 2500 words). \r\n‚Ä¢ Replication package. \r\n‚Ä¢ Points if the experiment is automated.', '‚Ä¢ Examples: \r\n‚Ä¢ Technical Debt \r\n‚Ä¢ Does it scale? \r\n‚Ä¢ Software testing \r\n‚Ä¢ Bus-factor \r\n‚Ä¢ Data integrity \r\n‚Ä¢ Innovation \r\n‚Ä¢ ‚Ä¶\r\n10\r\n\r\nIndividual\r\n‚Ä¢ Well-being of the individuals in an organisation.\u2028\r\nNote that it also includes how well individuals interact \r\nwith each other within the org. \r\n‚Ä¢ Examples: \r\n‚Ä¢ mental and physical well-being \r\n‚Ä¢ self-respect \r\n‚Ä¢ education/skills \r\n‚Ä¢ career development \r\n‚Ä¢ ‚Ä¶\r\n11\r\n\r\nSocial\r\n‚Ä¢ concerned with societal communities (groups of people, \r\norganisations) and the factors that erode trust in society. \r\n‚Ä¢ Examples: \r\n‚Ä¢ Social equity \r\n‚Ä¢ Justice \r\n‚Ä¢ Employment \r\n‚Ä¢ Democracy \r\n‚Ä¢ ‚Ä¶ \r\n‚Ä¢ Also includes compliance with policies and regulations \r\n12\r\n\r\nEnvironmental Sustainability\r\n‚Ä¢ the branch of Software Engineering that studies \r\nthe development of software that has minimal \r\nimpact in our planet throughout its whole \r\nlifecycle. \r\n‚Ä¢ Looking at software at different levels: \r\n‚Ä¢ Developing, Using, Serving, ‚Ä¶ \r\n‚Ä¢ Also includes e-waste. \r\n‚Ä¢ Almost identical to Green Software. (?)\r\n13\r\nBordallo II\r\n\r\nGreen Software\r\n‚Ä¢ Sustainability and energy efficiency. \r\n‚Ä¢ Building energy-efficient software is important also from a \r\ntechnical sustainability POV. \r\n‚Ä¢ Smartphones, smart wearables, IoT devices, etc. run on limited \r\npower resources. \r\n‚Ä¢ Developing software to these devices require energy-efficiency \r\ntesting and improvement. \r\n‚Ä¢ It also leads to environmental sustainability (e.g., less battery \r\ncycles) \r\n‚Ä¢ Important for UX (e.g., no need to walk around with power banks)\r\n14\r\n\r\nhttps://www.menti.com/uns9d89kzn\r\nWhat is the sustainability \r\ndimension you are most \r\ninterested in?\r\n?\r\n15\r\n\r\nEconomical sustainability tops the environment\r\n‚Ä¢ In general, a software project will not survive if it‚Äôs not economical \r\nsustainable \r\n‚Ä¢ Yet, a project can survive even if it is not environmental sustainable \r\n‚Ä¢ The mindset is changing! \r\n‚Ä¢ Software consumers have started to worry about the climate impact \r\nof their behaviour as users. \r\n‚Ä¢ Being environmentally sustainable is now an important competitive \r\nfactor \r\n‚Ä¢ Marketing teams are already using all eco-friendly labels. Technical \r\nteams are not there yet, though. \r\n‚Ä¢ It‚Äôs easier said than done!\r\n$\r\n16\r\n\r\nGreen Washing\r\n‚Ä¢ Deceptively use marketing techniques to \r\nclaim being eco-friendly. \r\n‚Ä¢ Opting for green-coloured designs. \r\n‚Ä¢ Red/orange is usually perceived as \r\ntasty. \r\n‚Ä¢ Green is perceived as eco-friendly. \r\n‚Ä¢ The VW case. (?)\r\n17\r\n\r\nThe VW scandal\r\nGreenwashing\r\n‚Ä¢ Used software to cheat on vehicle emissions \r\ntests. \r\n‚Ä¢ The vehicle‚Äôs software could detect whether they \r\nwere being tested, changing the performance \r\naccordingly to improve results. \r\n‚Ä¢ Affected 11M cars worldwide, 8M in Europe.\r\n18\r\n\r\nHow can we drive sustainability \r\nin the SE industry?\r\n\r\nGreen Procurement\r\n‚Ä¢ Customers decide on providers that share their values \r\n‚Ä¢ This is currently the main trigger reason why organisations \r\nworry about Sustainability and Green Software. \r\n‚Ä¢ Examples of green procurement: \r\n‚Ä¢ Customers that only buy green services/products \r\n‚Ä¢ Companies that only use green providers \r\n‚Ä¢ Developers that only work for green companies \r\n‚Ä¢ Green procurement makes environmental sustainability \r\nessential for economical sustainability.\r\n20\r\n\r\nSustainability via compliance\r\n‚Ä¢ EU wants to be carbon neutral by 2030 \r\n‚Ä¢ This also affects the ICT sector. Estimated to impact \r\n14% of the global carbon footprint by 2040. \r\n‚Ä¢ Some initiatives are already being negotiated. \r\n‚Ä¢ Extending the smartphone lifetime to 7 years. \r\n‚Ä¢ Right-to-repair movement. https://repair.eu \r\n‚Ä¢ Making IT services relying on clean energy more \r\naccessible (e.g., less taxes).\r\n21\r\n\r\nSoftware for Sustainability \r\n‚Ä¢ We are not covering it in this course.', 'Carolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nLu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\n1. Intro Class\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl\r\n\r\n1. Intro to Sustainable SE \r\n2. Intro to the course\r\n2\r\n\r\nof the electricity consumed worldwide \r\nby 2040 will stem from ICT\r\n14%\r\n\r\n4\r\nhttps://xkcd.com/1007/\r\n\r\nBuzz words\r\n‚Ä¢ Eco-friendly \r\n‚Ä¢ Climate change, action, adaption \r\n‚Ä¢ Energy efficiency \r\n‚Ä¢ Environmental-responsible \r\n‚Ä¢ Carbon-neutral; Climate-neutral; Net zero \r\n‚Ä¢ Carbon-offsetting \r\n‚Ä¢ Carbon-free \r\n‚Ä¢ Clean technology \r\n‚Ä¢ E-waste\r\n5\r\n\r\nhttps://www.menti.com/uns9d89kzn\r\nWhat is Sustainable \r\nSoftware Engineering?\r\n?\r\n6\r\n\r\nSustainable Software \r\nEngineering is‚Ä¶\r\n7\r\n‚Ä¶the discipline that studies the process of creating software systems that are able \r\nto create value in the long term without hindering its surrounding environment.\r\n\r\n8\r\nEconomical\r\nSocial\r\nTechnical\r\nIndividual\r\nEnvironmental\r\nSustainable\r\nSoftware\r\nEngineering\r\n‚≠ê\r\nTechnical\u2028\r\n‚öô\r\nEconomical\u2028\r\nüí∞\r\nSocial\u2028\r\nüë©üíºüë®üíºüë©üíºüë©üíº\r\nIndividual\u2028\r\nüë©üíª\r\nEnvironmental\u2028\r\nüå±\r\nSustainable\u2028\r\nSoftware \r\nEngineering\r\n\r\nEconomical\r\n‚Ä¢ Focused on assets, capital and added value\u2028\r\n(wealth creation, prosperity, profitability, capital \r\ninvestment, income, etc.) \r\n‚Ä¢ Nr of customers  \r\n‚Ä¢ Man-day-rate estimate \r\n‚Ä¢ Next round of funding \r\n‚Ä¢ Meet requirements in the contract\r\n9\r\n\r\nTechnical\r\n‚Ä¢ Longevity of information, systems, and infrastructure and their \r\nadequate evolution with changing surrounding conditions. \r\n‚Ä¢ Examples: \r\n‚Ä¢ Technical Debt \r\n‚Ä¢ Does it scale? \r\n‚Ä¢ Software testing \r\n‚Ä¢ Bus-factor \r\n‚Ä¢ Data integrity \r\n‚Ä¢ Innovation \r\n‚Ä¢ ‚Ä¶\r\n10\r\n\r\nIndividual\r\n‚Ä¢ Well-being of the individuals in an organisation.\u2028\r\nNote that it also includes how well individuals interact \r\nwith each other within the org. \r\n‚Ä¢ Examples: \r\n‚Ä¢ mental and physical well-being \r\n‚Ä¢ self-respect \r\n‚Ä¢ education/skills \r\n‚Ä¢ career development \r\n‚Ä¢ ‚Ä¶\r\n11\r\n\r\nSocial\r\n‚Ä¢ concerned with societal communities (groups of people, \r\norganisations) and the factors that erode trust in society. \r\n‚Ä¢ Examples: \r\n‚Ä¢ Social equity \r\n‚Ä¢ Justice \r\n‚Ä¢ Employment \r\n‚Ä¢ Democracy \r\n‚Ä¢ ‚Ä¶ \r\n‚Ä¢ Also includes compliance with policies and regulations \r\n12\r\n\r\nEnvironmental Sustainability\r\n‚Ä¢ the branch of Software Engineering that studies \r\nthe development of software that has minimal \r\nimpact in our planet throughout its whole \r\nlifecycle. \r\n‚Ä¢ Looking at software at different levels: \r\n‚Ä¢ Developing, Using, Serving, ‚Ä¶ \r\n‚Ä¢ Also includes e-waste. \r\n‚Ä¢ Almost identical to Green Software. (?)\r\n13\r\nBordallo II\r\n\r\nGreen Software\r\n‚Ä¢ Sustainability and energy efficiency. \r\n‚Ä¢ Building energy-efficient software is important also from a \r\ntechnical sustainability POV. \r\n‚Ä¢ Smartphones, smart wearables, IoT devices, etc. run on limited \r\npower resources. \r\n‚Ä¢ Developing software to these devices require energy-efficiency \r\ntesting and improvement. \r\n‚Ä¢ It also leads to environmental sustainability (e.g., less battery \r\ncycles) \r\n‚Ä¢ Important for UX (e.g., no need to walk around with power banks)\r\n14\r\n\r\nhttps://www.menti.com/uns9d89kzn\r\nWhat is the sustainability \r\ndimension you are most \r\ninterested in?\r\n?']","['<1-hop>\n\nShuffle \nüîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them.\n‚Ä¢ If you run 30 executions for version A and another batch for version B:\n‚Ä¢ External conditions that change over time will have a diÔ¨Äerent bias in \nthe 2 versions (e.g., room temperature changes).\n‚Ä¢ If you shuÔ¨Ñe, you reduce this risk.\n11', '<2-hop>\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio)\n‚Ä¢ Dynamic Retry Delay\n‚Ä¢ Push Over Poll\n‚Ä¢ Reduce Size\n‚Ä¢ Cache\n‚Ä¢ Avoid Graphics and Animations\n20', '<1-hop>\n\nShuffle \nüîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them.\n‚Ä¢ If you run 30 executions for version A and another batch for version B:\n‚Ä¢ External conditions that change over time will have a diÔ¨Äerent bias in \nthe 2 versions (e.g., room temperature changes).\n‚Ä¢ If you shuÔ¨Ñe, you reduce this risk.\n11', '<2-hop>\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio)\n‚Ä¢ Dynamic Retry Delay\n‚Ä¢ Push Over Poll\n‚Ä¢ Reduce Size\n‚Ä¢ Cache\n‚Ä¢ Avoid Graphics and Animations\n20']","To reduce risk and size in software engineering, consider the following strategies:

1. **Data-Centric Approaches**: Focus on improving the quality of data rather than just increasing its quantity. This involves better data collection, labeling, and preprocessing to ensure datasets are small but reliable, reducing noise and unnecessary complexity (Source: Green Data-centric AI).

2. **Model Simplification**: Simplify models by using techniques like model pruning, quantization, and distillation. This reduces the size of the models and the computational resources required, which in turn reduces risk by making systems more manageable and less prone to errors (Source: Data/Model Simplification).

3. **Energy Patterns**: Implement energy-efficient design patterns, such as batching operations and using dark UI themes for mobile apps, to reduce resource consumption and improve performance, thereby reducing risk (Source: Energy Patterns for Mobile Apps).

4. **Hyperparameter Tuning**: Use efficient hyperparameter tuning methods like Bayesian optimization, which converges faster and can help in reducing the computational cost and size of the models (Source: Hyperparameter Tuning).

5. **Green AI Practices**: Adopt Green AI practices by checking the necessity of AI, selecting green datacenters, and using low-power hardware. This not only reduces the environmental impact but also minimizes the risk associated with high energy consumption and large-scale models (Source: How can we adopt Green AI).

By implementing these strategies, software engineering projects can become more efficient, sustainable, and less risky.","To reduce risk, shuffling executions helps control external factors like temperature changes. To reduce size, EcoAndroid uses features like dynamic retry delay and push over poll.",0.0,0.5,0.7,0.0,,0.980885315377629
How shuffling reduce risk and EcoAndroid reduce size?,"['‚Ä¢ In a scientific project, the magic number is 30.\r\n7\r\n\r\n\r\nRest ‚è∏\r\n‚Ä¢ It is common practice to do a pause/sleep between executions/\r\nmeasurements. \r\n‚Ä¢ Prevent tail energy consumption from previous measurements. ? \r\n‚Ä¢ Prevent collateral tasks of previous measurement from affecting the next \r\nmeasurement. \r\n‚Ä¢ There is no golden rule but one minute should be enough. It can be more or \r\nless depending on your hardware or the duration of your energy test.\r\n9\r\n\r\nt\r\nP\r\nTail Energy Consumption\r\n\r\nShuffle üîÄ\r\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \r\nit is impossible to control all of them. \r\n‚Ä¢ If you run 30 executions for version A and another batch for version B: \r\n‚Ä¢ External conditions that change over time will have a different bias in \r\nthe 2 versions (e.g., room temperature changes). \r\n‚Ä¢ If you shuffle, you reduce this risk.\r\n11\r\n\r\nKeep it cool üå°\r\n‚Ä¢ Always make sure there is a stable room temperature. \r\n‚Ä¢ Tricky because, some times, experiments may have to run over a few days. \r\n‚Ä¢ If you cannot control room temperature: collect temperature data and filter \r\nout measurements where the room temperature is clearly deviating.\r\n12\r\n\r\nAutomate Executions ü§ñ\r\n‚Ä¢ (Already mentioned in the previous classes) \r\n‚Ä¢ One cannot run 30 shuffled experiments per version without automation‚Ä¶\r\n13\r\n\r\nData analysis\r\n14\r\n\r\n1. Exploratory Analysis\r\n‚Ä¢ Plot the data and inspect outliers or \r\nunexpected biases. \r\n‚Ä¢ Violin+box plots are usually handy. (?) \r\n‚Ä¢ It‚Äôs a nice way of combining the 30 \r\nexperiments, and of showing \r\ndescriptive statistics. (?) \r\n‚Ä¢ Shows the shape of the distribution \r\nof the data.\r\n15\r\n\r\n1. Exploratory Analysis (II)\r\n‚Ä¢ Data should be Normal. Unless there‚Äôs a \r\ngood reason. \r\n‚Ä¢ E.g., somewhere amongst the 30 executions, \r\nthere might be 1 or 2 that failed to finish due \r\nto some unexpected error. \r\n‚Ä¢ (It happens and that‚Äôs ok!)‚Äì consequently, \r\nthe execution is shorter and spends less \r\nenergy ‚Äì falsely appearing as more \r\nenergy efficient. \r\n‚Ä¢ If data is not Normal there might be some \r\nissues affecting the measurements that \r\nmight be ruining results. It is important to \r\ninvestigate this.\r\n16\r\n\r\nEnergy data is not normal. Why?\r\n‚Ä¢ It might be caused by one of the following reasons: \r\n‚Ä¢ There was an error in some of the executions. If not detected and fixed it \r\nmight ruin results. \r\n‚Ä¢ Your tests are not fully replicable or are not deterministic. Quite frequent \r\nwhen you have internet requests or random-based algorithms. \r\n‚Ä¢ There is an unusual task being run by the system during some experiments. \r\n‚Ä¢ The computer entered a different power mode. \r\n‚Ä¢ External physical conditions have changed. E.g., someone opened a \r\nwindow.\r\n17\r\n\r\nEnergy data is not normal. How to fix?\r\n‚Ä¢ We have 2+1 options: \r\n1. Remove outliers. If there are only a few points that deviate from the normal \r\ndistribution, it is okay to simply remove them. \r\n‚Ä¢ Use the z-score outlier removal. (?) \r\n‚Ä¢ Remove all data points that deviate from the mean more than 3 standard \r\ndeviations: \r\n \r\n2. Fix the issue and rerun experiments. \r\n3. Conclude that nothing can be done about it and data will never be normal. (e.g., \r\nin AI, executions are rarely deterministic). ‚ö† Only after ruling out the previous \r\npoints.\r\n| ¬Øx ‚àíx| > 3s\r\n18\r\n\r\nHow do we know whether data is Normal?', 'Lu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\n3. Scientific Guide for Reliable \r\nEnergy Experiments\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nCarolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl\r\n\r\n1. Scientific guide for energy measurements \r\n2. Energy consumption data analysis \r\n\r\nEnergy tests are flaky\r\n‚Ä¢ Multiple runs might yield different results \r\n‚Ä¢ There are many confounding factors that need to be controlled/minimized.\r\n3\r\n?\r\n\r\nZen mode üßò\r\n‚Ä¢ Close all applications. \r\n‚Ä¢ Turn off notifications. \r\n‚Ä¢ Only the required hardware should be connected (avoid USB drives, external \r\ndisks, external displays, etc.). \r\n‚Ä¢ Kill unnecessary services running in the background (e.g., web server, file \r\nsharing, etc.). \r\n‚Ä¢ If you do not need an internet or intranet connection, switch off your network. \r\n‚Ä¢ Prefer cable over wireless ‚Äì the energy consumption from a cable connection \r\nis more stable than from a wireless connection.\r\n4\r\n\r\nFreeze and report your settings ü•∂\r\n‚Ä¢ Fix display brightness; switch off auto brightness \r\n‚Ä¢ If Wifi is on, it should always be on, connected to the same network/\r\nendpoint.‚Ä¶\r\n5\r\n\r\nWarm-up üì∂\r\n‚Ä¢ Energy consumption is highly affected by the temperature of your hardware. \r\n‚Ä¢ Higher the temperature -> higher the resistance of electrical conductors ->\u2028\r\n-> higher dissipation -> higher energy consumption \r\n‚Ä¢ The first execution will appear more efficient because the hardware is still \r\ncold. \r\n‚Ä¢ Run a CPU-intensive task before measuring energy consumption. E.g., \r\nFibonacci sequence. At least 1min; 5min recommended. \r\n‚Ä¢\r\n6\r\n\r\nRepeat üîÅ\r\n‚Ä¢ The best way to make sure a measurement is valid is by repeating it. \r\n‚Ä¢ In a scientific project, the magic number is 30.\r\n7\r\n\r\n\r\nRest ‚è∏\r\n‚Ä¢ It is common practice to do a pause/sleep between executions/\r\nmeasurements. \r\n‚Ä¢ Prevent tail energy consumption from previous measurements. ? \r\n‚Ä¢ Prevent collateral tasks of previous measurement from affecting the next \r\nmeasurement. \r\n‚Ä¢ There is no golden rule but one minute should be enough. It can be more or \r\nless depending on your hardware or the duration of your energy test.\r\n9\r\n\r\nt\r\nP\r\nTail Energy Consumption\r\n\r\nShuffle üîÄ\r\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \r\nit is impossible to control all of them. \r\n‚Ä¢ If you run 30 executions for version A and another batch for version B: \r\n‚Ä¢ External conditions that change over time will have a different bias in \r\nthe 2 versions (e.g., room temperature changes). \r\n‚Ä¢ If you shuffle, you reduce this risk.\r\n11\r\n\r\nKeep it cool üå°\r\n‚Ä¢ Always make sure there is a stable room temperature. \r\n‚Ä¢ Tricky because, some times, experiments may have to run over a few days. \r\n‚Ä¢ If you cannot control room temperature: collect temperature data and filter \r\nout measurements where the room temperature is clearly deviating.\r\n12\r\n\r\nAutomate Executions ü§ñ\r\n‚Ä¢ (Already mentioned in the previous classes) \r\n‚Ä¢ One cannot run 30 shuffled experiments per version without automation‚Ä¶\r\n13\r\n\r\nData analysis\r\n14\r\n\r\n1. Exploratory Analysis\r\n‚Ä¢ Plot the data and inspect outliers or \r\nunexpected biases. \r\n‚Ä¢ Violin+box plots are usually handy. (?) \r\n‚Ä¢ It‚Äôs a nice way of combining the 30 \r\nexperiments, and of showing \r\ndescriptive statistics. (?) \r\n‚Ä¢ Shows the shape of the distribution \r\nof the data.\r\n15\r\n\r\n1. Exploratory Analysis (II)\r\n‚Ä¢ Data should be Normal.', '[‚Ä¶]\r\n13\r\n\r\nAvoid Extraneous Graphics and \r\nAnimations  \r\n‚Ä¢ Context: Mobile apps that feature impressive graphics \r\nand animations. [‚Ä¶] \r\n‚Ä¢ Solution: Study the importance of graphics and \r\nanimations to the user experience and reduce them when \r\napplicable. [‚Ä¶]\r\n‚Ä¢ Example: Resort to low frame rates for animations when \r\npossible. \r\nDespite being important to improve user experience, graphics \r\nand animations are battery intensive and should be used with \r\nmoderation.  \r\n14\r\n\r\nEnergy Patterns are \r\nmore Frequent\r\nin Android Apps\r\n\r\nExample case: Nextcloud\r\nFOSS\r\n\r\nExample case: Nextcloud\r\n‚Ä¢ Users complain that sometimes they go on a trip and  Nextcloud drains their \r\nbattery. Users consider uninstalling the app when battery life is essential. \r\n‚Ä¢ File sync can be energy-greedy. Send large files to the server, long 3G/4G data connections. \r\n‚Ä¢ It is mostly used for backup. No real-time collaboration is needed. \r\n‚Ä¢ Energy requirements vary depending on context and user. Some days you really \r\nneed all the battery you can get. \r\n‚Ä¢ https://github.com/nextcloud/android/commit/\r\n8bc432027e0d33e8043cf40192203203a40ca29c\r\nSolutions?\r\n17\r\n\r\nExample case: K-9 mail\r\n18\r\n\r\nExample case: K-9 mail\r\n19\r\nSolutions?\r\n‚Ä¢ Some users noticed that K-9 mail was spending more energy than usual. üôâ \r\n‚Ä¢ A user that was having issues with a personal mail server  noticed that K-9 \r\nmail was the one of the most energy-greedy apps. IMAP IDLE protocol for real-time \r\nnotifications. \r\n‚Ä¢ When a connection is not possible, the app automatically retries later. \r\n‚Ä¢ https://github.com/k9mail/k-9/commit/\r\n86f3b28f79509d1a4d613eb39f60603e08579ea3\r\n\r\nEcoAndroid\r\n‚Ä¢ Plugin for IntelliJ (Android Studio) \r\n‚Ä¢ Dynamic Retry Delay \r\n‚Ä¢ Push Over Poll \r\n‚Ä¢ Reduce Size \r\n‚Ä¢ Cache \r\n‚Ä¢ Avoid Graphics and Animations\r\n20\r\n\r\nCarbon-Aware Computing for \r\nDatacenters \r\nhttps://sites.google.com/view/energy-efficiency-languages\r\n21\r\nAna Radovanovic ÃÅ, Ross Koningstein, Ian Schneider, Bokan \r\nChen, Alexandre Duarte, Binz Roy, Diyue Xiao, Maya \r\nHaridasan, Patrick Hung, Nick Care, Saurav Talukdar, Eric \r\nMullen, Kendal Smith, MariEllen Cottman, and Walfredo Cirne \r\n\r\n\r\n‚Ä¢ Google‚Äôs Carbon-Intelligent Computing System (CICS) \r\n‚Ä¢ Main idea: use carbon-intensity data to shift datacenter jobs in time \r\n‚Ä¢ Typically, job schedulers use a metric of cluster capacity to schedule a job in \r\na particular cluster. \r\n‚Ä¢ CICS overrides this metric with the virtual capacity curve (VCC) that \r\nfactors in Carbon intensity \r\n‚Ä¢ When a new job comes in, the scheduler estimates its CPU load and power \r\nusage and assigns it to a cluster if the VCC is not exceeded.\r\n23\r\n\r\n‚Ä¢ Jobs are divided between flexible and inflexible. \r\n‚Ä¢ Flexible load is considered shapeable/shiftable as long as its total daily \r\ncompute (CPU) demand is preserved \r\n‚Ä¢ The system needs to consider that, while running a job, the virtual capacity \r\ncurve (VCC) might drop. Hence, this job should not start in the first place. \r\n‚Ä¢ They forecast VCC for the next day\r\n24\r\n\r\n\r\nVirtual Cluster Capacity (VCC)\r\n‚Ä¢ Aims at reducing the peak load at carbon intensive hours but in total it should allow for the \r\nsome amount of daily computation!', ""‚Ä¢ Our question: Can we save energy with alternative approaches? \r\n‚Ä¢ We studied Grid Search, Random Search and Bayesian \r\nOptimisation.\r\n27\r\nTim's MSc Thesis, 2022 \r\nAccepted at CAIN‚Äô23\r\n\r\n\r\nResults\r\n29\r\nConclusions? \r\n‚Ä¢ Bayesian converges faster. \r\n‚Ä¢ No clear winner between Grid and Random\r\n\r\nDeepSeekMoE\r\n30\r\nPreprint at ArXiv, 2024 https://arxiv.org/pdf/\r\n2401.06066\r\n\r\nMixture of Experts\r\n‚Ä¢ Llama3.1 has 405B parameters, DeepSeek V3 671B \r\n‚Ä¢ Yet DeepSeek has quicker inference times and claims less energy \r\nconsumption (?) \r\n‚Ä¢ Divide the model into smaller blocks of experts \r\n‚Ä¢ Tokens get routed to certain experts based on the query \r\n‚Ä¢ Only part of the network is active during inference \r\n‚Ä¢ DeepSeek claims only 37B out of 671B parameters get active\r\n31\r\n\r\nDeepSeekMoE\r\n32\r\n\r\nDeepSeekMoE\r\n33\r\n‚Ä¢ Comparable performance to \r\nLLaMA2 7B effectively using \r\nless half the parameters \r\n‚Ä¢ Less computational power \r\n‚Ä¢ Problems (?) \r\n‚Ä¢ Still need to load all the \r\nparameters \r\n‚Ä¢ High memory -> high \r\nembodied carbon\r\n\r\nGreen AI at FacebookMeta\r\n34\r\nSustainable AI: Environmental Implications, \r\nChallenges and Opportunities (2022)\r\n\r\nCarbon footprint mapped to the AI lifecycle\r\n‚Ä¢ There are 4 main overarching stages where carbon emissions need to be isolated: data \r\ncollection, experimentation, training, inference. \r\n‚Ä¢ At Facebook, recommendation systems split energy consumption evenly between \r\ntraining and inference; text translation models have a 35%/65% split. (Operational cost) \r\n‚Ä¢ Operational/embodied cost split: 30%/70%\r\n35\r\n\r\nOpen issues according to Meta\r\n‚Ä¢ A vast portion of projects only use GPUs at 30%.\u2028\r\nShould be higher to attenuate embodied carbon.\r\n36\r\nBased on 10K AI projects\r\n\r\nData Jan\r\nInformed Adaptation\r\nData Feb\r\nData Mar\r\nData Apr\r\nData May\r\n‚Ä¶\r\n~Data Dec\r\n~Data Dec\r\nData Jan\r\nData Feb\r\nData Mar\r\nData Apr\r\nData May\r\n‚Ä¶\r\nModel update Model update Model update\r\nCheck if \r\ndata change\r\nCheck if \r\ndata change\r\nCheck if \r\ndata change\r\nModel update\r\nBlind Adaptation\r\nThe AI Model will be \r\nupdated fewer times and \r\nonly when necessary.\r\nKnow when to retrain models\r\nNeither too early nor too late\r\n37\r\nAdaptation Techniques\r\n?\r\n\r\nGreen Architectural Tactics for ML-Enabled \r\nSystem\r\n38\r\nICSE-SEIS 2024\r\n\r\nArchitectural tactics\r\n39\r\n\r\nData-centric\r\n40\r\n‚Ä¢ Reduce data size \r\n‚Ä¢ Sampling \r\n‚Ä¢ Dimensionality reduction \r\n‚Ä¢ Quantization\r\n\r\nAlgorithm Design\r\n41\r\n‚Ä¢ Carefully select your algorithm \r\n‚Ä¢ You don‚Äôt need the fanciest \r\ntechniques\r\n\r\nModel Optimization\r\n42\r\n‚Ä¢ Add energy to training parameters \r\n‚Ä¢ Reduce FLOPs \r\n‚Ä¢ Pruning, sparsity \r\n‚Ä¢  Take advantage of existing models\r\n\r\nModel Training\r\n43\r\n‚Ä¢ Quantization\r\n‚Ä¢ SAVE TRAINING PROGRESS\r\n\r\nModel Deployment\r\n44\r\n‚Ä¢ Distributed deployment \r\n‚Ä¢ Energy efficient hardware and \r\nconfigurations\r\n\r\nModel Management\r\n45\r\n‚Ä¢ Reuse the model as much as possible \r\n\r\nRethinking the Architecture: Spiking Neural Networks\r\n46\r\n\r\nRethinking the Architecture: Spiking Neural Networks\r\n47\r\n\r\nSELF Lab\r\n48\r\n\r\nrecap"", '8. Green AI\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nLu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\nCarolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl\r\n\r\n- Overview of Green AI \r\n- Large language models \r\n- Green data-centric AI \r\n- Model simplification \r\n- Hyper parameter tuning \r\n- Mixture of Experts and DeepSeek \r\n- Green AI at Meta \r\n\r\nAI\r\n‚Ä¢ Artificial Intelligence (AI) is the branch of computer science that deals with \r\nautomating tasks that typically require human intelligence. \r\n‚Ä¢ In the past years AI has been widely applied across different domains.\u2028\r\nE.g., health care, transportation, finance. \r\n‚Ä¢ To deploy AI systems, we test them against benchmarks (or validation sets). \r\n‚Ä¢ The goal is to outperform the previous existing models. \r\n‚Ä¢ E.g., in Machine Learning we usually resort to accuracy metrics. The \r\nhighest the accuracy, the better the model.\r\n3\r\n\r\nSince 2012, the amount of computing used for AI \r\ntraining has been doubling every 6 months\r\n‚Ä¢ https://epoch.ai/blog/compute-trends\r\n4\r\n\r\n‚Ä¢ To create better AI systems we are currently adding \r\n‚Ä¢ More data \r\n‚Ä¢ More experiments \r\n‚Ä¢ Larger models\r\n5\r\n\r\nThe Equation of Red AI\r\nCost(R) ‚àùE¬∑D¬∑H\r\nCost of a single (E)xample\r\nSize of (D)ataset\r\nNumber of (H)yperparameters\r\nBy Schwartz et al. (2020)\r\n\r\nIssues of Red AI\r\n‚Ä¢ High costs (hardware, electricity, data access, etc.) \r\n‚Ä¢ Limited reproducibility.  \r\n‚Ä¢ Energy consumption. \r\n‚Ä¢ Carbon emissions. \r\n‚Ä¢ SMEs can hardly be competitive. \r\n‚Ä¢ Groundbreaking AI research is mostly done by tech giants.\r\n7\r\n\r\nA few examples of Red AI\r\n‚Ä¢ Google‚Äôs BERT-large \r\n‚Ä¢ 350 million features \r\n‚Ä¢ Trained for 2.5 days using 512 TPU chips, costing $60K+ \r\n‚Ä¢ Open-GPT3 (now GPT-4/o1) \r\n‚Ä¢ 550 tonnes CO2-eq (Patterson, 2021) \r\n‚Ä¢ 175 billion features \r\n‚Ä¢ API is open but no-pretrained model is available \r\n‚Ä¢ AlphaGo \r\n‚Ä¢ 1920 CPUs, 280 GPUs, costing $35M\r\n8\r\n\r\nRed AI in Large Language Models (LLMs)\r\n‚Ä¢ OPT by Meta reports 75 tons CO2-eq (1/7 of OpenGPT‚Äôs footprint).\u2028\r\n(Also 175billion params) \r\n‚Ä¢ However, Llama 3 reported 2,290 tons of CO2-eq (7.7M GPU hours \r\ntraining ) \r\n‚Ä¢ Open science: release includes both the pretrained models and the code \r\nneeded to train and use them. \r\n‚Ä¢ DeepSeek-V3 claims ‚Äúonly‚Äù 2.78M GPU hours \r\n‚Ä¢ Bloom by Huggingface reports 25 tons, 51 when considering embodied \r\nand operational carbon footprint. (176billion params)\r\n9\r\n\r\nRed AI\r\nAccuracy: 0.999999999\r\nGreen AI\r\n‚Ä¢ Energy \r\n‚Ä¢ Time \r\n‚Ä¢ Reproducibility \r\n‚Ä¢ Reusage\r\n\r\nHow can we adopt Green AI\r\n‚Ä¢ Check whether AI is needed. \r\n‚Ä¢ Select green datacenters. \r\n‚Ä¢ Run on low carbon intensity hours. \r\n‚Ä¢ Opt for GPU-optimised solutions (?) \r\n‚Ä¢ Opt for low-power hardware (e.g., Nvidia Jetson boards) \r\n‚Ä¢ Or GPUs that provide energy metrics (e.g., NVIDIA GPUs via the nvidia-smi tool) \r\n‚Ä¢ Report energy/carbon metrics (e.g., embed in MLFlow?)', '‚Ä¢ Groundbreaking AI research is mostly done by tech giants.\r\n7\r\n\r\nA few examples of Red AI\r\n‚Ä¢ Google‚Äôs BERT-large \r\n‚Ä¢ 350 million features \r\n‚Ä¢ Trained for 2.5 days using 512 TPU chips, costing $60K+ \r\n‚Ä¢ Open-GPT3 (now GPT-4/o1) \r\n‚Ä¢ 550 tonnes CO2-eq (Patterson, 2021) \r\n‚Ä¢ 175 billion features \r\n‚Ä¢ API is open but no-pretrained model is available \r\n‚Ä¢ AlphaGo \r\n‚Ä¢ 1920 CPUs, 280 GPUs, costing $35M\r\n8\r\n\r\nRed AI in Large Language Models (LLMs)\r\n‚Ä¢ OPT by Meta reports 75 tons CO2-eq (1/7 of OpenGPT‚Äôs footprint).\u2028\r\n(Also 175billion params) \r\n‚Ä¢ However, Llama 3 reported 2,290 tons of CO2-eq (7.7M GPU hours \r\ntraining ) \r\n‚Ä¢ Open science: release includes both the pretrained models and the code \r\nneeded to train and use them. \r\n‚Ä¢ DeepSeek-V3 claims ‚Äúonly‚Äù 2.78M GPU hours \r\n‚Ä¢ Bloom by Huggingface reports 25 tons, 51 when considering embodied \r\nand operational carbon footprint. (176billion params)\r\n9\r\n\r\nRed AI\r\nAccuracy: 0.999999999\r\nGreen AI\r\n‚Ä¢ Energy \r\n‚Ä¢ Time \r\n‚Ä¢ Reproducibility \r\n‚Ä¢ Reusage\r\n\r\nHow can we adopt Green AI\r\n‚Ä¢ Check whether AI is needed. \r\n‚Ä¢ Select green datacenters. \r\n‚Ä¢ Run on low carbon intensity hours. \r\n‚Ä¢ Opt for GPU-optimised solutions (?) \r\n‚Ä¢ Opt for low-power hardware (e.g., Nvidia Jetson boards) \r\n‚Ä¢ Or GPUs that provide energy metrics (e.g., NVIDIA GPUs via the nvidia-smi tool) \r\n‚Ä¢ Report energy/carbon metrics (e.g., embed in MLFlow?) \r\n‚Ä¢ Use pre-trained models (Transfer Learning) \r\n‚Ä¢ Preprocess dataset to reduce size. \r\n‚Ä¢ Improve parameter-tuning strategy.\r\n11\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ We need benchmarks. \r\n‚Ä¢ AllenAI leaderboard\u2028\r\nhttps://leaderboard.allenai.org \r\n‚Ä¢ No carbon metrics, yet \r\n‚Ä¢ Report comparable proxies for energy \r\nconsumption. \r\n‚Ä¢ ‚ö† Learning algorithms behave in a non-\r\ndeterministic \r\n‚Ä¢ ‚ö† Different data-points lead to different \r\nenergy consumption\r\n12\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ Reporting measured energy consumption \r\n‚Ä¢ + Accurate \r\n‚Ä¢ + Easy to map to carbon emissions \r\n‚Ä¢ - Hard to measure \r\n‚Ä¢ - Low replicability \r\n‚Ä¢ Reporting time / estimation based on time & hardware \r\n‚Ä¢ + Easy to measure \r\n‚Ä¢ + Correlates with energy consumption in most cases. \r\n‚Ä¢ -  Difficult to compare with measurements from other setups \r\n‚Ä¢ E.g., floating point operations (FPOs) (?) \r\n‚Ä¢ + comparable across different setups \r\n‚Ä¢ + cheap \r\n‚Ä¢ - does not factor in memory energy consumption \r\n‚Ä¢ - does not reflect carbon emissions\r\n13\r\n\r\nData-centric AI\r\n\r\nData-centric AI\r\n‚Ä¢ Emerging discipline that deals with systematically engineering data to build AI \r\nsystems. \r\n‚Ä¢ Shift from improving the training strategy to improving the data. \r\n‚Ä¢ It is better to have small but reliable datasets than large but noisy \r\ndatasets. \r\n‚Ä¢ => Improve data collection, data labelling, and data preprocessing. \r\n‚Ä¢ More about data-centric AI by Andrew Ng:\u2028\r\nhttps://www.youtube.com/watch?v=06-AZXmwHjo\r\n15\r\n\r\n\r\nGreen Data-centric AI\r\n‚Ä¢ How do different ML algorithms compare \r\nin terms of energy consumption? \r\n‚Ä¢ How does number of rows relate to the \r\nenergy consumption of ML models? \r\n‚Ä¢ How does number of features relate to \r\nthe energy consumption of ML models? \r\n‚Ä¢ What is the impact of reducing data in the \r\nperformance of the model?', 'google.com/view/energy-efficiency-languages\r\n21\r\nAna Radovanovic ÃÅ, Ross Koningstein, Ian Schneider, Bokan \r\nChen, Alexandre Duarte, Binz Roy, Diyue Xiao, Maya \r\nHaridasan, Patrick Hung, Nick Care, Saurav Talukdar, Eric \r\nMullen, Kendal Smith, MariEllen Cottman, and Walfredo Cirne \r\n\r\n\r\n‚Ä¢ Google‚Äôs Carbon-Intelligent Computing System (CICS) \r\n‚Ä¢ Main idea: use carbon-intensity data to shift datacenter jobs in time \r\n‚Ä¢ Typically, job schedulers use a metric of cluster capacity to schedule a job in \r\na particular cluster. \r\n‚Ä¢ CICS overrides this metric with the virtual capacity curve (VCC) that \r\nfactors in Carbon intensity \r\n‚Ä¢ When a new job comes in, the scheduler estimates its CPU load and power \r\nusage and assigns it to a cluster if the VCC is not exceeded.\r\n23\r\n\r\n‚Ä¢ Jobs are divided between flexible and inflexible. \r\n‚Ä¢ Flexible load is considered shapeable/shiftable as long as its total daily \r\ncompute (CPU) demand is preserved \r\n‚Ä¢ The system needs to consider that, while running a job, the virtual capacity \r\ncurve (VCC) might drop. Hence, this job should not start in the first place. \r\n‚Ä¢ They forecast VCC for the next day\r\n24\r\n\r\n\r\nVirtual Cluster Capacity (VCC)\r\n‚Ä¢ Aims at reducing the peak load at carbon intensive hours but in total it should allow for the \r\nsome amount of daily computation! \r\n‚Ä¢ Considers Carbon intensity \r\n‚Ä¢ Using data from electricityMap.org \r\n‚Ä¢ It does not use carbon intensity directly.\u2028\r\nCarbon intensity is converted to a cost (kgCO2 -> $$) \r\n‚Ä¢ This way, they can factor in other metrics that can also be converted to money. E.g., the \r\ncost saved by preventing peak load \r\n‚Ä¢ Peak workload entails extra cost at the infrastructure level (e.g., control faclities‚Äô \r\ntemperature). \r\n‚Ä¢ By using money cost instead of carbon cost, they have more data available.\r\n26\r\n\r\nVirtual Cluster Capacity (VCC)\r\n‚Ä¢ If the forecast of VCC fails it shift flexible workload more than expected.  \r\n‚Ä¢ This happens because the amount of workload forecasted was below the \r\nworkload needed, and VCC was ‚Äúaggressively‚Äù low. \r\n‚Ä¢ The systems fall back to the real cluster capacity for 1 week until results \r\nstart being realistic again.\r\n27\r\n\r\nNext steps\r\n‚Ä¢ They will consider spatial flexibility. \r\n‚Ä¢ I.e., tasks that can be shifted over time and over space. \r\n‚Ä¢ It needs to factor in relocation overheads, though.\r\n28\r\n\r\nCritical questions\r\n‚Ä¢ Who defines what is flexible and inflexible? \r\n‚Ä¢ How do you estimate the CPU load of a given task?\r\n29\r\n\r\nEnergy Regression Testing\r\n‚ÜíEnergy?\r\nGreener? Greener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\n\r\nE-compare\r\nGithub Actions\r\n‚ûú https://koenhagen.github.io/E-Compare/\r\n\r\nEnergy Regression Testing \r\n\r\n4. Debugging Energy with \r\nDocker Images\r\n\r\nUnveiling the Energy Vampires \r\nA methodology for debugging Software \r\nEnergy Consumption\r\n ‚úÖ ICSE 2025\r\n\r\nData Centers and Docker\r\n‚Ä¢ Containers are the most popular way to deploy apps into the cloud \r\n‚Ä¢ Base image is an important choice when building an image \r\n‚Ä¢ Criteria \r\n‚Ä¢ Linux distribution and binaries \r\n‚Ä¢ Image size \r\n‚Ä¢ Energy?\r\n35\r\n\r\nRedis energy consumption\r\n‚Ä¢ Ubuntu/Alpine base images have different energy consumption for Redis\r\n36\r\n\r\nRedis Energy Consumption\r\n‚Ä¢RQ1: What is the difference \r\nin energy consumption \r\nbetween glibc and musl? \r\n‚Ä¢RQ2: Can we use tracing \r\nto compare energy \r\nconsumption in shared \r\nlibraries?', 'Lu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\n7. Green SE ‚Äì Research\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nCarolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl\r\n\r\n1. Energy patterns for mobile apps \r\n2. Carbon-aware datacenters \r\n3. Energy Regression Testing \r\n4. Debugging Energy with Docker images \r\n5. Energy Efficiency vs Code Quality \r\n\r\n‚Ä¢ While learning about these works, try to be critical about them and find their \r\npitfalls.\r\n3\r\n\r\n‚Ä¢ We have seen that measuring energy consumption is not trivial \r\n‚Ä¢ It is not practical considering that developers have other priorities above \r\nenergy efficiency \r\n‚Ä¢ At the same time, every now and then there are some efforts to improve \r\nenergy efficiency in some cases. This is time consuming and requires \r\nexpertise. \r\n‚Ä¢ How can we reuse these efforts?\r\n4\r\n\r\nEnergy Patterns for Mobile \r\nApps\r\nhttps://tqrg.github.io/energy-patterns/\r\n\r\nMethodology\r\n5. Catalog of Energy Patterns\r\n22 \r\npatterns\r\nF-droid\r\nCurated Lists\r\n1. App Collection\r\n1783 \r\napps\r\n3. Manual Refinement of Subjects of \r\nInterest\r\n1563 \r\nchanges\r\n4. Thematic Analysis\r\n431 \r\nreusable \r\nchanges\r\n2. Collect Changes With Potential Interest\r\n/.*(energy|power|battery).*/\r\n6028 \r\nchanges\r\n\r\nThematic Analysis\r\n1. Familiarization with data \r\n2. Generating initial labels \r\n3. Reviewing themes\r\n4. Defining and naming themes\r\n\r\n‚Ä¢ Energy Pattern: design pattern to improve energy efficiency.. \r\n‚Ä¢ 22 energy patterns. \r\n‚Ä¢ Each pattern is described by Context, Solution, Example, References from \r\nliterature, and Occurences (links to code changes from git repositories).\r\n8\r\n\r\nhttps://tqrg.github.io/energy-patterns\r\n\r\nDark UI Colors \r\nProvide a dark UI color theme to \r\nsave battery on devices with \r\nAMOLED screens.\r\n‚Ä¢ Context: [‚Ä¶] Apps that require heavy usage of screen can \r\nhave a substantial negative impact on battery life. \r\n‚Ä¢ Solution: Provide a UI theme with dark background colors. [‚Ä¶]\r\n‚Ä¢ Example: In a reading app, provide a theme with a dark \r\nbackground using light colors to display text. [‚Ä¶] \r\n10\r\n\r\nDark UI Colors \r\nProvide a dark UI color theme to \r\nsave battery on devices with \r\nAMOLED screens.\r\n‚Ä¢ Context: [‚Ä¶] Apps that require heavy usage of screen can \r\nhave a substantial negative impact on battery life. \r\n‚Ä¢ Solution: Provide a UI theme with dark background colors. [‚Ä¶]\r\n‚Ä¢ Example: In a reading app, provide a theme with a dark \r\nbackground using light colors to display text. [‚Ä¶] \r\n11\r\n\r\nDynamic Retry Delay\r\n‚Ä¢ Context: [‚Ä¶] In a mobile app, when a given resource is \r\nunavailable, the app will unnecessarily try to connect the resource \r\nfor a number of times, leading to unnecessary power consumption. \r\n‚Ä¢ Solution: Increase retry interval after each failed connection. [‚Ä¶]\r\n‚Ä¢ Example: Consider a mobile app that provides a news feed and \r\nthe app is not able to reach the server to collect updates. [‚Ä¶] use \r\nthe Fibonacci series to increase the time between attempts.\r\nWhenever an attempt to access a \r\nresource fails, increase the time \r\ninterval before retrying.\r\n12\r\n\r\nBatch Operations \r\n‚Ä¢ Context: Executing operations separately leads to extraneous \r\ntail energy consumptions  \r\n‚Ä¢ Solution: Bundle multiple operations in a single one. [‚Ä¶]\r\n‚Ä¢ Example: Use system provided APIs to schedule background \r\ntasks. These APIs, guarantee that device will exit sleep mode \r\nonly when there is a reasonable amount of work to do or when a \r\ngiven task is urgent.', '‚Ä¢ By using money cost instead of carbon cost, they have more data available.\r\n26\r\n\r\nVirtual Cluster Capacity (VCC)\r\n‚Ä¢ If the forecast of VCC fails it shift flexible workload more than expected.  \r\n‚Ä¢ This happens because the amount of workload forecasted was below the \r\nworkload needed, and VCC was ‚Äúaggressively‚Äù low. \r\n‚Ä¢ The systems fall back to the real cluster capacity for 1 week until results \r\nstart being realistic again.\r\n27\r\n\r\nNext steps\r\n‚Ä¢ They will consider spatial flexibility. \r\n‚Ä¢ I.e., tasks that can be shifted over time and over space. \r\n‚Ä¢ It needs to factor in relocation overheads, though.\r\n28\r\n\r\nCritical questions\r\n‚Ä¢ Who defines what is flexible and inflexible? \r\n‚Ä¢ How do you estimate the CPU load of a given task?\r\n29\r\n\r\nEnergy Regression Testing\r\n‚ÜíEnergy?\r\nGreener? Greener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\n\r\nE-compare\r\nGithub Actions\r\n‚ûú https://koenhagen.github.io/E-Compare/\r\n\r\nEnergy Regression Testing \r\n\r\n4. Debugging Energy with \r\nDocker Images\r\n\r\nUnveiling the Energy Vampires \r\nA methodology for debugging Software \r\nEnergy Consumption\r\n ‚úÖ ICSE 2025\r\n\r\nData Centers and Docker\r\n‚Ä¢ Containers are the most popular way to deploy apps into the cloud \r\n‚Ä¢ Base image is an important choice when building an image \r\n‚Ä¢ Criteria \r\n‚Ä¢ Linux distribution and binaries \r\n‚Ä¢ Image size \r\n‚Ä¢ Energy?\r\n35\r\n\r\nRedis energy consumption\r\n‚Ä¢ Ubuntu/Alpine base images have different energy consumption for Redis\r\n36\r\n\r\nRedis Energy Consumption\r\n‚Ä¢RQ1: What is the difference \r\nin energy consumption \r\nbetween glibc and musl? \r\n‚Ä¢RQ2: Can we use tracing \r\nto compare energy \r\nconsumption in shared \r\nlibraries? \r\n‚Ä¢RQ3: Can we verify the \r\norigin of energy \r\nconsumption differences by \r\nrecreating the workload \r\nbehavior closely?\r\n37\r\n\r\nTracing\r\n‚Ä¢ Find libc function running at the end of the benchmark \r\n‚Ä¢ Tracing: Capture calls made to libc \r\n‚Ä¢ Introduces non-linear overhead\r\n38\r\n\r\nSynchronization\r\n‚Ä¢ Tracing slows down execution and increase energy consumption \r\n‚Ä¢ Run separately and synchronize with logs\r\n39\r\n\r\nTracing Analysis\r\n40\r\n\r\nTracing Analysis\r\n41\r\n\r\nBenchmarking memcpy\r\n‚Ä¢ Copy bytes from one part of memory to \r\nanother \r\n‚Ä¢ Depending on function parameters, different \r\nassembly-level optimizations \r\n‚Ä¢ Some not included in musl\r\n42\r\n\r\nBenchmarking memcpy\r\n‚Ä¢ Copy 4 bytes from fixed \r\npointer to moving pointer \r\n‚Ä¢ (100,300,500,600) x 1M \r\nrequests \r\n‚Ä¢  15% more power and 3X time\r\n43\r\n\r\nConclusions\r\n‚Ä¢ Significant difference in energy consumption for memcpy \r\n‚Ä¢ 8.6% difference for Redis workload and 13% in our benchmark \r\n‚Ä¢ musl trades performance for a smaller codebase \r\n‚Ä¢ No official documentation \r\n‚Ä¢ No awareness about energy performance\r\n44\r\n\r\n5. Energy Efficiency vs Code \r\nQuality\r\n\r\nMeasuring Maintainability\r\n‚Ä¢ According to ISO/IEC 25010, Maintainability is ‚Äúthe degree of \r\neffectiveness and efficiency with which a software product or \r\nsystem can be modified to improve it, correct it or adapt it to \r\nchanges in environment, and in requirements‚Äù \r\n‚Ä¢ We use the code analysis tool Better Code Hub to assess \r\nmaintainability \r\n‚Ä¢ Better Code Hub maps the ISO/IEC 25010 standard on \r\nmaintainability into a set of guidelines derived from static analysis\r\n46\r\n\r\nMaintainability of Energy Changes\r\n‚Ä¢ What is the impact of making energy-oriented code changes on \r\nthe maintainability of mobile apps?', ""Unless there‚Äôs a \r\ngood reason. \r\n‚Ä¢ E.g., somewhere amongst the 30 executions, \r\nthere might be 1 or 2 that failed to finish due \r\nto some unexpected error. \r\n‚Ä¢ (It happens and that‚Äôs ok!)‚Äì consequently, \r\nthe execution is shorter and spends less \r\nenergy ‚Äì falsely appearing as more \r\nenergy efficient. \r\n‚Ä¢ If data is not Normal there might be some \r\nissues affecting the measurements that \r\nmight be ruining results. It is important to \r\ninvestigate this.\r\n16\r\n\r\nEnergy data is not normal. Why?\r\n‚Ä¢ It might be caused by one of the following reasons: \r\n‚Ä¢ There was an error in some of the executions. If not detected and fixed it \r\nmight ruin results. \r\n‚Ä¢ Your tests are not fully replicable or are not deterministic. Quite frequent \r\nwhen you have internet requests or random-based algorithms. \r\n‚Ä¢ There is an unusual task being run by the system during some experiments. \r\n‚Ä¢ The computer entered a different power mode. \r\n‚Ä¢ External physical conditions have changed. E.g., someone opened a \r\nwindow.\r\n17\r\n\r\nEnergy data is not normal. How to fix?\r\n‚Ä¢ We have 2+1 options: \r\n1. Remove outliers. If there are only a few points that deviate from the normal \r\ndistribution, it is okay to simply remove them. \r\n‚Ä¢ Use the z-score outlier removal. (?) \r\n‚Ä¢ Remove all data points that deviate from the mean more than 3 standard \r\ndeviations: \r\n \r\n2. Fix the issue and rerun experiments. \r\n3. Conclude that nothing can be done about it and data will never be normal. (e.g., \r\nin AI, executions are rarely deterministic). ‚ö† Only after ruling out the previous \r\npoints.\r\n| ¬Øx ‚àíx| > 3s\r\n18\r\n\r\nHow do we know whether data is Normal?\r\n‚Ä¢ Visualise distribution shape: violin plots, histograms, density plot.\u2028\r\n \r\n‚Ä¢ Shapiro-Wilk test.\u2028\r\ndata is not normal;\u2028\r\nwe are not sure but it is okay to assume that data is \r\nnormal.\r\np-value < 0.05 ‚áí\r\np-value ‚â•0.05 ‚áí\r\n19\r\n\r\nAfter having all data ready, which artefact \r\nis more energy efficient(?) \r\nFirst approach: compare sample means. \r\n‚ö† assuming normal distribution\r\n\r\nStatistical significance\r\n‚Ä¢ Even if, on average, one artefact has lower \r\nenergy consumption than other,  it might be just \r\na random difference. \r\n‚Ä¢ When we extract a sample from a normal \r\ndistribution it will never be the exact same \r\n‚Ä¢ Statistical significance tests help you \r\nunderstand the differences in the average are \r\nconclusive/significant or inconclusive/\r\ninsignificant.\r\n21\r\n‚ö† assuming normal distribution\r\n\r\nStatistical significance test\r\n‚Ä¢ Two-sided parametric test Welch‚Äôs t-test. \r\n‚Ä¢ Less known alternative to student‚Äôs t-test.\r\n22\r\nWelch‚Äôs t-test in Python\r\nfrom scipy.stats import ttest_ind \r\n_,pvalue = ttest_ind(sample_a, sample_b, \r\n                     equal_var=False, \r\n                     alternative='two-sided')\r\n(?)\r\n‚ö† assuming normal distribution\r\n\r\nEffect Size analysis\r\n‚Ä¢ Now that we know that results are statistically significant we need to \r\nmeasure the difference between the two samples. \r\n‚Ä¢ Mean difference: \r\n \r\n‚Ä¢ Percent change: \r\n \r\n‚Ä¢ Cohen‚Äôs d (informal definition: mean difference normalized by a combined \r\nstandard deviation): \r\nŒî¬Øx\r\nxB ‚àíxA\r\nxA\r\n√ó 100 % = Œî¬Øx\r\nxA\r\n√ó 100 %\r\nŒî¬Øx\r\n1\r\n2\r\ns21 + s22\r\n23\r\n‚ö† assuming normal distribution\r\n\r\nImagine that version A spends 70J and \r\nversion B spends 69J with a \r\n."", ""‚Ä¢ 6 machine learning algorithms: SVM, Decision Tree, KNN, Random Forrest, \r\nAdaBoost, Bagging Classifier. \r\n‚Ä¢ Reduce the number of rows. 10%, 20%, .., 100% \r\n‚Ä¢ Stratified random sampling (?) \r\n‚Ä¢ Reduce the number of features. 10%, 20%, .., 100% \r\n‚Ä¢ Feature importance metric based on the Chi-Square Test (Chi2) \r\n‚Ä¢ Estimate energy consumption using a RAPL-based tool. (?)\r\n18\r\n\r\n‚Ä¢ Repeat 30 times \r\n‚Ä¢ Fix random seeds \r\n‚Ä¢ ‚Ä¶ \r\n‚Ä¢ Data was not Normal => tailed Normal distribution.\r\n19\r\n(?)\r\n\r\nResults: energy consumption of algorithms\r\n\r\nResults: energy vs data shape\r\n\r\nResults: performance vs data shape\r\n\r\nDiscussion\r\n‚Ä¢ Other data properties should be investigated. \r\n‚Ä¢ E.g., data types \r\n‚Ä¢ Reporting energy data is essential. It can lead to different model selection \r\nwithout hindering model performance. \r\n‚Ä¢ There is a big opportunity in Model and Data Simplification.\r\n23\r\n\r\nData/Model Simplification\r\n‚Ä¢ (?) \r\n‚Ä¢ Data selection \r\n‚Ä¢ Data quantisation. Posit? \r\n‚Ä¢ Data distillation \r\n‚Ä¢ Coreset extraction (?) \r\n‚Ä¢ Model distillation \r\n‚Ä¢ Model quantisation \r\n‚Ä¢ Model pruning \r\n‚Ä¢ ‚Ä¶\r\n24\r\n\r\nPosit vs Float\r\nMore about this: https://spectrum.ieee.org/floating-point-numbers-posits-processor\r\nBetter for DL use cases\r\n\r\nHow can we tune \r\nlearning \r\nparameters \r\nefficiently?\r\n\r\nHyper parameter tuning\r\n‚Ä¢ When training an ML model, there are several parameters that need to be \r\ntuned. \r\n‚Ä¢ E.g., in SVM we have the Regularization parameter C, the kernel function, \r\nthe degree of the kernel function, and depending on the case, many other. \r\n‚Ä¢ The common approach revolves around grid search. The user provides a \r\nsequence of possible values for each parameter and the pipeline runs all \r\npossible combinations. \r\n‚Ä¢ Our question: Can we save energy with alternative approaches? \r\n‚Ä¢ We studied Grid Search, Random Search and Bayesian \r\nOptimisation.\r\n27\r\nTim's MSc Thesis, 2022 \r\nAccepted at CAIN‚Äô23\r\n\r\n\r\nResults\r\n29\r\nConclusions? \r\n‚Ä¢ Bayesian converges faster. \r\n‚Ä¢ No clear winner between Grid and Random\r\n\r\nDeepSeekMoE\r\n30\r\nPreprint at ArXiv, 2024 https://arxiv.org/pdf/\r\n2401.06066\r\n\r\nMixture of Experts\r\n‚Ä¢ Llama3.1 has 405B parameters, DeepSeek V3 671B \r\n‚Ä¢ Yet DeepSeek has quicker inference times and claims less energy \r\nconsumption (?) \r\n‚Ä¢ Divide the model into smaller blocks of experts \r\n‚Ä¢ Tokens get routed to certain experts based on the query \r\n‚Ä¢ Only part of the network is active during inference \r\n‚Ä¢ DeepSeek claims only 37B out of 671B parameters get active\r\n31\r\n\r\nDeepSeekMoE\r\n32\r\n\r\nDeepSeekMoE\r\n33\r\n‚Ä¢ Comparable performance to \r\nLLaMA2 7B effectively using \r\nless half the parameters \r\n‚Ä¢ Less computational power \r\n‚Ä¢ Problems (?) \r\n‚Ä¢ Still need to load all the \r\nparameters \r\n‚Ä¢ High memory -> high \r\nembodied carbon\r\n\r\nGreen AI at FacebookMeta\r\n34\r\nSustainable AI: Environmental Implications, \r\nChallenges and Opportunities (2022)\r\n\r\nCarbon footprint mapped to the AI lifecycle\r\n‚Ä¢ There are 4 main overarching stages where carbon emissions need to be isolated: data \r\ncollection, experimentation, training, inference. \r\n‚Ä¢ At Facebook, recommendation systems split energy consumption evenly between \r\ntraining and inference; text translation models have a 35%/65% split. (Operational cost) \r\n‚Ä¢ Operational/embodied cost split: 30%/70%\r\n35\r\n\r\nOpen issues according to Meta\r\n‚Ä¢ A vast portion of projects only use GPUs at 30%.\u2028\r\nShould be higher to attenuate embodied carbon."", '27\r\n\r\nCarbon intensity\r\n‚Ä¢ How much carbon is emitted per kWh of electricity consumed. \r\n‚Ä¢ The common unit: \r\n ü§∑ \r\n‚Ä¢ E.g.,  gas-based power plants emit less carbon than coal-based plants. \r\n‚Ä¢ The power grid is a mix between different sources of electricity ‚Äì different \r\nlocations have different carbon intensity.\r\ngCO2eq/kWh\r\n28\r\n\r\nhttps://app.electricitymaps.com/map\r\n\r\nBy Asim Hussain: https://principles.green/principles/carbon-intensity/\r\nüìù Reducing software energy consumption can help reduce the carbon intensity. Why?\r\n\r\nOne would expect zero carbon intensity from solar-\r\npanels or wind farms, but that‚Äôs not the case.\r\n‚ö†\r\n?\r\n\r\nMarginal Power Plant\r\n‚Ä¢ Renewable-based power plants cannot adapt to demand. \r\n‚Ä¢ When demand is higher than the existing power in the electricity grid, we \r\nneed a power plant that is able to scale up to that demand. \r\n‚Ä¢ This is usually done by fossil-based power plants. They are called the \r\nmarginal power plants. \r\n‚Ä¢ The problem is that marginal power plants do not scale down to zero. \r\n‚Ä¢ There is always a minimum carbon that needs to be emitted, even if there is \r\na lot of renewable energy in the grid.\r\n32\r\n\r\nBy Asim Hussain: https://principles.green/principles/carbon-intensity/\r\nHow could we fix this?\r\nWhat‚Äôs the problem here?\r\n\r\nMarginal Carbon Intensity\r\n‚Ä¢ Increase or decrease in carbon emissions in the electrical grid, in response \r\nto an infinitesimal increase/decrease in power demand/supply.\r\n\r\nFrom: ‚ÄúLiterature Review: On the effectiveness of a Marginal Carbon Intensity Signal ‚Äú\r\n\r\nWhy is marginal carbon intensity \r\nrelevant for software?\r\n‚Ä¢ Tip: consider a task scheduler in a datacenter.\r\n\r\nRecap\r\n‚Ä¢ Power \r\n‚Ä¢ Energy \r\n‚Ä¢ Average Power \r\n‚Ä¢ Energy Delay Product \r\n‚Ä¢ Electric charge (battery capacity) \r\n‚Ä¢ Carbon dioxide equivalent (carbon emissions) \r\n‚Ä¢ 100-global-warming potential \r\n‚Ä¢ Carbon Intensity \r\n‚Ä¢ Marginal Carbon Intensity\r\n37\r\n?\r\n\r\nFurther Reading\r\n‚Ä¢ Blog post on energy units:\u2028\r\nhttps://luiscruz.github.io/2023/05/13/energy-units.html \r\n38\r\n?', '8\r\n\r\nhttps://tqrg.github.io/energy-patterns\r\n\r\nDark UI Colors \r\nProvide a dark UI color theme to \r\nsave battery on devices with \r\nAMOLED screens.\r\n‚Ä¢ Context: [‚Ä¶] Apps that require heavy usage of screen can \r\nhave a substantial negative impact on battery life. \r\n‚Ä¢ Solution: Provide a UI theme with dark background colors. [‚Ä¶]\r\n‚Ä¢ Example: In a reading app, provide a theme with a dark \r\nbackground using light colors to display text. [‚Ä¶] \r\n10\r\n\r\nDark UI Colors \r\nProvide a dark UI color theme to \r\nsave battery on devices with \r\nAMOLED screens.\r\n‚Ä¢ Context: [‚Ä¶] Apps that require heavy usage of screen can \r\nhave a substantial negative impact on battery life. \r\n‚Ä¢ Solution: Provide a UI theme with dark background colors. [‚Ä¶]\r\n‚Ä¢ Example: In a reading app, provide a theme with a dark \r\nbackground using light colors to display text. [‚Ä¶] \r\n11\r\n\r\nDynamic Retry Delay\r\n‚Ä¢ Context: [‚Ä¶] In a mobile app, when a given resource is \r\nunavailable, the app will unnecessarily try to connect the resource \r\nfor a number of times, leading to unnecessary power consumption. \r\n‚Ä¢ Solution: Increase retry interval after each failed connection. [‚Ä¶]\r\n‚Ä¢ Example: Consider a mobile app that provides a news feed and \r\nthe app is not able to reach the server to collect updates. [‚Ä¶] use \r\nthe Fibonacci series to increase the time between attempts.\r\nWhenever an attempt to access a \r\nresource fails, increase the time \r\ninterval before retrying.\r\n12\r\n\r\nBatch Operations \r\n‚Ä¢ Context: Executing operations separately leads to extraneous \r\ntail energy consumptions  \r\n‚Ä¢ Solution: Bundle multiple operations in a single one. [‚Ä¶]\r\n‚Ä¢ Example: Use system provided APIs to schedule background \r\ntasks. These APIs, guarantee that device will exit sleep mode \r\nonly when there is a reasonable amount of work to do or when a \r\ngiven task is urgent. [‚Ä¶]\r\n13\r\n\r\nAvoid Extraneous Graphics and \r\nAnimations  \r\n‚Ä¢ Context: Mobile apps that feature impressive graphics \r\nand animations. [‚Ä¶] \r\n‚Ä¢ Solution: Study the importance of graphics and \r\nanimations to the user experience and reduce them when \r\napplicable. [‚Ä¶]\r\n‚Ä¢ Example: Resort to low frame rates for animations when \r\npossible. \r\nDespite being important to improve user experience, graphics \r\nand animations are battery intensive and should be used with \r\nmoderation.  \r\n14\r\n\r\nEnergy Patterns are \r\nmore Frequent\r\nin Android Apps\r\n\r\nExample case: Nextcloud\r\nFOSS\r\n\r\nExample case: Nextcloud\r\n‚Ä¢ Users complain that sometimes they go on a trip and  Nextcloud drains their \r\nbattery. Users consider uninstalling the app when battery life is essential. \r\n‚Ä¢ File sync can be energy-greedy. Send large files to the server, long 3G/4G data connections. \r\n‚Ä¢ It is mostly used for backup. No real-time collaboration is needed. \r\n‚Ä¢ Energy requirements vary depending on context and user. Some days you really \r\nneed all the battery you can get. \r\n‚Ä¢ https://github.com/nextcloud/android/commit/\r\n8bc432027e0d33e8043cf40192203203a40ca29c\r\nSolutions?\r\n17\r\n\r\nExample case: K-9 mail\r\n18\r\n\r\nExample case: K-9 mail\r\n19\r\nSolutions?\r\n‚Ä¢ Some users noticed that K-9 mail was spending more energy than usual. üôâ \r\n‚Ä¢ A user that was having issues with a personal mail server  noticed that K-9 \r\nmail was the one of the most energy-greedy apps. IMAP IDLE protocol for real-time \r\nnotifications. \r\n‚Ä¢ When a connection is not possible, the app automatically retries later. \r\n‚Ä¢ https://github.', '‚Ä¢ Examples: \r\n‚Ä¢ Technical Debt \r\n‚Ä¢ Does it scale? \r\n‚Ä¢ Software testing \r\n‚Ä¢ Bus-factor \r\n‚Ä¢ Data integrity \r\n‚Ä¢ Innovation \r\n‚Ä¢ ‚Ä¶\r\n10\r\n\r\nIndividual\r\n‚Ä¢ Well-being of the individuals in an organisation.\u2028\r\nNote that it also includes how well individuals interact \r\nwith each other within the org. \r\n‚Ä¢ Examples: \r\n‚Ä¢ mental and physical well-being \r\n‚Ä¢ self-respect \r\n‚Ä¢ education/skills \r\n‚Ä¢ career development \r\n‚Ä¢ ‚Ä¶\r\n11\r\n\r\nSocial\r\n‚Ä¢ concerned with societal communities (groups of people, \r\norganisations) and the factors that erode trust in society. \r\n‚Ä¢ Examples: \r\n‚Ä¢ Social equity \r\n‚Ä¢ Justice \r\n‚Ä¢ Employment \r\n‚Ä¢ Democracy \r\n‚Ä¢ ‚Ä¶ \r\n‚Ä¢ Also includes compliance with policies and regulations \r\n12\r\n\r\nEnvironmental Sustainability\r\n‚Ä¢ the branch of Software Engineering that studies \r\nthe development of software that has minimal \r\nimpact in our planet throughout its whole \r\nlifecycle. \r\n‚Ä¢ Looking at software at different levels: \r\n‚Ä¢ Developing, Using, Serving, ‚Ä¶ \r\n‚Ä¢ Also includes e-waste. \r\n‚Ä¢ Almost identical to Green Software. (?)\r\n13\r\nBordallo II\r\n\r\nGreen Software\r\n‚Ä¢ Sustainability and energy efficiency. \r\n‚Ä¢ Building energy-efficient software is important also from a \r\ntechnical sustainability POV. \r\n‚Ä¢ Smartphones, smart wearables, IoT devices, etc. run on limited \r\npower resources. \r\n‚Ä¢ Developing software to these devices require energy-efficiency \r\ntesting and improvement. \r\n‚Ä¢ It also leads to environmental sustainability (e.g., less battery \r\ncycles) \r\n‚Ä¢ Important for UX (e.g., no need to walk around with power banks)\r\n14\r\n\r\nhttps://www.menti.com/uns9d89kzn\r\nWhat is the sustainability \r\ndimension you are most \r\ninterested in?\r\n?\r\n15\r\n\r\nEconomical sustainability tops the environment\r\n‚Ä¢ In general, a software project will not survive if it‚Äôs not economical \r\nsustainable \r\n‚Ä¢ Yet, a project can survive even if it is not environmental sustainable \r\n‚Ä¢ The mindset is changing! \r\n‚Ä¢ Software consumers have started to worry about the climate impact \r\nof their behaviour as users. \r\n‚Ä¢ Being environmentally sustainable is now an important competitive \r\nfactor \r\n‚Ä¢ Marketing teams are already using all eco-friendly labels. Technical \r\nteams are not there yet, though. \r\n‚Ä¢ It‚Äôs easier said than done!\r\n$\r\n16\r\n\r\nGreen Washing\r\n‚Ä¢ Deceptively use marketing techniques to \r\nclaim being eco-friendly. \r\n‚Ä¢ Opting for green-coloured designs. \r\n‚Ä¢ Red/orange is usually perceived as \r\ntasty. \r\n‚Ä¢ Green is perceived as eco-friendly. \r\n‚Ä¢ The VW case. (?)\r\n17\r\n\r\nThe VW scandal\r\nGreenwashing\r\n‚Ä¢ Used software to cheat on vehicle emissions \r\ntests. \r\n‚Ä¢ The vehicle‚Äôs software could detect whether they \r\nwere being tested, changing the performance \r\naccordingly to improve results. \r\n‚Ä¢ Affected 11M cars worldwide, 8M in Europe.\r\n18\r\n\r\nHow can we drive sustainability \r\nin the SE industry?\r\n\r\nGreen Procurement\r\n‚Ä¢ Customers decide on providers that share their values \r\n‚Ä¢ This is currently the main trigger reason why organisations \r\nworry about Sustainability and Green Software. \r\n‚Ä¢ Examples of green procurement: \r\n‚Ä¢ Customers that only buy green services/products \r\n‚Ä¢ Companies that only use green providers \r\n‚Ä¢ Developers that only work for green companies \r\n‚Ä¢ Green procurement makes environmental sustainability \r\nessential for economical sustainability.\r\n20\r\n\r\nSustainability via compliance\r\n‚Ä¢ EU wants to be carbon neutral by 2030 \r\n‚Ä¢ This also affects the ICT sector. Estimated to impact \r\n14% of the global carbon footprint by 2040. \r\n‚Ä¢ Some initiatives are already being negotiated. \r\n‚Ä¢ Extending the smartphone lifetime to 7 years. \r\n‚Ä¢ Right-to-repair movement. https://repair.eu \r\n‚Ä¢ Making IT services relying on clean energy more \r\naccessible (e.g., less taxes).\r\n21\r\n\r\nSoftware for Sustainability \r\n‚Ä¢ We are not covering it in this course.', '‚Ä¢ Improve parameter-tuning strategy.\r\n11\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ We need benchmarks. \r\n‚Ä¢ AllenAI leaderboard\u2028\r\nhttps://leaderboard.allenai.org \r\n‚Ä¢ No carbon metrics, yet \r\n‚Ä¢ Report comparable proxies for energy \r\nconsumption. \r\n‚Ä¢ ‚ö† Learning algorithms behave in a non-\r\ndeterministic \r\n‚Ä¢ ‚ö† Different data-points lead to different \r\nenergy consumption\r\n12\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ Reporting measured energy consumption \r\n‚Ä¢ + Accurate \r\n‚Ä¢ + Easy to map to carbon emissions \r\n‚Ä¢ - Hard to measure \r\n‚Ä¢ - Low replicability \r\n‚Ä¢ Reporting time / estimation based on time & hardware \r\n‚Ä¢ + Easy to measure \r\n‚Ä¢ + Correlates with energy consumption in most cases. \r\n‚Ä¢ -  Difficult to compare with measurements from other setups \r\n‚Ä¢ E.g., floating point operations (FPOs) (?) \r\n‚Ä¢ + comparable across different setups \r\n‚Ä¢ + cheap \r\n‚Ä¢ - does not factor in memory energy consumption \r\n‚Ä¢ - does not reflect carbon emissions\r\n13\r\n\r\nData-centric AI\r\n\r\nData-centric AI\r\n‚Ä¢ Emerging discipline that deals with systematically engineering data to build AI \r\nsystems. \r\n‚Ä¢ Shift from improving the training strategy to improving the data. \r\n‚Ä¢ It is better to have small but reliable datasets than large but noisy \r\ndatasets. \r\n‚Ä¢ => Improve data collection, data labelling, and data preprocessing. \r\n‚Ä¢ More about data-centric AI by Andrew Ng:\u2028\r\nhttps://www.youtube.com/watch?v=06-AZXmwHjo\r\n15\r\n\r\n\r\nGreen Data-centric AI\r\n‚Ä¢ How do different ML algorithms compare \r\nin terms of energy consumption? \r\n‚Ä¢ How does number of rows relate to the \r\nenergy consumption of ML models? \r\n‚Ä¢ How does number of features relate to \r\nthe energy consumption of ML models? \r\n‚Ä¢ What is the impact of reducing data in the \r\nperformance of the model? \r\n‚Ä¢ Method -> results -> discussion\r\n17\r\n\r\nMethod\r\n‚Ä¢ Single object of study: natural language model to detect spam messages. \r\n‚Ä¢ 6 machine learning algorithms: SVM, Decision Tree, KNN, Random Forrest, \r\nAdaBoost, Bagging Classifier. \r\n‚Ä¢ Reduce the number of rows. 10%, 20%, .., 100% \r\n‚Ä¢ Stratified random sampling (?) \r\n‚Ä¢ Reduce the number of features. 10%, 20%, .., 100% \r\n‚Ä¢ Feature importance metric based on the Chi-Square Test (Chi2) \r\n‚Ä¢ Estimate energy consumption using a RAPL-based tool. (?)\r\n18\r\n\r\n‚Ä¢ Repeat 30 times \r\n‚Ä¢ Fix random seeds \r\n‚Ä¢ ‚Ä¶ \r\n‚Ä¢ Data was not Normal => tailed Normal distribution.\r\n19\r\n(?)\r\n\r\nResults: energy consumption of algorithms\r\n\r\nResults: energy vs data shape\r\n\r\nResults: performance vs data shape\r\n\r\nDiscussion\r\n‚Ä¢ Other data properties should be investigated. \r\n‚Ä¢ E.g., data types \r\n‚Ä¢ Reporting energy data is essential. It can lead to different model selection \r\nwithout hindering model performance. \r\n‚Ä¢ There is a big opportunity in Model and Data Simplification.\r\n23\r\n\r\nData/Model Simplification\r\n‚Ä¢ (?) \r\n‚Ä¢ Data selection \r\n‚Ä¢ Data quantisation. Posit? \r\n‚Ä¢ Data distillation \r\n‚Ä¢ Coreset extraction (?) \r\n‚Ä¢ Model distillation \r\n‚Ä¢ Model quantisation \r\n‚Ä¢ Model pruning \r\n‚Ä¢ ‚Ä¶\r\n24\r\n\r\nPosit vs Float\r\nMore about this: https://spectrum.ieee.org/floating-point-numbers-posits-processor\r\nBetter for DL use cases\r\n\r\nHow can we tune \r\nlearning \r\nparameters \r\nefficiently?\r\n\r\nHyper parameter tuning\r\n‚Ä¢ When training an ML model, there are several parameters that need to be \r\ntuned. \r\n‚Ä¢ E.g., in SVM we have the Regularization parameter C, the kernel function, \r\nthe degree of the kernel function, and depending on the case, many other. \r\n‚Ä¢ The common approach revolves around grid search.', 'Carolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nLu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\n1. Intro Class\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl\r\n\r\n1. Intro to Sustainable SE \r\n2. Intro to the course\r\n2\r\n\r\nof the electricity consumed worldwide \r\nby 2040 will stem from ICT\r\n14%\r\n\r\n4\r\nhttps://xkcd.com/1007/\r\n\r\nBuzz words\r\n‚Ä¢ Eco-friendly \r\n‚Ä¢ Climate change, action, adaption \r\n‚Ä¢ Energy efficiency \r\n‚Ä¢ Environmental-responsible \r\n‚Ä¢ Carbon-neutral; Climate-neutral; Net zero \r\n‚Ä¢ Carbon-offsetting \r\n‚Ä¢ Carbon-free \r\n‚Ä¢ Clean technology \r\n‚Ä¢ E-waste\r\n5\r\n\r\nhttps://www.menti.com/uns9d89kzn\r\nWhat is Sustainable \r\nSoftware Engineering?\r\n?\r\n6\r\n\r\nSustainable Software \r\nEngineering is‚Ä¶\r\n7\r\n‚Ä¶the discipline that studies the process of creating software systems that are able \r\nto create value in the long term without hindering its surrounding environment.\r\n\r\n8\r\nEconomical\r\nSocial\r\nTechnical\r\nIndividual\r\nEnvironmental\r\nSustainable\r\nSoftware\r\nEngineering\r\n‚≠ê\r\nTechnical\u2028\r\n‚öô\r\nEconomical\u2028\r\nüí∞\r\nSocial\u2028\r\nüë©üíºüë®üíºüë©üíºüë©üíº\r\nIndividual\u2028\r\nüë©üíª\r\nEnvironmental\u2028\r\nüå±\r\nSustainable\u2028\r\nSoftware \r\nEngineering\r\n\r\nEconomical\r\n‚Ä¢ Focused on assets, capital and added value\u2028\r\n(wealth creation, prosperity, profitability, capital \r\ninvestment, income, etc.) \r\n‚Ä¢ Nr of customers  \r\n‚Ä¢ Man-day-rate estimate \r\n‚Ä¢ Next round of funding \r\n‚Ä¢ Meet requirements in the contract\r\n9\r\n\r\nTechnical\r\n‚Ä¢ Longevity of information, systems, and infrastructure and their \r\nadequate evolution with changing surrounding conditions. \r\n‚Ä¢ Examples: \r\n‚Ä¢ Technical Debt \r\n‚Ä¢ Does it scale? \r\n‚Ä¢ Software testing \r\n‚Ä¢ Bus-factor \r\n‚Ä¢ Data integrity \r\n‚Ä¢ Innovation \r\n‚Ä¢ ‚Ä¶\r\n10\r\n\r\nIndividual\r\n‚Ä¢ Well-being of the individuals in an organisation.\u2028\r\nNote that it also includes how well individuals interact \r\nwith each other within the org. \r\n‚Ä¢ Examples: \r\n‚Ä¢ mental and physical well-being \r\n‚Ä¢ self-respect \r\n‚Ä¢ education/skills \r\n‚Ä¢ career development \r\n‚Ä¢ ‚Ä¶\r\n11\r\n\r\nSocial\r\n‚Ä¢ concerned with societal communities (groups of people, \r\norganisations) and the factors that erode trust in society. \r\n‚Ä¢ Examples: \r\n‚Ä¢ Social equity \r\n‚Ä¢ Justice \r\n‚Ä¢ Employment \r\n‚Ä¢ Democracy \r\n‚Ä¢ ‚Ä¶ \r\n‚Ä¢ Also includes compliance with policies and regulations \r\n12\r\n\r\nEnvironmental Sustainability\r\n‚Ä¢ the branch of Software Engineering that studies \r\nthe development of software that has minimal \r\nimpact in our planet throughout its whole \r\nlifecycle. \r\n‚Ä¢ Looking at software at different levels: \r\n‚Ä¢ Developing, Using, Serving, ‚Ä¶ \r\n‚Ä¢ Also includes e-waste. \r\n‚Ä¢ Almost identical to Green Software. (?)\r\n13\r\nBordallo II\r\n\r\nGreen Software\r\n‚Ä¢ Sustainability and energy efficiency. \r\n‚Ä¢ Building energy-efficient software is important also from a \r\ntechnical sustainability POV. \r\n‚Ä¢ Smartphones, smart wearables, IoT devices, etc. run on limited \r\npower resources. \r\n‚Ä¢ Developing software to these devices require energy-efficiency \r\ntesting and improvement. \r\n‚Ä¢ It also leads to environmental sustainability (e.g., less battery \r\ncycles) \r\n‚Ä¢ Important for UX (e.g., no need to walk around with power banks)\r\n14\r\n\r\nhttps://www.menti.com/uns9d89kzn\r\nWhat is the sustainability \r\ndimension you are most \r\ninterested in?\r\n?', 'CO2eq =\r\n‚àë\r\ng‚ààGHG\r\n(GWPg ‚ãÖmg)\r\n23\r\nCO2eq = GWPCO2 ‚ãÖmCO2 + GWPCH4 ‚ãÖmCH4 + GWPN2O ‚ãÖmN2O\r\n= 1 √ó 1000 + 21 √ó 20 + 310 √ó 5\r\n= 2670kgCO2eq\r\n\r\nNote: \r\n- 100-GWP is only an estimation;  \r\n- different sources reveal different estimations; \r\n- there is also the 20-GWP and the 500-GWP. \r\nI use this source: Foster et al. (2017) Changes in Atmospheric Constituents and in Radiative Forcing  \r\nhttps://archive.ipcc.ch/pdf/assessment-report/ar4/wg1/ar4-wg1-chapter2.pdf \r\n\r\nCarbon credits (quick detour)\r\n‚Ä¢ Strategy used to regulate allowed emissions and to make carbon emission \r\nrights tradable. \r\n‚Ä¢ Each entity (e.g., company/country) has a budget of carbon credits. \r\n‚Ä¢ Entities can buy carbon credits from other entities when they are over budget. \r\n‚Ä¢ In the case of companies, carbon credits can only be bought from GHG \r\nmitigation projects. \r\n‚Ä¢ 1 carbon credit = 1 tonne CO2-eq  \r\n‚Ä¢ Consequence: the price of carbon credits is rising and carbon trading is \r\nstarting to be interesting for investors.\r\n25\r\n\r\nWhen should we use Carbon vs Energy?\r\n‚Ä¢ Energy/Power is more useful at the software usecase level. \r\n‚Ä¢ Carbon is more useful at the infrastructure level (e.g., datacenter) or at the \r\nproject level (e.g., the impact of developing a full software project). \r\n‚Ä¢ Choose your metrics wisely ;)\r\n26\r\n\r\n‚Ä¢ Carbon emissions ‚úÖ \r\n‚Ä¢ How do we go from energy consumption to carbon consumption?\r\n27\r\n\r\nCarbon intensity\r\n‚Ä¢ How much carbon is emitted per kWh of electricity consumed. \r\n‚Ä¢ The common unit: \r\n ü§∑ \r\n‚Ä¢ E.g.,  gas-based power plants emit less carbon than coal-based plants. \r\n‚Ä¢ The power grid is a mix between different sources of electricity ‚Äì different \r\nlocations have different carbon intensity.\r\ngCO2eq/kWh\r\n28\r\n\r\nhttps://app.electricitymaps.com/map\r\n\r\nBy Asim Hussain: https://principles.green/principles/carbon-intensity/\r\nüìù Reducing software energy consumption can help reduce the carbon intensity. Why?\r\n\r\nOne would expect zero carbon intensity from solar-\r\npanels or wind farms, but that‚Äôs not the case.\r\n‚ö†\r\n?\r\n\r\nMarginal Power Plant\r\n‚Ä¢ Renewable-based power plants cannot adapt to demand. \r\n‚Ä¢ When demand is higher than the existing power in the electricity grid, we \r\nneed a power plant that is able to scale up to that demand. \r\n‚Ä¢ This is usually done by fossil-based power plants. They are called the \r\nmarginal power plants. \r\n‚Ä¢ The problem is that marginal power plants do not scale down to zero. \r\n‚Ä¢ There is always a minimum carbon that needs to be emitted, even if there is \r\na lot of renewable energy in the grid.\r\n32\r\n\r\nBy Asim Hussain: https://principles.green/principles/carbon-intensity/\r\nHow could we fix this?\r\nWhat‚Äôs the problem here?\r\n\r\nMarginal Carbon Intensity\r\n‚Ä¢ Increase or decrease in carbon emissions in the electrical grid, in response \r\nto an infinitesimal increase/decrease in power demand/supply.\r\n\r\nFrom: ‚ÄúLiterature Review: On the effectiveness of a Marginal Carbon Intensity Signal ‚Äú\r\n\r\nWhy is marginal carbon intensity \r\nrelevant for software?\r\n‚Ä¢ Tip: consider a task scheduler in a datacenter.', 'Energy profiling of static analysis tools\r\n‚Ä¢ What is the energy consumption of a ""typical run"" for a few OSS projects? \r\n‚Ä¢ Does the type of analysis matter? Are certain analysis more expensive? Does \r\nthe number of rules that are activated in a static analysis tool important for the \r\nenergy consumption? \r\n‚Ä¢ Differences between static analysis tools [lower priority]\r\n\r\nB5. Tool supporting SusAF workshop / process\r\n‚Ä¢ Lead engineers through process & questions \r\n‚Ä¢ Interface to create & document the two diagrams \r\n‚Ä¢ (!) Should be easy to start using & set up \r\n‚Ä¢ You may also create a simplified version / \u2028\r\nyour favorite sustainability framework\r\nEnvironmental\r\nEconomic\r\nTechnical\r\nIndividual\r\nSocial\r\nImmediate\r\nEnabling\r\nStructural\r\nAirbnb\r\ngreater \r\nearnings\r\nincrease \r\nin rents\r\ngentrification\r\ngreater racial \r\ndisparities\r\nrent \r\nrooms\r\n5\r\n1\r\n3\r\n4\r\n2\r\n \r\n \r\n \r\n \r\n \r\n \r\nVery \r\nunlikely \r\nVery \r\nlikely \r\n\r\nB6. Dataset of government-developed OS software\r\n‚Ä¢ Governments develop & use software for supporting society\u2028\r\nOpen-source development & policies are on the rise \r\n‚Ä¢ But studying government software is difficult b/c we don‚Äôt know what is out \r\nthere\u2028\r\n‚Üí Lack of incentive to make popular \u2028\r\n‚Üí Language barriers \r\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \r\nbuildable?, open dev. history?, requirements documentation? \r\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!\r\n\r\nB7. Queue - but better for the student / TA society\r\n‚Ä¢ Requirements analysis regarding social and individual sustainability effects \r\nof Queue \r\n‚Ä¢ Other EIP / TUD used software also possible: e.g., Answers EWI \r\n‚Ä¢ Non-technical project ‚Üí proper process (workshops? Interviews?) & rich \r\ndescription of outcomes focus of grading\r\nhttps://eip.pages.ewi.tudelft.nl/eip-website/queue.html\r\n\r\nC1. Compare energy consumption of docker images for \r\nML workloads.\r\n‚Ä¢ Similar to what we have seen in the lectures but for ML-specific workloads. \r\n‚Ä¢ We can reuse existing experiment replication packages.\r\n22\r\n\r\nC2. Plugin to visualize Hugging Face carbon emissions.\r\n‚Ä¢ https://huggingface.co/blog/leaderboard-emissions-\r\nanalysis \r\n‚Ä¢\r\nYoo, Taewon, et al. ""Visualizing the Carbon Intensity of Machine Learning Inference for Image Analysis on TensorFlow Hub.""\r\n\r\nC3. Plugin for ChatGPT\r\n‚Ä¢ Users seldom know how much carbon they are emitting when they interact \r\nwith chat GPT. \r\n‚Ä¢ Let‚Äôs make it transparent to the users. Browser plugin?\r\n24\r\nCO2\r\n\r\nC4. NutriScore for software libraries\r\n25\r\n‚Ä¢ NutriScore labels are not perfect but they are a good starting point! \r\n‚Ä¢ What if we could do the same thing for the energy efficiency of software. \r\n‚Ä¢ (Also open to individual or social sustainability) \r\n‚Ä¢ This work can be scoped in particular domains/ecossystems/use cases. \r\n‚Ä¢ Libraries for stats? ML? Web Dev? Cloud?\r\n\r\nC5. Add energy-awareness to existing software\r\n26\r\n‚Ä¢ Streamlit, Notebooks, JSFiddle, \r\nPyScript, zsh, etc. \r\n‚Ä¢\r\n\r\nC6 - Green Shift Left\r\n‚Ä¢ Estimate energy efficiency using static code analysis. \r\n‚Ä¢ We don‚Äôt need an accurate value. \r\n‚Ä¢ It is useful to know which code is more likely to \r\nintroduce energy hotspots and that should be \r\nreviewed with more attention. \r\n‚Ä¢ Can be scoped to a particular domain (react, php, data \r\nscience, web, etc., etc.)', 'Lu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\n2. Tools to Measure Software Energy \r\n(lab)\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nCarolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl\r\n\r\n1. Tools \r\n2. Hands-on \r\n3. Project 1\r\n\r\n3\r\nHardware Power \r\nMonitors\r\nEnergy Profilers\r\n\r\nHardware Power Monitors\r\n‚Ä¢ Connects directly to the power source of the device/\r\ncomponent. \r\n‚Ä¢ Some power monitors also replace the power source. \r\n‚Ä¢ Example: \r\n‚Ä¢ Monsoon Power Monitor (for IoT and smartphones).  \r\n‚Ä¢ Can be fully automated using a Python API. \r\n‚Ä¢ It measures and powers small electronic devices. \r\n‚Ä¢ There are many power/energy meters out there but for \r\nsoftware use cases we need to be able to control them \r\nusing an API.\r\n4\r\n\r\nConnecting Monsoon to a Smartphone\r\n‚Ä¢ 1. Disassemble the smartphone and find the \r\nconnectors of the battery.  \r\n‚Ä¢ iFixit usually has nice tutorials and blueprints. \r\nhttps://www.ifixit.com\r\n5\r\n\r\nConnecting Monsoon to a Smartphone\r\n‚Ä¢ 2. Extract the electronic component of the battery \r\n‚Ä¢ Modern batteries are connected through 4 terminals: \r\n‚Ä¢ Positive \r\n‚Ä¢ Negative \r\n‚Ä¢ BTEMP, battery temperature (used for safety) \r\n‚Ä¢ BST, battery system indicator (provides info about \r\nthe battery) \r\n‚Ä¢ Hence, one cannot simply connect + and - pins\r\n6\r\n\r\n‚Ä¢ 3. Connect the electronic component \r\ndirectly to the monitor.\r\nConnecting Monsoon to a Smartphone\r\n7\r\n\r\nConnecting Monsoon to a Smartphone\r\n‚Ä¢ 4. Use the library PyMonsoon to control the power \r\nmonitor. \r\n‚Ä¢ https://github.com/msoon/PyMonsoon \r\n‚Ä¢ 4.1. Set the monsoon to desired Voltage. Choose \r\nthe typical voltage of the original battery. For the \r\nNexus 5X, 3.8V was equivalent to its battery at \r\naround 60% capacity. \r\n‚Ä¢ 4.2. Start measuring\r\n8\r\n\r\nConnecting Monsoon to a Smartphone\r\n‚Ä¢ 5. Automate User Interface interaction \r\n‚Ä¢ The last thing you want to do is to manually interact with the smartphone \r\nwhile you measure energy consumption. Tests are less accurate, less \r\nreproducible, and, in this case, the screen cannot not be easily accessed. \r\n‚Ä¢ Tools to automate interaction with Android phones: \r\n‚Ä¢ To open, install, close apps: adb \r\n‚Ä¢ To interact with the app: Appium, Robotium, UIAutomator, espresso, \r\netc. \r\n‚Ä¢ Alternative: physalia is a library that automates all adb interactions and \r\nPyMonsoon calls.\r\n9\r\n\r\nIssue 1: USB cable!\r\n‚Ä¢ You need the USB cable to automate the interaction with the phone. \r\n‚Ä¢ When you connect the USB cable, measurements become\u2028\r\nunreliable. \r\n‚Ä¢ Solution: \r\n‚Ä¢ Monsoon has a feature to control the USB connection (switch on/off) \r\n‚Ä¢ Option 1: Right before starting measurements, the USB connection is stopped. \r\n‚Ä¢ Works fine when when all the interaction instructions can be sent in advance and the time for the \r\nexecution is already known. \r\n‚Ä¢ Option 2: using USB, set up a wireless ADB connection. Stop USB connections afterwards. \r\n‚Ä¢ How to: https://stackoverflow.com/a/3623727\r\n10\r\n\r\nIssue 2: your app is not exclusive\r\n‚Ä¢ Many activities run in a smartphone device. E.g., getting push notifications, \r\nchecking nearby bluetooth devices, etc. \r\n‚Ä¢ Moreover, brightness may change according to environment. Different \r\nscreen brightness, different results.', 'Set the monsoon to desired Voltage. Choose \r\nthe typical voltage of the original battery. For the \r\nNexus 5X, 3.8V was equivalent to its battery at \r\naround 60% capacity. \r\n‚Ä¢ 4.2. Start measuring\r\n8\r\n\r\nConnecting Monsoon to a Smartphone\r\n‚Ä¢ 5. Automate User Interface interaction \r\n‚Ä¢ The last thing you want to do is to manually interact with the smartphone \r\nwhile you measure energy consumption. Tests are less accurate, less \r\nreproducible, and, in this case, the screen cannot not be easily accessed. \r\n‚Ä¢ Tools to automate interaction with Android phones: \r\n‚Ä¢ To open, install, close apps: adb \r\n‚Ä¢ To interact with the app: Appium, Robotium, UIAutomator, espresso, \r\netc. \r\n‚Ä¢ Alternative: physalia is a library that automates all adb interactions and \r\nPyMonsoon calls.\r\n9\r\n\r\nIssue 1: USB cable!\r\n‚Ä¢ You need the USB cable to automate the interaction with the phone. \r\n‚Ä¢ When you connect the USB cable, measurements become\u2028\r\nunreliable. \r\n‚Ä¢ Solution: \r\n‚Ä¢ Monsoon has a feature to control the USB connection (switch on/off) \r\n‚Ä¢ Option 1: Right before starting measurements, the USB connection is stopped. \r\n‚Ä¢ Works fine when when all the interaction instructions can be sent in advance and the time for the \r\nexecution is already known. \r\n‚Ä¢ Option 2: using USB, set up a wireless ADB connection. Stop USB connections afterwards. \r\n‚Ä¢ How to: https://stackoverflow.com/a/3623727\r\n10\r\n\r\nIssue 2: your app is not exclusive\r\n‚Ä¢ Many activities run in a smartphone device. E.g., getting push notifications, \r\nchecking nearby bluetooth devices, etc. \r\n‚Ä¢ Moreover, brightness may change according to environment. Different \r\nscreen brightness, different results. \r\n‚Ä¢ You need to reduce tasks to the bare minimum: \r\n‚Ä¢ Set brightness to a fixed value; turn off notifications, kill all user-owned \r\nprocesses, turn off cellular data, bluetooth, location services, account \r\nsyncs; uninstall all unnecessary apps, etc.\r\n11\r\n\r\nWhen it comes to desktop/cloud software, the sources \r\nof noise are different but the same concerns apply. \r\n \r\nEach case is different ‚Äì think it through!\r\n‚ö†\r\n\r\nEnergy Profilers\r\n‚Ä¢ Simple setup! Quite reliable (if you choose the profiler wisely). \r\n‚Ä¢ Recently, they are starting to rely on internal power sensors. \r\n‚Ä¢ Still sensitive to noise from concurrent processes/tasks! ‚ö†\r\n13\r\n\r\nExamples of Energy Profilers\r\n\r\n15\r\nhttps://www.websitecarbon.com\r\n\r\n16\r\nhttps://mlco2.github.io/impact/\r\n\r\nIntel Power Monitor\r\n‚Ä¢ Install: https://software.intel.com/content/www/us/en/\r\ndevelop/articles/intel-power-gadget.html \r\n‚Ä¢ To collect: Logging > Log to File \r\n \r\n‚Ä¢ It will store a CSV file with all the collected power data. \r\n(File location is specified in the settings) \r\n‚Ä¢ Based on Intel RAPL. Works with Intel-based Windows \r\nand Macs. \r\n‚Ä¢ Alternative-twin for M1-based Macs: Mx Power Gadget.\u2028\r\nhttps://www.seense.com/menubarstats/mxpg/\r\n17\r\n‚ö† No longer supported by Intel ‚ö†  \r\n\r\n18\r\nüîó https://luiscruz.github.io/\r\n2021/07/20/measuring-energy.html\r\n(Missing Apple m1 tools: mxpg, powermetrics)\r\n\r\n19\r\nEnergiBridge\r\nhttps://github.com/tdurieux/energibridge\r\n> target/release/energibridge -o results.csv --summary sleep 10\r\n\r\nHands-on 1\r\n‚Ä¢ Install your energy profiler (EnergiBridge).']","['<1-hop>\n\nShuffle \nüîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them.\n‚Ä¢ If you run 30 executions for version A and another batch for version B:\n‚Ä¢ External conditions that change over time will have a diÔ¨Äerent bias in \nthe 2 versions (e.g., room temperature changes).\n‚Ä¢ If you shuÔ¨Ñe, you reduce this risk.\n11', '<2-hop>\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio)\n‚Ä¢ Dynamic Retry Delay\n‚Ä¢ Push Over Poll\n‚Ä¢ Reduce Size\n‚Ä¢ Cache\n‚Ä¢ Avoid Graphics and Animations\n20', '<1-hop>\n\nShuffle \nüîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them.\n‚Ä¢ If you run 30 executions for version A and another batch for version B:\n‚Ä¢ External conditions that change over time will have a diÔ¨Äerent bias in \nthe 2 versions (e.g., room temperature changes).\n‚Ä¢ If you shuÔ¨Ñe, you reduce this risk.\n11', '<2-hop>\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio)\n‚Ä¢ Dynamic Retry Delay\n‚Ä¢ Push Over Poll\n‚Ä¢ Reduce Size\n‚Ä¢ Cache\n‚Ä¢ Avoid Graphics and Animations\n20', '<1-hop>\n\nShuffle \nüîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them.\n‚Ä¢ If you run 30 executions for version A and another batch for version B:\n‚Ä¢ External conditions that change over time will have a diÔ¨Äerent bias in \nthe 2 versions (e.g., room temperature changes).\n‚Ä¢ If you shuÔ¨Ñe, you reduce this risk.\n11', '<2-hop>\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio)\n‚Ä¢ Dynamic Retry Delay\n‚Ä¢ Push Over Poll\n‚Ä¢ Reduce Size\n‚Ä¢ Cache\n‚Ä¢ Avoid Graphics and Animations\n20']","Shuffling reduces risk by minimizing the impact of external conditions that change over time, which can introduce bias in experiments. By shuffling the order of executions for different versions of a test, you reduce the risk of these external factors affecting the results differently for each version (Source 11).

EcoAndroid reduces size by implementing strategies such as dynamic retry delay, push over poll, and caching, which help in optimizing the app's performance and reducing unnecessary energy consumption. These strategies contribute to making the app more energy-efficient and potentially reducing its overall size by eliminating redundant processes and data handling (Source 20).",Shuffling reduce risk by controlling external factors like room temperature changes. EcoAndroid reduce size by using features like caching and avoiding graphics and animations.,0.0,1.0,1.0,0.18,,0.9667521773909601
How shuffling reduce risk when compare to EcoAndroid reduce size?,"['Lu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\n3. Scientific Guide for Reliable \r\nEnergy Experiments\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nCarolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl\r\n\r\n1. Scientific guide for energy measurements \r\n2. Energy consumption data analysis \r\n\r\nEnergy tests are flaky\r\n‚Ä¢ Multiple runs might yield different results \r\n‚Ä¢ There are many confounding factors that need to be controlled/minimized.\r\n3\r\n?\r\n\r\nZen mode üßò\r\n‚Ä¢ Close all applications. \r\n‚Ä¢ Turn off notifications. \r\n‚Ä¢ Only the required hardware should be connected (avoid USB drives, external \r\ndisks, external displays, etc.). \r\n‚Ä¢ Kill unnecessary services running in the background (e.g., web server, file \r\nsharing, etc.). \r\n‚Ä¢ If you do not need an internet or intranet connection, switch off your network. \r\n‚Ä¢ Prefer cable over wireless ‚Äì the energy consumption from a cable connection \r\nis more stable than from a wireless connection.\r\n4\r\n\r\nFreeze and report your settings ü•∂\r\n‚Ä¢ Fix display brightness; switch off auto brightness \r\n‚Ä¢ If Wifi is on, it should always be on, connected to the same network/\r\nendpoint.‚Ä¶\r\n5\r\n\r\nWarm-up üì∂\r\n‚Ä¢ Energy consumption is highly affected by the temperature of your hardware. \r\n‚Ä¢ Higher the temperature -> higher the resistance of electrical conductors ->\u2028\r\n-> higher dissipation -> higher energy consumption \r\n‚Ä¢ The first execution will appear more efficient because the hardware is still \r\ncold. \r\n‚Ä¢ Run a CPU-intensive task before measuring energy consumption. E.g., \r\nFibonacci sequence. At least 1min; 5min recommended. \r\n‚Ä¢\r\n6\r\n\r\nRepeat üîÅ\r\n‚Ä¢ The best way to make sure a measurement is valid is by repeating it. \r\n‚Ä¢ In a scientific project, the magic number is 30.\r\n7\r\n\r\n\r\nRest ‚è∏\r\n‚Ä¢ It is common practice to do a pause/sleep between executions/\r\nmeasurements. \r\n‚Ä¢ Prevent tail energy consumption from previous measurements. ? \r\n‚Ä¢ Prevent collateral tasks of previous measurement from affecting the next \r\nmeasurement. \r\n‚Ä¢ There is no golden rule but one minute should be enough. It can be more or \r\nless depending on your hardware or the duration of your energy test.\r\n9\r\n\r\nt\r\nP\r\nTail Energy Consumption\r\n\r\nShuffle üîÄ\r\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \r\nit is impossible to control all of them. \r\n‚Ä¢ If you run 30 executions for version A and another batch for version B: \r\n‚Ä¢ External conditions that change over time will have a different bias in \r\nthe 2 versions (e.g., room temperature changes). \r\n‚Ä¢ If you shuffle, you reduce this risk.\r\n11\r\n\r\nKeep it cool üå°\r\n‚Ä¢ Always make sure there is a stable room temperature. \r\n‚Ä¢ Tricky because, some times, experiments may have to run over a few days. \r\n‚Ä¢ If you cannot control room temperature: collect temperature data and filter \r\nout measurements where the room temperature is clearly deviating.\r\n12\r\n\r\nAutomate Executions ü§ñ\r\n‚Ä¢ (Already mentioned in the previous classes) \r\n‚Ä¢ One cannot run 30 shuffled experiments per version without automation‚Ä¶\r\n13\r\n\r\nData analysis\r\n14\r\n\r\n1. Exploratory Analysis\r\n‚Ä¢ Plot the data and inspect outliers or \r\nunexpected biases. \r\n‚Ä¢ Violin+box plots are usually handy. (?) \r\n‚Ä¢ It‚Äôs a nice way of combining the 30 \r\nexperiments, and of showing \r\ndescriptive statistics. (?) \r\n‚Ä¢ Shows the shape of the distribution \r\nof the data.\r\n15\r\n\r\n1. Exploratory Analysis (II)\r\n‚Ä¢ Data should be Normal.', '‚Ä¢ In a scientific project, the magic number is 30.\r\n7\r\n\r\n\r\nRest ‚è∏\r\n‚Ä¢ It is common practice to do a pause/sleep between executions/\r\nmeasurements. \r\n‚Ä¢ Prevent tail energy consumption from previous measurements. ? \r\n‚Ä¢ Prevent collateral tasks of previous measurement from affecting the next \r\nmeasurement. \r\n‚Ä¢ There is no golden rule but one minute should be enough. It can be more or \r\nless depending on your hardware or the duration of your energy test.\r\n9\r\n\r\nt\r\nP\r\nTail Energy Consumption\r\n\r\nShuffle üîÄ\r\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \r\nit is impossible to control all of them. \r\n‚Ä¢ If you run 30 executions for version A and another batch for version B: \r\n‚Ä¢ External conditions that change over time will have a different bias in \r\nthe 2 versions (e.g., room temperature changes). \r\n‚Ä¢ If you shuffle, you reduce this risk.\r\n11\r\n\r\nKeep it cool üå°\r\n‚Ä¢ Always make sure there is a stable room temperature. \r\n‚Ä¢ Tricky because, some times, experiments may have to run over a few days. \r\n‚Ä¢ If you cannot control room temperature: collect temperature data and filter \r\nout measurements where the room temperature is clearly deviating.\r\n12\r\n\r\nAutomate Executions ü§ñ\r\n‚Ä¢ (Already mentioned in the previous classes) \r\n‚Ä¢ One cannot run 30 shuffled experiments per version without automation‚Ä¶\r\n13\r\n\r\nData analysis\r\n14\r\n\r\n1. Exploratory Analysis\r\n‚Ä¢ Plot the data and inspect outliers or \r\nunexpected biases. \r\n‚Ä¢ Violin+box plots are usually handy. (?) \r\n‚Ä¢ It‚Äôs a nice way of combining the 30 \r\nexperiments, and of showing \r\ndescriptive statistics. (?) \r\n‚Ä¢ Shows the shape of the distribution \r\nof the data.\r\n15\r\n\r\n1. Exploratory Analysis (II)\r\n‚Ä¢ Data should be Normal. Unless there‚Äôs a \r\ngood reason. \r\n‚Ä¢ E.g., somewhere amongst the 30 executions, \r\nthere might be 1 or 2 that failed to finish due \r\nto some unexpected error. \r\n‚Ä¢ (It happens and that‚Äôs ok!)‚Äì consequently, \r\nthe execution is shorter and spends less \r\nenergy ‚Äì falsely appearing as more \r\nenergy efficient. \r\n‚Ä¢ If data is not Normal there might be some \r\nissues affecting the measurements that \r\nmight be ruining results. It is important to \r\ninvestigate this.\r\n16\r\n\r\nEnergy data is not normal. Why?\r\n‚Ä¢ It might be caused by one of the following reasons: \r\n‚Ä¢ There was an error in some of the executions. If not detected and fixed it \r\nmight ruin results. \r\n‚Ä¢ Your tests are not fully replicable or are not deterministic. Quite frequent \r\nwhen you have internet requests or random-based algorithms. \r\n‚Ä¢ There is an unusual task being run by the system during some experiments. \r\n‚Ä¢ The computer entered a different power mode. \r\n‚Ä¢ External physical conditions have changed. E.g., someone opened a \r\nwindow.\r\n17\r\n\r\nEnergy data is not normal. How to fix?\r\n‚Ä¢ We have 2+1 options: \r\n1. Remove outliers. If there are only a few points that deviate from the normal \r\ndistribution, it is okay to simply remove them. \r\n‚Ä¢ Use the z-score outlier removal. (?) \r\n‚Ä¢ Remove all data points that deviate from the mean more than 3 standard \r\ndeviations: \r\n \r\n2. Fix the issue and rerun experiments. \r\n3. Conclude that nothing can be done about it and data will never be normal. (e.g., \r\nin AI, executions are rarely deterministic). ‚ö† Only after ruling out the previous \r\npoints.\r\n| ¬Øx ‚àíx| > 3s\r\n18\r\n\r\nHow do we know whether data is Normal?', '[‚Ä¶]\r\n13\r\n\r\nAvoid Extraneous Graphics and \r\nAnimations  \r\n‚Ä¢ Context: Mobile apps that feature impressive graphics \r\nand animations. [‚Ä¶] \r\n‚Ä¢ Solution: Study the importance of graphics and \r\nanimations to the user experience and reduce them when \r\napplicable. [‚Ä¶]\r\n‚Ä¢ Example: Resort to low frame rates for animations when \r\npossible. \r\nDespite being important to improve user experience, graphics \r\nand animations are battery intensive and should be used with \r\nmoderation.  \r\n14\r\n\r\nEnergy Patterns are \r\nmore Frequent\r\nin Android Apps\r\n\r\nExample case: Nextcloud\r\nFOSS\r\n\r\nExample case: Nextcloud\r\n‚Ä¢ Users complain that sometimes they go on a trip and  Nextcloud drains their \r\nbattery. Users consider uninstalling the app when battery life is essential. \r\n‚Ä¢ File sync can be energy-greedy. Send large files to the server, long 3G/4G data connections. \r\n‚Ä¢ It is mostly used for backup. No real-time collaboration is needed. \r\n‚Ä¢ Energy requirements vary depending on context and user. Some days you really \r\nneed all the battery you can get. \r\n‚Ä¢ https://github.com/nextcloud/android/commit/\r\n8bc432027e0d33e8043cf40192203203a40ca29c\r\nSolutions?\r\n17\r\n\r\nExample case: K-9 mail\r\n18\r\n\r\nExample case: K-9 mail\r\n19\r\nSolutions?\r\n‚Ä¢ Some users noticed that K-9 mail was spending more energy than usual. üôâ \r\n‚Ä¢ A user that was having issues with a personal mail server  noticed that K-9 \r\nmail was the one of the most energy-greedy apps. IMAP IDLE protocol for real-time \r\nnotifications. \r\n‚Ä¢ When a connection is not possible, the app automatically retries later. \r\n‚Ä¢ https://github.com/k9mail/k-9/commit/\r\n86f3b28f79509d1a4d613eb39f60603e08579ea3\r\n\r\nEcoAndroid\r\n‚Ä¢ Plugin for IntelliJ (Android Studio) \r\n‚Ä¢ Dynamic Retry Delay \r\n‚Ä¢ Push Over Poll \r\n‚Ä¢ Reduce Size \r\n‚Ä¢ Cache \r\n‚Ä¢ Avoid Graphics and Animations\r\n20\r\n\r\nCarbon-Aware Computing for \r\nDatacenters \r\nhttps://sites.google.com/view/energy-efficiency-languages\r\n21\r\nAna Radovanovic ÃÅ, Ross Koningstein, Ian Schneider, Bokan \r\nChen, Alexandre Duarte, Binz Roy, Diyue Xiao, Maya \r\nHaridasan, Patrick Hung, Nick Care, Saurav Talukdar, Eric \r\nMullen, Kendal Smith, MariEllen Cottman, and Walfredo Cirne \r\n\r\n\r\n‚Ä¢ Google‚Äôs Carbon-Intelligent Computing System (CICS) \r\n‚Ä¢ Main idea: use carbon-intensity data to shift datacenter jobs in time \r\n‚Ä¢ Typically, job schedulers use a metric of cluster capacity to schedule a job in \r\na particular cluster. \r\n‚Ä¢ CICS overrides this metric with the virtual capacity curve (VCC) that \r\nfactors in Carbon intensity \r\n‚Ä¢ When a new job comes in, the scheduler estimates its CPU load and power \r\nusage and assigns it to a cluster if the VCC is not exceeded.\r\n23\r\n\r\n‚Ä¢ Jobs are divided between flexible and inflexible. \r\n‚Ä¢ Flexible load is considered shapeable/shiftable as long as its total daily \r\ncompute (CPU) demand is preserved \r\n‚Ä¢ The system needs to consider that, while running a job, the virtual capacity \r\ncurve (VCC) might drop. Hence, this job should not start in the first place. \r\n‚Ä¢ They forecast VCC for the next day\r\n24\r\n\r\n\r\nVirtual Cluster Capacity (VCC)\r\n‚Ä¢ Aims at reducing the peak load at carbon intensive hours but in total it should allow for the \r\nsome amount of daily computation!', ""‚Ä¢ Our question: Can we save energy with alternative approaches? \r\n‚Ä¢ We studied Grid Search, Random Search and Bayesian \r\nOptimisation.\r\n27\r\nTim's MSc Thesis, 2022 \r\nAccepted at CAIN‚Äô23\r\n\r\n\r\nResults\r\n29\r\nConclusions? \r\n‚Ä¢ Bayesian converges faster. \r\n‚Ä¢ No clear winner between Grid and Random\r\n\r\nDeepSeekMoE\r\n30\r\nPreprint at ArXiv, 2024 https://arxiv.org/pdf/\r\n2401.06066\r\n\r\nMixture of Experts\r\n‚Ä¢ Llama3.1 has 405B parameters, DeepSeek V3 671B \r\n‚Ä¢ Yet DeepSeek has quicker inference times and claims less energy \r\nconsumption (?) \r\n‚Ä¢ Divide the model into smaller blocks of experts \r\n‚Ä¢ Tokens get routed to certain experts based on the query \r\n‚Ä¢ Only part of the network is active during inference \r\n‚Ä¢ DeepSeek claims only 37B out of 671B parameters get active\r\n31\r\n\r\nDeepSeekMoE\r\n32\r\n\r\nDeepSeekMoE\r\n33\r\n‚Ä¢ Comparable performance to \r\nLLaMA2 7B effectively using \r\nless half the parameters \r\n‚Ä¢ Less computational power \r\n‚Ä¢ Problems (?) \r\n‚Ä¢ Still need to load all the \r\nparameters \r\n‚Ä¢ High memory -> high \r\nembodied carbon\r\n\r\nGreen AI at FacebookMeta\r\n34\r\nSustainable AI: Environmental Implications, \r\nChallenges and Opportunities (2022)\r\n\r\nCarbon footprint mapped to the AI lifecycle\r\n‚Ä¢ There are 4 main overarching stages where carbon emissions need to be isolated: data \r\ncollection, experimentation, training, inference. \r\n‚Ä¢ At Facebook, recommendation systems split energy consumption evenly between \r\ntraining and inference; text translation models have a 35%/65% split. (Operational cost) \r\n‚Ä¢ Operational/embodied cost split: 30%/70%\r\n35\r\n\r\nOpen issues according to Meta\r\n‚Ä¢ A vast portion of projects only use GPUs at 30%.\u2028\r\nShould be higher to attenuate embodied carbon.\r\n36\r\nBased on 10K AI projects\r\n\r\nData Jan\r\nInformed Adaptation\r\nData Feb\r\nData Mar\r\nData Apr\r\nData May\r\n‚Ä¶\r\n~Data Dec\r\n~Data Dec\r\nData Jan\r\nData Feb\r\nData Mar\r\nData Apr\r\nData May\r\n‚Ä¶\r\nModel update Model update Model update\r\nCheck if \r\ndata change\r\nCheck if \r\ndata change\r\nCheck if \r\ndata change\r\nModel update\r\nBlind Adaptation\r\nThe AI Model will be \r\nupdated fewer times and \r\nonly when necessary.\r\nKnow when to retrain models\r\nNeither too early nor too late\r\n37\r\nAdaptation Techniques\r\n?\r\n\r\nGreen Architectural Tactics for ML-Enabled \r\nSystem\r\n38\r\nICSE-SEIS 2024\r\n\r\nArchitectural tactics\r\n39\r\n\r\nData-centric\r\n40\r\n‚Ä¢ Reduce data size \r\n‚Ä¢ Sampling \r\n‚Ä¢ Dimensionality reduction \r\n‚Ä¢ Quantization\r\n\r\nAlgorithm Design\r\n41\r\n‚Ä¢ Carefully select your algorithm \r\n‚Ä¢ You don‚Äôt need the fanciest \r\ntechniques\r\n\r\nModel Optimization\r\n42\r\n‚Ä¢ Add energy to training parameters \r\n‚Ä¢ Reduce FLOPs \r\n‚Ä¢ Pruning, sparsity \r\n‚Ä¢  Take advantage of existing models\r\n\r\nModel Training\r\n43\r\n‚Ä¢ Quantization\r\n‚Ä¢ SAVE TRAINING PROGRESS\r\n\r\nModel Deployment\r\n44\r\n‚Ä¢ Distributed deployment \r\n‚Ä¢ Energy efficient hardware and \r\nconfigurations\r\n\r\nModel Management\r\n45\r\n‚Ä¢ Reuse the model as much as possible \r\n\r\nRethinking the Architecture: Spiking Neural Networks\r\n46\r\n\r\nRethinking the Architecture: Spiking Neural Networks\r\n47\r\n\r\nSELF Lab\r\n48\r\n\r\nrecap"", '8. Green AI\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nLu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\nCarolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl\r\n\r\n- Overview of Green AI \r\n- Large language models \r\n- Green data-centric AI \r\n- Model simplification \r\n- Hyper parameter tuning \r\n- Mixture of Experts and DeepSeek \r\n- Green AI at Meta \r\n\r\nAI\r\n‚Ä¢ Artificial Intelligence (AI) is the branch of computer science that deals with \r\nautomating tasks that typically require human intelligence. \r\n‚Ä¢ In the past years AI has been widely applied across different domains.\u2028\r\nE.g., health care, transportation, finance. \r\n‚Ä¢ To deploy AI systems, we test them against benchmarks (or validation sets). \r\n‚Ä¢ The goal is to outperform the previous existing models. \r\n‚Ä¢ E.g., in Machine Learning we usually resort to accuracy metrics. The \r\nhighest the accuracy, the better the model.\r\n3\r\n\r\nSince 2012, the amount of computing used for AI \r\ntraining has been doubling every 6 months\r\n‚Ä¢ https://epoch.ai/blog/compute-trends\r\n4\r\n\r\n‚Ä¢ To create better AI systems we are currently adding \r\n‚Ä¢ More data \r\n‚Ä¢ More experiments \r\n‚Ä¢ Larger models\r\n5\r\n\r\nThe Equation of Red AI\r\nCost(R) ‚àùE¬∑D¬∑H\r\nCost of a single (E)xample\r\nSize of (D)ataset\r\nNumber of (H)yperparameters\r\nBy Schwartz et al. (2020)\r\n\r\nIssues of Red AI\r\n‚Ä¢ High costs (hardware, electricity, data access, etc.) \r\n‚Ä¢ Limited reproducibility.  \r\n‚Ä¢ Energy consumption. \r\n‚Ä¢ Carbon emissions. \r\n‚Ä¢ SMEs can hardly be competitive. \r\n‚Ä¢ Groundbreaking AI research is mostly done by tech giants.\r\n7\r\n\r\nA few examples of Red AI\r\n‚Ä¢ Google‚Äôs BERT-large \r\n‚Ä¢ 350 million features \r\n‚Ä¢ Trained for 2.5 days using 512 TPU chips, costing $60K+ \r\n‚Ä¢ Open-GPT3 (now GPT-4/o1) \r\n‚Ä¢ 550 tonnes CO2-eq (Patterson, 2021) \r\n‚Ä¢ 175 billion features \r\n‚Ä¢ API is open but no-pretrained model is available \r\n‚Ä¢ AlphaGo \r\n‚Ä¢ 1920 CPUs, 280 GPUs, costing $35M\r\n8\r\n\r\nRed AI in Large Language Models (LLMs)\r\n‚Ä¢ OPT by Meta reports 75 tons CO2-eq (1/7 of OpenGPT‚Äôs footprint).\u2028\r\n(Also 175billion params) \r\n‚Ä¢ However, Llama 3 reported 2,290 tons of CO2-eq (7.7M GPU hours \r\ntraining ) \r\n‚Ä¢ Open science: release includes both the pretrained models and the code \r\nneeded to train and use them. \r\n‚Ä¢ DeepSeek-V3 claims ‚Äúonly‚Äù 2.78M GPU hours \r\n‚Ä¢ Bloom by Huggingface reports 25 tons, 51 when considering embodied \r\nand operational carbon footprint. (176billion params)\r\n9\r\n\r\nRed AI\r\nAccuracy: 0.999999999\r\nGreen AI\r\n‚Ä¢ Energy \r\n‚Ä¢ Time \r\n‚Ä¢ Reproducibility \r\n‚Ä¢ Reusage\r\n\r\nHow can we adopt Green AI\r\n‚Ä¢ Check whether AI is needed. \r\n‚Ä¢ Select green datacenters. \r\n‚Ä¢ Run on low carbon intensity hours. \r\n‚Ä¢ Opt for GPU-optimised solutions (?) \r\n‚Ä¢ Opt for low-power hardware (e.g., Nvidia Jetson boards) \r\n‚Ä¢ Or GPUs that provide energy metrics (e.g., NVIDIA GPUs via the nvidia-smi tool) \r\n‚Ä¢ Report energy/carbon metrics (e.g., embed in MLFlow?)', '‚Ä¢ Groundbreaking AI research is mostly done by tech giants.\r\n7\r\n\r\nA few examples of Red AI\r\n‚Ä¢ Google‚Äôs BERT-large \r\n‚Ä¢ 350 million features \r\n‚Ä¢ Trained for 2.5 days using 512 TPU chips, costing $60K+ \r\n‚Ä¢ Open-GPT3 (now GPT-4/o1) \r\n‚Ä¢ 550 tonnes CO2-eq (Patterson, 2021) \r\n‚Ä¢ 175 billion features \r\n‚Ä¢ API is open but no-pretrained model is available \r\n‚Ä¢ AlphaGo \r\n‚Ä¢ 1920 CPUs, 280 GPUs, costing $35M\r\n8\r\n\r\nRed AI in Large Language Models (LLMs)\r\n‚Ä¢ OPT by Meta reports 75 tons CO2-eq (1/7 of OpenGPT‚Äôs footprint).\u2028\r\n(Also 175billion params) \r\n‚Ä¢ However, Llama 3 reported 2,290 tons of CO2-eq (7.7M GPU hours \r\ntraining ) \r\n‚Ä¢ Open science: release includes both the pretrained models and the code \r\nneeded to train and use them. \r\n‚Ä¢ DeepSeek-V3 claims ‚Äúonly‚Äù 2.78M GPU hours \r\n‚Ä¢ Bloom by Huggingface reports 25 tons, 51 when considering embodied \r\nand operational carbon footprint. (176billion params)\r\n9\r\n\r\nRed AI\r\nAccuracy: 0.999999999\r\nGreen AI\r\n‚Ä¢ Energy \r\n‚Ä¢ Time \r\n‚Ä¢ Reproducibility \r\n‚Ä¢ Reusage\r\n\r\nHow can we adopt Green AI\r\n‚Ä¢ Check whether AI is needed. \r\n‚Ä¢ Select green datacenters. \r\n‚Ä¢ Run on low carbon intensity hours. \r\n‚Ä¢ Opt for GPU-optimised solutions (?) \r\n‚Ä¢ Opt for low-power hardware (e.g., Nvidia Jetson boards) \r\n‚Ä¢ Or GPUs that provide energy metrics (e.g., NVIDIA GPUs via the nvidia-smi tool) \r\n‚Ä¢ Report energy/carbon metrics (e.g., embed in MLFlow?) \r\n‚Ä¢ Use pre-trained models (Transfer Learning) \r\n‚Ä¢ Preprocess dataset to reduce size. \r\n‚Ä¢ Improve parameter-tuning strategy.\r\n11\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ We need benchmarks. \r\n‚Ä¢ AllenAI leaderboard\u2028\r\nhttps://leaderboard.allenai.org \r\n‚Ä¢ No carbon metrics, yet \r\n‚Ä¢ Report comparable proxies for energy \r\nconsumption. \r\n‚Ä¢ ‚ö† Learning algorithms behave in a non-\r\ndeterministic \r\n‚Ä¢ ‚ö† Different data-points lead to different \r\nenergy consumption\r\n12\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ Reporting measured energy consumption \r\n‚Ä¢ + Accurate \r\n‚Ä¢ + Easy to map to carbon emissions \r\n‚Ä¢ - Hard to measure \r\n‚Ä¢ - Low replicability \r\n‚Ä¢ Reporting time / estimation based on time & hardware \r\n‚Ä¢ + Easy to measure \r\n‚Ä¢ + Correlates with energy consumption in most cases. \r\n‚Ä¢ -  Difficult to compare with measurements from other setups \r\n‚Ä¢ E.g., floating point operations (FPOs) (?) \r\n‚Ä¢ + comparable across different setups \r\n‚Ä¢ + cheap \r\n‚Ä¢ - does not factor in memory energy consumption \r\n‚Ä¢ - does not reflect carbon emissions\r\n13\r\n\r\nData-centric AI\r\n\r\nData-centric AI\r\n‚Ä¢ Emerging discipline that deals with systematically engineering data to build AI \r\nsystems. \r\n‚Ä¢ Shift from improving the training strategy to improving the data. \r\n‚Ä¢ It is better to have small but reliable datasets than large but noisy \r\ndatasets. \r\n‚Ä¢ => Improve data collection, data labelling, and data preprocessing. \r\n‚Ä¢ More about data-centric AI by Andrew Ng:\u2028\r\nhttps://www.youtube.com/watch?v=06-AZXmwHjo\r\n15\r\n\r\n\r\nGreen Data-centric AI\r\n‚Ä¢ How do different ML algorithms compare \r\nin terms of energy consumption? \r\n‚Ä¢ How does number of rows relate to the \r\nenergy consumption of ML models? \r\n‚Ä¢ How does number of features relate to \r\nthe energy consumption of ML models? \r\n‚Ä¢ What is the impact of reducing data in the \r\nperformance of the model?', ""Unless there‚Äôs a \r\ngood reason. \r\n‚Ä¢ E.g., somewhere amongst the 30 executions, \r\nthere might be 1 or 2 that failed to finish due \r\nto some unexpected error. \r\n‚Ä¢ (It happens and that‚Äôs ok!)‚Äì consequently, \r\nthe execution is shorter and spends less \r\nenergy ‚Äì falsely appearing as more \r\nenergy efficient. \r\n‚Ä¢ If data is not Normal there might be some \r\nissues affecting the measurements that \r\nmight be ruining results. It is important to \r\ninvestigate this.\r\n16\r\n\r\nEnergy data is not normal. Why?\r\n‚Ä¢ It might be caused by one of the following reasons: \r\n‚Ä¢ There was an error in some of the executions. If not detected and fixed it \r\nmight ruin results. \r\n‚Ä¢ Your tests are not fully replicable or are not deterministic. Quite frequent \r\nwhen you have internet requests or random-based algorithms. \r\n‚Ä¢ There is an unusual task being run by the system during some experiments. \r\n‚Ä¢ The computer entered a different power mode. \r\n‚Ä¢ External physical conditions have changed. E.g., someone opened a \r\nwindow.\r\n17\r\n\r\nEnergy data is not normal. How to fix?\r\n‚Ä¢ We have 2+1 options: \r\n1. Remove outliers. If there are only a few points that deviate from the normal \r\ndistribution, it is okay to simply remove them. \r\n‚Ä¢ Use the z-score outlier removal. (?) \r\n‚Ä¢ Remove all data points that deviate from the mean more than 3 standard \r\ndeviations: \r\n \r\n2. Fix the issue and rerun experiments. \r\n3. Conclude that nothing can be done about it and data will never be normal. (e.g., \r\nin AI, executions are rarely deterministic). ‚ö† Only after ruling out the previous \r\npoints.\r\n| ¬Øx ‚àíx| > 3s\r\n18\r\n\r\nHow do we know whether data is Normal?\r\n‚Ä¢ Visualise distribution shape: violin plots, histograms, density plot.\u2028\r\n \r\n‚Ä¢ Shapiro-Wilk test.\u2028\r\ndata is not normal;\u2028\r\nwe are not sure but it is okay to assume that data is \r\nnormal.\r\np-value < 0.05 ‚áí\r\np-value ‚â•0.05 ‚áí\r\n19\r\n\r\nAfter having all data ready, which artefact \r\nis more energy efficient(?) \r\nFirst approach: compare sample means. \r\n‚ö† assuming normal distribution\r\n\r\nStatistical significance\r\n‚Ä¢ Even if, on average, one artefact has lower \r\nenergy consumption than other,  it might be just \r\na random difference. \r\n‚Ä¢ When we extract a sample from a normal \r\ndistribution it will never be the exact same \r\n‚Ä¢ Statistical significance tests help you \r\nunderstand the differences in the average are \r\nconclusive/significant or inconclusive/\r\ninsignificant.\r\n21\r\n‚ö† assuming normal distribution\r\n\r\nStatistical significance test\r\n‚Ä¢ Two-sided parametric test Welch‚Äôs t-test. \r\n‚Ä¢ Less known alternative to student‚Äôs t-test.\r\n22\r\nWelch‚Äôs t-test in Python\r\nfrom scipy.stats import ttest_ind \r\n_,pvalue = ttest_ind(sample_a, sample_b, \r\n                     equal_var=False, \r\n                     alternative='two-sided')\r\n(?)\r\n‚ö† assuming normal distribution\r\n\r\nEffect Size analysis\r\n‚Ä¢ Now that we know that results are statistically significant we need to \r\nmeasure the difference between the two samples. \r\n‚Ä¢ Mean difference: \r\n \r\n‚Ä¢ Percent change: \r\n \r\n‚Ä¢ Cohen‚Äôs d (informal definition: mean difference normalized by a combined \r\nstandard deviation): \r\nŒî¬Øx\r\nxB ‚àíxA\r\nxA\r\n√ó 100 % = Œî¬Øx\r\nxA\r\n√ó 100 %\r\nŒî¬Øx\r\n1\r\n2\r\ns21 + s22\r\n23\r\n‚ö† assuming normal distribution\r\n\r\nImagine that version A spends 70J and \r\nversion B spends 69J with a \r\n."", ""‚Ä¢ 6 machine learning algorithms: SVM, Decision Tree, KNN, Random Forrest, \r\nAdaBoost, Bagging Classifier. \r\n‚Ä¢ Reduce the number of rows. 10%, 20%, .., 100% \r\n‚Ä¢ Stratified random sampling (?) \r\n‚Ä¢ Reduce the number of features. 10%, 20%, .., 100% \r\n‚Ä¢ Feature importance metric based on the Chi-Square Test (Chi2) \r\n‚Ä¢ Estimate energy consumption using a RAPL-based tool. (?)\r\n18\r\n\r\n‚Ä¢ Repeat 30 times \r\n‚Ä¢ Fix random seeds \r\n‚Ä¢ ‚Ä¶ \r\n‚Ä¢ Data was not Normal => tailed Normal distribution.\r\n19\r\n(?)\r\n\r\nResults: energy consumption of algorithms\r\n\r\nResults: energy vs data shape\r\n\r\nResults: performance vs data shape\r\n\r\nDiscussion\r\n‚Ä¢ Other data properties should be investigated. \r\n‚Ä¢ E.g., data types \r\n‚Ä¢ Reporting energy data is essential. It can lead to different model selection \r\nwithout hindering model performance. \r\n‚Ä¢ There is a big opportunity in Model and Data Simplification.\r\n23\r\n\r\nData/Model Simplification\r\n‚Ä¢ (?) \r\n‚Ä¢ Data selection \r\n‚Ä¢ Data quantisation. Posit? \r\n‚Ä¢ Data distillation \r\n‚Ä¢ Coreset extraction (?) \r\n‚Ä¢ Model distillation \r\n‚Ä¢ Model quantisation \r\n‚Ä¢ Model pruning \r\n‚Ä¢ ‚Ä¶\r\n24\r\n\r\nPosit vs Float\r\nMore about this: https://spectrum.ieee.org/floating-point-numbers-posits-processor\r\nBetter for DL use cases\r\n\r\nHow can we tune \r\nlearning \r\nparameters \r\nefficiently?\r\n\r\nHyper parameter tuning\r\n‚Ä¢ When training an ML model, there are several parameters that need to be \r\ntuned. \r\n‚Ä¢ E.g., in SVM we have the Regularization parameter C, the kernel function, \r\nthe degree of the kernel function, and depending on the case, many other. \r\n‚Ä¢ The common approach revolves around grid search. The user provides a \r\nsequence of possible values for each parameter and the pipeline runs all \r\npossible combinations. \r\n‚Ä¢ Our question: Can we save energy with alternative approaches? \r\n‚Ä¢ We studied Grid Search, Random Search and Bayesian \r\nOptimisation.\r\n27\r\nTim's MSc Thesis, 2022 \r\nAccepted at CAIN‚Äô23\r\n\r\n\r\nResults\r\n29\r\nConclusions? \r\n‚Ä¢ Bayesian converges faster. \r\n‚Ä¢ No clear winner between Grid and Random\r\n\r\nDeepSeekMoE\r\n30\r\nPreprint at ArXiv, 2024 https://arxiv.org/pdf/\r\n2401.06066\r\n\r\nMixture of Experts\r\n‚Ä¢ Llama3.1 has 405B parameters, DeepSeek V3 671B \r\n‚Ä¢ Yet DeepSeek has quicker inference times and claims less energy \r\nconsumption (?) \r\n‚Ä¢ Divide the model into smaller blocks of experts \r\n‚Ä¢ Tokens get routed to certain experts based on the query \r\n‚Ä¢ Only part of the network is active during inference \r\n‚Ä¢ DeepSeek claims only 37B out of 671B parameters get active\r\n31\r\n\r\nDeepSeekMoE\r\n32\r\n\r\nDeepSeekMoE\r\n33\r\n‚Ä¢ Comparable performance to \r\nLLaMA2 7B effectively using \r\nless half the parameters \r\n‚Ä¢ Less computational power \r\n‚Ä¢ Problems (?) \r\n‚Ä¢ Still need to load all the \r\nparameters \r\n‚Ä¢ High memory -> high \r\nembodied carbon\r\n\r\nGreen AI at FacebookMeta\r\n34\r\nSustainable AI: Environmental Implications, \r\nChallenges and Opportunities (2022)\r\n\r\nCarbon footprint mapped to the AI lifecycle\r\n‚Ä¢ There are 4 main overarching stages where carbon emissions need to be isolated: data \r\ncollection, experimentation, training, inference. \r\n‚Ä¢ At Facebook, recommendation systems split energy consumption evenly between \r\ntraining and inference; text translation models have a 35%/65% split. (Operational cost) \r\n‚Ä¢ Operational/embodied cost split: 30%/70%\r\n35\r\n\r\nOpen issues according to Meta\r\n‚Ä¢ A vast portion of projects only use GPUs at 30%.\u2028\r\nShould be higher to attenuate embodied carbon."", 'Lu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\n7. Green SE ‚Äì Research\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nCarolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl\r\n\r\n1. Energy patterns for mobile apps \r\n2. Carbon-aware datacenters \r\n3. Energy Regression Testing \r\n4. Debugging Energy with Docker images \r\n5. Energy Efficiency vs Code Quality \r\n\r\n‚Ä¢ While learning about these works, try to be critical about them and find their \r\npitfalls.\r\n3\r\n\r\n‚Ä¢ We have seen that measuring energy consumption is not trivial \r\n‚Ä¢ It is not practical considering that developers have other priorities above \r\nenergy efficiency \r\n‚Ä¢ At the same time, every now and then there are some efforts to improve \r\nenergy efficiency in some cases. This is time consuming and requires \r\nexpertise. \r\n‚Ä¢ How can we reuse these efforts?\r\n4\r\n\r\nEnergy Patterns for Mobile \r\nApps\r\nhttps://tqrg.github.io/energy-patterns/\r\n\r\nMethodology\r\n5. Catalog of Energy Patterns\r\n22 \r\npatterns\r\nF-droid\r\nCurated Lists\r\n1. App Collection\r\n1783 \r\napps\r\n3. Manual Refinement of Subjects of \r\nInterest\r\n1563 \r\nchanges\r\n4. Thematic Analysis\r\n431 \r\nreusable \r\nchanges\r\n2. Collect Changes With Potential Interest\r\n/.*(energy|power|battery).*/\r\n6028 \r\nchanges\r\n\r\nThematic Analysis\r\n1. Familiarization with data \r\n2. Generating initial labels \r\n3. Reviewing themes\r\n4. Defining and naming themes\r\n\r\n‚Ä¢ Energy Pattern: design pattern to improve energy efficiency.. \r\n‚Ä¢ 22 energy patterns. \r\n‚Ä¢ Each pattern is described by Context, Solution, Example, References from \r\nliterature, and Occurences (links to code changes from git repositories).\r\n8\r\n\r\nhttps://tqrg.github.io/energy-patterns\r\n\r\nDark UI Colors \r\nProvide a dark UI color theme to \r\nsave battery on devices with \r\nAMOLED screens.\r\n‚Ä¢ Context: [‚Ä¶] Apps that require heavy usage of screen can \r\nhave a substantial negative impact on battery life. \r\n‚Ä¢ Solution: Provide a UI theme with dark background colors. [‚Ä¶]\r\n‚Ä¢ Example: In a reading app, provide a theme with a dark \r\nbackground using light colors to display text. [‚Ä¶] \r\n10\r\n\r\nDark UI Colors \r\nProvide a dark UI color theme to \r\nsave battery on devices with \r\nAMOLED screens.\r\n‚Ä¢ Context: [‚Ä¶] Apps that require heavy usage of screen can \r\nhave a substantial negative impact on battery life. \r\n‚Ä¢ Solution: Provide a UI theme with dark background colors. [‚Ä¶]\r\n‚Ä¢ Example: In a reading app, provide a theme with a dark \r\nbackground using light colors to display text. [‚Ä¶] \r\n11\r\n\r\nDynamic Retry Delay\r\n‚Ä¢ Context: [‚Ä¶] In a mobile app, when a given resource is \r\nunavailable, the app will unnecessarily try to connect the resource \r\nfor a number of times, leading to unnecessary power consumption. \r\n‚Ä¢ Solution: Increase retry interval after each failed connection. [‚Ä¶]\r\n‚Ä¢ Example: Consider a mobile app that provides a news feed and \r\nthe app is not able to reach the server to collect updates. [‚Ä¶] use \r\nthe Fibonacci series to increase the time between attempts.\r\nWhenever an attempt to access a \r\nresource fails, increase the time \r\ninterval before retrying.\r\n12\r\n\r\nBatch Operations \r\n‚Ä¢ Context: Executing operations separately leads to extraneous \r\ntail energy consumptions  \r\n‚Ä¢ Solution: Bundle multiple operations in a single one. [‚Ä¶]\r\n‚Ä¢ Example: Use system provided APIs to schedule background \r\ntasks. These APIs, guarantee that device will exit sleep mode \r\nonly when there is a reasonable amount of work to do or when a \r\ngiven task is urgent.', '27\r\n\r\nCarbon intensity\r\n‚Ä¢ How much carbon is emitted per kWh of electricity consumed. \r\n‚Ä¢ The common unit: \r\n ü§∑ \r\n‚Ä¢ E.g.,  gas-based power plants emit less carbon than coal-based plants. \r\n‚Ä¢ The power grid is a mix between different sources of electricity ‚Äì different \r\nlocations have different carbon intensity.\r\ngCO2eq/kWh\r\n28\r\n\r\nhttps://app.electricitymaps.com/map\r\n\r\nBy Asim Hussain: https://principles.green/principles/carbon-intensity/\r\nüìù Reducing software energy consumption can help reduce the carbon intensity. Why?\r\n\r\nOne would expect zero carbon intensity from solar-\r\npanels or wind farms, but that‚Äôs not the case.\r\n‚ö†\r\n?\r\n\r\nMarginal Power Plant\r\n‚Ä¢ Renewable-based power plants cannot adapt to demand. \r\n‚Ä¢ When demand is higher than the existing power in the electricity grid, we \r\nneed a power plant that is able to scale up to that demand. \r\n‚Ä¢ This is usually done by fossil-based power plants. They are called the \r\nmarginal power plants. \r\n‚Ä¢ The problem is that marginal power plants do not scale down to zero. \r\n‚Ä¢ There is always a minimum carbon that needs to be emitted, even if there is \r\na lot of renewable energy in the grid.\r\n32\r\n\r\nBy Asim Hussain: https://principles.green/principles/carbon-intensity/\r\nHow could we fix this?\r\nWhat‚Äôs the problem here?\r\n\r\nMarginal Carbon Intensity\r\n‚Ä¢ Increase or decrease in carbon emissions in the electrical grid, in response \r\nto an infinitesimal increase/decrease in power demand/supply.\r\n\r\nFrom: ‚ÄúLiterature Review: On the effectiveness of a Marginal Carbon Intensity Signal ‚Äú\r\n\r\nWhy is marginal carbon intensity \r\nrelevant for software?\r\n‚Ä¢ Tip: consider a task scheduler in a datacenter.\r\n\r\nRecap\r\n‚Ä¢ Power \r\n‚Ä¢ Energy \r\n‚Ä¢ Average Power \r\n‚Ä¢ Energy Delay Product \r\n‚Ä¢ Electric charge (battery capacity) \r\n‚Ä¢ Carbon dioxide equivalent (carbon emissions) \r\n‚Ä¢ 100-global-warming potential \r\n‚Ä¢ Carbon Intensity \r\n‚Ä¢ Marginal Carbon Intensity\r\n37\r\n?\r\n\r\nFurther Reading\r\n‚Ä¢ Blog post on energy units:\u2028\r\nhttps://luiscruz.github.io/2023/05/13/energy-units.html \r\n38\r\n?', '‚Ä¢ Improve parameter-tuning strategy.\r\n11\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ We need benchmarks. \r\n‚Ä¢ AllenAI leaderboard\u2028\r\nhttps://leaderboard.allenai.org \r\n‚Ä¢ No carbon metrics, yet \r\n‚Ä¢ Report comparable proxies for energy \r\nconsumption. \r\n‚Ä¢ ‚ö† Learning algorithms behave in a non-\r\ndeterministic \r\n‚Ä¢ ‚ö† Different data-points lead to different \r\nenergy consumption\r\n12\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ Reporting measured energy consumption \r\n‚Ä¢ + Accurate \r\n‚Ä¢ + Easy to map to carbon emissions \r\n‚Ä¢ - Hard to measure \r\n‚Ä¢ - Low replicability \r\n‚Ä¢ Reporting time / estimation based on time & hardware \r\n‚Ä¢ + Easy to measure \r\n‚Ä¢ + Correlates with energy consumption in most cases. \r\n‚Ä¢ -  Difficult to compare with measurements from other setups \r\n‚Ä¢ E.g., floating point operations (FPOs) (?) \r\n‚Ä¢ + comparable across different setups \r\n‚Ä¢ + cheap \r\n‚Ä¢ - does not factor in memory energy consumption \r\n‚Ä¢ - does not reflect carbon emissions\r\n13\r\n\r\nData-centric AI\r\n\r\nData-centric AI\r\n‚Ä¢ Emerging discipline that deals with systematically engineering data to build AI \r\nsystems. \r\n‚Ä¢ Shift from improving the training strategy to improving the data. \r\n‚Ä¢ It is better to have small but reliable datasets than large but noisy \r\ndatasets. \r\n‚Ä¢ => Improve data collection, data labelling, and data preprocessing. \r\n‚Ä¢ More about data-centric AI by Andrew Ng:\u2028\r\nhttps://www.youtube.com/watch?v=06-AZXmwHjo\r\n15\r\n\r\n\r\nGreen Data-centric AI\r\n‚Ä¢ How do different ML algorithms compare \r\nin terms of energy consumption? \r\n‚Ä¢ How does number of rows relate to the \r\nenergy consumption of ML models? \r\n‚Ä¢ How does number of features relate to \r\nthe energy consumption of ML models? \r\n‚Ä¢ What is the impact of reducing data in the \r\nperformance of the model? \r\n‚Ä¢ Method -> results -> discussion\r\n17\r\n\r\nMethod\r\n‚Ä¢ Single object of study: natural language model to detect spam messages. \r\n‚Ä¢ 6 machine learning algorithms: SVM, Decision Tree, KNN, Random Forrest, \r\nAdaBoost, Bagging Classifier. \r\n‚Ä¢ Reduce the number of rows. 10%, 20%, .., 100% \r\n‚Ä¢ Stratified random sampling (?) \r\n‚Ä¢ Reduce the number of features. 10%, 20%, .., 100% \r\n‚Ä¢ Feature importance metric based on the Chi-Square Test (Chi2) \r\n‚Ä¢ Estimate energy consumption using a RAPL-based tool. (?)\r\n18\r\n\r\n‚Ä¢ Repeat 30 times \r\n‚Ä¢ Fix random seeds \r\n‚Ä¢ ‚Ä¶ \r\n‚Ä¢ Data was not Normal => tailed Normal distribution.\r\n19\r\n(?)\r\n\r\nResults: energy consumption of algorithms\r\n\r\nResults: energy vs data shape\r\n\r\nResults: performance vs data shape\r\n\r\nDiscussion\r\n‚Ä¢ Other data properties should be investigated. \r\n‚Ä¢ E.g., data types \r\n‚Ä¢ Reporting energy data is essential. It can lead to different model selection \r\nwithout hindering model performance. \r\n‚Ä¢ There is a big opportunity in Model and Data Simplification.\r\n23\r\n\r\nData/Model Simplification\r\n‚Ä¢ (?) \r\n‚Ä¢ Data selection \r\n‚Ä¢ Data quantisation. Posit? \r\n‚Ä¢ Data distillation \r\n‚Ä¢ Coreset extraction (?) \r\n‚Ä¢ Model distillation \r\n‚Ä¢ Model quantisation \r\n‚Ä¢ Model pruning \r\n‚Ä¢ ‚Ä¶\r\n24\r\n\r\nPosit vs Float\r\nMore about this: https://spectrum.ieee.org/floating-point-numbers-posits-processor\r\nBetter for DL use cases\r\n\r\nHow can we tune \r\nlearning \r\nparameters \r\nefficiently?\r\n\r\nHyper parameter tuning\r\n‚Ä¢ When training an ML model, there are several parameters that need to be \r\ntuned. \r\n‚Ä¢ E.g., in SVM we have the Regularization parameter C, the kernel function, \r\nthe degree of the kernel function, and depending on the case, many other. \r\n‚Ä¢ The common approach revolves around grid search.', 'google.com/view/energy-efficiency-languages\r\n21\r\nAna Radovanovic ÃÅ, Ross Koningstein, Ian Schneider, Bokan \r\nChen, Alexandre Duarte, Binz Roy, Diyue Xiao, Maya \r\nHaridasan, Patrick Hung, Nick Care, Saurav Talukdar, Eric \r\nMullen, Kendal Smith, MariEllen Cottman, and Walfredo Cirne \r\n\r\n\r\n‚Ä¢ Google‚Äôs Carbon-Intelligent Computing System (CICS) \r\n‚Ä¢ Main idea: use carbon-intensity data to shift datacenter jobs in time \r\n‚Ä¢ Typically, job schedulers use a metric of cluster capacity to schedule a job in \r\na particular cluster. \r\n‚Ä¢ CICS overrides this metric with the virtual capacity curve (VCC) that \r\nfactors in Carbon intensity \r\n‚Ä¢ When a new job comes in, the scheduler estimates its CPU load and power \r\nusage and assigns it to a cluster if the VCC is not exceeded.\r\n23\r\n\r\n‚Ä¢ Jobs are divided between flexible and inflexible. \r\n‚Ä¢ Flexible load is considered shapeable/shiftable as long as its total daily \r\ncompute (CPU) demand is preserved \r\n‚Ä¢ The system needs to consider that, while running a job, the virtual capacity \r\ncurve (VCC) might drop. Hence, this job should not start in the first place. \r\n‚Ä¢ They forecast VCC for the next day\r\n24\r\n\r\n\r\nVirtual Cluster Capacity (VCC)\r\n‚Ä¢ Aims at reducing the peak load at carbon intensive hours but in total it should allow for the \r\nsome amount of daily computation! \r\n‚Ä¢ Considers Carbon intensity \r\n‚Ä¢ Using data from electricityMap.org \r\n‚Ä¢ It does not use carbon intensity directly.\u2028\r\nCarbon intensity is converted to a cost (kgCO2 -> $$) \r\n‚Ä¢ This way, they can factor in other metrics that can also be converted to money. E.g., the \r\ncost saved by preventing peak load \r\n‚Ä¢ Peak workload entails extra cost at the infrastructure level (e.g., control faclities‚Äô \r\ntemperature). \r\n‚Ä¢ By using money cost instead of carbon cost, they have more data available.\r\n26\r\n\r\nVirtual Cluster Capacity (VCC)\r\n‚Ä¢ If the forecast of VCC fails it shift flexible workload more than expected.  \r\n‚Ä¢ This happens because the amount of workload forecasted was below the \r\nworkload needed, and VCC was ‚Äúaggressively‚Äù low. \r\n‚Ä¢ The systems fall back to the real cluster capacity for 1 week until results \r\nstart being realistic again.\r\n27\r\n\r\nNext steps\r\n‚Ä¢ They will consider spatial flexibility. \r\n‚Ä¢ I.e., tasks that can be shifted over time and over space. \r\n‚Ä¢ It needs to factor in relocation overheads, though.\r\n28\r\n\r\nCritical questions\r\n‚Ä¢ Who defines what is flexible and inflexible? \r\n‚Ä¢ How do you estimate the CPU load of a given task?\r\n29\r\n\r\nEnergy Regression Testing\r\n‚ÜíEnergy?\r\nGreener? Greener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\n\r\nE-compare\r\nGithub Actions\r\n‚ûú https://koenhagen.github.io/E-Compare/\r\n\r\nEnergy Regression Testing \r\n\r\n4. Debugging Energy with \r\nDocker Images\r\n\r\nUnveiling the Energy Vampires \r\nA methodology for debugging Software \r\nEnergy Consumption\r\n ‚úÖ ICSE 2025\r\n\r\nData Centers and Docker\r\n‚Ä¢ Containers are the most popular way to deploy apps into the cloud \r\n‚Ä¢ Base image is an important choice when building an image \r\n‚Ä¢ Criteria \r\n‚Ä¢ Linux distribution and binaries \r\n‚Ä¢ Image size \r\n‚Ä¢ Energy?\r\n35\r\n\r\nRedis energy consumption\r\n‚Ä¢ Ubuntu/Alpine base images have different energy consumption for Redis\r\n36\r\n\r\nRedis Energy Consumption\r\n‚Ä¢RQ1: What is the difference \r\nin energy consumption \r\nbetween glibc and musl? \r\n‚Ä¢RQ2: Can we use tracing \r\nto compare energy \r\nconsumption in shared \r\nlibraries?', '‚Ä¢ By using money cost instead of carbon cost, they have more data available.\r\n26\r\n\r\nVirtual Cluster Capacity (VCC)\r\n‚Ä¢ If the forecast of VCC fails it shift flexible workload more than expected.  \r\n‚Ä¢ This happens because the amount of workload forecasted was below the \r\nworkload needed, and VCC was ‚Äúaggressively‚Äù low. \r\n‚Ä¢ The systems fall back to the real cluster capacity for 1 week until results \r\nstart being realistic again.\r\n27\r\n\r\nNext steps\r\n‚Ä¢ They will consider spatial flexibility. \r\n‚Ä¢ I.e., tasks that can be shifted over time and over space. \r\n‚Ä¢ It needs to factor in relocation overheads, though.\r\n28\r\n\r\nCritical questions\r\n‚Ä¢ Who defines what is flexible and inflexible? \r\n‚Ä¢ How do you estimate the CPU load of a given task?\r\n29\r\n\r\nEnergy Regression Testing\r\n‚ÜíEnergy?\r\nGreener? Greener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\n\r\nE-compare\r\nGithub Actions\r\n‚ûú https://koenhagen.github.io/E-Compare/\r\n\r\nEnergy Regression Testing \r\n\r\n4. Debugging Energy with \r\nDocker Images\r\n\r\nUnveiling the Energy Vampires \r\nA methodology for debugging Software \r\nEnergy Consumption\r\n ‚úÖ ICSE 2025\r\n\r\nData Centers and Docker\r\n‚Ä¢ Containers are the most popular way to deploy apps into the cloud \r\n‚Ä¢ Base image is an important choice when building an image \r\n‚Ä¢ Criteria \r\n‚Ä¢ Linux distribution and binaries \r\n‚Ä¢ Image size \r\n‚Ä¢ Energy?\r\n35\r\n\r\nRedis energy consumption\r\n‚Ä¢ Ubuntu/Alpine base images have different energy consumption for Redis\r\n36\r\n\r\nRedis Energy Consumption\r\n‚Ä¢RQ1: What is the difference \r\nin energy consumption \r\nbetween glibc and musl? \r\n‚Ä¢RQ2: Can we use tracing \r\nto compare energy \r\nconsumption in shared \r\nlibraries? \r\n‚Ä¢RQ3: Can we verify the \r\norigin of energy \r\nconsumption differences by \r\nrecreating the workload \r\nbehavior closely?\r\n37\r\n\r\nTracing\r\n‚Ä¢ Find libc function running at the end of the benchmark \r\n‚Ä¢ Tracing: Capture calls made to libc \r\n‚Ä¢ Introduces non-linear overhead\r\n38\r\n\r\nSynchronization\r\n‚Ä¢ Tracing slows down execution and increase energy consumption \r\n‚Ä¢ Run separately and synchronize with logs\r\n39\r\n\r\nTracing Analysis\r\n40\r\n\r\nTracing Analysis\r\n41\r\n\r\nBenchmarking memcpy\r\n‚Ä¢ Copy bytes from one part of memory to \r\nanother \r\n‚Ä¢ Depending on function parameters, different \r\nassembly-level optimizations \r\n‚Ä¢ Some not included in musl\r\n42\r\n\r\nBenchmarking memcpy\r\n‚Ä¢ Copy 4 bytes from fixed \r\npointer to moving pointer \r\n‚Ä¢ (100,300,500,600) x 1M \r\nrequests \r\n‚Ä¢  15% more power and 3X time\r\n43\r\n\r\nConclusions\r\n‚Ä¢ Significant difference in energy consumption for memcpy \r\n‚Ä¢ 8.6% difference for Redis workload and 13% in our benchmark \r\n‚Ä¢ musl trades performance for a smaller codebase \r\n‚Ä¢ No official documentation \r\n‚Ä¢ No awareness about energy performance\r\n44\r\n\r\n5. Energy Efficiency vs Code \r\nQuality\r\n\r\nMeasuring Maintainability\r\n‚Ä¢ According to ISO/IEC 25010, Maintainability is ‚Äúthe degree of \r\neffectiveness and efficiency with which a software product or \r\nsystem can be modified to improve it, correct it or adapt it to \r\nchanges in environment, and in requirements‚Äù \r\n‚Ä¢ We use the code analysis tool Better Code Hub to assess \r\nmaintainability \r\n‚Ä¢ Better Code Hub maps the ISO/IEC 25010 standard on \r\nmaintainability into a set of guidelines derived from static analysis\r\n46\r\n\r\nMaintainability of Energy Changes\r\n‚Ä¢ What is the impact of making energy-oriented code changes on \r\nthe maintainability of mobile apps?', 'Carolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nLu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\n1. Intro Class\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl\r\n\r\n1. Intro to Sustainable SE \r\n2. Intro to the course\r\n2\r\n\r\nof the electricity consumed worldwide \r\nby 2040 will stem from ICT\r\n14%\r\n\r\n4\r\nhttps://xkcd.com/1007/\r\n\r\nBuzz words\r\n‚Ä¢ Eco-friendly \r\n‚Ä¢ Climate change, action, adaption \r\n‚Ä¢ Energy efficiency \r\n‚Ä¢ Environmental-responsible \r\n‚Ä¢ Carbon-neutral; Climate-neutral; Net zero \r\n‚Ä¢ Carbon-offsetting \r\n‚Ä¢ Carbon-free \r\n‚Ä¢ Clean technology \r\n‚Ä¢ E-waste\r\n5\r\n\r\nhttps://www.menti.com/uns9d89kzn\r\nWhat is Sustainable \r\nSoftware Engineering?\r\n?\r\n6\r\n\r\nSustainable Software \r\nEngineering is‚Ä¶\r\n7\r\n‚Ä¶the discipline that studies the process of creating software systems that are able \r\nto create value in the long term without hindering its surrounding environment.\r\n\r\n8\r\nEconomical\r\nSocial\r\nTechnical\r\nIndividual\r\nEnvironmental\r\nSustainable\r\nSoftware\r\nEngineering\r\n‚≠ê\r\nTechnical\u2028\r\n‚öô\r\nEconomical\u2028\r\nüí∞\r\nSocial\u2028\r\nüë©üíºüë®üíºüë©üíºüë©üíº\r\nIndividual\u2028\r\nüë©üíª\r\nEnvironmental\u2028\r\nüå±\r\nSustainable\u2028\r\nSoftware \r\nEngineering\r\n\r\nEconomical\r\n‚Ä¢ Focused on assets, capital and added value\u2028\r\n(wealth creation, prosperity, profitability, capital \r\ninvestment, income, etc.) \r\n‚Ä¢ Nr of customers  \r\n‚Ä¢ Man-day-rate estimate \r\n‚Ä¢ Next round of funding \r\n‚Ä¢ Meet requirements in the contract\r\n9\r\n\r\nTechnical\r\n‚Ä¢ Longevity of information, systems, and infrastructure and their \r\nadequate evolution with changing surrounding conditions. \r\n‚Ä¢ Examples: \r\n‚Ä¢ Technical Debt \r\n‚Ä¢ Does it scale? \r\n‚Ä¢ Software testing \r\n‚Ä¢ Bus-factor \r\n‚Ä¢ Data integrity \r\n‚Ä¢ Innovation \r\n‚Ä¢ ‚Ä¶\r\n10\r\n\r\nIndividual\r\n‚Ä¢ Well-being of the individuals in an organisation.\u2028\r\nNote that it also includes how well individuals interact \r\nwith each other within the org. \r\n‚Ä¢ Examples: \r\n‚Ä¢ mental and physical well-being \r\n‚Ä¢ self-respect \r\n‚Ä¢ education/skills \r\n‚Ä¢ career development \r\n‚Ä¢ ‚Ä¶\r\n11\r\n\r\nSocial\r\n‚Ä¢ concerned with societal communities (groups of people, \r\norganisations) and the factors that erode trust in society. \r\n‚Ä¢ Examples: \r\n‚Ä¢ Social equity \r\n‚Ä¢ Justice \r\n‚Ä¢ Employment \r\n‚Ä¢ Democracy \r\n‚Ä¢ ‚Ä¶ \r\n‚Ä¢ Also includes compliance with policies and regulations \r\n12\r\n\r\nEnvironmental Sustainability\r\n‚Ä¢ the branch of Software Engineering that studies \r\nthe development of software that has minimal \r\nimpact in our planet throughout its whole \r\nlifecycle. \r\n‚Ä¢ Looking at software at different levels: \r\n‚Ä¢ Developing, Using, Serving, ‚Ä¶ \r\n‚Ä¢ Also includes e-waste. \r\n‚Ä¢ Almost identical to Green Software. (?)\r\n13\r\nBordallo II\r\n\r\nGreen Software\r\n‚Ä¢ Sustainability and energy efficiency. \r\n‚Ä¢ Building energy-efficient software is important also from a \r\ntechnical sustainability POV. \r\n‚Ä¢ Smartphones, smart wearables, IoT devices, etc. run on limited \r\npower resources. \r\n‚Ä¢ Developing software to these devices require energy-efficiency \r\ntesting and improvement. \r\n‚Ä¢ It also leads to environmental sustainability (e.g., less battery \r\ncycles) \r\n‚Ä¢ Important for UX (e.g., no need to walk around with power banks)\r\n14\r\n\r\nhttps://www.menti.com/uns9d89kzn\r\nWhat is the sustainability \r\ndimension you are most \r\ninterested in?\r\n?', ""Oversimplification\r\nThere are also multiple other advantages‚Ä¶\r\n\r\nHuman vs. computer computation\r\n- Fast real-time decision making, e.g. sports, e-sports\r\n- Adaptive, e.g. context-aware and employs selective attention\r\n- Energy efficient: Close to 100 billion neurons in the brain\r\n- Robust, for example to changes in illumination or obstructions in object tracking\r\n\r\nHuman vs. computer computation\r\nBrains are energy efficient: Why?\r\n1.\r\nHigh temporal resolution (more computation with less neurons)\r\n2.\r\nSparse encoding\r\n\r\nHuman vs. computer computation\r\nQuestions?\r\nBrains are energy efficient: Why?\r\n1.\r\nHigh temporal resolution (more computation with less neurons)\r\n2.\r\nSparse encoding\r\n\r\nHow do biological neurons communicate?\r\nAnalogy to artificial neural networks\r\nReal neuron\r\nArtificial neuron\r\nCurrent\r\n\r\nHow do biological neurons communicate?\r\nHow does the electrical activity propagate?\r\n?\r\nCurrent\r\n\r\nHow do biological neurons work?\r\ntime\r\nelectrode\r\nhttps://tinmard.github.io/spike-sorting-animation.html\r\nQuick electrical pulses trigger chemical signals for the next neuron ‚Üí Spikes\r\n\r\nHow do biological neurons work?\r\nQuick electrical pulses trigger chemical signals for the next neuron ‚Üí Spikes\r\nhttps://tinmard.github.io/spike-sorting-animation.html\r\ntime\r\nelectrode\r\nFrom CS perspective:\r\nSparse binary \r\nencoding\r\n\r\nBiologically realistic spiking neuron models\r\nBiologically realistic neuron models have \r\na new dimension: Time!\r\nSpiking neural networks (SNNs):\r\nThe input x  (t  ) to each neuron is summed \r\n(integrated) over time.\r\nscalar\r\nfunction of \r\ntime\r\n(t)\r\n(t)\r\nhttps://www.mdpi.com/2076-3425/12/7/863\r\n\r\nHow to model spiking neurons?\r\nANN: Perceptron, threshold activation function:\r\n\r\nHow to model spiking neurons?\r\nANN: Perceptron, threshold activation function:\r\n\r\nHow to model spiking neurons?\r\nSpiking neural network (SNN): The 'input current' Œµ(t) is integrated over time.\r\nspike\r\n\r\nHow to model spiking neurons?\r\nEquivalence to perceptron: Computation at least as complex as a perceptron.\r\n\r\nNon-leaky integrate-and-fire (IF) neuron\r\nThe temporal profile of the input current Œµ(t) can be chosen differently, for different computations.\r\n\r\nQuestions?\r\n\r\nComputation with spiking neurons\r\nCoincidence detection\r\n\r\nComputation with spiking neurons\r\nCoincidence detection\r\nx, y ‚àà {0, 1}n\r\nExample: n = 2\r\ninput = \r\nx1\r\nx2\r\ny1\r\ny2\r\n= \r\n0\r\n1\r\n1\r\n1\r\noutput? \r\n\r\nCoincidence detection\r\nComputation with spiking neurons\r\n\r\nCoincidence detection\r\nCan be trivially computed with a single spiking neuron! Requires at least n/log(n+1) hidden \r\nunits for a perceptron (proof in [7]).\r\nComputation with spiking neurons\r\n\r\nCoincidence detection\r\nCan be trivially computed with a single spiking neuron! Requires at least n/log(n+1) hidden \r\nunits for a perceptron (proof in [7]).\r\nBrains are energy efficient: \r\n1.\r\nHigh temporal resolution (more computation with less neurons)\r\nComputation with spiking neurons\r\n\r\nEncoding strategies\r\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\r\nHow should we encode information about 'features' in a large network with many spikes?\r\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\r\nElephant?\r\nhttps://www.nationalgeographic.com/anim\r\nals/mammals/facts/african-elephant\r\n\r\nFiring rates\r\nClassical view of the brain:\r\n- Each neuron is selective for one specific \r\nfeature in the input."", 'p-value = 0.04\r\nOn average, version B spent less energy than version A  ‚Äî  ‚úÖ \r\nThere is statistical significance ‚Äî  ‚úÖ \r\nEffect size, percent-change is ‚âà1% ‚Äî ü§î \r\n‚ö† Do we care?\r\n(?)\r\n\r\nPractical Significance\r\n‚Ä¢ Depending on the case, a 2% improvement might be either wonderful or completely \r\nuseless. \r\n‚Ä¢ Effect size analyses help assess practical significance but might not be enough. \r\n‚Ä¢ A critical discussion always needs to be performed. Consider context and explain in what \r\nsense the effect size might be relevant. \r\n‚Ä¢ E.g.: \r\n‚Ä¢  to improve 2% in energy efficiency the code will be less readable or the user \r\nexperience is not so appealing. \r\n‚Ä¢ A particular method improves 2% but it will only be used 1% of the time. \r\n‚Ä¢ There is no particular metric or structure, but this kind of critical analysis is very important.\r\n25\r\n\r\nWhat if data is not Normal?\r\nSame approach but different tests/metrics!\r\n\r\nNon-normal data\r\n‚Ä¢ Statistical significance: non-parametric test (?) \r\n‚Ä¢ Mann-Whitney U test. Instead of looking at standard deviation or mean, it orders \r\nsamples and compares with each other. \r\n‚Ä¢ Less power than parametric-tests (?) \r\n‚Ä¢ Effect size \r\n‚Ä¢ Median difference: \r\n \r\n‚Ä¢ Percentage of pairs supporting a conclusion\u2028\r\n(i.e., # pairs where version A > version B/ total pairs) \r\n‚Ä¢ Common language effect size: \r\nŒîM\r\nU1\r\nN1N2\r\n27\r\n\r\nRecap\r\nImpossible to \r\nfix but \r\nexplainable.\r\n\r\nEnergy Efficiency Across \r\nProgramming Languages\r\nhttps://sites.google.com/view/energy-efficiency-languages\r\n29\r\nRui Pereira, Marco Couto, Francisco Ribeiro, Rui Rua, J√°come \r\nCunha, Jo√£o Paulo Fernandes, and Jo√£o Saraiva\r\n\r\n‚Ä¢ Is a faster programming language also more energy efficient? \r\n‚Ä¢ Comparing different programming languages is not an easy task. \r\n‚Ä¢ They differ in many mechanisms: \r\n‚Ä¢ Interpreted vs Compiled \r\n‚Ä¢ Optimisations at the compiler level \r\n‚Ä¢ Virtual machine \r\n‚Ä¢ Garbage collector \r\n‚Ä¢ Available libraries\r\n30\r\n\r\nResearch Questions\r\n‚Ä¢ Can we compare the energy efficiency of software languages?  \r\n‚Ä¢ Is the faster language always the most energy efficient? \r\n‚Ä¢ How does memory usage relate to energy consumption? (We don‚Äôt cover this one) \r\n‚Ä¢ Can we automatically decide what is the best programming language \r\nconsidering energy, time, and memory usage?  \r\n‚Ä¢ How do the results of our energy consumption analysis of programming \r\nlanguages gathered from rigorous performance benchmarking solutions \r\ncompare to results of average day-to-day solutions? \u2028\r\n31\r\n\r\nMethodology\r\n\r\nThe Computer Language Benchmarks Game \r\n‚Ä¢ https://benchmarksgame-team.pages.debian.net/benchmarksgame/\r\n33\r\n\r\nProblems in the Computer Language Benchmarks Game\r\n34\r\n\r\n‚Ä¢ 27 Programming languages across different paradigms  \r\n‚Ä¢ Functional (e.g., Ocaml, F#, Haskell) \r\n‚Ä¢ Imperative (e.g., C, Go, Python) \r\n‚Ä¢ Object-oriented (e.g., C++, C#, Java) \r\n‚Ä¢ Scripting (or interpretative) (e.g., JavaScript, Python, Ruby) \r\n‚Ä¢ (These are not mutual exclusive) \r\n‚Ä¢ Intel RAPL‚Äôs C library to measure energy consumption\r\n35\r\n\r\n‚Ä¢ Execute each benchmark solution 10 times. \r\n‚Ä¢ Collect energy data and timestamps. \r\n‚Ä¢ Two-minute interval between executions\r\n36\r\n\r\n\r\n\r\n\r\nCritical thinking\r\n‚Ä¢ There is no doubt this is an excellent study. Yet, as any excellent study, there‚Äôs \r\na lot we can discuss and criticise constructively. \r\n‚Ä¢ What kind of issues you see in drawing conclusions from such a table of \r\nresults?', 'Energy profiling of static analysis tools\r\n‚Ä¢ What is the energy consumption of a ""typical run"" for a few OSS projects? \r\n‚Ä¢ Does the type of analysis matter? Are certain analysis more expensive? Does \r\nthe number of rules that are activated in a static analysis tool important for the \r\nenergy consumption? \r\n‚Ä¢ Differences between static analysis tools [lower priority]\r\n\r\nB5. Tool supporting SusAF workshop / process\r\n‚Ä¢ Lead engineers through process & questions \r\n‚Ä¢ Interface to create & document the two diagrams \r\n‚Ä¢ (!) Should be easy to start using & set up \r\n‚Ä¢ You may also create a simplified version / \u2028\r\nyour favorite sustainability framework\r\nEnvironmental\r\nEconomic\r\nTechnical\r\nIndividual\r\nSocial\r\nImmediate\r\nEnabling\r\nStructural\r\nAirbnb\r\ngreater \r\nearnings\r\nincrease \r\nin rents\r\ngentrification\r\ngreater racial \r\ndisparities\r\nrent \r\nrooms\r\n5\r\n1\r\n3\r\n4\r\n2\r\n \r\n \r\n \r\n \r\n \r\n \r\nVery \r\nunlikely \r\nVery \r\nlikely \r\n\r\nB6. Dataset of government-developed OS software\r\n‚Ä¢ Governments develop & use software for supporting society\u2028\r\nOpen-source development & policies are on the rise \r\n‚Ä¢ But studying government software is difficult b/c we don‚Äôt know what is out \r\nthere\u2028\r\n‚Üí Lack of incentive to make popular \u2028\r\n‚Üí Language barriers \r\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \r\nbuildable?, open dev. history?, requirements documentation? \r\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!\r\n\r\nB7. Queue - but better for the student / TA society\r\n‚Ä¢ Requirements analysis regarding social and individual sustainability effects \r\nof Queue \r\n‚Ä¢ Other EIP / TUD used software also possible: e.g., Answers EWI \r\n‚Ä¢ Non-technical project ‚Üí proper process (workshops? Interviews?) & rich \r\ndescription of outcomes focus of grading\r\nhttps://eip.pages.ewi.tudelft.nl/eip-website/queue.html\r\n\r\nC1. Compare energy consumption of docker images for \r\nML workloads.\r\n‚Ä¢ Similar to what we have seen in the lectures but for ML-specific workloads. \r\n‚Ä¢ We can reuse existing experiment replication packages.\r\n22\r\n\r\nC2. Plugin to visualize Hugging Face carbon emissions.\r\n‚Ä¢ https://huggingface.co/blog/leaderboard-emissions-\r\nanalysis \r\n‚Ä¢\r\nYoo, Taewon, et al. ""Visualizing the Carbon Intensity of Machine Learning Inference for Image Analysis on TensorFlow Hub.""\r\n\r\nC3. Plugin for ChatGPT\r\n‚Ä¢ Users seldom know how much carbon they are emitting when they interact \r\nwith chat GPT. \r\n‚Ä¢ Let‚Äôs make it transparent to the users. Browser plugin?\r\n24\r\nCO2\r\n\r\nC4. NutriScore for software libraries\r\n25\r\n‚Ä¢ NutriScore labels are not perfect but they are a good starting point! \r\n‚Ä¢ What if we could do the same thing for the energy efficiency of software. \r\n‚Ä¢ (Also open to individual or social sustainability) \r\n‚Ä¢ This work can be scoped in particular domains/ecossystems/use cases. \r\n‚Ä¢ Libraries for stats? ML? Web Dev? Cloud?\r\n\r\nC5. Add energy-awareness to existing software\r\n26\r\n‚Ä¢ Streamlit, Notebooks, JSFiddle, \r\nPyScript, zsh, etc. \r\n‚Ä¢\r\n\r\nC6 - Green Shift Left\r\n‚Ä¢ Estimate energy efficiency using static code analysis. \r\n‚Ä¢ We don‚Äôt need an accurate value. \r\n‚Ä¢ It is useful to know which code is more likely to \r\nintroduce energy hotspots and that should be \r\nreviewed with more attention. \r\n‚Ä¢ Can be scoped to a particular domain (react, php, data \r\nscience, web, etc., etc.)', ""‚Ä¢ Visualise distribution shape: violin plots, histograms, density plot.\u2028\r\n \r\n‚Ä¢ Shapiro-Wilk test.\u2028\r\ndata is not normal;\u2028\r\nwe are not sure but it is okay to assume that data is \r\nnormal.\r\np-value < 0.05 ‚áí\r\np-value ‚â•0.05 ‚áí\r\n19\r\n\r\nAfter having all data ready, which artefact \r\nis more energy efficient(?) \r\nFirst approach: compare sample means. \r\n‚ö† assuming normal distribution\r\n\r\nStatistical significance\r\n‚Ä¢ Even if, on average, one artefact has lower \r\nenergy consumption than other,  it might be just \r\na random difference. \r\n‚Ä¢ When we extract a sample from a normal \r\ndistribution it will never be the exact same \r\n‚Ä¢ Statistical significance tests help you \r\nunderstand the differences in the average are \r\nconclusive/significant or inconclusive/\r\ninsignificant.\r\n21\r\n‚ö† assuming normal distribution\r\n\r\nStatistical significance test\r\n‚Ä¢ Two-sided parametric test Welch‚Äôs t-test. \r\n‚Ä¢ Less known alternative to student‚Äôs t-test.\r\n22\r\nWelch‚Äôs t-test in Python\r\nfrom scipy.stats import ttest_ind \r\n_,pvalue = ttest_ind(sample_a, sample_b, \r\n                     equal_var=False, \r\n                     alternative='two-sided')\r\n(?)\r\n‚ö† assuming normal distribution\r\n\r\nEffect Size analysis\r\n‚Ä¢ Now that we know that results are statistically significant we need to \r\nmeasure the difference between the two samples. \r\n‚Ä¢ Mean difference: \r\n \r\n‚Ä¢ Percent change: \r\n \r\n‚Ä¢ Cohen‚Äôs d (informal definition: mean difference normalized by a combined \r\nstandard deviation): \r\nŒî¬Øx\r\nxB ‚àíxA\r\nxA\r\n√ó 100 % = Œî¬Øx\r\nxA\r\n√ó 100 %\r\nŒî¬Øx\r\n1\r\n2\r\ns21 + s22\r\n23\r\n‚ö† assuming normal distribution\r\n\r\nImagine that version A spends 70J and \r\nversion B spends 69J with a \r\n.\r\np-value = 0.04\r\nOn average, version B spent less energy than version A  ‚Äî  ‚úÖ \r\nThere is statistical significance ‚Äî  ‚úÖ \r\nEffect size, percent-change is ‚âà1% ‚Äî ü§î \r\n‚ö† Do we care?\r\n(?)\r\n\r\nPractical Significance\r\n‚Ä¢ Depending on the case, a 2% improvement might be either wonderful or completely \r\nuseless. \r\n‚Ä¢ Effect size analyses help assess practical significance but might not be enough. \r\n‚Ä¢ A critical discussion always needs to be performed. Consider context and explain in what \r\nsense the effect size might be relevant. \r\n‚Ä¢ E.g.: \r\n‚Ä¢  to improve 2% in energy efficiency the code will be less readable or the user \r\nexperience is not so appealing. \r\n‚Ä¢ A particular method improves 2% but it will only be used 1% of the time. \r\n‚Ä¢ There is no particular metric or structure, but this kind of critical analysis is very important.\r\n25\r\n\r\nWhat if data is not Normal?\r\nSame approach but different tests/metrics!\r\n\r\nNon-normal data\r\n‚Ä¢ Statistical significance: non-parametric test (?) \r\n‚Ä¢ Mann-Whitney U test. Instead of looking at standard deviation or mean, it orders \r\nsamples and compares with each other. \r\n‚Ä¢ Less power than parametric-tests (?) \r\n‚Ä¢ Effect size \r\n‚Ä¢ Median difference: \r\n \r\n‚Ä¢ Percentage of pairs supporting a conclusion\u2028\r\n(i.e., # pairs where version A > version B/ total pairs) \r\n‚Ä¢ Common language effect size: \r\nŒîM\r\nU1\r\nN1N2\r\n27\r\n\r\nRecap\r\nImpossible to \r\nfix but \r\nexplainable."", '‚Ä¢ Examples: \r\n‚Ä¢ Technical Debt \r\n‚Ä¢ Does it scale? \r\n‚Ä¢ Software testing \r\n‚Ä¢ Bus-factor \r\n‚Ä¢ Data integrity \r\n‚Ä¢ Innovation \r\n‚Ä¢ ‚Ä¶\r\n10\r\n\r\nIndividual\r\n‚Ä¢ Well-being of the individuals in an organisation.\u2028\r\nNote that it also includes how well individuals interact \r\nwith each other within the org. \r\n‚Ä¢ Examples: \r\n‚Ä¢ mental and physical well-being \r\n‚Ä¢ self-respect \r\n‚Ä¢ education/skills \r\n‚Ä¢ career development \r\n‚Ä¢ ‚Ä¶\r\n11\r\n\r\nSocial\r\n‚Ä¢ concerned with societal communities (groups of people, \r\norganisations) and the factors that erode trust in society. \r\n‚Ä¢ Examples: \r\n‚Ä¢ Social equity \r\n‚Ä¢ Justice \r\n‚Ä¢ Employment \r\n‚Ä¢ Democracy \r\n‚Ä¢ ‚Ä¶ \r\n‚Ä¢ Also includes compliance with policies and regulations \r\n12\r\n\r\nEnvironmental Sustainability\r\n‚Ä¢ the branch of Software Engineering that studies \r\nthe development of software that has minimal \r\nimpact in our planet throughout its whole \r\nlifecycle. \r\n‚Ä¢ Looking at software at different levels: \r\n‚Ä¢ Developing, Using, Serving, ‚Ä¶ \r\n‚Ä¢ Also includes e-waste. \r\n‚Ä¢ Almost identical to Green Software. (?)\r\n13\r\nBordallo II\r\n\r\nGreen Software\r\n‚Ä¢ Sustainability and energy efficiency. \r\n‚Ä¢ Building energy-efficient software is important also from a \r\ntechnical sustainability POV. \r\n‚Ä¢ Smartphones, smart wearables, IoT devices, etc. run on limited \r\npower resources. \r\n‚Ä¢ Developing software to these devices require energy-efficiency \r\ntesting and improvement. \r\n‚Ä¢ It also leads to environmental sustainability (e.g., less battery \r\ncycles) \r\n‚Ä¢ Important for UX (e.g., no need to walk around with power banks)\r\n14\r\n\r\nhttps://www.menti.com/uns9d89kzn\r\nWhat is the sustainability \r\ndimension you are most \r\ninterested in?\r\n?\r\n15\r\n\r\nEconomical sustainability tops the environment\r\n‚Ä¢ In general, a software project will not survive if it‚Äôs not economical \r\nsustainable \r\n‚Ä¢ Yet, a project can survive even if it is not environmental sustainable \r\n‚Ä¢ The mindset is changing! \r\n‚Ä¢ Software consumers have started to worry about the climate impact \r\nof their behaviour as users. \r\n‚Ä¢ Being environmentally sustainable is now an important competitive \r\nfactor \r\n‚Ä¢ Marketing teams are already using all eco-friendly labels. Technical \r\nteams are not there yet, though. \r\n‚Ä¢ It‚Äôs easier said than done!\r\n$\r\n16\r\n\r\nGreen Washing\r\n‚Ä¢ Deceptively use marketing techniques to \r\nclaim being eco-friendly. \r\n‚Ä¢ Opting for green-coloured designs. \r\n‚Ä¢ Red/orange is usually perceived as \r\ntasty. \r\n‚Ä¢ Green is perceived as eco-friendly. \r\n‚Ä¢ The VW case. (?)\r\n17\r\n\r\nThe VW scandal\r\nGreenwashing\r\n‚Ä¢ Used software to cheat on vehicle emissions \r\ntests. \r\n‚Ä¢ The vehicle‚Äôs software could detect whether they \r\nwere being tested, changing the performance \r\naccordingly to improve results. \r\n‚Ä¢ Affected 11M cars worldwide, 8M in Europe.\r\n18\r\n\r\nHow can we drive sustainability \r\nin the SE industry?\r\n\r\nGreen Procurement\r\n‚Ä¢ Customers decide on providers that share their values \r\n‚Ä¢ This is currently the main trigger reason why organisations \r\nworry about Sustainability and Green Software. \r\n‚Ä¢ Examples of green procurement: \r\n‚Ä¢ Customers that only buy green services/products \r\n‚Ä¢ Companies that only use green providers \r\n‚Ä¢ Developers that only work for green companies \r\n‚Ä¢ Green procurement makes environmental sustainability \r\nessential for economical sustainability.\r\n20\r\n\r\nSustainability via compliance\r\n‚Ä¢ EU wants to be carbon neutral by 2030 \r\n‚Ä¢ This also affects the ICT sector. Estimated to impact \r\n14% of the global carbon footprint by 2040. \r\n‚Ä¢ Some initiatives are already being negotiated. \r\n‚Ä¢ Extending the smartphone lifetime to 7 years. \r\n‚Ä¢ Right-to-repair movement. https://repair.eu \r\n‚Ä¢ Making IT services relying on clean energy more \r\naccessible (e.g., less taxes).\r\n21\r\n\r\nSoftware for Sustainability \r\n‚Ä¢ We are not covering it in this course.', '‚Ä¢RQ3: Can we verify the \r\norigin of energy \r\nconsumption differences by \r\nrecreating the workload \r\nbehavior closely?\r\n37\r\n\r\nTracing\r\n‚Ä¢ Find libc function running at the end of the benchmark \r\n‚Ä¢ Tracing: Capture calls made to libc \r\n‚Ä¢ Introduces non-linear overhead\r\n38\r\n\r\nSynchronization\r\n‚Ä¢ Tracing slows down execution and increase energy consumption \r\n‚Ä¢ Run separately and synchronize with logs\r\n39\r\n\r\nTracing Analysis\r\n40\r\n\r\nTracing Analysis\r\n41\r\n\r\nBenchmarking memcpy\r\n‚Ä¢ Copy bytes from one part of memory to \r\nanother \r\n‚Ä¢ Depending on function parameters, different \r\nassembly-level optimizations \r\n‚Ä¢ Some not included in musl\r\n42\r\n\r\nBenchmarking memcpy\r\n‚Ä¢ Copy 4 bytes from fixed \r\npointer to moving pointer \r\n‚Ä¢ (100,300,500,600) x 1M \r\nrequests \r\n‚Ä¢  15% more power and 3X time\r\n43\r\n\r\nConclusions\r\n‚Ä¢ Significant difference in energy consumption for memcpy \r\n‚Ä¢ 8.6% difference for Redis workload and 13% in our benchmark \r\n‚Ä¢ musl trades performance for a smaller codebase \r\n‚Ä¢ No official documentation \r\n‚Ä¢ No awareness about energy performance\r\n44\r\n\r\n5. Energy Efficiency vs Code \r\nQuality\r\n\r\nMeasuring Maintainability\r\n‚Ä¢ According to ISO/IEC 25010, Maintainability is ‚Äúthe degree of \r\neffectiveness and efficiency with which a software product or \r\nsystem can be modified to improve it, correct it or adapt it to \r\nchanges in environment, and in requirements‚Äù \r\n‚Ä¢ We use the code analysis tool Better Code Hub to assess \r\nmaintainability \r\n‚Ä¢ Better Code Hub maps the ISO/IEC 25010 standard on \r\nmaintainability into a set of guidelines derived from static analysis\r\n46\r\n\r\nMaintainability of Energy Changes\r\n‚Ä¢ What is the impact of making energy-oriented code changes on \r\nthe maintainability of mobile apps? \r\nMaintainability \r\nDifference \r\nvE-2\r\nvE-1\r\nvE\r\nEnergy \r\nCommit\r\nvE+1\r\nM(vE-1)\r\nM(vE)\r\nParent \r\nCommit\r\n‚àÜM\r\n47\r\n\r\nThreshold Marks\r\n48\r\n\r\nBetter Code Hub\r\nMaintainability\r\nCombine\r\ndatasets\r\nEnergy\r\nCommits\r\nBaseline\r\nCommits\r\nBao et al. \r\n(2015)\r\nMoura et al. \r\n(2016)\r\nCruz et al. \r\n(2018)\r\nCruz et al. \r\n(2019)\r\nEnergy Code Changes \r\nDataset\r\n539 commits\u2028\r\nfrom 306 mobile apps\r\n539 baseline commits\u2028\r\nfrom 306 mobile apps\r\n49\r\n\r\nImpact of energy changes on \r\nmaintainability\r\n50\r\n\r\nWhich energy \r\npatterns are more \r\nlikely to affect \r\nmaintainability?\r\n51\r\n\r\nTypical maintainability issue I\r\nhttps://github.com/einmalfel/PodListen/commit/2ed5a65\r\n4 changed files with 28 additions and 0 deletions.\r\n‚Ä¶\r\n‚Ä¶\r\n52\r\n\r\nTypical maintainability issue II\r\nhttps://github.com/mozilla/MozStumbler/commit/6ea0268\r\n5 changed files with 66 additions and 14 deletions.\r\n53\r\n\r\n54']","['<1-hop>\n\nShuffle \nüîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them.\n‚Ä¢ If you run 30 executions for version A and another batch for version B:\n‚Ä¢ External conditions that change over time will have a diÔ¨Äerent bias in \nthe 2 versions (e.g., room temperature changes).\n‚Ä¢ If you shuÔ¨Ñe, you reduce this risk.\n11', '<2-hop>\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio)\n‚Ä¢ Dynamic Retry Delay\n‚Ä¢ Push Over Poll\n‚Ä¢ Reduce Size\n‚Ä¢ Cache\n‚Ä¢ Avoid Graphics and Animations\n20']","Shuffling reduces risk by minimizing the bias introduced by external conditions that change over time during experiments. When you run multiple executions for different versions (e.g., version A and version B), shuffling the order of these executions helps ensure that any changes in external conditions, such as room temperature, affect both versions equally, thereby reducing the risk of biased results.

In contrast, EcoAndroid's ""Reduce Size"" approach focuses on minimizing energy consumption by reducing the size of data or operations, such as using smaller data sets or optimizing the size of transmitted data. This approach directly targets the energy efficiency of the application by reducing the computational load and, consequently, the energy required for processing.

While shuffling addresses the variability and bias in experimental conditions, reducing size in EcoAndroid directly impacts the energy consumption of the application itself. Both strategies aim to improve energy efficiency but tackle different aspects of the problem.",Shuffling reduce risk by balance external factor like room temperature change while EcoAndroid reduce size by optimize resource use.,0.0,,,0.4,,0.8119457470977774
How shuffling reduce risk when reduce size in software engineering?,"['‚Ä¢ In a scientific project, the magic number is 30.\r\n7\r\n\r\n\r\nRest ‚è∏\r\n‚Ä¢ It is common practice to do a pause/sleep between executions/\r\nmeasurements. \r\n‚Ä¢ Prevent tail energy consumption from previous measurements. ? \r\n‚Ä¢ Prevent collateral tasks of previous measurement from affecting the next \r\nmeasurement. \r\n‚Ä¢ There is no golden rule but one minute should be enough. It can be more or \r\nless depending on your hardware or the duration of your energy test.\r\n9\r\n\r\nt\r\nP\r\nTail Energy Consumption\r\n\r\nShuffle üîÄ\r\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \r\nit is impossible to control all of them. \r\n‚Ä¢ If you run 30 executions for version A and another batch for version B: \r\n‚Ä¢ External conditions that change over time will have a different bias in \r\nthe 2 versions (e.g., room temperature changes). \r\n‚Ä¢ If you shuffle, you reduce this risk.\r\n11\r\n\r\nKeep it cool üå°\r\n‚Ä¢ Always make sure there is a stable room temperature. \r\n‚Ä¢ Tricky because, some times, experiments may have to run over a few days. \r\n‚Ä¢ If you cannot control room temperature: collect temperature data and filter \r\nout measurements where the room temperature is clearly deviating.\r\n12\r\n\r\nAutomate Executions ü§ñ\r\n‚Ä¢ (Already mentioned in the previous classes) \r\n‚Ä¢ One cannot run 30 shuffled experiments per version without automation‚Ä¶\r\n13\r\n\r\nData analysis\r\n14\r\n\r\n1. Exploratory Analysis\r\n‚Ä¢ Plot the data and inspect outliers or \r\nunexpected biases. \r\n‚Ä¢ Violin+box plots are usually handy. (?) \r\n‚Ä¢ It‚Äôs a nice way of combining the 30 \r\nexperiments, and of showing \r\ndescriptive statistics. (?) \r\n‚Ä¢ Shows the shape of the distribution \r\nof the data.\r\n15\r\n\r\n1. Exploratory Analysis (II)\r\n‚Ä¢ Data should be Normal. Unless there‚Äôs a \r\ngood reason. \r\n‚Ä¢ E.g., somewhere amongst the 30 executions, \r\nthere might be 1 or 2 that failed to finish due \r\nto some unexpected error. \r\n‚Ä¢ (It happens and that‚Äôs ok!)‚Äì consequently, \r\nthe execution is shorter and spends less \r\nenergy ‚Äì falsely appearing as more \r\nenergy efficient. \r\n‚Ä¢ If data is not Normal there might be some \r\nissues affecting the measurements that \r\nmight be ruining results. It is important to \r\ninvestigate this.\r\n16\r\n\r\nEnergy data is not normal. Why?\r\n‚Ä¢ It might be caused by one of the following reasons: \r\n‚Ä¢ There was an error in some of the executions. If not detected and fixed it \r\nmight ruin results. \r\n‚Ä¢ Your tests are not fully replicable or are not deterministic. Quite frequent \r\nwhen you have internet requests or random-based algorithms. \r\n‚Ä¢ There is an unusual task being run by the system during some experiments. \r\n‚Ä¢ The computer entered a different power mode. \r\n‚Ä¢ External physical conditions have changed. E.g., someone opened a \r\nwindow.\r\n17\r\n\r\nEnergy data is not normal. How to fix?\r\n‚Ä¢ We have 2+1 options: \r\n1. Remove outliers. If there are only a few points that deviate from the normal \r\ndistribution, it is okay to simply remove them. \r\n‚Ä¢ Use the z-score outlier removal. (?) \r\n‚Ä¢ Remove all data points that deviate from the mean more than 3 standard \r\ndeviations: \r\n \r\n2. Fix the issue and rerun experiments. \r\n3. Conclude that nothing can be done about it and data will never be normal. (e.g., \r\nin AI, executions are rarely deterministic). ‚ö† Only after ruling out the previous \r\npoints.\r\n| ¬Øx ‚àíx| > 3s\r\n18\r\n\r\nHow do we know whether data is Normal?', 'Lu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\n3. Scientific Guide for Reliable \r\nEnergy Experiments\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nCarolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl\r\n\r\n1. Scientific guide for energy measurements \r\n2. Energy consumption data analysis \r\n\r\nEnergy tests are flaky\r\n‚Ä¢ Multiple runs might yield different results \r\n‚Ä¢ There are many confounding factors that need to be controlled/minimized.\r\n3\r\n?\r\n\r\nZen mode üßò\r\n‚Ä¢ Close all applications. \r\n‚Ä¢ Turn off notifications. \r\n‚Ä¢ Only the required hardware should be connected (avoid USB drives, external \r\ndisks, external displays, etc.). \r\n‚Ä¢ Kill unnecessary services running in the background (e.g., web server, file \r\nsharing, etc.). \r\n‚Ä¢ If you do not need an internet or intranet connection, switch off your network. \r\n‚Ä¢ Prefer cable over wireless ‚Äì the energy consumption from a cable connection \r\nis more stable than from a wireless connection.\r\n4\r\n\r\nFreeze and report your settings ü•∂\r\n‚Ä¢ Fix display brightness; switch off auto brightness \r\n‚Ä¢ If Wifi is on, it should always be on, connected to the same network/\r\nendpoint.‚Ä¶\r\n5\r\n\r\nWarm-up üì∂\r\n‚Ä¢ Energy consumption is highly affected by the temperature of your hardware. \r\n‚Ä¢ Higher the temperature -> higher the resistance of electrical conductors ->\u2028\r\n-> higher dissipation -> higher energy consumption \r\n‚Ä¢ The first execution will appear more efficient because the hardware is still \r\ncold. \r\n‚Ä¢ Run a CPU-intensive task before measuring energy consumption. E.g., \r\nFibonacci sequence. At least 1min; 5min recommended. \r\n‚Ä¢\r\n6\r\n\r\nRepeat üîÅ\r\n‚Ä¢ The best way to make sure a measurement is valid is by repeating it. \r\n‚Ä¢ In a scientific project, the magic number is 30.\r\n7\r\n\r\n\r\nRest ‚è∏\r\n‚Ä¢ It is common practice to do a pause/sleep between executions/\r\nmeasurements. \r\n‚Ä¢ Prevent tail energy consumption from previous measurements. ? \r\n‚Ä¢ Prevent collateral tasks of previous measurement from affecting the next \r\nmeasurement. \r\n‚Ä¢ There is no golden rule but one minute should be enough. It can be more or \r\nless depending on your hardware or the duration of your energy test.\r\n9\r\n\r\nt\r\nP\r\nTail Energy Consumption\r\n\r\nShuffle üîÄ\r\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \r\nit is impossible to control all of them. \r\n‚Ä¢ If you run 30 executions for version A and another batch for version B: \r\n‚Ä¢ External conditions that change over time will have a different bias in \r\nthe 2 versions (e.g., room temperature changes). \r\n‚Ä¢ If you shuffle, you reduce this risk.\r\n11\r\n\r\nKeep it cool üå°\r\n‚Ä¢ Always make sure there is a stable room temperature. \r\n‚Ä¢ Tricky because, some times, experiments may have to run over a few days. \r\n‚Ä¢ If you cannot control room temperature: collect temperature data and filter \r\nout measurements where the room temperature is clearly deviating.\r\n12\r\n\r\nAutomate Executions ü§ñ\r\n‚Ä¢ (Already mentioned in the previous classes) \r\n‚Ä¢ One cannot run 30 shuffled experiments per version without automation‚Ä¶\r\n13\r\n\r\nData analysis\r\n14\r\n\r\n1. Exploratory Analysis\r\n‚Ä¢ Plot the data and inspect outliers or \r\nunexpected biases. \r\n‚Ä¢ Violin+box plots are usually handy. (?) \r\n‚Ä¢ It‚Äôs a nice way of combining the 30 \r\nexperiments, and of showing \r\ndescriptive statistics. (?) \r\n‚Ä¢ Shows the shape of the distribution \r\nof the data.\r\n15\r\n\r\n1. Exploratory Analysis (II)\r\n‚Ä¢ Data should be Normal.', ""‚Ä¢ Our question: Can we save energy with alternative approaches? \r\n‚Ä¢ We studied Grid Search, Random Search and Bayesian \r\nOptimisation.\r\n27\r\nTim's MSc Thesis, 2022 \r\nAccepted at CAIN‚Äô23\r\n\r\n\r\nResults\r\n29\r\nConclusions? \r\n‚Ä¢ Bayesian converges faster. \r\n‚Ä¢ No clear winner between Grid and Random\r\n\r\nDeepSeekMoE\r\n30\r\nPreprint at ArXiv, 2024 https://arxiv.org/pdf/\r\n2401.06066\r\n\r\nMixture of Experts\r\n‚Ä¢ Llama3.1 has 405B parameters, DeepSeek V3 671B \r\n‚Ä¢ Yet DeepSeek has quicker inference times and claims less energy \r\nconsumption (?) \r\n‚Ä¢ Divide the model into smaller blocks of experts \r\n‚Ä¢ Tokens get routed to certain experts based on the query \r\n‚Ä¢ Only part of the network is active during inference \r\n‚Ä¢ DeepSeek claims only 37B out of 671B parameters get active\r\n31\r\n\r\nDeepSeekMoE\r\n32\r\n\r\nDeepSeekMoE\r\n33\r\n‚Ä¢ Comparable performance to \r\nLLaMA2 7B effectively using \r\nless half the parameters \r\n‚Ä¢ Less computational power \r\n‚Ä¢ Problems (?) \r\n‚Ä¢ Still need to load all the \r\nparameters \r\n‚Ä¢ High memory -> high \r\nembodied carbon\r\n\r\nGreen AI at FacebookMeta\r\n34\r\nSustainable AI: Environmental Implications, \r\nChallenges and Opportunities (2022)\r\n\r\nCarbon footprint mapped to the AI lifecycle\r\n‚Ä¢ There are 4 main overarching stages where carbon emissions need to be isolated: data \r\ncollection, experimentation, training, inference. \r\n‚Ä¢ At Facebook, recommendation systems split energy consumption evenly between \r\ntraining and inference; text translation models have a 35%/65% split. (Operational cost) \r\n‚Ä¢ Operational/embodied cost split: 30%/70%\r\n35\r\n\r\nOpen issues according to Meta\r\n‚Ä¢ A vast portion of projects only use GPUs at 30%.\u2028\r\nShould be higher to attenuate embodied carbon.\r\n36\r\nBased on 10K AI projects\r\n\r\nData Jan\r\nInformed Adaptation\r\nData Feb\r\nData Mar\r\nData Apr\r\nData May\r\n‚Ä¶\r\n~Data Dec\r\n~Data Dec\r\nData Jan\r\nData Feb\r\nData Mar\r\nData Apr\r\nData May\r\n‚Ä¶\r\nModel update Model update Model update\r\nCheck if \r\ndata change\r\nCheck if \r\ndata change\r\nCheck if \r\ndata change\r\nModel update\r\nBlind Adaptation\r\nThe AI Model will be \r\nupdated fewer times and \r\nonly when necessary.\r\nKnow when to retrain models\r\nNeither too early nor too late\r\n37\r\nAdaptation Techniques\r\n?\r\n\r\nGreen Architectural Tactics for ML-Enabled \r\nSystem\r\n38\r\nICSE-SEIS 2024\r\n\r\nArchitectural tactics\r\n39\r\n\r\nData-centric\r\n40\r\n‚Ä¢ Reduce data size \r\n‚Ä¢ Sampling \r\n‚Ä¢ Dimensionality reduction \r\n‚Ä¢ Quantization\r\n\r\nAlgorithm Design\r\n41\r\n‚Ä¢ Carefully select your algorithm \r\n‚Ä¢ You don‚Äôt need the fanciest \r\ntechniques\r\n\r\nModel Optimization\r\n42\r\n‚Ä¢ Add energy to training parameters \r\n‚Ä¢ Reduce FLOPs \r\n‚Ä¢ Pruning, sparsity \r\n‚Ä¢  Take advantage of existing models\r\n\r\nModel Training\r\n43\r\n‚Ä¢ Quantization\r\n‚Ä¢ SAVE TRAINING PROGRESS\r\n\r\nModel Deployment\r\n44\r\n‚Ä¢ Distributed deployment \r\n‚Ä¢ Energy efficient hardware and \r\nconfigurations\r\n\r\nModel Management\r\n45\r\n‚Ä¢ Reuse the model as much as possible \r\n\r\nRethinking the Architecture: Spiking Neural Networks\r\n46\r\n\r\nRethinking the Architecture: Spiking Neural Networks\r\n47\r\n\r\nSELF Lab\r\n48\r\n\r\nrecap"", '[‚Ä¶]\r\n13\r\n\r\nAvoid Extraneous Graphics and \r\nAnimations  \r\n‚Ä¢ Context: Mobile apps that feature impressive graphics \r\nand animations. [‚Ä¶] \r\n‚Ä¢ Solution: Study the importance of graphics and \r\nanimations to the user experience and reduce them when \r\napplicable. [‚Ä¶]\r\n‚Ä¢ Example: Resort to low frame rates for animations when \r\npossible. \r\nDespite being important to improve user experience, graphics \r\nand animations are battery intensive and should be used with \r\nmoderation.  \r\n14\r\n\r\nEnergy Patterns are \r\nmore Frequent\r\nin Android Apps\r\n\r\nExample case: Nextcloud\r\nFOSS\r\n\r\nExample case: Nextcloud\r\n‚Ä¢ Users complain that sometimes they go on a trip and  Nextcloud drains their \r\nbattery. Users consider uninstalling the app when battery life is essential. \r\n‚Ä¢ File sync can be energy-greedy. Send large files to the server, long 3G/4G data connections. \r\n‚Ä¢ It is mostly used for backup. No real-time collaboration is needed. \r\n‚Ä¢ Energy requirements vary depending on context and user. Some days you really \r\nneed all the battery you can get. \r\n‚Ä¢ https://github.com/nextcloud/android/commit/\r\n8bc432027e0d33e8043cf40192203203a40ca29c\r\nSolutions?\r\n17\r\n\r\nExample case: K-9 mail\r\n18\r\n\r\nExample case: K-9 mail\r\n19\r\nSolutions?\r\n‚Ä¢ Some users noticed that K-9 mail was spending more energy than usual. üôâ \r\n‚Ä¢ A user that was having issues with a personal mail server  noticed that K-9 \r\nmail was the one of the most energy-greedy apps. IMAP IDLE protocol for real-time \r\nnotifications. \r\n‚Ä¢ When a connection is not possible, the app automatically retries later. \r\n‚Ä¢ https://github.com/k9mail/k-9/commit/\r\n86f3b28f79509d1a4d613eb39f60603e08579ea3\r\n\r\nEcoAndroid\r\n‚Ä¢ Plugin for IntelliJ (Android Studio) \r\n‚Ä¢ Dynamic Retry Delay \r\n‚Ä¢ Push Over Poll \r\n‚Ä¢ Reduce Size \r\n‚Ä¢ Cache \r\n‚Ä¢ Avoid Graphics and Animations\r\n20\r\n\r\nCarbon-Aware Computing for \r\nDatacenters \r\nhttps://sites.google.com/view/energy-efficiency-languages\r\n21\r\nAna Radovanovic ÃÅ, Ross Koningstein, Ian Schneider, Bokan \r\nChen, Alexandre Duarte, Binz Roy, Diyue Xiao, Maya \r\nHaridasan, Patrick Hung, Nick Care, Saurav Talukdar, Eric \r\nMullen, Kendal Smith, MariEllen Cottman, and Walfredo Cirne \r\n\r\n\r\n‚Ä¢ Google‚Äôs Carbon-Intelligent Computing System (CICS) \r\n‚Ä¢ Main idea: use carbon-intensity data to shift datacenter jobs in time \r\n‚Ä¢ Typically, job schedulers use a metric of cluster capacity to schedule a job in \r\na particular cluster. \r\n‚Ä¢ CICS overrides this metric with the virtual capacity curve (VCC) that \r\nfactors in Carbon intensity \r\n‚Ä¢ When a new job comes in, the scheduler estimates its CPU load and power \r\nusage and assigns it to a cluster if the VCC is not exceeded.\r\n23\r\n\r\n‚Ä¢ Jobs are divided between flexible and inflexible. \r\n‚Ä¢ Flexible load is considered shapeable/shiftable as long as its total daily \r\ncompute (CPU) demand is preserved \r\n‚Ä¢ The system needs to consider that, while running a job, the virtual capacity \r\ncurve (VCC) might drop. Hence, this job should not start in the first place. \r\n‚Ä¢ They forecast VCC for the next day\r\n24\r\n\r\n\r\nVirtual Cluster Capacity (VCC)\r\n‚Ä¢ Aims at reducing the peak load at carbon intensive hours but in total it should allow for the \r\nsome amount of daily computation!', ""Unless there‚Äôs a \r\ngood reason. \r\n‚Ä¢ E.g., somewhere amongst the 30 executions, \r\nthere might be 1 or 2 that failed to finish due \r\nto some unexpected error. \r\n‚Ä¢ (It happens and that‚Äôs ok!)‚Äì consequently, \r\nthe execution is shorter and spends less \r\nenergy ‚Äì falsely appearing as more \r\nenergy efficient. \r\n‚Ä¢ If data is not Normal there might be some \r\nissues affecting the measurements that \r\nmight be ruining results. It is important to \r\ninvestigate this.\r\n16\r\n\r\nEnergy data is not normal. Why?\r\n‚Ä¢ It might be caused by one of the following reasons: \r\n‚Ä¢ There was an error in some of the executions. If not detected and fixed it \r\nmight ruin results. \r\n‚Ä¢ Your tests are not fully replicable or are not deterministic. Quite frequent \r\nwhen you have internet requests or random-based algorithms. \r\n‚Ä¢ There is an unusual task being run by the system during some experiments. \r\n‚Ä¢ The computer entered a different power mode. \r\n‚Ä¢ External physical conditions have changed. E.g., someone opened a \r\nwindow.\r\n17\r\n\r\nEnergy data is not normal. How to fix?\r\n‚Ä¢ We have 2+1 options: \r\n1. Remove outliers. If there are only a few points that deviate from the normal \r\ndistribution, it is okay to simply remove them. \r\n‚Ä¢ Use the z-score outlier removal. (?) \r\n‚Ä¢ Remove all data points that deviate from the mean more than 3 standard \r\ndeviations: \r\n \r\n2. Fix the issue and rerun experiments. \r\n3. Conclude that nothing can be done about it and data will never be normal. (e.g., \r\nin AI, executions are rarely deterministic). ‚ö† Only after ruling out the previous \r\npoints.\r\n| ¬Øx ‚àíx| > 3s\r\n18\r\n\r\nHow do we know whether data is Normal?\r\n‚Ä¢ Visualise distribution shape: violin plots, histograms, density plot.\u2028\r\n \r\n‚Ä¢ Shapiro-Wilk test.\u2028\r\ndata is not normal;\u2028\r\nwe are not sure but it is okay to assume that data is \r\nnormal.\r\np-value < 0.05 ‚áí\r\np-value ‚â•0.05 ‚áí\r\n19\r\n\r\nAfter having all data ready, which artefact \r\nis more energy efficient(?) \r\nFirst approach: compare sample means. \r\n‚ö† assuming normal distribution\r\n\r\nStatistical significance\r\n‚Ä¢ Even if, on average, one artefact has lower \r\nenergy consumption than other,  it might be just \r\na random difference. \r\n‚Ä¢ When we extract a sample from a normal \r\ndistribution it will never be the exact same \r\n‚Ä¢ Statistical significance tests help you \r\nunderstand the differences in the average are \r\nconclusive/significant or inconclusive/\r\ninsignificant.\r\n21\r\n‚ö† assuming normal distribution\r\n\r\nStatistical significance test\r\n‚Ä¢ Two-sided parametric test Welch‚Äôs t-test. \r\n‚Ä¢ Less known alternative to student‚Äôs t-test.\r\n22\r\nWelch‚Äôs t-test in Python\r\nfrom scipy.stats import ttest_ind \r\n_,pvalue = ttest_ind(sample_a, sample_b, \r\n                     equal_var=False, \r\n                     alternative='two-sided')\r\n(?)\r\n‚ö† assuming normal distribution\r\n\r\nEffect Size analysis\r\n‚Ä¢ Now that we know that results are statistically significant we need to \r\nmeasure the difference between the two samples. \r\n‚Ä¢ Mean difference: \r\n \r\n‚Ä¢ Percent change: \r\n \r\n‚Ä¢ Cohen‚Äôs d (informal definition: mean difference normalized by a combined \r\nstandard deviation): \r\nŒî¬Øx\r\nxB ‚àíxA\r\nxA\r\n√ó 100 % = Œî¬Øx\r\nxA\r\n√ó 100 %\r\nŒî¬Øx\r\n1\r\n2\r\ns21 + s22\r\n23\r\n‚ö† assuming normal distribution\r\n\r\nImagine that version A spends 70J and \r\nversion B spends 69J with a \r\n."", 'google.com/view/energy-efficiency-languages\r\n21\r\nAna Radovanovic ÃÅ, Ross Koningstein, Ian Schneider, Bokan \r\nChen, Alexandre Duarte, Binz Roy, Diyue Xiao, Maya \r\nHaridasan, Patrick Hung, Nick Care, Saurav Talukdar, Eric \r\nMullen, Kendal Smith, MariEllen Cottman, and Walfredo Cirne \r\n\r\n\r\n‚Ä¢ Google‚Äôs Carbon-Intelligent Computing System (CICS) \r\n‚Ä¢ Main idea: use carbon-intensity data to shift datacenter jobs in time \r\n‚Ä¢ Typically, job schedulers use a metric of cluster capacity to schedule a job in \r\na particular cluster. \r\n‚Ä¢ CICS overrides this metric with the virtual capacity curve (VCC) that \r\nfactors in Carbon intensity \r\n‚Ä¢ When a new job comes in, the scheduler estimates its CPU load and power \r\nusage and assigns it to a cluster if the VCC is not exceeded.\r\n23\r\n\r\n‚Ä¢ Jobs are divided between flexible and inflexible. \r\n‚Ä¢ Flexible load is considered shapeable/shiftable as long as its total daily \r\ncompute (CPU) demand is preserved \r\n‚Ä¢ The system needs to consider that, while running a job, the virtual capacity \r\ncurve (VCC) might drop. Hence, this job should not start in the first place. \r\n‚Ä¢ They forecast VCC for the next day\r\n24\r\n\r\n\r\nVirtual Cluster Capacity (VCC)\r\n‚Ä¢ Aims at reducing the peak load at carbon intensive hours but in total it should allow for the \r\nsome amount of daily computation! \r\n‚Ä¢ Considers Carbon intensity \r\n‚Ä¢ Using data from electricityMap.org \r\n‚Ä¢ It does not use carbon intensity directly.\u2028\r\nCarbon intensity is converted to a cost (kgCO2 -> $$) \r\n‚Ä¢ This way, they can factor in other metrics that can also be converted to money. E.g., the \r\ncost saved by preventing peak load \r\n‚Ä¢ Peak workload entails extra cost at the infrastructure level (e.g., control faclities‚Äô \r\ntemperature). \r\n‚Ä¢ By using money cost instead of carbon cost, they have more data available.\r\n26\r\n\r\nVirtual Cluster Capacity (VCC)\r\n‚Ä¢ If the forecast of VCC fails it shift flexible workload more than expected.  \r\n‚Ä¢ This happens because the amount of workload forecasted was below the \r\nworkload needed, and VCC was ‚Äúaggressively‚Äù low. \r\n‚Ä¢ The systems fall back to the real cluster capacity for 1 week until results \r\nstart being realistic again.\r\n27\r\n\r\nNext steps\r\n‚Ä¢ They will consider spatial flexibility. \r\n‚Ä¢ I.e., tasks that can be shifted over time and over space. \r\n‚Ä¢ It needs to factor in relocation overheads, though.\r\n28\r\n\r\nCritical questions\r\n‚Ä¢ Who defines what is flexible and inflexible? \r\n‚Ä¢ How do you estimate the CPU load of a given task?\r\n29\r\n\r\nEnergy Regression Testing\r\n‚ÜíEnergy?\r\nGreener? Greener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\n\r\nE-compare\r\nGithub Actions\r\n‚ûú https://koenhagen.github.io/E-Compare/\r\n\r\nEnergy Regression Testing \r\n\r\n4. Debugging Energy with \r\nDocker Images\r\n\r\nUnveiling the Energy Vampires \r\nA methodology for debugging Software \r\nEnergy Consumption\r\n ‚úÖ ICSE 2025\r\n\r\nData Centers and Docker\r\n‚Ä¢ Containers are the most popular way to deploy apps into the cloud \r\n‚Ä¢ Base image is an important choice when building an image \r\n‚Ä¢ Criteria \r\n‚Ä¢ Linux distribution and binaries \r\n‚Ä¢ Image size \r\n‚Ä¢ Energy?\r\n35\r\n\r\nRedis energy consumption\r\n‚Ä¢ Ubuntu/Alpine base images have different energy consumption for Redis\r\n36\r\n\r\nRedis Energy Consumption\r\n‚Ä¢RQ1: What is the difference \r\nin energy consumption \r\nbetween glibc and musl? \r\n‚Ä¢RQ2: Can we use tracing \r\nto compare energy \r\nconsumption in shared \r\nlibraries?', ""‚Ä¢ 6 machine learning algorithms: SVM, Decision Tree, KNN, Random Forrest, \r\nAdaBoost, Bagging Classifier. \r\n‚Ä¢ Reduce the number of rows. 10%, 20%, .., 100% \r\n‚Ä¢ Stratified random sampling (?) \r\n‚Ä¢ Reduce the number of features. 10%, 20%, .., 100% \r\n‚Ä¢ Feature importance metric based on the Chi-Square Test (Chi2) \r\n‚Ä¢ Estimate energy consumption using a RAPL-based tool. (?)\r\n18\r\n\r\n‚Ä¢ Repeat 30 times \r\n‚Ä¢ Fix random seeds \r\n‚Ä¢ ‚Ä¶ \r\n‚Ä¢ Data was not Normal => tailed Normal distribution.\r\n19\r\n(?)\r\n\r\nResults: energy consumption of algorithms\r\n\r\nResults: energy vs data shape\r\n\r\nResults: performance vs data shape\r\n\r\nDiscussion\r\n‚Ä¢ Other data properties should be investigated. \r\n‚Ä¢ E.g., data types \r\n‚Ä¢ Reporting energy data is essential. It can lead to different model selection \r\nwithout hindering model performance. \r\n‚Ä¢ There is a big opportunity in Model and Data Simplification.\r\n23\r\n\r\nData/Model Simplification\r\n‚Ä¢ (?) \r\n‚Ä¢ Data selection \r\n‚Ä¢ Data quantisation. Posit? \r\n‚Ä¢ Data distillation \r\n‚Ä¢ Coreset extraction (?) \r\n‚Ä¢ Model distillation \r\n‚Ä¢ Model quantisation \r\n‚Ä¢ Model pruning \r\n‚Ä¢ ‚Ä¶\r\n24\r\n\r\nPosit vs Float\r\nMore about this: https://spectrum.ieee.org/floating-point-numbers-posits-processor\r\nBetter for DL use cases\r\n\r\nHow can we tune \r\nlearning \r\nparameters \r\nefficiently?\r\n\r\nHyper parameter tuning\r\n‚Ä¢ When training an ML model, there are several parameters that need to be \r\ntuned. \r\n‚Ä¢ E.g., in SVM we have the Regularization parameter C, the kernel function, \r\nthe degree of the kernel function, and depending on the case, many other. \r\n‚Ä¢ The common approach revolves around grid search. The user provides a \r\nsequence of possible values for each parameter and the pipeline runs all \r\npossible combinations. \r\n‚Ä¢ Our question: Can we save energy with alternative approaches? \r\n‚Ä¢ We studied Grid Search, Random Search and Bayesian \r\nOptimisation.\r\n27\r\nTim's MSc Thesis, 2022 \r\nAccepted at CAIN‚Äô23\r\n\r\n\r\nResults\r\n29\r\nConclusions? \r\n‚Ä¢ Bayesian converges faster. \r\n‚Ä¢ No clear winner between Grid and Random\r\n\r\nDeepSeekMoE\r\n30\r\nPreprint at ArXiv, 2024 https://arxiv.org/pdf/\r\n2401.06066\r\n\r\nMixture of Experts\r\n‚Ä¢ Llama3.1 has 405B parameters, DeepSeek V3 671B \r\n‚Ä¢ Yet DeepSeek has quicker inference times and claims less energy \r\nconsumption (?) \r\n‚Ä¢ Divide the model into smaller blocks of experts \r\n‚Ä¢ Tokens get routed to certain experts based on the query \r\n‚Ä¢ Only part of the network is active during inference \r\n‚Ä¢ DeepSeek claims only 37B out of 671B parameters get active\r\n31\r\n\r\nDeepSeekMoE\r\n32\r\n\r\nDeepSeekMoE\r\n33\r\n‚Ä¢ Comparable performance to \r\nLLaMA2 7B effectively using \r\nless half the parameters \r\n‚Ä¢ Less computational power \r\n‚Ä¢ Problems (?) \r\n‚Ä¢ Still need to load all the \r\nparameters \r\n‚Ä¢ High memory -> high \r\nembodied carbon\r\n\r\nGreen AI at FacebookMeta\r\n34\r\nSustainable AI: Environmental Implications, \r\nChallenges and Opportunities (2022)\r\n\r\nCarbon footprint mapped to the AI lifecycle\r\n‚Ä¢ There are 4 main overarching stages where carbon emissions need to be isolated: data \r\ncollection, experimentation, training, inference. \r\n‚Ä¢ At Facebook, recommendation systems split energy consumption evenly between \r\ntraining and inference; text translation models have a 35%/65% split. (Operational cost) \r\n‚Ä¢ Operational/embodied cost split: 30%/70%\r\n35\r\n\r\nOpen issues according to Meta\r\n‚Ä¢ A vast portion of projects only use GPUs at 30%.\u2028\r\nShould be higher to attenuate embodied carbon."", '‚Ä¢ Groundbreaking AI research is mostly done by tech giants.\r\n7\r\n\r\nA few examples of Red AI\r\n‚Ä¢ Google‚Äôs BERT-large \r\n‚Ä¢ 350 million features \r\n‚Ä¢ Trained for 2.5 days using 512 TPU chips, costing $60K+ \r\n‚Ä¢ Open-GPT3 (now GPT-4/o1) \r\n‚Ä¢ 550 tonnes CO2-eq (Patterson, 2021) \r\n‚Ä¢ 175 billion features \r\n‚Ä¢ API is open but no-pretrained model is available \r\n‚Ä¢ AlphaGo \r\n‚Ä¢ 1920 CPUs, 280 GPUs, costing $35M\r\n8\r\n\r\nRed AI in Large Language Models (LLMs)\r\n‚Ä¢ OPT by Meta reports 75 tons CO2-eq (1/7 of OpenGPT‚Äôs footprint).\u2028\r\n(Also 175billion params) \r\n‚Ä¢ However, Llama 3 reported 2,290 tons of CO2-eq (7.7M GPU hours \r\ntraining ) \r\n‚Ä¢ Open science: release includes both the pretrained models and the code \r\nneeded to train and use them. \r\n‚Ä¢ DeepSeek-V3 claims ‚Äúonly‚Äù 2.78M GPU hours \r\n‚Ä¢ Bloom by Huggingface reports 25 tons, 51 when considering embodied \r\nand operational carbon footprint. (176billion params)\r\n9\r\n\r\nRed AI\r\nAccuracy: 0.999999999\r\nGreen AI\r\n‚Ä¢ Energy \r\n‚Ä¢ Time \r\n‚Ä¢ Reproducibility \r\n‚Ä¢ Reusage\r\n\r\nHow can we adopt Green AI\r\n‚Ä¢ Check whether AI is needed. \r\n‚Ä¢ Select green datacenters. \r\n‚Ä¢ Run on low carbon intensity hours. \r\n‚Ä¢ Opt for GPU-optimised solutions (?) \r\n‚Ä¢ Opt for low-power hardware (e.g., Nvidia Jetson boards) \r\n‚Ä¢ Or GPUs that provide energy metrics (e.g., NVIDIA GPUs via the nvidia-smi tool) \r\n‚Ä¢ Report energy/carbon metrics (e.g., embed in MLFlow?) \r\n‚Ä¢ Use pre-trained models (Transfer Learning) \r\n‚Ä¢ Preprocess dataset to reduce size. \r\n‚Ä¢ Improve parameter-tuning strategy.\r\n11\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ We need benchmarks. \r\n‚Ä¢ AllenAI leaderboard\u2028\r\nhttps://leaderboard.allenai.org \r\n‚Ä¢ No carbon metrics, yet \r\n‚Ä¢ Report comparable proxies for energy \r\nconsumption. \r\n‚Ä¢ ‚ö† Learning algorithms behave in a non-\r\ndeterministic \r\n‚Ä¢ ‚ö† Different data-points lead to different \r\nenergy consumption\r\n12\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ Reporting measured energy consumption \r\n‚Ä¢ + Accurate \r\n‚Ä¢ + Easy to map to carbon emissions \r\n‚Ä¢ - Hard to measure \r\n‚Ä¢ - Low replicability \r\n‚Ä¢ Reporting time / estimation based on time & hardware \r\n‚Ä¢ + Easy to measure \r\n‚Ä¢ + Correlates with energy consumption in most cases. \r\n‚Ä¢ -  Difficult to compare with measurements from other setups \r\n‚Ä¢ E.g., floating point operations (FPOs) (?) \r\n‚Ä¢ + comparable across different setups \r\n‚Ä¢ + cheap \r\n‚Ä¢ - does not factor in memory energy consumption \r\n‚Ä¢ - does not reflect carbon emissions\r\n13\r\n\r\nData-centric AI\r\n\r\nData-centric AI\r\n‚Ä¢ Emerging discipline that deals with systematically engineering data to build AI \r\nsystems. \r\n‚Ä¢ Shift from improving the training strategy to improving the data. \r\n‚Ä¢ It is better to have small but reliable datasets than large but noisy \r\ndatasets. \r\n‚Ä¢ => Improve data collection, data labelling, and data preprocessing. \r\n‚Ä¢ More about data-centric AI by Andrew Ng:\u2028\r\nhttps://www.youtube.com/watch?v=06-AZXmwHjo\r\n15\r\n\r\n\r\nGreen Data-centric AI\r\n‚Ä¢ How do different ML algorithms compare \r\nin terms of energy consumption? \r\n‚Ä¢ How does number of rows relate to the \r\nenergy consumption of ML models? \r\n‚Ä¢ How does number of features relate to \r\nthe energy consumption of ML models? \r\n‚Ä¢ What is the impact of reducing data in the \r\nperformance of the model?', '‚Ä¢ By using money cost instead of carbon cost, they have more data available.\r\n26\r\n\r\nVirtual Cluster Capacity (VCC)\r\n‚Ä¢ If the forecast of VCC fails it shift flexible workload more than expected.  \r\n‚Ä¢ This happens because the amount of workload forecasted was below the \r\nworkload needed, and VCC was ‚Äúaggressively‚Äù low. \r\n‚Ä¢ The systems fall back to the real cluster capacity for 1 week until results \r\nstart being realistic again.\r\n27\r\n\r\nNext steps\r\n‚Ä¢ They will consider spatial flexibility. \r\n‚Ä¢ I.e., tasks that can be shifted over time and over space. \r\n‚Ä¢ It needs to factor in relocation overheads, though.\r\n28\r\n\r\nCritical questions\r\n‚Ä¢ Who defines what is flexible and inflexible? \r\n‚Ä¢ How do you estimate the CPU load of a given task?\r\n29\r\n\r\nEnergy Regression Testing\r\n‚ÜíEnergy?\r\nGreener? Greener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\n\r\nE-compare\r\nGithub Actions\r\n‚ûú https://koenhagen.github.io/E-Compare/\r\n\r\nEnergy Regression Testing \r\n\r\n4. Debugging Energy with \r\nDocker Images\r\n\r\nUnveiling the Energy Vampires \r\nA methodology for debugging Software \r\nEnergy Consumption\r\n ‚úÖ ICSE 2025\r\n\r\nData Centers and Docker\r\n‚Ä¢ Containers are the most popular way to deploy apps into the cloud \r\n‚Ä¢ Base image is an important choice when building an image \r\n‚Ä¢ Criteria \r\n‚Ä¢ Linux distribution and binaries \r\n‚Ä¢ Image size \r\n‚Ä¢ Energy?\r\n35\r\n\r\nRedis energy consumption\r\n‚Ä¢ Ubuntu/Alpine base images have different energy consumption for Redis\r\n36\r\n\r\nRedis Energy Consumption\r\n‚Ä¢RQ1: What is the difference \r\nin energy consumption \r\nbetween glibc and musl? \r\n‚Ä¢RQ2: Can we use tracing \r\nto compare energy \r\nconsumption in shared \r\nlibraries? \r\n‚Ä¢RQ3: Can we verify the \r\norigin of energy \r\nconsumption differences by \r\nrecreating the workload \r\nbehavior closely?\r\n37\r\n\r\nTracing\r\n‚Ä¢ Find libc function running at the end of the benchmark \r\n‚Ä¢ Tracing: Capture calls made to libc \r\n‚Ä¢ Introduces non-linear overhead\r\n38\r\n\r\nSynchronization\r\n‚Ä¢ Tracing slows down execution and increase energy consumption \r\n‚Ä¢ Run separately and synchronize with logs\r\n39\r\n\r\nTracing Analysis\r\n40\r\n\r\nTracing Analysis\r\n41\r\n\r\nBenchmarking memcpy\r\n‚Ä¢ Copy bytes from one part of memory to \r\nanother \r\n‚Ä¢ Depending on function parameters, different \r\nassembly-level optimizations \r\n‚Ä¢ Some not included in musl\r\n42\r\n\r\nBenchmarking memcpy\r\n‚Ä¢ Copy 4 bytes from fixed \r\npointer to moving pointer \r\n‚Ä¢ (100,300,500,600) x 1M \r\nrequests \r\n‚Ä¢  15% more power and 3X time\r\n43\r\n\r\nConclusions\r\n‚Ä¢ Significant difference in energy consumption for memcpy \r\n‚Ä¢ 8.6% difference for Redis workload and 13% in our benchmark \r\n‚Ä¢ musl trades performance for a smaller codebase \r\n‚Ä¢ No official documentation \r\n‚Ä¢ No awareness about energy performance\r\n44\r\n\r\n5. Energy Efficiency vs Code \r\nQuality\r\n\r\nMeasuring Maintainability\r\n‚Ä¢ According to ISO/IEC 25010, Maintainability is ‚Äúthe degree of \r\neffectiveness and efficiency with which a software product or \r\nsystem can be modified to improve it, correct it or adapt it to \r\nchanges in environment, and in requirements‚Äù \r\n‚Ä¢ We use the code analysis tool Better Code Hub to assess \r\nmaintainability \r\n‚Ä¢ Better Code Hub maps the ISO/IEC 25010 standard on \r\nmaintainability into a set of guidelines derived from static analysis\r\n46\r\n\r\nMaintainability of Energy Changes\r\n‚Ä¢ What is the impact of making energy-oriented code changes on \r\nthe maintainability of mobile apps?', '‚Ä¢ Improve parameter-tuning strategy.\r\n11\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ We need benchmarks. \r\n‚Ä¢ AllenAI leaderboard\u2028\r\nhttps://leaderboard.allenai.org \r\n‚Ä¢ No carbon metrics, yet \r\n‚Ä¢ Report comparable proxies for energy \r\nconsumption. \r\n‚Ä¢ ‚ö† Learning algorithms behave in a non-\r\ndeterministic \r\n‚Ä¢ ‚ö† Different data-points lead to different \r\nenergy consumption\r\n12\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ Reporting measured energy consumption \r\n‚Ä¢ + Accurate \r\n‚Ä¢ + Easy to map to carbon emissions \r\n‚Ä¢ - Hard to measure \r\n‚Ä¢ - Low replicability \r\n‚Ä¢ Reporting time / estimation based on time & hardware \r\n‚Ä¢ + Easy to measure \r\n‚Ä¢ + Correlates with energy consumption in most cases. \r\n‚Ä¢ -  Difficult to compare with measurements from other setups \r\n‚Ä¢ E.g., floating point operations (FPOs) (?) \r\n‚Ä¢ + comparable across different setups \r\n‚Ä¢ + cheap \r\n‚Ä¢ - does not factor in memory energy consumption \r\n‚Ä¢ - does not reflect carbon emissions\r\n13\r\n\r\nData-centric AI\r\n\r\nData-centric AI\r\n‚Ä¢ Emerging discipline that deals with systematically engineering data to build AI \r\nsystems. \r\n‚Ä¢ Shift from improving the training strategy to improving the data. \r\n‚Ä¢ It is better to have small but reliable datasets than large but noisy \r\ndatasets. \r\n‚Ä¢ => Improve data collection, data labelling, and data preprocessing. \r\n‚Ä¢ More about data-centric AI by Andrew Ng:\u2028\r\nhttps://www.youtube.com/watch?v=06-AZXmwHjo\r\n15\r\n\r\n\r\nGreen Data-centric AI\r\n‚Ä¢ How do different ML algorithms compare \r\nin terms of energy consumption? \r\n‚Ä¢ How does number of rows relate to the \r\nenergy consumption of ML models? \r\n‚Ä¢ How does number of features relate to \r\nthe energy consumption of ML models? \r\n‚Ä¢ What is the impact of reducing data in the \r\nperformance of the model? \r\n‚Ä¢ Method -> results -> discussion\r\n17\r\n\r\nMethod\r\n‚Ä¢ Single object of study: natural language model to detect spam messages. \r\n‚Ä¢ 6 machine learning algorithms: SVM, Decision Tree, KNN, Random Forrest, \r\nAdaBoost, Bagging Classifier. \r\n‚Ä¢ Reduce the number of rows. 10%, 20%, .., 100% \r\n‚Ä¢ Stratified random sampling (?) \r\n‚Ä¢ Reduce the number of features. 10%, 20%, .., 100% \r\n‚Ä¢ Feature importance metric based on the Chi-Square Test (Chi2) \r\n‚Ä¢ Estimate energy consumption using a RAPL-based tool. (?)\r\n18\r\n\r\n‚Ä¢ Repeat 30 times \r\n‚Ä¢ Fix random seeds \r\n‚Ä¢ ‚Ä¶ \r\n‚Ä¢ Data was not Normal => tailed Normal distribution.\r\n19\r\n(?)\r\n\r\nResults: energy consumption of algorithms\r\n\r\nResults: energy vs data shape\r\n\r\nResults: performance vs data shape\r\n\r\nDiscussion\r\n‚Ä¢ Other data properties should be investigated. \r\n‚Ä¢ E.g., data types \r\n‚Ä¢ Reporting energy data is essential. It can lead to different model selection \r\nwithout hindering model performance. \r\n‚Ä¢ There is a big opportunity in Model and Data Simplification.\r\n23\r\n\r\nData/Model Simplification\r\n‚Ä¢ (?) \r\n‚Ä¢ Data selection \r\n‚Ä¢ Data quantisation. Posit? \r\n‚Ä¢ Data distillation \r\n‚Ä¢ Coreset extraction (?) \r\n‚Ä¢ Model distillation \r\n‚Ä¢ Model quantisation \r\n‚Ä¢ Model pruning \r\n‚Ä¢ ‚Ä¶\r\n24\r\n\r\nPosit vs Float\r\nMore about this: https://spectrum.ieee.org/floating-point-numbers-posits-processor\r\nBetter for DL use cases\r\n\r\nHow can we tune \r\nlearning \r\nparameters \r\nefficiently?\r\n\r\nHyper parameter tuning\r\n‚Ä¢ When training an ML model, there are several parameters that need to be \r\ntuned. \r\n‚Ä¢ E.g., in SVM we have the Regularization parameter C, the kernel function, \r\nthe degree of the kernel function, and depending on the case, many other. \r\n‚Ä¢ The common approach revolves around grid search.', '8. Green AI\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nLu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\nCarolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl\r\n\r\n- Overview of Green AI \r\n- Large language models \r\n- Green data-centric AI \r\n- Model simplification \r\n- Hyper parameter tuning \r\n- Mixture of Experts and DeepSeek \r\n- Green AI at Meta \r\n\r\nAI\r\n‚Ä¢ Artificial Intelligence (AI) is the branch of computer science that deals with \r\nautomating tasks that typically require human intelligence. \r\n‚Ä¢ In the past years AI has been widely applied across different domains.\u2028\r\nE.g., health care, transportation, finance. \r\n‚Ä¢ To deploy AI systems, we test them against benchmarks (or validation sets). \r\n‚Ä¢ The goal is to outperform the previous existing models. \r\n‚Ä¢ E.g., in Machine Learning we usually resort to accuracy metrics. The \r\nhighest the accuracy, the better the model.\r\n3\r\n\r\nSince 2012, the amount of computing used for AI \r\ntraining has been doubling every 6 months\r\n‚Ä¢ https://epoch.ai/blog/compute-trends\r\n4\r\n\r\n‚Ä¢ To create better AI systems we are currently adding \r\n‚Ä¢ More data \r\n‚Ä¢ More experiments \r\n‚Ä¢ Larger models\r\n5\r\n\r\nThe Equation of Red AI\r\nCost(R) ‚àùE¬∑D¬∑H\r\nCost of a single (E)xample\r\nSize of (D)ataset\r\nNumber of (H)yperparameters\r\nBy Schwartz et al. (2020)\r\n\r\nIssues of Red AI\r\n‚Ä¢ High costs (hardware, electricity, data access, etc.) \r\n‚Ä¢ Limited reproducibility.  \r\n‚Ä¢ Energy consumption. \r\n‚Ä¢ Carbon emissions. \r\n‚Ä¢ SMEs can hardly be competitive. \r\n‚Ä¢ Groundbreaking AI research is mostly done by tech giants.\r\n7\r\n\r\nA few examples of Red AI\r\n‚Ä¢ Google‚Äôs BERT-large \r\n‚Ä¢ 350 million features \r\n‚Ä¢ Trained for 2.5 days using 512 TPU chips, costing $60K+ \r\n‚Ä¢ Open-GPT3 (now GPT-4/o1) \r\n‚Ä¢ 550 tonnes CO2-eq (Patterson, 2021) \r\n‚Ä¢ 175 billion features \r\n‚Ä¢ API is open but no-pretrained model is available \r\n‚Ä¢ AlphaGo \r\n‚Ä¢ 1920 CPUs, 280 GPUs, costing $35M\r\n8\r\n\r\nRed AI in Large Language Models (LLMs)\r\n‚Ä¢ OPT by Meta reports 75 tons CO2-eq (1/7 of OpenGPT‚Äôs footprint).\u2028\r\n(Also 175billion params) \r\n‚Ä¢ However, Llama 3 reported 2,290 tons of CO2-eq (7.7M GPU hours \r\ntraining ) \r\n‚Ä¢ Open science: release includes both the pretrained models and the code \r\nneeded to train and use them. \r\n‚Ä¢ DeepSeek-V3 claims ‚Äúonly‚Äù 2.78M GPU hours \r\n‚Ä¢ Bloom by Huggingface reports 25 tons, 51 when considering embodied \r\nand operational carbon footprint. (176billion params)\r\n9\r\n\r\nRed AI\r\nAccuracy: 0.999999999\r\nGreen AI\r\n‚Ä¢ Energy \r\n‚Ä¢ Time \r\n‚Ä¢ Reproducibility \r\n‚Ä¢ Reusage\r\n\r\nHow can we adopt Green AI\r\n‚Ä¢ Check whether AI is needed. \r\n‚Ä¢ Select green datacenters. \r\n‚Ä¢ Run on low carbon intensity hours. \r\n‚Ä¢ Opt for GPU-optimised solutions (?) \r\n‚Ä¢ Opt for low-power hardware (e.g., Nvidia Jetson boards) \r\n‚Ä¢ Or GPUs that provide energy metrics (e.g., NVIDIA GPUs via the nvidia-smi tool) \r\n‚Ä¢ Report energy/carbon metrics (e.g., embed in MLFlow?)', 'Interviews?) & rich \r\ndescription of outcomes focus of grading\r\nhttps://eip.pages.ewi.tudelft.nl/eip-website/queue.html\r\n\r\nC1. Compare energy consumption of docker images for \r\nML workloads.\r\n‚Ä¢ Similar to what we have seen in the lectures but for ML-specific workloads. \r\n‚Ä¢ We can reuse existing experiment replication packages.\r\n22\r\n\r\nC2. Plugin to visualize Hugging Face carbon emissions.\r\n‚Ä¢ https://huggingface.co/blog/leaderboard-emissions-\r\nanalysis \r\n‚Ä¢\r\nYoo, Taewon, et al. ""Visualizing the Carbon Intensity of Machine Learning Inference for Image Analysis on TensorFlow Hub.""\r\n\r\nC3. Plugin for ChatGPT\r\n‚Ä¢ Users seldom know how much carbon they are emitting when they interact \r\nwith chat GPT. \r\n‚Ä¢ Let‚Äôs make it transparent to the users. Browser plugin?\r\n24\r\nCO2\r\n\r\nC4. NutriScore for software libraries\r\n25\r\n‚Ä¢ NutriScore labels are not perfect but they are a good starting point! \r\n‚Ä¢ What if we could do the same thing for the energy efficiency of software. \r\n‚Ä¢ (Also open to individual or social sustainability) \r\n‚Ä¢ This work can be scoped in particular domains/ecossystems/use cases. \r\n‚Ä¢ Libraries for stats? ML? Web Dev? Cloud?\r\n\r\nC5. Add energy-awareness to existing software\r\n26\r\n‚Ä¢ Streamlit, Notebooks, JSFiddle, \r\nPyScript, zsh, etc. \r\n‚Ä¢\r\n\r\nC6 - Green Shift Left\r\n‚Ä¢ Estimate energy efficiency using static code analysis. \r\n‚Ä¢ We don‚Äôt need an accurate value. \r\n‚Ä¢ It is useful to know which code is more likely to \r\nintroduce energy hotspots and that should be \r\nreviewed with more attention. \r\n‚Ä¢ Can be scoped to a particular domain (react, php, data \r\nscience, web, etc., etc.)\r\n27\r\n\r\nC7 - Education\r\n‚Ä¢ Educational game for Software \r\nSustainability practices \r\n‚Ä¢ Purpose: use within software teams to \r\ndiscuss or learn about different sustainable \r\nIT practices: at the organisation level, \r\nsoftware, etc.\r\n28\r\nhttps://github.com/OttoKaaij/Ticket-To-Sustainability/?tab=readme-ov-file\r\n\r\nProject ideas (old)\r\n‚Ä¢ Plugin from EnergiBridge (GUI, report generator, python library, etc.) \r\n‚Ä¢ Plugin for ChatGPT (carbon emissions per chat window) \r\n‚Ä¢ Seamless measurements for AI libraries \r\n‚Ä¢ Energy patterns for Green AI \r\n‚Ä¢ Sustainable SW dev gamification \r\n‚Ä¢ Sustainability auditor for AI projects \r\n‚Ä¢ Energy Profiling of screen colour filter tools (or display settings) \r\n‚Ä¢ ‚Ä¶ you can also propose yours!\r\n\r\nhttps://edu.nl/64gpk\r\nedu.nl/64gpk', '5. Green Software Metrics\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nLu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\nCarolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl\r\nSustainableSE 2025\r\n\r\nBitcoin example\r\n‚Ä¢ 1 bitcoin transaction is equivalent to more than 1.5 million VISA transactions. \r\n \r\n   \r\n \r\n‚Ä¢ Day-to-day metrics are easy to grasp \r\n‚Ä¢ If we say 8 gigajoules, it‚Äôs a bit more difficult to understand. \r\n‚Ä¢ These numbers keep changing (check it here: https://www.statista.com/\r\nstatistics/881541/bitcoin-energy-consumption-transaction-comparison-visa/)\r\n2\r\n\r\n3\r\n\r\n(Electrical) Energy\r\n‚Ä¢ Work required to move charged particles. \r\n‚Ä¢ Same concept but different perspective when talking about thermal, \r\nmechanical, or nuclear energy. \r\n‚Ä¢ Most common units: \r\n‚Ä¢ joule (J) -  recommended; scientific communications; metric from the \r\nInternational System of Units \r\n‚Ä¢ kilowatt-hour (kWh) - more common, e.g., used for household electricity \r\nconsumption\r\n4\r\n+q\r\n-q\r\nF\r\nF\r\n\r\nPower\r\n‚Ä¢ Amount of work being done per unit of time. \r\n‚Ä¢ Commonly measured in watts (W).\r\n5\r\n\r\n‚à´\r\ntf=9\r\nti=1\r\nP(t)dt\r\n\r\n‚à´\r\ntf=9\r\nti=1\r\nP(t)dt\r\n\r\nA = a + b\r\n2\r\nh\r\nMeasured Energy \r\nConsumption\r\n=\r\nPtn + Ptn+1\r\n2\r\n‚ãÖŒît = 3.5W + 2.0W\r\n2\r\n‚ãÖ1s = 2.75J\r\nA = ?\r\na\r\nb\r\nh\r\n\r\n‚à´\r\ntn\r\nt0\r\nP(t)dt ‚âàŒît\r\n2 [P(t0) + 2P(t1) + 2P(t2) + . . . + 2P(tn‚àí1) + P(tn)]\r\nMeasured Energy \r\nConsumption\r\n‚ö† Sometimes you cannot assume that the sampling interval (\r\n) is always the same. ‚ö†\r\nŒît\r\nTrapezoid Rule\r\n\r\nTrapezoid Rule in Python\r\nimport numpy as np \r\nenergy_consumption = np.trapz(power_sample, timestamps) \r\n\r\nAverage power\r\n‚Ä¢ Easy to convert to energy consumption \r\n‚Ä¢ Simply multiply by the elapsed time. \r\n‚Ä¢ (This is another reason to always collect time data along with energy \r\nmetrics.)\r\n11\r\nEnergy = Pavg¬∑Œît\r\n\r\nPower or Energy?\r\n‚Ä¢ Average power consumption makes sense when we report the \r\nconsumption of a continuous use case. E.g., reading an ebook in your \r\ncomputer. \r\n‚Ä¢ Energy consumption makes sense in one-off use cases. E.g., energy \r\nconsumption of a bitcoin transaction. \r\n‚ö†\r\n\r\nLearning activity\r\n‚Ä¢ Pair up with one colleague and discuss potential software use cases where \r\none should test energy efficiency. \r\n‚Ä¢ Choose one use case where energy consumption is the best metric to \r\ndiscuss/test energy efficiency. \r\n‚Ä¢ Choose one use case where average power consumption is the best \r\nmetric to discuss/test energy efficiency.\r\n13\r\n\r\nEnergy Delay Product (EDP)\r\n‚Ä¢ In some cases, to achieve less energy consumption, one simply runs the \r\nsoftware on a low power mode of the CPU. \r\n‚Ä¢ E.g., setting the CPU at a low frequency will make execution slow but more \r\nenergy-efficient. \r\n‚Ä¢ Energy consumption metric that penalizes slow runs \r\n \r\n \r\n‚Ä¢ Gives more importance to application runtime, with the goal of making both \r\nlow energy and fast runtime applications.', ""‚Ä¢ Visualise distribution shape: violin plots, histograms, density plot.\u2028\r\n \r\n‚Ä¢ Shapiro-Wilk test.\u2028\r\ndata is not normal;\u2028\r\nwe are not sure but it is okay to assume that data is \r\nnormal.\r\np-value < 0.05 ‚áí\r\np-value ‚â•0.05 ‚áí\r\n19\r\n\r\nAfter having all data ready, which artefact \r\nis more energy efficient(?) \r\nFirst approach: compare sample means. \r\n‚ö† assuming normal distribution\r\n\r\nStatistical significance\r\n‚Ä¢ Even if, on average, one artefact has lower \r\nenergy consumption than other,  it might be just \r\na random difference. \r\n‚Ä¢ When we extract a sample from a normal \r\ndistribution it will never be the exact same \r\n‚Ä¢ Statistical significance tests help you \r\nunderstand the differences in the average are \r\nconclusive/significant or inconclusive/\r\ninsignificant.\r\n21\r\n‚ö† assuming normal distribution\r\n\r\nStatistical significance test\r\n‚Ä¢ Two-sided parametric test Welch‚Äôs t-test. \r\n‚Ä¢ Less known alternative to student‚Äôs t-test.\r\n22\r\nWelch‚Äôs t-test in Python\r\nfrom scipy.stats import ttest_ind \r\n_,pvalue = ttest_ind(sample_a, sample_b, \r\n                     equal_var=False, \r\n                     alternative='two-sided')\r\n(?)\r\n‚ö† assuming normal distribution\r\n\r\nEffect Size analysis\r\n‚Ä¢ Now that we know that results are statistically significant we need to \r\nmeasure the difference between the two samples. \r\n‚Ä¢ Mean difference: \r\n \r\n‚Ä¢ Percent change: \r\n \r\n‚Ä¢ Cohen‚Äôs d (informal definition: mean difference normalized by a combined \r\nstandard deviation): \r\nŒî¬Øx\r\nxB ‚àíxA\r\nxA\r\n√ó 100 % = Œî¬Øx\r\nxA\r\n√ó 100 %\r\nŒî¬Øx\r\n1\r\n2\r\ns21 + s22\r\n23\r\n‚ö† assuming normal distribution\r\n\r\nImagine that version A spends 70J and \r\nversion B spends 69J with a \r\n.\r\np-value = 0.04\r\nOn average, version B spent less energy than version A  ‚Äî  ‚úÖ \r\nThere is statistical significance ‚Äî  ‚úÖ \r\nEffect size, percent-change is ‚âà1% ‚Äî ü§î \r\n‚ö† Do we care?\r\n(?)\r\n\r\nPractical Significance\r\n‚Ä¢ Depending on the case, a 2% improvement might be either wonderful or completely \r\nuseless. \r\n‚Ä¢ Effect size analyses help assess practical significance but might not be enough. \r\n‚Ä¢ A critical discussion always needs to be performed. Consider context and explain in what \r\nsense the effect size might be relevant. \r\n‚Ä¢ E.g.: \r\n‚Ä¢  to improve 2% in energy efficiency the code will be less readable or the user \r\nexperience is not so appealing. \r\n‚Ä¢ A particular method improves 2% but it will only be used 1% of the time. \r\n‚Ä¢ There is no particular metric or structure, but this kind of critical analysis is very important.\r\n25\r\n\r\nWhat if data is not Normal?\r\nSame approach but different tests/metrics!\r\n\r\nNon-normal data\r\n‚Ä¢ Statistical significance: non-parametric test (?) \r\n‚Ä¢ Mann-Whitney U test. Instead of looking at standard deviation or mean, it orders \r\nsamples and compares with each other. \r\n‚Ä¢ Less power than parametric-tests (?) \r\n‚Ä¢ Effect size \r\n‚Ä¢ Median difference: \r\n \r\n‚Ä¢ Percentage of pairs supporting a conclusion\u2028\r\n(i.e., # pairs where version A > version B/ total pairs) \r\n‚Ä¢ Common language effect size: \r\nŒîM\r\nU1\r\nN1N2\r\n27\r\n\r\nRecap\r\nImpossible to \r\nfix but \r\nexplainable."", '27\r\n\r\nCarbon intensity\r\n‚Ä¢ How much carbon is emitted per kWh of electricity consumed. \r\n‚Ä¢ The common unit: \r\n ü§∑ \r\n‚Ä¢ E.g.,  gas-based power plants emit less carbon than coal-based plants. \r\n‚Ä¢ The power grid is a mix between different sources of electricity ‚Äì different \r\nlocations have different carbon intensity.\r\ngCO2eq/kWh\r\n28\r\n\r\nhttps://app.electricitymaps.com/map\r\n\r\nBy Asim Hussain: https://principles.green/principles/carbon-intensity/\r\nüìù Reducing software energy consumption can help reduce the carbon intensity. Why?\r\n\r\nOne would expect zero carbon intensity from solar-\r\npanels or wind farms, but that‚Äôs not the case.\r\n‚ö†\r\n?\r\n\r\nMarginal Power Plant\r\n‚Ä¢ Renewable-based power plants cannot adapt to demand. \r\n‚Ä¢ When demand is higher than the existing power in the electricity grid, we \r\nneed a power plant that is able to scale up to that demand. \r\n‚Ä¢ This is usually done by fossil-based power plants. They are called the \r\nmarginal power plants. \r\n‚Ä¢ The problem is that marginal power plants do not scale down to zero. \r\n‚Ä¢ There is always a minimum carbon that needs to be emitted, even if there is \r\na lot of renewable energy in the grid.\r\n32\r\n\r\nBy Asim Hussain: https://principles.green/principles/carbon-intensity/\r\nHow could we fix this?\r\nWhat‚Äôs the problem here?\r\n\r\nMarginal Carbon Intensity\r\n‚Ä¢ Increase or decrease in carbon emissions in the electrical grid, in response \r\nto an infinitesimal increase/decrease in power demand/supply.\r\n\r\nFrom: ‚ÄúLiterature Review: On the effectiveness of a Marginal Carbon Intensity Signal ‚Äú\r\n\r\nWhy is marginal carbon intensity \r\nrelevant for software?\r\n‚Ä¢ Tip: consider a task scheduler in a datacenter.\r\n\r\nRecap\r\n‚Ä¢ Power \r\n‚Ä¢ Energy \r\n‚Ä¢ Average Power \r\n‚Ä¢ Energy Delay Product \r\n‚Ä¢ Electric charge (battery capacity) \r\n‚Ä¢ Carbon dioxide equivalent (carbon emissions) \r\n‚Ä¢ 100-global-warming potential \r\n‚Ä¢ Carbon Intensity \r\n‚Ä¢ Marginal Carbon Intensity\r\n37\r\n?\r\n\r\nFurther Reading\r\n‚Ä¢ Blog post on energy units:\u2028\r\nhttps://luiscruz.github.io/2023/05/13/energy-units.html \r\n38\r\n?', 'Energy profiling of static analysis tools\r\n‚Ä¢ What is the energy consumption of a ""typical run"" for a few OSS projects? \r\n‚Ä¢ Does the type of analysis matter? Are certain analysis more expensive? Does \r\nthe number of rules that are activated in a static analysis tool important for the \r\nenergy consumption? \r\n‚Ä¢ Differences between static analysis tools [lower priority]\r\n\r\nB5. Tool supporting SusAF workshop / process\r\n‚Ä¢ Lead engineers through process & questions \r\n‚Ä¢ Interface to create & document the two diagrams \r\n‚Ä¢ (!) Should be easy to start using & set up \r\n‚Ä¢ You may also create a simplified version / \u2028\r\nyour favorite sustainability framework\r\nEnvironmental\r\nEconomic\r\nTechnical\r\nIndividual\r\nSocial\r\nImmediate\r\nEnabling\r\nStructural\r\nAirbnb\r\ngreater \r\nearnings\r\nincrease \r\nin rents\r\ngentrification\r\ngreater racial \r\ndisparities\r\nrent \r\nrooms\r\n5\r\n1\r\n3\r\n4\r\n2\r\n \r\n \r\n \r\n \r\n \r\n \r\nVery \r\nunlikely \r\nVery \r\nlikely \r\n\r\nB6. Dataset of government-developed OS software\r\n‚Ä¢ Governments develop & use software for supporting society\u2028\r\nOpen-source development & policies are on the rise \r\n‚Ä¢ But studying government software is difficult b/c we don‚Äôt know what is out \r\nthere\u2028\r\n‚Üí Lack of incentive to make popular \u2028\r\n‚Üí Language barriers \r\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \r\nbuildable?, open dev. history?, requirements documentation? \r\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!\r\n\r\nB7. Queue - but better for the student / TA society\r\n‚Ä¢ Requirements analysis regarding social and individual sustainability effects \r\nof Queue \r\n‚Ä¢ Other EIP / TUD used software also possible: e.g., Answers EWI \r\n‚Ä¢ Non-technical project ‚Üí proper process (workshops? Interviews?) & rich \r\ndescription of outcomes focus of grading\r\nhttps://eip.pages.ewi.tudelft.nl/eip-website/queue.html\r\n\r\nC1. Compare energy consumption of docker images for \r\nML workloads.\r\n‚Ä¢ Similar to what we have seen in the lectures but for ML-specific workloads. \r\n‚Ä¢ We can reuse existing experiment replication packages.\r\n22\r\n\r\nC2. Plugin to visualize Hugging Face carbon emissions.\r\n‚Ä¢ https://huggingface.co/blog/leaderboard-emissions-\r\nanalysis \r\n‚Ä¢\r\nYoo, Taewon, et al. ""Visualizing the Carbon Intensity of Machine Learning Inference for Image Analysis on TensorFlow Hub.""\r\n\r\nC3. Plugin for ChatGPT\r\n‚Ä¢ Users seldom know how much carbon they are emitting when they interact \r\nwith chat GPT. \r\n‚Ä¢ Let‚Äôs make it transparent to the users. Browser plugin?\r\n24\r\nCO2\r\n\r\nC4. NutriScore for software libraries\r\n25\r\n‚Ä¢ NutriScore labels are not perfect but they are a good starting point! \r\n‚Ä¢ What if we could do the same thing for the energy efficiency of software. \r\n‚Ä¢ (Also open to individual or social sustainability) \r\n‚Ä¢ This work can be scoped in particular domains/ecossystems/use cases. \r\n‚Ä¢ Libraries for stats? ML? Web Dev? Cloud?\r\n\r\nC5. Add energy-awareness to existing software\r\n26\r\n‚Ä¢ Streamlit, Notebooks, JSFiddle, \r\nPyScript, zsh, etc. \r\n‚Ä¢\r\n\r\nC6 - Green Shift Left\r\n‚Ä¢ Estimate energy efficiency using static code analysis. \r\n‚Ä¢ We don‚Äôt need an accurate value. \r\n‚Ä¢ It is useful to know which code is more likely to \r\nintroduce energy hotspots and that should be \r\nreviewed with more attention. \r\n‚Ä¢ Can be scoped to a particular domain (react, php, data \r\nscience, web, etc., etc.)', 'p-value = 0.04\r\nOn average, version B spent less energy than version A  ‚Äî  ‚úÖ \r\nThere is statistical significance ‚Äî  ‚úÖ \r\nEffect size, percent-change is ‚âà1% ‚Äî ü§î \r\n‚ö† Do we care?\r\n(?)\r\n\r\nPractical Significance\r\n‚Ä¢ Depending on the case, a 2% improvement might be either wonderful or completely \r\nuseless. \r\n‚Ä¢ Effect size analyses help assess practical significance but might not be enough. \r\n‚Ä¢ A critical discussion always needs to be performed. Consider context and explain in what \r\nsense the effect size might be relevant. \r\n‚Ä¢ E.g.: \r\n‚Ä¢  to improve 2% in energy efficiency the code will be less readable or the user \r\nexperience is not so appealing. \r\n‚Ä¢ A particular method improves 2% but it will only be used 1% of the time. \r\n‚Ä¢ There is no particular metric or structure, but this kind of critical analysis is very important.\r\n25\r\n\r\nWhat if data is not Normal?\r\nSame approach but different tests/metrics!\r\n\r\nNon-normal data\r\n‚Ä¢ Statistical significance: non-parametric test (?) \r\n‚Ä¢ Mann-Whitney U test. Instead of looking at standard deviation or mean, it orders \r\nsamples and compares with each other. \r\n‚Ä¢ Less power than parametric-tests (?) \r\n‚Ä¢ Effect size \r\n‚Ä¢ Median difference: \r\n \r\n‚Ä¢ Percentage of pairs supporting a conclusion\u2028\r\n(i.e., # pairs where version A > version B/ total pairs) \r\n‚Ä¢ Common language effect size: \r\nŒîM\r\nU1\r\nN1N2\r\n27\r\n\r\nRecap\r\nImpossible to \r\nfix but \r\nexplainable.\r\n\r\nEnergy Efficiency Across \r\nProgramming Languages\r\nhttps://sites.google.com/view/energy-efficiency-languages\r\n29\r\nRui Pereira, Marco Couto, Francisco Ribeiro, Rui Rua, J√°come \r\nCunha, Jo√£o Paulo Fernandes, and Jo√£o Saraiva\r\n\r\n‚Ä¢ Is a faster programming language also more energy efficient? \r\n‚Ä¢ Comparing different programming languages is not an easy task. \r\n‚Ä¢ They differ in many mechanisms: \r\n‚Ä¢ Interpreted vs Compiled \r\n‚Ä¢ Optimisations at the compiler level \r\n‚Ä¢ Virtual machine \r\n‚Ä¢ Garbage collector \r\n‚Ä¢ Available libraries\r\n30\r\n\r\nResearch Questions\r\n‚Ä¢ Can we compare the energy efficiency of software languages?  \r\n‚Ä¢ Is the faster language always the most energy efficient? \r\n‚Ä¢ How does memory usage relate to energy consumption? (We don‚Äôt cover this one) \r\n‚Ä¢ Can we automatically decide what is the best programming language \r\nconsidering energy, time, and memory usage?  \r\n‚Ä¢ How do the results of our energy consumption analysis of programming \r\nlanguages gathered from rigorous performance benchmarking solutions \r\ncompare to results of average day-to-day solutions? \u2028\r\n31\r\n\r\nMethodology\r\n\r\nThe Computer Language Benchmarks Game \r\n‚Ä¢ https://benchmarksgame-team.pages.debian.net/benchmarksgame/\r\n33\r\n\r\nProblems in the Computer Language Benchmarks Game\r\n34\r\n\r\n‚Ä¢ 27 Programming languages across different paradigms  \r\n‚Ä¢ Functional (e.g., Ocaml, F#, Haskell) \r\n‚Ä¢ Imperative (e.g., C, Go, Python) \r\n‚Ä¢ Object-oriented (e.g., C++, C#, Java) \r\n‚Ä¢ Scripting (or interpretative) (e.g., JavaScript, Python, Ruby) \r\n‚Ä¢ (These are not mutual exclusive) \r\n‚Ä¢ Intel RAPL‚Äôs C library to measure energy consumption\r\n35\r\n\r\n‚Ä¢ Execute each benchmark solution 10 times. \r\n‚Ä¢ Collect energy data and timestamps. \r\n‚Ä¢ Two-minute interval between executions\r\n36\r\n\r\n\r\n\r\n\r\nCritical thinking\r\n‚Ä¢ There is no doubt this is an excellent study. Yet, as any excellent study, there‚Äôs \r\na lot we can discuss and criticise constructively. \r\n‚Ä¢ What kind of issues you see in drawing conclusions from such a table of \r\nresults?', '‚Ä¢ Comparing different programming languages is not an easy task. \r\n‚Ä¢ They differ in many mechanisms: \r\n‚Ä¢ Interpreted vs Compiled \r\n‚Ä¢ Optimisations at the compiler level \r\n‚Ä¢ Virtual machine \r\n‚Ä¢ Garbage collector \r\n‚Ä¢ Available libraries\r\n30\r\n\r\nResearch Questions\r\n‚Ä¢ Can we compare the energy efficiency of software languages?  \r\n‚Ä¢ Is the faster language always the most energy efficient? \r\n‚Ä¢ How does memory usage relate to energy consumption? (We don‚Äôt cover this one) \r\n‚Ä¢ Can we automatically decide what is the best programming language \r\nconsidering energy, time, and memory usage?  \r\n‚Ä¢ How do the results of our energy consumption analysis of programming \r\nlanguages gathered from rigorous performance benchmarking solutions \r\ncompare to results of average day-to-day solutions? \u2028\r\n31\r\n\r\nMethodology\r\n\r\nThe Computer Language Benchmarks Game \r\n‚Ä¢ https://benchmarksgame-team.pages.debian.net/benchmarksgame/\r\n33\r\n\r\nProblems in the Computer Language Benchmarks Game\r\n34\r\n\r\n‚Ä¢ 27 Programming languages across different paradigms  \r\n‚Ä¢ Functional (e.g., Ocaml, F#, Haskell) \r\n‚Ä¢ Imperative (e.g., C, Go, Python) \r\n‚Ä¢ Object-oriented (e.g., C++, C#, Java) \r\n‚Ä¢ Scripting (or interpretative) (e.g., JavaScript, Python, Ruby) \r\n‚Ä¢ (These are not mutual exclusive) \r\n‚Ä¢ Intel RAPL‚Äôs C library to measure energy consumption\r\n35\r\n\r\n‚Ä¢ Execute each benchmark solution 10 times. \r\n‚Ä¢ Collect energy data and timestamps. \r\n‚Ä¢ Two-minute interval between executions\r\n36\r\n\r\n\r\n\r\n\r\nCritical thinking\r\n‚Ä¢ There is no doubt this is an excellent study. Yet, as any excellent study, there‚Äôs \r\na lot we can discuss and criticise constructively. \r\n‚Ä¢ What kind of issues you see in drawing conclusions from such a table of \r\nresults? \r\n‚Ä¢ Is the benchmark representative of the most common usage behaviour? \r\n‚Ä¢ Are the implemented solutions representative? \r\n‚Ä¢ Does it make sense to use the average to compare energy consumption \r\nacross different problems? \r\n‚Ä¢ ‚Ä¶\r\n40\r\n\r\nReproducing with Rosetta Code \r\n‚Ä¢ Rosetta Code is a programming chrestomathy repository \r\n \r\n‚Ä¢ 900 usecases/tasks solved across 700 different programming languages \r\n‚Ä¢ Purpose: if you know a programming language we can easily learn how the \r\nsame task is solved in a language you are not familiar with.\r\n41\r\n(?)\r\n\r\n\r\n\r\nRevisiting Research Questions\r\n‚Ä¢ Can we compare the energy efficiency of software languages?  \r\n‚Ä¢ Is the faster language always the most energy efficient? \r\n‚Ä¢ How does memory usage relate to energy consumption?  \r\n‚Ä¢ Can we automatically decide what is the best programming language considering \r\nenergy, time, and memory usage?  \r\n‚Ä¢ How do the results of our energy consumption analysis of programming \r\nlanguages gathered from rigorous performance benchmarking solutions \r\ncompare to results of average day-to-day solutions?  \r\n‚Ä¢ What would happen if we cherry picked the tasks?\u2028\r\n44\r\n\r\n\r\nLu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\n3. Scientific Guide for Reliable \r\nEnergy Experiments\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nCarolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl', 'It‚Äôs more important that we learn how to \r\ndiscuss this topic and come up with new ideas than learning all the theory. \r\nCritical thinking over checkboxes. \r\n‚Ä¢ Mix of content and discussion \r\n‚Ä¢ Ultimately, the lectures aim to give you food for thought and the necessary \r\nknowledge to excel in Project 2. (We will talk about it later)\r\n30\r\n\r\nhttps://luiscruz.github.io/course_sustainableSE/\r\n31\r\nContent of the course üëá\r\n\r\n32\r\nhttps://mattermost.tudelft.nl/signup_user_complete/?id=1nj9tk6usjf8xmsws8wpq3s5uy&md=link&sbr=su\r\n\r\nProject 1\r\n‚Ä¢ Goal: Measure the energy consumption of software applications. \r\n‚Ä¢ Approach: energy measurement tools; use case testing. \r\n‚Ä¢ Deliverable: blog-style report (approx. 2500 words) \r\n‚Ä¢ Deadline: Week 3, Feb 28, 2025 \r\n‚Ä¢ Group size: 4‚Äì5\r\n33\r\n\r\nProject 2\r\n‚Ä¢ Goal: Create a solution/tool/technique that helps building green software. (You \r\ncan come up with your own idea or choose one from a list of suggestions). \r\n‚Ä¢ Approach: open-source software development; literature review. \r\n‚Ä¢ Deliverable: library/tool/app; paper; presentation. \r\n‚Ä¢ Two deadlines:\u2028\r\n1. Paper and software: Week 8, April 4, 2025\u2028\r\n2. Presentation: Week 9, April 11, 2025 \r\n‚Ä¢ Group size: 4‚Äì5\r\n34\r\n\r\nGuest Lectures\r\nNergis T√∂men \r\nComputer Vision lab | TU Delft \r\nWeek 4, Wed, Mar 5, 2025\r\n35\r\n\r\nCommunity \r\nHow to get involved?\r\n36\r\n\r\nGreen TU\r\n‚Ä¢ https://www.tudelft.nl/sustainability/get-\r\ninvolved/greentu \r\n‚Ä¢ Student organisation at the TU Delft devoted \r\nto stimulating sustainability in education, \r\nresearch, university operations and \r\ncommunity engagement.\r\n37\r\n\r\nClimateAction.tech\r\n‚Ä¢ Great community for outreach \r\n‚Ä¢ Based on Slack  \r\n‚Ä¢ Regular meetings, talks, social events \r\n‚Ä¢ You can join as a volunteer or simply to \r\nconnect to other techies \r\n‚Ä¢ Also good to for job hunting on green tech.\r\n38\r\n\r\nClimateAction.tech\r\n39\r\n\r\nBranch magazine\r\n‚Ä¢ Stay up-to-date on sustainable tech \r\n‚Ä¢ Creativity booster \r\n‚Ä¢ Carbon-aware UI \r\n‚Ä¢ https://branch.climateaction.tech üîó\r\n40\r\n\r\nThis is the fourth edition\r\n‚Ä¢ Any feedback is welcome! Email or DM!\r\n41\r\n\r\n42\r\n\r\nCarolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nLu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\n1. Intro Class\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl', 'Lu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\n10. Project 2\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nCarolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl\r\n\r\n1. Goal/assignment \r\n2. Deliverables \r\n3. Strategy \r\n4. Ideas\r\n\r\nAssignment\r\n‚Ä¢ Goal: Solve a Sustainable Software Engineering problem. \r\n‚Ä¢ Identify 1 problem that should be fixed to help enabling sustainability in \r\nthe software engineering industry/community. \r\n‚Ä¢ Propose a solution. A tool, framework, guidelines, etc. \r\n‚Ä¢ Implementation. \r\n‚Ä¢ Validation. (Depending on the idea) \r\n‚Ä¢ Dissemination/social impact. (Solution should be open source, welcome \r\ncontributors, post on social media? Tool website? Available in a package \r\nmanager?)\r\n3\r\n\r\nDeliverables\r\n‚Ä¢ Paper-like article. (Min 4 pages, max 10) \r\n‚Ä¢ Online git repo with open source codebase and/or replication package. \r\n‚Ä¢ Presentation: 5 min + 5min Q&A\r\n4\r\n\r\nArticle\r\n‚Ä¢ Different projects will have different expectations -> Make agreements with \r\nyour coach. \r\n‚Ä¢ Some projects are more technical and some projects more theoretical. \r\n‚Ä¢ Common requirements: \r\n‚Ä¢ Motivation, formulation of the problem being addressed, etc. \r\n‚Ä¢ Description of the solution. \r\n‚Ä¢ Validation of the solution (if applicable -> discuss with coach) \r\n‚Ä¢ Discussion of the solution. (Including limitations)\r\n5\r\n\r\nStrategy\r\n‚Ä¢ Starting next week, there are no lectures  \r\n‚Ä¢ Steering meetings from week 5 till week 9 (either online or in person).  \r\n‚Ä¢ 1 steering meeting per week. (4+1 sprints) \r\n‚Ä¢ Every week, you need to plan different tasks and assignments. \r\n‚Ä¢ Deadline April 4.\r\n6\r\n\r\nStrategy\r\n‚Ä¢ Week 0 \r\n‚Ä¢ Decide project idea (today) \r\n‚Ä¢ Define steering meeting schedule \r\n‚Ä¢ Create working document of the \r\narticle: Problem statement and solution \r\nproposal! \r\n‚Ä¢ Define and assign tasks for each week. \r\n‚Ä¢ Week 1 \r\n‚Ä¢ Implementation \r\n‚Ä¢ Agreements with supervisor. \r\n‚Ä¢ Week 2 \r\n‚Ä¢ Implementation \r\n‚Ä¢ Week 3 \r\n‚Ä¢ Implementation, Full draft of article, \r\ndissemination. \r\n‚Ä¢ Week 4 \r\n‚Ä¢ Final refinements \r\n‚Ä¢ Prepare presentation\r\n7\r\n\r\nProject ideas\r\n‚Ä¢ A1. Prototype cross-machine comparable benchmarks \r\n‚Ä¢ A2. Add energy metrics to LMstudio/Ollama \r\n‚Ä¢ A3. Visualizations built-in with EnergiBridge \r\n‚Ä¢ A4. Service-based version of EnergiBridge\r\n\r\nProject ideas\r\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \r\n‚Ä¢ B2. Study test generation energy consumption \r\n‚Ä¢ B3. Energy profiling of static analysis tools \r\n‚Ä¢ B4. Detailed energy profiling of build pipelines \r\n‚Ä¢ B5. Tool supporting SusAF workshop / process \r\n‚Ä¢ B6. Dataset of government-developed OS software \r\n‚Ä¢ B7. Queue - but better for the student / TA society\r\nQuality Assurance & Testing\r\nSocial & Individual \u2028\r\nSustainability\r\n\r\nProject ideas\r\n‚Ä¢ C1. Compare energy consumption of docker images for ML workloads. \r\n‚Ä¢ C2. Create a plugin to visualize Hugging Face carbon emissions in detail. \r\n‚Ä¢ C3. Plugin for ChatGPT (footprint per chat window) \r\n‚Ä¢ C4. NutriScore for software libraries. \r\n‚Ä¢ C5. Add energy-awareness to existing software \r\n‚Ä¢ C6. Green Shift Left \r\n‚Ä¢ C7. Education for Sustainable SE\r\n\r\nA1.']","['<1-hop>\n\nShuffle \nüîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them.\n‚Ä¢ If you run 30 executions for version A and another batch for version B:\n‚Ä¢ External conditions that change over time will have a diÔ¨Äerent bias in \nthe 2 versions (e.g., room temperature changes).\n‚Ä¢ If you shuÔ¨Ñe, you reduce this risk.\n11', '<2-hop>\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio)\n‚Ä¢ Dynamic Retry Delay\n‚Ä¢ Push Over Poll\n‚Ä¢ Reduce Size\n‚Ä¢ Cache\n‚Ä¢ Avoid Graphics and Animations\n20', '<1-hop>\n\nShuffle \nüîÄ\n‚Ä¢ It is not a mystery that energy consumption depends on so many factors that \nit is impossible to control all of them.\n‚Ä¢ If you run 30 executions for version A and another batch for version B:\n‚Ä¢ External conditions that change over time will have a diÔ¨Äerent bias in \nthe 2 versions (e.g., room temperature changes).\n‚Ä¢ If you shuÔ¨Ñe, you reduce this risk.\n11', '<2-hop>\n\nEcoAndroid\n‚Ä¢ Plugin for IntelliJ (Android Studio)\n‚Ä¢ Dynamic Retry Delay\n‚Ä¢ Push Over Poll\n‚Ä¢ Reduce Size\n‚Ä¢ Cache\n‚Ä¢ Avoid Graphics and Animations\n20']","Shuffling reduces risk in software engineering experiments by minimizing the impact of external conditions that change over time, which can introduce bias. When you run multiple executions, such as 30 for one version and another batch for a different version, external factors like room temperature can vary and affect the results differently for each version. By shuffling the order of executions, you distribute these external influences more evenly across all tests, thereby reducing the risk of biased results due to changing conditions. This approach is particularly useful when reducing the size of datasets or experiments, as it helps ensure that any observed differences are due to the changes being tested rather than external factors.","Shuffling reduce risk by controlling external factors like room temperature changes, which help in reducing size in software engineering.",0.0,0.0,0.8,0.71,,0.9551598280926026
How spiking neural networks relate to McCulloch-Pitts model?,"[""- Higher firing rate (spikes per unit time) for \r\n'selected' feature.\r\nAdapted from Hubel & Wiesel, 1959\r\n\r\nFiring rates\r\nClassical view of the brain:\r\n- Each neuron is selective for one specific \r\nfeature in the input.\r\n- Higher firing rate (spikes per unit time) for \r\n'selected' feature.\r\n- Link to modern ANNs: The scalar output of \r\nan artificial neuron is interpreted as the firing \r\nrate.\r\nAdapted from Hubel & Wiesel, 1959\r\n\r\nFiring rates\r\nClassical view of the brain:\r\n- Each neuron is selective for one specific \r\nfeature in the input.\r\n- Higher firing rate (spikes per unit time) for \r\n'selected' feature.\r\n- Link to modern ANNs: The scalar output of \r\nan artificial neuron is interpreted as the firing \r\nrate.\r\nAdapted from Hubel & Wiesel, 1959\r\nBut rate coding is inefficient and slow‚Ä¶\r\n(i.e. each neuron needs to fire many spikes to get good precision)\r\nboth in vivo and in silico.\r\n\r\nDifferent encoding strategies with spiking neurons [8]\r\n7 neurons\r\n7 time bins\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nn\r\n6\r\n(in the general \r\ncase a \r\nnumber \r\nbetween 0-7)\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nn\r\nTotal spike \r\ncount can \r\nencode 3 bits.\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nIndividual rates \r\ncan encode 7 \r\nbits.\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nLatency can \r\nencode ~3*7 or \r\n~19 bits.\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nRank order can \r\nencode ~12 bits.\r\n\r\nDifferent encoding strategies with spiking neurons\r\n\r\nDifferent encoding strategies with spiking neurons\r\nUsing latency or spatio-temporal codes\r\nour encoding is faster and more spike-efficient (sparser)!\r\n\r\nDifferent encoding strategies with spiking neurons\r\nUsing latency or spatio-temporal codes\r\nour encoding is faster and more spike-efficient (sparser)!\r\nQuestions?\r\n\r\nNeuromorphic computing\r\nWhat is the advantage for applications?\r\n-\r\nLess spikes = less energy consumption in specialized neuromorphic hardware\r\n(e.g. Intel Loihi [12])\r\nBrains are energy efficient: \r\n2. Sparse encoding\r\n\r\nMultiply-accumulate (MAC) operations:\r\nNormal neuron: Multiplies input with \r\nweights, then adds.\r\nSpiking neuron: Consider binary input (e.g. input currents are piecewise \r\nconstant and assume values {0,1}). There is no multiplication, only addition.\r\n\r\nAssume one multiplier and one adder circuit uses M and A energy respectively with AÔπ§M\r\n(e.g., for a 45nm CMOS process, standard energy usage is A = 0.9 pJ and M = 3.7 pJ).\r\nNormal neuron: nin x nout multiplications,\r\n(nin‚Äì 1) x nout additions\r\nSpiking neuron: 0 multiplications, (nactive‚Äì 1) x nout \r\nadditions, with nactive ‚â§ nin\r\nEnergy consumption:\r\nEnormal = M nin nout + A (nin‚Äì 1) nout = 17.5 pJ\r\nEnergy consumption:\r\nEspiking = A (nactive‚Äì 1) nout = 2.7 pJ\r\nMultiply-accumulate (MAC) operations:\r\n\r\nAssume one multiplier and one adder circuit uses M and A energy respectively with AÔπ§M\r\n(e.g., for a 45nm CMOS process, standard energy usage is A = 0.9 pJ and M = 3.7 pJ)."", 'Different encoding strategies with spiking neurons\r\n\r\nDifferent encoding strategies with spiking neurons\r\nUsing latency or spatio-temporal codes\r\nour encoding is faster and more spike-efficient (sparser)!\r\n\r\nDifferent encoding strategies with spiking neurons\r\nUsing latency or spatio-temporal codes\r\nour encoding is faster and more spike-efficient (sparser)!\r\nQuestions?\r\n\r\nNeuromorphic computing\r\nWhat is the advantage for applications?\r\n-\r\nLess spikes = less energy consumption in specialized neuromorphic hardware\r\n(e.g. Intel Loihi [12])\r\nBrains are energy efficient: \r\n2. Sparse encoding\r\n\r\nMultiply-accumulate (MAC) operations:\r\nNormal neuron: Multiplies input with \r\nweights, then adds.\r\nSpiking neuron: Consider binary input (e.g. input currents are piecewise \r\nconstant and assume values {0,1}). There is no multiplication, only addition.\r\n\r\nAssume one multiplier and one adder circuit uses M and A energy respectively with AÔπ§M\r\n(e.g., for a 45nm CMOS process, standard energy usage is A = 0.9 pJ and M = 3.7 pJ).\r\nNormal neuron: nin x nout multiplications,\r\n(nin‚Äì 1) x nout additions\r\nSpiking neuron: 0 multiplications, (nactive‚Äì 1) x nout \r\nadditions, with nactive ‚â§ nin\r\nEnergy consumption:\r\nEnormal = M nin nout + A (nin‚Äì 1) nout = 17.5 pJ\r\nEnergy consumption:\r\nEspiking = A (nactive‚Äì 1) nout = 2.7 pJ\r\nMultiply-accumulate (MAC) operations:\r\n\r\nAssume one multiplier and one adder circuit uses M and A energy respectively with AÔπ§M\r\n(e.g., for a 45nm CMOS process, standard energy usage is A = 0.9 pJ and M = 3.7 pJ).\r\nNormal neuron: nin x nout multiplications,\r\n(nin‚Äì 1) x nout additions\r\nSpiking neuron: 0 multiplications, (nactive‚Äì 1) x nout \r\nadditions, with nactive ‚â§ nin\r\nEnergy consumption:\r\nEnormal = M nin nout + A (nin‚Äì 1) nout = 17.5 pJ\r\nEnergy consumption:\r\nEspiking = A (nactive‚Äì 1) nout = 2.7 pJ\r\nMultiply-accumulate (MAC) operations:\r\nSNN challenge: how to \r\ncompute with the least \r\namount of spikes!\r\n\r\nOften, we observe a \r\nsparsity (energy)-\r\ntask accuracy trade-off\r\n(Left: results for image \r\nclassification)\r\nSNN challenge: how to \r\ncompute with the least \r\namount of spikes!\r\nhttps://arxiv.org/pdf/2409.08290\r\n\r\nIn practice, energy \r\nconsumption computations \r\nare complex. \r\nNeed to take into account\r\n- memory access,\r\n- addressing,\r\n- auxiliary operations,\r\nin addition to MACs.\r\nEstimated energy consumption for 3 different datasets (CIFAR10, GSC, NCARS; image, sound \r\nand video classification respectively). FNN‚Äôs are conventional feed-forward neural networks.\r\nIn this example: SNNs are 6 to 8 times more energy efficient than FNNs.\r\nhttps://arxiv.org/pdf/2210.13107\r\nComputing energy consumption\r\n\r\nIn practice, energy \r\nconsumption computations \r\nare complex. \r\nNeed to take into account\r\n- memory access,\r\n- addressing,\r\n- auxiliary operations,\r\nin addition to MACs.\r\nEstimated energy consumption for 3 different datasets (CIFAR10, GSC, NCARS; image, sound \r\nand video classification respectively). FNN‚Äôs are conventional feed-forward neural networks.\r\nIn this example: SNNs are 6 to 8 times more energy efficient than FNNs.', 'Normal neuron: nin x nout multiplications,\r\n(nin‚Äì 1) x nout additions\r\nSpiking neuron: 0 multiplications, (nactive‚Äì 1) x nout \r\nadditions, with nactive ‚â§ nin\r\nEnergy consumption:\r\nEnormal = M nin nout + A (nin‚Äì 1) nout = 17.5 pJ\r\nEnergy consumption:\r\nEspiking = A (nactive‚Äì 1) nout = 2.7 pJ\r\nMultiply-accumulate (MAC) operations:\r\nSNN challenge: how to \r\ncompute with the least \r\namount of spikes!\r\n\r\nOften, we observe a \r\nsparsity (energy)-\r\ntask accuracy trade-off\r\n(Left: results for image \r\nclassification)\r\nSNN challenge: how to \r\ncompute with the least \r\namount of spikes!\r\nhttps://arxiv.org/pdf/2409.08290\r\n\r\nIn practice, energy \r\nconsumption computations \r\nare complex. \r\nNeed to take into account\r\n- memory access,\r\n- addressing,\r\n- auxiliary operations,\r\nin addition to MACs.\r\nEstimated energy consumption for 3 different datasets (CIFAR10, GSC, NCARS; image, sound \r\nand video classification respectively). FNN‚Äôs are conventional feed-forward neural networks.\r\nIn this example: SNNs are 6 to 8 times more energy efficient than FNNs.\r\nhttps://arxiv.org/pdf/2210.13107\r\nComputing energy consumption\r\n\r\nIn practice, energy \r\nconsumption computations \r\nare complex. \r\nNeed to take into account\r\n- memory access,\r\n- addressing,\r\n- auxiliary operations,\r\nin addition to MACs.\r\nEstimated energy consumption for 3 different datasets (CIFAR10, GSC, NCARS; image, sound \r\nand video classification respectively). FNN‚Äôs are conventional feed-forward neural networks.\r\nIn this example: SNNs are 6 to 8 times more energy efficient than FNNs.\r\nComputing energy consumption\r\nQuestions?\r\n\r\nReading materials\r\nMain reading:\r\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \r\nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\r\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\r\n- Neuromorphic computing:\r\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \r\nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\r\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \r\noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\r\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019.', 'In this example: SNNs are 6 to 8 times more energy efficient than FNNs.\r\nComputing energy consumption\r\nQuestions?\r\n\r\nReading materials\r\nMain reading:\r\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \r\nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\r\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\r\n- Neuromorphic computing:\r\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \r\nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\r\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \r\noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\r\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \r\nhttps://www.nature.com/articles/s41586-019-1677-2\r\nExtra reading:\r\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \r\nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\r\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \r\nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \r\nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\r\nBasics of \'conventional\' neural networks:\r\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\r\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.\r\n\r\nReferences\r\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \r\nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\r\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947.', '575(7784):607-17. \r\nhttps://www.nature.com/articles/s41586-019-1677-2\r\nExtra reading:\r\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \r\nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\r\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \r\nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \r\nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\r\nBasics of \'conventional\' neural networks:\r\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\r\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.\r\n\r\nReferences\r\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \r\nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\r\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \r\n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\r\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \r\nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\r\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \r\n(not publicly available) doi:10.1037/h0042519\r\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \r\nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\r\n6) https://github.com/idsc-frazzoli/retina\r\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \r\nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\r\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \r\nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\r\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \r\nNeural Networks.', ""Spiking neural network (SNN): The 'input current' Œµ(t) is integrated over time.\r\nspike\r\n\r\nHow to model spiking neurons?\r\nEquivalence to perceptron: Computation at least as complex as a perceptron.\r\n\r\nNon-leaky integrate-and-fire (IF) neuron\r\nThe temporal profile of the input current Œµ(t) can be chosen differently, for different computations.\r\n\r\nQuestions?\r\n\r\nComputation with spiking neurons\r\nCoincidence detection\r\n\r\nComputation with spiking neurons\r\nCoincidence detection\r\nx, y ‚àà {0, 1}n\r\nExample: n = 2\r\ninput = \r\nx1\r\nx2\r\ny1\r\ny2\r\n= \r\n0\r\n1\r\n1\r\n1\r\noutput? \r\n\r\nCoincidence detection\r\nComputation with spiking neurons\r\n\r\nCoincidence detection\r\nCan be trivially computed with a single spiking neuron! Requires at least n/log(n+1) hidden \r\nunits for a perceptron (proof in [7]).\r\nComputation with spiking neurons\r\n\r\nCoincidence detection\r\nCan be trivially computed with a single spiking neuron! Requires at least n/log(n+1) hidden \r\nunits for a perceptron (proof in [7]).\r\nBrains are energy efficient: \r\n1.\r\nHigh temporal resolution (more computation with less neurons)\r\nComputation with spiking neurons\r\n\r\nEncoding strategies\r\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\r\nHow should we encode information about 'features' in a large network with many spikes?\r\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\r\nElephant?\r\nhttps://www.nationalgeographic.com/anim\r\nals/mammals/facts/african-elephant\r\n\r\nFiring rates\r\nClassical view of the brain:\r\n- Each neuron is selective for one specific \r\nfeature in the input.\r\n- Higher firing rate (spikes per unit time) for \r\n'selected' feature.\r\nAdapted from Hubel & Wiesel, 1959\r\n\r\nFiring rates\r\nClassical view of the brain:\r\n- Each neuron is selective for one specific \r\nfeature in the input.\r\n- Higher firing rate (spikes per unit time) for \r\n'selected' feature.\r\n- Link to modern ANNs: The scalar output of \r\nan artificial neuron is interpreted as the firing \r\nrate.\r\nAdapted from Hubel & Wiesel, 1959\r\n\r\nFiring rates\r\nClassical view of the brain:\r\n- Each neuron is selective for one specific \r\nfeature in the input.\r\n- Higher firing rate (spikes per unit time) for \r\n'selected' feature.\r\n- Link to modern ANNs: The scalar output of \r\nan artificial neuron is interpreted as the firing \r\nrate.\r\nAdapted from Hubel & Wiesel, 1959\r\nBut rate coding is inefficient and slow‚Ä¶\r\n(i.e. each neuron needs to fire many spikes to get good precision)\r\nboth in vivo and in silico.\r\n\r\nDifferent encoding strategies with spiking neurons [8]\r\n7 neurons\r\n7 time bins\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nn\r\n6\r\n(in the general \r\ncase a \r\nnumber \r\nbetween 0-7)\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nn\r\nTotal spike \r\ncount can \r\nencode 3 bits.\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nIndividual rates \r\ncan encode 7 \r\nbits.\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nLatency can \r\nencode ~3*7 or \r\n~19 bits.\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nRank order can \r\nencode ~12 bits."", '9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\r\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \r\nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\r\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \r\n(not publicly available) doi:10.1037/h0042519\r\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \r\nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\r\n6) https://github.com/idsc-frazzoli/retina\r\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \r\nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\r\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \r\nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\r\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \r\nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\r\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \r\nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\r\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \r\nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\r\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\r\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\r\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \r\n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568', ""Oversimplification\r\nThere are also multiple other advantages‚Ä¶\r\n\r\nHuman vs. computer computation\r\n- Fast real-time decision making, e.g. sports, e-sports\r\n- Adaptive, e.g. context-aware and employs selective attention\r\n- Energy efficient: Close to 100 billion neurons in the brain\r\n- Robust, for example to changes in illumination or obstructions in object tracking\r\n\r\nHuman vs. computer computation\r\nBrains are energy efficient: Why?\r\n1.\r\nHigh temporal resolution (more computation with less neurons)\r\n2.\r\nSparse encoding\r\n\r\nHuman vs. computer computation\r\nQuestions?\r\nBrains are energy efficient: Why?\r\n1.\r\nHigh temporal resolution (more computation with less neurons)\r\n2.\r\nSparse encoding\r\n\r\nHow do biological neurons communicate?\r\nAnalogy to artificial neural networks\r\nReal neuron\r\nArtificial neuron\r\nCurrent\r\n\r\nHow do biological neurons communicate?\r\nHow does the electrical activity propagate?\r\n?\r\nCurrent\r\n\r\nHow do biological neurons work?\r\ntime\r\nelectrode\r\nhttps://tinmard.github.io/spike-sorting-animation.html\r\nQuick electrical pulses trigger chemical signals for the next neuron ‚Üí Spikes\r\n\r\nHow do biological neurons work?\r\nQuick electrical pulses trigger chemical signals for the next neuron ‚Üí Spikes\r\nhttps://tinmard.github.io/spike-sorting-animation.html\r\ntime\r\nelectrode\r\nFrom CS perspective:\r\nSparse binary \r\nencoding\r\n\r\nBiologically realistic spiking neuron models\r\nBiologically realistic neuron models have \r\na new dimension: Time!\r\nSpiking neural networks (SNNs):\r\nThe input x  (t  ) to each neuron is summed \r\n(integrated) over time.\r\nscalar\r\nfunction of \r\ntime\r\n(t)\r\n(t)\r\nhttps://www.mdpi.com/2076-3425/12/7/863\r\n\r\nHow to model spiking neurons?\r\nANN: Perceptron, threshold activation function:\r\n\r\nHow to model spiking neurons?\r\nANN: Perceptron, threshold activation function:\r\n\r\nHow to model spiking neurons?\r\nSpiking neural network (SNN): The 'input current' Œµ(t) is integrated over time.\r\nspike\r\n\r\nHow to model spiking neurons?\r\nEquivalence to perceptron: Computation at least as complex as a perceptron.\r\n\r\nNon-leaky integrate-and-fire (IF) neuron\r\nThe temporal profile of the input current Œµ(t) can be chosen differently, for different computations.\r\n\r\nQuestions?\r\n\r\nComputation with spiking neurons\r\nCoincidence detection\r\n\r\nComputation with spiking neurons\r\nCoincidence detection\r\nx, y ‚àà {0, 1}n\r\nExample: n = 2\r\ninput = \r\nx1\r\nx2\r\ny1\r\ny2\r\n= \r\n0\r\n1\r\n1\r\n1\r\noutput? \r\n\r\nCoincidence detection\r\nComputation with spiking neurons\r\n\r\nCoincidence detection\r\nCan be trivially computed with a single spiking neuron! Requires at least n/log(n+1) hidden \r\nunits for a perceptron (proof in [7]).\r\nComputation with spiking neurons\r\n\r\nCoincidence detection\r\nCan be trivially computed with a single spiking neuron! Requires at least n/log(n+1) hidden \r\nunits for a perceptron (proof in [7]).\r\nBrains are energy efficient: \r\n1.\r\nHigh temporal resolution (more computation with less neurons)\r\nComputation with spiking neurons\r\n\r\nEncoding strategies\r\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\r\nHow should we encode information about 'features' in a large network with many spikes?\r\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\r\nElephant?\r\nhttps://www.nationalgeographic.com/anim\r\nals/mammals/facts/african-elephant\r\n\r\nFiring rates\r\nClassical view of the brain:\r\n- Each neuron is selective for one specific \r\nfeature in the input."", 'Neuromorphic computing\r\nCS4575\r\nSustainable Software Engineering\r\n05.03.2025\r\nNergis T√∂men\r\n\r\nIntroduction\r\nComputer Vision Lab\r\nBiomorphic Intelligence Lab\r\nBiomedical Intervention Optimisation Lab\r\nNergis\r\n\r\nNeuromorphic computing\r\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\r\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\r\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing\r\n\r\nHow many of you are familiar \r\nwith neural networks?\r\n\r\nSimple model of an artificial neuron\r\nhttps://medium.com/@cprasenjit32/perceptron-a-simple-yet-mighty-machine-learning-algorithm-9ff6b7d86a71\r\n\r\nWhat is a neural network?\r\nhttps://www.tibco.com/reference-center/what-is-a-neural-network\r\n\r\nWhy is it called a \'neural network\'?\r\nhttps://www.tibco.com/reference-center/what-is-a-neural-network\r\n\r\nWhat is a neural network?\r\nWhy is it called a \'neural network\'?\r\nMcCulloch-Pitts neuron [1, 2] (1943)\r\nWarren Sturgis McCulloch\r\n(Neurophysiologist)\r\nWalter Pitts\r\n(Logician)\r\n\r\nHow do biological neurons work?\r\nhttps://commons.wikimedia.org/wiki/File:Coincidence_detection_in_dendrites_of_pyramidal_neurons.gif\r\n\'Input current\' travels down the dendrites (top),\r\nget integrated (summed!) in the cell body\r\nwhich generates an \'output current\' (bottom)\r\nwhich is chemically transmitted to the dendrites of \r\nother neurons.\r\n\r\nSimplified picture\r\nReal neuron\r\nArtificial neuron\r\nhttps://vajiramandravi.com/quest-upsc-notes/artificial-neural-network/\r\n\r\nWhat is a neural network?\r\nMcCulloch-Pitts neuron [1, 2]\r\n1940s: How do biological neurons compute basic \r\nlogic functions? (e.g. logic gates)\r\nNote: Ref. [3] gives a nice brief history on the ideas which lead to the \r\nMcCulloch-Pitts neuron.\r\n\r\nWhat is a neural network?\r\n1950s: How are neurons organized to perform \r\nsensory perception?\r\n\r\nWhat is a neural network?\r\n1950s: How are neurons organized to perform \r\nsensory perception?\r\nThe first ""neural network"": Perceptron (1958). [4]\r\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\r\nFrank Rosenblatt (Psychologist)\r\nwith a Mark I Perceptron computer in 1960\r\n\r\nWhat is a neural network?\r\n1950s: How are neurons organized to perform \r\nsensory perception?\r\nThe first ""neural network"": Perceptron (1958). [4]\r\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\r\nFrank Rosenblatt (Psychologist)\r\nwith a Mark I Perceptron computer in 1960\r\nPower-efficient\r\n\r\nNeuromorphic computing\r\nWhy neuromorphic computing?\r\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\r\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\r\n\r\nNeuromorphic computing\r\nWhy neuromorphic computing?\r\n‚ÄòBiological inspiration‚Äô for artificial neural networks (ANNs) is not a new idea.\r\nEmulation (as opposed to simulation) of neural networks in hardware is not a new idea.', 'Power-efficiency at scale\r\nModern, deep neural networks*\r\nare trained using GPUs.\r\n* It is estimated that ChatGPT was trained on \r\n10,000-20,000 GPUs and that it will require\r\n30,000 GPUs to keep running stably in the future.\r\n* It is estimated that ChatGPT has 10-20 billion \r\nparameters.\r\nhttps://www.anandtech.com/show/4008/nvidias-geforce-gtx-580/17\r\n\r\nPower-efficiency at scale\r\nModern, deep neural networks*\r\nare trained using GPUs.\r\n* It is estimated that ChatGPT was trained on \r\n10,000-20,000 GPUs and that it will require\r\n30,000 GPUs to keep running stably in the future.\r\n* It is estimated that ChatGPT has 10-20 billion \r\nparameters.\r\nSingle model with 20 billion parameters:\r\n200 Watts x 30,000 GPUs = 6M Watts\r\n\r\nPower-efficiency at scale\r\nhttps://hai.stanford.edu/ai-index/2024-ai-index-report\r\nTraining a single large language model can \r\ngenerate greater CO2 emissions than the \r\ntotal lifetime emissions of 8 cars (in 2020)!\r\n\r\nPower-efficiency at scale\r\nhttps://hai.stanford.edu/ai-index/2024-ai-index-report\r\nTraining a single model can consume \r\nmore than 1000 MWh of power!\r\n\r\nPower-efficiency at scale\r\nhttps://hai.stanford.edu/ai-index/2024-ai-index-report\r\nTraining a single model can consume \r\nmore than 1000 MWh of power!\r\n‚Ä¶ with energy costs reaching 200M USD!\r\n\r\nPower-efficiency at scale\r\nYour brain runs on:\r\n\r\nPower-efficiency at scale\r\nYour brain runs on:\r\nHigh estimate ~3000 kcal a day\r\n   ‚âà145 Watts\r\n* Human brain has ~600 trillion synapses \r\n(‚âàparameters).\r\n\r\nPower-efficiency at scale\r\nYour brain runs on:\r\nHigh estimate ~3000 kcal a day\r\n   ‚âà145 Watts\r\n* Human brain has ~600 trillion synapses \r\n(‚âàparameters).\r\nOversimplification\r\nThere are also multiple other advantages‚Ä¶\r\n\r\nHuman vs. computer computation\r\n- Fast real-time decision making, e.g. sports, e-sports\r\n- Adaptive, e.g. context-aware and employs selective attention\r\n- Energy efficient: Close to 100 billion neurons in the brain\r\n- Robust, for example to changes in illumination or obstructions in object tracking\r\n\r\nHuman vs. computer computation\r\nBrains are energy efficient: Why?\r\n1.\r\nHigh temporal resolution (more computation with less neurons)\r\n2.\r\nSparse encoding\r\n\r\nHuman vs. computer computation\r\nQuestions?\r\nBrains are energy efficient: Why?\r\n1.\r\nHigh temporal resolution (more computation with less neurons)\r\n2.\r\nSparse encoding\r\n\r\nHow do biological neurons communicate?\r\nAnalogy to artificial neural networks\r\nReal neuron\r\nArtificial neuron\r\nCurrent\r\n\r\nHow do biological neurons communicate?\r\nHow does the electrical activity propagate?\r\n?\r\nCurrent\r\n\r\nHow do biological neurons work?\r\ntime\r\nelectrode\r\nhttps://tinmard.github.io/spike-sorting-animation.html\r\nQuick electrical pulses trigger chemical signals for the next neuron ‚Üí Spikes\r\n\r\nHow do biological neurons work?\r\nQuick electrical pulses trigger chemical signals for the next neuron ‚Üí Spikes\r\nhttps://tinmard.github.io/spike-sorting-animation.html\r\ntime\r\nelectrode\r\nFrom CS perspective:\r\nSparse binary \r\nencoding\r\n\r\nBiologically realistic spiking neuron models\r\nBiologically realistic neuron models have \r\na new dimension: Time!\r\nSpiking neural networks (SNNs):\r\nThe input x  (t  ) to each neuron is summed \r\n(integrated) over time.\r\nscalar\r\nfunction of \r\ntime\r\n(t)\r\n(t)\r\nhttps://www.mdpi.com/2076-3425/12/7/863\r\n\r\nHow to model spiking neurons?', 'McCulloch-Pitts neuron [1, 2]\r\n1940s: How do biological neurons compute basic \r\nlogic functions? (e.g. logic gates)\r\nNote: Ref. [3] gives a nice brief history on the ideas which lead to the \r\nMcCulloch-Pitts neuron.\r\n\r\nWhat is a neural network?\r\n1950s: How are neurons organized to perform \r\nsensory perception?\r\n\r\nWhat is a neural network?\r\n1950s: How are neurons organized to perform \r\nsensory perception?\r\nThe first ""neural network"": Perceptron (1958). [4]\r\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\r\nFrank Rosenblatt (Psychologist)\r\nwith a Mark I Perceptron computer in 1960\r\n\r\nWhat is a neural network?\r\n1950s: How are neurons organized to perform \r\nsensory perception?\r\nThe first ""neural network"": Perceptron (1958). [4]\r\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\r\nFrank Rosenblatt (Psychologist)\r\nwith a Mark I Perceptron computer in 1960\r\nPower-efficient\r\n\r\nNeuromorphic computing\r\nWhy neuromorphic computing?\r\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\r\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\r\n\r\nNeuromorphic computing\r\nWhy neuromorphic computing?\r\n‚ÄòBiological inspiration‚Äô for artificial neural networks (ANNs) is not a new idea.\r\nEmulation (as opposed to simulation) of neural networks in hardware is not a new idea.\r\nQuestion: What can we gain from increasing biological realism in existing neural networks?\r\n\r\nPower-efficiency at scale\r\nModern, deep neural networks*\r\nare trained using GPUs.\r\n* It is estimated that ChatGPT was trained on \r\n10,000-20,000 GPUs and that it will require\r\n30,000 GPUs to keep running stably in the future.\r\n* It is estimated that ChatGPT has 10-20 billion \r\nparameters.\r\nhttps://www.anandtech.com/show/4008/nvidias-geforce-gtx-580/17\r\n\r\nPower-efficiency at scale\r\nModern, deep neural networks*\r\nare trained using GPUs.\r\n* It is estimated that ChatGPT was trained on \r\n10,000-20,000 GPUs and that it will require\r\n30,000 GPUs to keep running stably in the future.\r\n* It is estimated that ChatGPT has 10-20 billion \r\nparameters.\r\nSingle model with 20 billion parameters:\r\n200 Watts x 30,000 GPUs = 6M Watts\r\n\r\nPower-efficiency at scale\r\nhttps://hai.stanford.edu/ai-index/2024-ai-index-report\r\nTraining a single large language model can \r\ngenerate greater CO2 emissions than the \r\ntotal lifetime emissions of 8 cars (in 2020)!\r\n\r\nPower-efficiency at scale\r\nhttps://hai.stanford.edu/ai-index/2024-ai-index-report\r\nTraining a single model can consume \r\nmore than 1000 MWh of power!\r\n\r\nPower-efficiency at scale\r\nhttps://hai.stanford.edu/ai-index/2024-ai-index-report\r\nTraining a single model can consume \r\nmore than 1000 MWh of power!\r\n‚Ä¶ with energy costs reaching 200M USD!\r\n\r\nPower-efficiency at scale\r\nYour brain runs on:\r\n\r\nPower-efficiency at scale\r\nYour brain runs on:\r\nHigh estimate ~3000 kcal a day\r\n   ‚âà145 Watts\r\n* Human brain has ~600 trillion synapses \r\n(‚âàparameters).', ""‚Ä¢ Our question: Can we save energy with alternative approaches? \r\n‚Ä¢ We studied Grid Search, Random Search and Bayesian \r\nOptimisation.\r\n27\r\nTim's MSc Thesis, 2022 \r\nAccepted at CAIN‚Äô23\r\n\r\n\r\nResults\r\n29\r\nConclusions? \r\n‚Ä¢ Bayesian converges faster. \r\n‚Ä¢ No clear winner between Grid and Random\r\n\r\nDeepSeekMoE\r\n30\r\nPreprint at ArXiv, 2024 https://arxiv.org/pdf/\r\n2401.06066\r\n\r\nMixture of Experts\r\n‚Ä¢ Llama3.1 has 405B parameters, DeepSeek V3 671B \r\n‚Ä¢ Yet DeepSeek has quicker inference times and claims less energy \r\nconsumption (?) \r\n‚Ä¢ Divide the model into smaller blocks of experts \r\n‚Ä¢ Tokens get routed to certain experts based on the query \r\n‚Ä¢ Only part of the network is active during inference \r\n‚Ä¢ DeepSeek claims only 37B out of 671B parameters get active\r\n31\r\n\r\nDeepSeekMoE\r\n32\r\n\r\nDeepSeekMoE\r\n33\r\n‚Ä¢ Comparable performance to \r\nLLaMA2 7B effectively using \r\nless half the parameters \r\n‚Ä¢ Less computational power \r\n‚Ä¢ Problems (?) \r\n‚Ä¢ Still need to load all the \r\nparameters \r\n‚Ä¢ High memory -> high \r\nembodied carbon\r\n\r\nGreen AI at FacebookMeta\r\n34\r\nSustainable AI: Environmental Implications, \r\nChallenges and Opportunities (2022)\r\n\r\nCarbon footprint mapped to the AI lifecycle\r\n‚Ä¢ There are 4 main overarching stages where carbon emissions need to be isolated: data \r\ncollection, experimentation, training, inference. \r\n‚Ä¢ At Facebook, recommendation systems split energy consumption evenly between \r\ntraining and inference; text translation models have a 35%/65% split. (Operational cost) \r\n‚Ä¢ Operational/embodied cost split: 30%/70%\r\n35\r\n\r\nOpen issues according to Meta\r\n‚Ä¢ A vast portion of projects only use GPUs at 30%.\u2028\r\nShould be higher to attenuate embodied carbon.\r\n36\r\nBased on 10K AI projects\r\n\r\nData Jan\r\nInformed Adaptation\r\nData Feb\r\nData Mar\r\nData Apr\r\nData May\r\n‚Ä¶\r\n~Data Dec\r\n~Data Dec\r\nData Jan\r\nData Feb\r\nData Mar\r\nData Apr\r\nData May\r\n‚Ä¶\r\nModel update Model update Model update\r\nCheck if \r\ndata change\r\nCheck if \r\ndata change\r\nCheck if \r\ndata change\r\nModel update\r\nBlind Adaptation\r\nThe AI Model will be \r\nupdated fewer times and \r\nonly when necessary.\r\nKnow when to retrain models\r\nNeither too early nor too late\r\n37\r\nAdaptation Techniques\r\n?\r\n\r\nGreen Architectural Tactics for ML-Enabled \r\nSystem\r\n38\r\nICSE-SEIS 2024\r\n\r\nArchitectural tactics\r\n39\r\n\r\nData-centric\r\n40\r\n‚Ä¢ Reduce data size \r\n‚Ä¢ Sampling \r\n‚Ä¢ Dimensionality reduction \r\n‚Ä¢ Quantization\r\n\r\nAlgorithm Design\r\n41\r\n‚Ä¢ Carefully select your algorithm \r\n‚Ä¢ You don‚Äôt need the fanciest \r\ntechniques\r\n\r\nModel Optimization\r\n42\r\n‚Ä¢ Add energy to training parameters \r\n‚Ä¢ Reduce FLOPs \r\n‚Ä¢ Pruning, sparsity \r\n‚Ä¢  Take advantage of existing models\r\n\r\nModel Training\r\n43\r\n‚Ä¢ Quantization\r\n‚Ä¢ SAVE TRAINING PROGRESS\r\n\r\nModel Deployment\r\n44\r\n‚Ä¢ Distributed deployment \r\n‚Ä¢ Energy efficient hardware and \r\nconfigurations\r\n\r\nModel Management\r\n45\r\n‚Ä¢ Reuse the model as much as possible \r\n\r\nRethinking the Architecture: Spiking Neural Networks\r\n46\r\n\r\nRethinking the Architecture: Spiking Neural Networks\r\n47\r\n\r\nSELF Lab\r\n48\r\n\r\nrecap"", '‚Ä¢ Improve parameter-tuning strategy.\r\n11\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ We need benchmarks. \r\n‚Ä¢ AllenAI leaderboard\u2028\r\nhttps://leaderboard.allenai.org \r\n‚Ä¢ No carbon metrics, yet \r\n‚Ä¢ Report comparable proxies for energy \r\nconsumption. \r\n‚Ä¢ ‚ö† Learning algorithms behave in a non-\r\ndeterministic \r\n‚Ä¢ ‚ö† Different data-points lead to different \r\nenergy consumption\r\n12\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ Reporting measured energy consumption \r\n‚Ä¢ + Accurate \r\n‚Ä¢ + Easy to map to carbon emissions \r\n‚Ä¢ - Hard to measure \r\n‚Ä¢ - Low replicability \r\n‚Ä¢ Reporting time / estimation based on time & hardware \r\n‚Ä¢ + Easy to measure \r\n‚Ä¢ + Correlates with energy consumption in most cases. \r\n‚Ä¢ -  Difficult to compare with measurements from other setups \r\n‚Ä¢ E.g., floating point operations (FPOs) (?) \r\n‚Ä¢ + comparable across different setups \r\n‚Ä¢ + cheap \r\n‚Ä¢ - does not factor in memory energy consumption \r\n‚Ä¢ - does not reflect carbon emissions\r\n13\r\n\r\nData-centric AI\r\n\r\nData-centric AI\r\n‚Ä¢ Emerging discipline that deals with systematically engineering data to build AI \r\nsystems. \r\n‚Ä¢ Shift from improving the training strategy to improving the data. \r\n‚Ä¢ It is better to have small but reliable datasets than large but noisy \r\ndatasets. \r\n‚Ä¢ => Improve data collection, data labelling, and data preprocessing. \r\n‚Ä¢ More about data-centric AI by Andrew Ng:\u2028\r\nhttps://www.youtube.com/watch?v=06-AZXmwHjo\r\n15\r\n\r\n\r\nGreen Data-centric AI\r\n‚Ä¢ How do different ML algorithms compare \r\nin terms of energy consumption? \r\n‚Ä¢ How does number of rows relate to the \r\nenergy consumption of ML models? \r\n‚Ä¢ How does number of features relate to \r\nthe energy consumption of ML models? \r\n‚Ä¢ What is the impact of reducing data in the \r\nperformance of the model? \r\n‚Ä¢ Method -> results -> discussion\r\n17\r\n\r\nMethod\r\n‚Ä¢ Single object of study: natural language model to detect spam messages. \r\n‚Ä¢ 6 machine learning algorithms: SVM, Decision Tree, KNN, Random Forrest, \r\nAdaBoost, Bagging Classifier. \r\n‚Ä¢ Reduce the number of rows. 10%, 20%, .., 100% \r\n‚Ä¢ Stratified random sampling (?) \r\n‚Ä¢ Reduce the number of features. 10%, 20%, .., 100% \r\n‚Ä¢ Feature importance metric based on the Chi-Square Test (Chi2) \r\n‚Ä¢ Estimate energy consumption using a RAPL-based tool. (?)\r\n18\r\n\r\n‚Ä¢ Repeat 30 times \r\n‚Ä¢ Fix random seeds \r\n‚Ä¢ ‚Ä¶ \r\n‚Ä¢ Data was not Normal => tailed Normal distribution.\r\n19\r\n(?)\r\n\r\nResults: energy consumption of algorithms\r\n\r\nResults: energy vs data shape\r\n\r\nResults: performance vs data shape\r\n\r\nDiscussion\r\n‚Ä¢ Other data properties should be investigated. \r\n‚Ä¢ E.g., data types \r\n‚Ä¢ Reporting energy data is essential. It can lead to different model selection \r\nwithout hindering model performance. \r\n‚Ä¢ There is a big opportunity in Model and Data Simplification.\r\n23\r\n\r\nData/Model Simplification\r\n‚Ä¢ (?) \r\n‚Ä¢ Data selection \r\n‚Ä¢ Data quantisation. Posit? \r\n‚Ä¢ Data distillation \r\n‚Ä¢ Coreset extraction (?) \r\n‚Ä¢ Model distillation \r\n‚Ä¢ Model quantisation \r\n‚Ä¢ Model pruning \r\n‚Ä¢ ‚Ä¶\r\n24\r\n\r\nPosit vs Float\r\nMore about this: https://spectrum.ieee.org/floating-point-numbers-posits-processor\r\nBetter for DL use cases\r\n\r\nHow can we tune \r\nlearning \r\nparameters \r\nefficiently?\r\n\r\nHyper parameter tuning\r\n‚Ä¢ When training an ML model, there are several parameters that need to be \r\ntuned. \r\n‚Ä¢ E.g., in SVM we have the Regularization parameter C, the kernel function, \r\nthe degree of the kernel function, and depending on the case, many other. \r\n‚Ä¢ The common approach revolves around grid search.', ""Unless there‚Äôs a \r\ngood reason. \r\n‚Ä¢ E.g., somewhere amongst the 30 executions, \r\nthere might be 1 or 2 that failed to finish due \r\nto some unexpected error. \r\n‚Ä¢ (It happens and that‚Äôs ok!)‚Äì consequently, \r\nthe execution is shorter and spends less \r\nenergy ‚Äì falsely appearing as more \r\nenergy efficient. \r\n‚Ä¢ If data is not Normal there might be some \r\nissues affecting the measurements that \r\nmight be ruining results. It is important to \r\ninvestigate this.\r\n16\r\n\r\nEnergy data is not normal. Why?\r\n‚Ä¢ It might be caused by one of the following reasons: \r\n‚Ä¢ There was an error in some of the executions. If not detected and fixed it \r\nmight ruin results. \r\n‚Ä¢ Your tests are not fully replicable or are not deterministic. Quite frequent \r\nwhen you have internet requests or random-based algorithms. \r\n‚Ä¢ There is an unusual task being run by the system during some experiments. \r\n‚Ä¢ The computer entered a different power mode. \r\n‚Ä¢ External physical conditions have changed. E.g., someone opened a \r\nwindow.\r\n17\r\n\r\nEnergy data is not normal. How to fix?\r\n‚Ä¢ We have 2+1 options: \r\n1. Remove outliers. If there are only a few points that deviate from the normal \r\ndistribution, it is okay to simply remove them. \r\n‚Ä¢ Use the z-score outlier removal. (?) \r\n‚Ä¢ Remove all data points that deviate from the mean more than 3 standard \r\ndeviations: \r\n \r\n2. Fix the issue and rerun experiments. \r\n3. Conclude that nothing can be done about it and data will never be normal. (e.g., \r\nin AI, executions are rarely deterministic). ‚ö† Only after ruling out the previous \r\npoints.\r\n| ¬Øx ‚àíx| > 3s\r\n18\r\n\r\nHow do we know whether data is Normal?\r\n‚Ä¢ Visualise distribution shape: violin plots, histograms, density plot.\u2028\r\n \r\n‚Ä¢ Shapiro-Wilk test.\u2028\r\ndata is not normal;\u2028\r\nwe are not sure but it is okay to assume that data is \r\nnormal.\r\np-value < 0.05 ‚áí\r\np-value ‚â•0.05 ‚áí\r\n19\r\n\r\nAfter having all data ready, which artefact \r\nis more energy efficient(?) \r\nFirst approach: compare sample means. \r\n‚ö† assuming normal distribution\r\n\r\nStatistical significance\r\n‚Ä¢ Even if, on average, one artefact has lower \r\nenergy consumption than other,  it might be just \r\na random difference. \r\n‚Ä¢ When we extract a sample from a normal \r\ndistribution it will never be the exact same \r\n‚Ä¢ Statistical significance tests help you \r\nunderstand the differences in the average are \r\nconclusive/significant or inconclusive/\r\ninsignificant.\r\n21\r\n‚ö† assuming normal distribution\r\n\r\nStatistical significance test\r\n‚Ä¢ Two-sided parametric test Welch‚Äôs t-test. \r\n‚Ä¢ Less known alternative to student‚Äôs t-test.\r\n22\r\nWelch‚Äôs t-test in Python\r\nfrom scipy.stats import ttest_ind \r\n_,pvalue = ttest_ind(sample_a, sample_b, \r\n                     equal_var=False, \r\n                     alternative='two-sided')\r\n(?)\r\n‚ö† assuming normal distribution\r\n\r\nEffect Size analysis\r\n‚Ä¢ Now that we know that results are statistically significant we need to \r\nmeasure the difference between the two samples. \r\n‚Ä¢ Mean difference: \r\n \r\n‚Ä¢ Percent change: \r\n \r\n‚Ä¢ Cohen‚Äôs d (informal definition: mean difference normalized by a combined \r\nstandard deviation): \r\nŒî¬Øx\r\nxB ‚àíxA\r\nxA\r\n√ó 100 % = Œî¬Øx\r\nxA\r\n√ó 100 %\r\nŒî¬Øx\r\n1\r\n2\r\ns21 + s22\r\n23\r\n‚ö† assuming normal distribution\r\n\r\nImagine that version A spends 70J and \r\nversion B spends 69J with a \r\n."", ""‚Ä¢ 6 machine learning algorithms: SVM, Decision Tree, KNN, Random Forrest, \r\nAdaBoost, Bagging Classifier. \r\n‚Ä¢ Reduce the number of rows. 10%, 20%, .., 100% \r\n‚Ä¢ Stratified random sampling (?) \r\n‚Ä¢ Reduce the number of features. 10%, 20%, .., 100% \r\n‚Ä¢ Feature importance metric based on the Chi-Square Test (Chi2) \r\n‚Ä¢ Estimate energy consumption using a RAPL-based tool. (?)\r\n18\r\n\r\n‚Ä¢ Repeat 30 times \r\n‚Ä¢ Fix random seeds \r\n‚Ä¢ ‚Ä¶ \r\n‚Ä¢ Data was not Normal => tailed Normal distribution.\r\n19\r\n(?)\r\n\r\nResults: energy consumption of algorithms\r\n\r\nResults: energy vs data shape\r\n\r\nResults: performance vs data shape\r\n\r\nDiscussion\r\n‚Ä¢ Other data properties should be investigated. \r\n‚Ä¢ E.g., data types \r\n‚Ä¢ Reporting energy data is essential. It can lead to different model selection \r\nwithout hindering model performance. \r\n‚Ä¢ There is a big opportunity in Model and Data Simplification.\r\n23\r\n\r\nData/Model Simplification\r\n‚Ä¢ (?) \r\n‚Ä¢ Data selection \r\n‚Ä¢ Data quantisation. Posit? \r\n‚Ä¢ Data distillation \r\n‚Ä¢ Coreset extraction (?) \r\n‚Ä¢ Model distillation \r\n‚Ä¢ Model quantisation \r\n‚Ä¢ Model pruning \r\n‚Ä¢ ‚Ä¶\r\n24\r\n\r\nPosit vs Float\r\nMore about this: https://spectrum.ieee.org/floating-point-numbers-posits-processor\r\nBetter for DL use cases\r\n\r\nHow can we tune \r\nlearning \r\nparameters \r\nefficiently?\r\n\r\nHyper parameter tuning\r\n‚Ä¢ When training an ML model, there are several parameters that need to be \r\ntuned. \r\n‚Ä¢ E.g., in SVM we have the Regularization parameter C, the kernel function, \r\nthe degree of the kernel function, and depending on the case, many other. \r\n‚Ä¢ The common approach revolves around grid search. The user provides a \r\nsequence of possible values for each parameter and the pipeline runs all \r\npossible combinations. \r\n‚Ä¢ Our question: Can we save energy with alternative approaches? \r\n‚Ä¢ We studied Grid Search, Random Search and Bayesian \r\nOptimisation.\r\n27\r\nTim's MSc Thesis, 2022 \r\nAccepted at CAIN‚Äô23\r\n\r\n\r\nResults\r\n29\r\nConclusions? \r\n‚Ä¢ Bayesian converges faster. \r\n‚Ä¢ No clear winner between Grid and Random\r\n\r\nDeepSeekMoE\r\n30\r\nPreprint at ArXiv, 2024 https://arxiv.org/pdf/\r\n2401.06066\r\n\r\nMixture of Experts\r\n‚Ä¢ Llama3.1 has 405B parameters, DeepSeek V3 671B \r\n‚Ä¢ Yet DeepSeek has quicker inference times and claims less energy \r\nconsumption (?) \r\n‚Ä¢ Divide the model into smaller blocks of experts \r\n‚Ä¢ Tokens get routed to certain experts based on the query \r\n‚Ä¢ Only part of the network is active during inference \r\n‚Ä¢ DeepSeek claims only 37B out of 671B parameters get active\r\n31\r\n\r\nDeepSeekMoE\r\n32\r\n\r\nDeepSeekMoE\r\n33\r\n‚Ä¢ Comparable performance to \r\nLLaMA2 7B effectively using \r\nless half the parameters \r\n‚Ä¢ Less computational power \r\n‚Ä¢ Problems (?) \r\n‚Ä¢ Still need to load all the \r\nparameters \r\n‚Ä¢ High memory -> high \r\nembodied carbon\r\n\r\nGreen AI at FacebookMeta\r\n34\r\nSustainable AI: Environmental Implications, \r\nChallenges and Opportunities (2022)\r\n\r\nCarbon footprint mapped to the AI lifecycle\r\n‚Ä¢ There are 4 main overarching stages where carbon emissions need to be isolated: data \r\ncollection, experimentation, training, inference. \r\n‚Ä¢ At Facebook, recommendation systems split energy consumption evenly between \r\ntraining and inference; text translation models have a 35%/65% split. (Operational cost) \r\n‚Ä¢ Operational/embodied cost split: 30%/70%\r\n35\r\n\r\nOpen issues according to Meta\r\n‚Ä¢ A vast portion of projects only use GPUs at 30%.\u2028\r\nShould be higher to attenuate embodied carbon."", ""‚Ä¢ Visualise distribution shape: violin plots, histograms, density plot.\u2028\r\n \r\n‚Ä¢ Shapiro-Wilk test.\u2028\r\ndata is not normal;\u2028\r\nwe are not sure but it is okay to assume that data is \r\nnormal.\r\np-value < 0.05 ‚áí\r\np-value ‚â•0.05 ‚áí\r\n19\r\n\r\nAfter having all data ready, which artefact \r\nis more energy efficient(?) \r\nFirst approach: compare sample means. \r\n‚ö† assuming normal distribution\r\n\r\nStatistical significance\r\n‚Ä¢ Even if, on average, one artefact has lower \r\nenergy consumption than other,  it might be just \r\na random difference. \r\n‚Ä¢ When we extract a sample from a normal \r\ndistribution it will never be the exact same \r\n‚Ä¢ Statistical significance tests help you \r\nunderstand the differences in the average are \r\nconclusive/significant or inconclusive/\r\ninsignificant.\r\n21\r\n‚ö† assuming normal distribution\r\n\r\nStatistical significance test\r\n‚Ä¢ Two-sided parametric test Welch‚Äôs t-test. \r\n‚Ä¢ Less known alternative to student‚Äôs t-test.\r\n22\r\nWelch‚Äôs t-test in Python\r\nfrom scipy.stats import ttest_ind \r\n_,pvalue = ttest_ind(sample_a, sample_b, \r\n                     equal_var=False, \r\n                     alternative='two-sided')\r\n(?)\r\n‚ö† assuming normal distribution\r\n\r\nEffect Size analysis\r\n‚Ä¢ Now that we know that results are statistically significant we need to \r\nmeasure the difference between the two samples. \r\n‚Ä¢ Mean difference: \r\n \r\n‚Ä¢ Percent change: \r\n \r\n‚Ä¢ Cohen‚Äôs d (informal definition: mean difference normalized by a combined \r\nstandard deviation): \r\nŒî¬Øx\r\nxB ‚àíxA\r\nxA\r\n√ó 100 % = Œî¬Øx\r\nxA\r\n√ó 100 %\r\nŒî¬Øx\r\n1\r\n2\r\ns21 + s22\r\n23\r\n‚ö† assuming normal distribution\r\n\r\nImagine that version A spends 70J and \r\nversion B spends 69J with a \r\n.\r\np-value = 0.04\r\nOn average, version B spent less energy than version A  ‚Äî  ‚úÖ \r\nThere is statistical significance ‚Äî  ‚úÖ \r\nEffect size, percent-change is ‚âà1% ‚Äî ü§î \r\n‚ö† Do we care?\r\n(?)\r\n\r\nPractical Significance\r\n‚Ä¢ Depending on the case, a 2% improvement might be either wonderful or completely \r\nuseless. \r\n‚Ä¢ Effect size analyses help assess practical significance but might not be enough. \r\n‚Ä¢ A critical discussion always needs to be performed. Consider context and explain in what \r\nsense the effect size might be relevant. \r\n‚Ä¢ E.g.: \r\n‚Ä¢  to improve 2% in energy efficiency the code will be less readable or the user \r\nexperience is not so appealing. \r\n‚Ä¢ A particular method improves 2% but it will only be used 1% of the time. \r\n‚Ä¢ There is no particular metric or structure, but this kind of critical analysis is very important.\r\n25\r\n\r\nWhat if data is not Normal?\r\nSame approach but different tests/metrics!\r\n\r\nNon-normal data\r\n‚Ä¢ Statistical significance: non-parametric test (?) \r\n‚Ä¢ Mann-Whitney U test. Instead of looking at standard deviation or mean, it orders \r\nsamples and compares with each other. \r\n‚Ä¢ Less power than parametric-tests (?) \r\n‚Ä¢ Effect size \r\n‚Ä¢ Median difference: \r\n \r\n‚Ä¢ Percentage of pairs supporting a conclusion\u2028\r\n(i.e., # pairs where version A > version B/ total pairs) \r\n‚Ä¢ Common language effect size: \r\nŒîM\r\nU1\r\nN1N2\r\n27\r\n\r\nRecap\r\nImpossible to \r\nfix but \r\nexplainable."", '8. Green AI\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nLu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\nCarolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl\r\n\r\n- Overview of Green AI \r\n- Large language models \r\n- Green data-centric AI \r\n- Model simplification \r\n- Hyper parameter tuning \r\n- Mixture of Experts and DeepSeek \r\n- Green AI at Meta \r\n\r\nAI\r\n‚Ä¢ Artificial Intelligence (AI) is the branch of computer science that deals with \r\nautomating tasks that typically require human intelligence. \r\n‚Ä¢ In the past years AI has been widely applied across different domains.\u2028\r\nE.g., health care, transportation, finance. \r\n‚Ä¢ To deploy AI systems, we test them against benchmarks (or validation sets). \r\n‚Ä¢ The goal is to outperform the previous existing models. \r\n‚Ä¢ E.g., in Machine Learning we usually resort to accuracy metrics. The \r\nhighest the accuracy, the better the model.\r\n3\r\n\r\nSince 2012, the amount of computing used for AI \r\ntraining has been doubling every 6 months\r\n‚Ä¢ https://epoch.ai/blog/compute-trends\r\n4\r\n\r\n‚Ä¢ To create better AI systems we are currently adding \r\n‚Ä¢ More data \r\n‚Ä¢ More experiments \r\n‚Ä¢ Larger models\r\n5\r\n\r\nThe Equation of Red AI\r\nCost(R) ‚àùE¬∑D¬∑H\r\nCost of a single (E)xample\r\nSize of (D)ataset\r\nNumber of (H)yperparameters\r\nBy Schwartz et al. (2020)\r\n\r\nIssues of Red AI\r\n‚Ä¢ High costs (hardware, electricity, data access, etc.) \r\n‚Ä¢ Limited reproducibility.  \r\n‚Ä¢ Energy consumption. \r\n‚Ä¢ Carbon emissions. \r\n‚Ä¢ SMEs can hardly be competitive. \r\n‚Ä¢ Groundbreaking AI research is mostly done by tech giants.\r\n7\r\n\r\nA few examples of Red AI\r\n‚Ä¢ Google‚Äôs BERT-large \r\n‚Ä¢ 350 million features \r\n‚Ä¢ Trained for 2.5 days using 512 TPU chips, costing $60K+ \r\n‚Ä¢ Open-GPT3 (now GPT-4/o1) \r\n‚Ä¢ 550 tonnes CO2-eq (Patterson, 2021) \r\n‚Ä¢ 175 billion features \r\n‚Ä¢ API is open but no-pretrained model is available \r\n‚Ä¢ AlphaGo \r\n‚Ä¢ 1920 CPUs, 280 GPUs, costing $35M\r\n8\r\n\r\nRed AI in Large Language Models (LLMs)\r\n‚Ä¢ OPT by Meta reports 75 tons CO2-eq (1/7 of OpenGPT‚Äôs footprint).\u2028\r\n(Also 175billion params) \r\n‚Ä¢ However, Llama 3 reported 2,290 tons of CO2-eq (7.7M GPU hours \r\ntraining ) \r\n‚Ä¢ Open science: release includes both the pretrained models and the code \r\nneeded to train and use them. \r\n‚Ä¢ DeepSeek-V3 claims ‚Äúonly‚Äù 2.78M GPU hours \r\n‚Ä¢ Bloom by Huggingface reports 25 tons, 51 when considering embodied \r\nand operational carbon footprint. (176billion params)\r\n9\r\n\r\nRed AI\r\nAccuracy: 0.999999999\r\nGreen AI\r\n‚Ä¢ Energy \r\n‚Ä¢ Time \r\n‚Ä¢ Reproducibility \r\n‚Ä¢ Reusage\r\n\r\nHow can we adopt Green AI\r\n‚Ä¢ Check whether AI is needed. \r\n‚Ä¢ Select green datacenters. \r\n‚Ä¢ Run on low carbon intensity hours. \r\n‚Ä¢ Opt for GPU-optimised solutions (?) \r\n‚Ä¢ Opt for low-power hardware (e.g., Nvidia Jetson boards) \r\n‚Ä¢ Or GPUs that provide energy metrics (e.g., NVIDIA GPUs via the nvidia-smi tool) \r\n‚Ä¢ Report energy/carbon metrics (e.g., embed in MLFlow?)', '‚Ä¢ Groundbreaking AI research is mostly done by tech giants.\r\n7\r\n\r\nA few examples of Red AI\r\n‚Ä¢ Google‚Äôs BERT-large \r\n‚Ä¢ 350 million features \r\n‚Ä¢ Trained for 2.5 days using 512 TPU chips, costing $60K+ \r\n‚Ä¢ Open-GPT3 (now GPT-4/o1) \r\n‚Ä¢ 550 tonnes CO2-eq (Patterson, 2021) \r\n‚Ä¢ 175 billion features \r\n‚Ä¢ API is open but no-pretrained model is available \r\n‚Ä¢ AlphaGo \r\n‚Ä¢ 1920 CPUs, 280 GPUs, costing $35M\r\n8\r\n\r\nRed AI in Large Language Models (LLMs)\r\n‚Ä¢ OPT by Meta reports 75 tons CO2-eq (1/7 of OpenGPT‚Äôs footprint).\u2028\r\n(Also 175billion params) \r\n‚Ä¢ However, Llama 3 reported 2,290 tons of CO2-eq (7.7M GPU hours \r\ntraining ) \r\n‚Ä¢ Open science: release includes both the pretrained models and the code \r\nneeded to train and use them. \r\n‚Ä¢ DeepSeek-V3 claims ‚Äúonly‚Äù 2.78M GPU hours \r\n‚Ä¢ Bloom by Huggingface reports 25 tons, 51 when considering embodied \r\nand operational carbon footprint. (176billion params)\r\n9\r\n\r\nRed AI\r\nAccuracy: 0.999999999\r\nGreen AI\r\n‚Ä¢ Energy \r\n‚Ä¢ Time \r\n‚Ä¢ Reproducibility \r\n‚Ä¢ Reusage\r\n\r\nHow can we adopt Green AI\r\n‚Ä¢ Check whether AI is needed. \r\n‚Ä¢ Select green datacenters. \r\n‚Ä¢ Run on low carbon intensity hours. \r\n‚Ä¢ Opt for GPU-optimised solutions (?) \r\n‚Ä¢ Opt for low-power hardware (e.g., Nvidia Jetson boards) \r\n‚Ä¢ Or GPUs that provide energy metrics (e.g., NVIDIA GPUs via the nvidia-smi tool) \r\n‚Ä¢ Report energy/carbon metrics (e.g., embed in MLFlow?) \r\n‚Ä¢ Use pre-trained models (Transfer Learning) \r\n‚Ä¢ Preprocess dataset to reduce size. \r\n‚Ä¢ Improve parameter-tuning strategy.\r\n11\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ We need benchmarks. \r\n‚Ä¢ AllenAI leaderboard\u2028\r\nhttps://leaderboard.allenai.org \r\n‚Ä¢ No carbon metrics, yet \r\n‚Ä¢ Report comparable proxies for energy \r\nconsumption. \r\n‚Ä¢ ‚ö† Learning algorithms behave in a non-\r\ndeterministic \r\n‚Ä¢ ‚ö† Different data-points lead to different \r\nenergy consumption\r\n12\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ Reporting measured energy consumption \r\n‚Ä¢ + Accurate \r\n‚Ä¢ + Easy to map to carbon emissions \r\n‚Ä¢ - Hard to measure \r\n‚Ä¢ - Low replicability \r\n‚Ä¢ Reporting time / estimation based on time & hardware \r\n‚Ä¢ + Easy to measure \r\n‚Ä¢ + Correlates with energy consumption in most cases. \r\n‚Ä¢ -  Difficult to compare with measurements from other setups \r\n‚Ä¢ E.g., floating point operations (FPOs) (?) \r\n‚Ä¢ + comparable across different setups \r\n‚Ä¢ + cheap \r\n‚Ä¢ - does not factor in memory energy consumption \r\n‚Ä¢ - does not reflect carbon emissions\r\n13\r\n\r\nData-centric AI\r\n\r\nData-centric AI\r\n‚Ä¢ Emerging discipline that deals with systematically engineering data to build AI \r\nsystems. \r\n‚Ä¢ Shift from improving the training strategy to improving the data. \r\n‚Ä¢ It is better to have small but reliable datasets than large but noisy \r\ndatasets. \r\n‚Ä¢ => Improve data collection, data labelling, and data preprocessing. \r\n‚Ä¢ More about data-centric AI by Andrew Ng:\u2028\r\nhttps://www.youtube.com/watch?v=06-AZXmwHjo\r\n15\r\n\r\n\r\nGreen Data-centric AI\r\n‚Ä¢ How do different ML algorithms compare \r\nin terms of energy consumption? \r\n‚Ä¢ How does number of rows relate to the \r\nenergy consumption of ML models? \r\n‚Ä¢ How does number of features relate to \r\nthe energy consumption of ML models? \r\n‚Ä¢ What is the impact of reducing data in the \r\nperformance of the model?', 'p-value = 0.04\r\nOn average, version B spent less energy than version A  ‚Äî  ‚úÖ \r\nThere is statistical significance ‚Äî  ‚úÖ \r\nEffect size, percent-change is ‚âà1% ‚Äî ü§î \r\n‚ö† Do we care?\r\n(?)\r\n\r\nPractical Significance\r\n‚Ä¢ Depending on the case, a 2% improvement might be either wonderful or completely \r\nuseless. \r\n‚Ä¢ Effect size analyses help assess practical significance but might not be enough. \r\n‚Ä¢ A critical discussion always needs to be performed. Consider context and explain in what \r\nsense the effect size might be relevant. \r\n‚Ä¢ E.g.: \r\n‚Ä¢  to improve 2% in energy efficiency the code will be less readable or the user \r\nexperience is not so appealing. \r\n‚Ä¢ A particular method improves 2% but it will only be used 1% of the time. \r\n‚Ä¢ There is no particular metric or structure, but this kind of critical analysis is very important.\r\n25\r\n\r\nWhat if data is not Normal?\r\nSame approach but different tests/metrics!\r\n\r\nNon-normal data\r\n‚Ä¢ Statistical significance: non-parametric test (?) \r\n‚Ä¢ Mann-Whitney U test. Instead of looking at standard deviation or mean, it orders \r\nsamples and compares with each other. \r\n‚Ä¢ Less power than parametric-tests (?) \r\n‚Ä¢ Effect size \r\n‚Ä¢ Median difference: \r\n \r\n‚Ä¢ Percentage of pairs supporting a conclusion\u2028\r\n(i.e., # pairs where version A > version B/ total pairs) \r\n‚Ä¢ Common language effect size: \r\nŒîM\r\nU1\r\nN1N2\r\n27\r\n\r\nRecap\r\nImpossible to \r\nfix but \r\nexplainable.\r\n\r\nEnergy Efficiency Across \r\nProgramming Languages\r\nhttps://sites.google.com/view/energy-efficiency-languages\r\n29\r\nRui Pereira, Marco Couto, Francisco Ribeiro, Rui Rua, J√°come \r\nCunha, Jo√£o Paulo Fernandes, and Jo√£o Saraiva\r\n\r\n‚Ä¢ Is a faster programming language also more energy efficient? \r\n‚Ä¢ Comparing different programming languages is not an easy task. \r\n‚Ä¢ They differ in many mechanisms: \r\n‚Ä¢ Interpreted vs Compiled \r\n‚Ä¢ Optimisations at the compiler level \r\n‚Ä¢ Virtual machine \r\n‚Ä¢ Garbage collector \r\n‚Ä¢ Available libraries\r\n30\r\n\r\nResearch Questions\r\n‚Ä¢ Can we compare the energy efficiency of software languages?  \r\n‚Ä¢ Is the faster language always the most energy efficient? \r\n‚Ä¢ How does memory usage relate to energy consumption? (We don‚Äôt cover this one) \r\n‚Ä¢ Can we automatically decide what is the best programming language \r\nconsidering energy, time, and memory usage?  \r\n‚Ä¢ How do the results of our energy consumption analysis of programming \r\nlanguages gathered from rigorous performance benchmarking solutions \r\ncompare to results of average day-to-day solutions? \u2028\r\n31\r\n\r\nMethodology\r\n\r\nThe Computer Language Benchmarks Game \r\n‚Ä¢ https://benchmarksgame-team.pages.debian.net/benchmarksgame/\r\n33\r\n\r\nProblems in the Computer Language Benchmarks Game\r\n34\r\n\r\n‚Ä¢ 27 Programming languages across different paradigms  \r\n‚Ä¢ Functional (e.g., Ocaml, F#, Haskell) \r\n‚Ä¢ Imperative (e.g., C, Go, Python) \r\n‚Ä¢ Object-oriented (e.g., C++, C#, Java) \r\n‚Ä¢ Scripting (or interpretative) (e.g., JavaScript, Python, Ruby) \r\n‚Ä¢ (These are not mutual exclusive) \r\n‚Ä¢ Intel RAPL‚Äôs C library to measure energy consumption\r\n35\r\n\r\n‚Ä¢ Execute each benchmark solution 10 times. \r\n‚Ä¢ Collect energy data and timestamps. \r\n‚Ä¢ Two-minute interval between executions\r\n36\r\n\r\n\r\n\r\n\r\nCritical thinking\r\n‚Ä¢ There is no doubt this is an excellent study. Yet, as any excellent study, there‚Äôs \r\na lot we can discuss and criticise constructively. \r\n‚Ä¢ What kind of issues you see in drawing conclusions from such a table of \r\nresults?', '‚Ä¢ Deadline April 4.\r\n6\r\n\r\nStrategy\r\n‚Ä¢ Week 0 \r\n‚Ä¢ Decide project idea (today) \r\n‚Ä¢ Define steering meeting schedule \r\n‚Ä¢ Create working document of the \r\narticle: Problem statement and solution \r\nproposal! \r\n‚Ä¢ Define and assign tasks for each week. \r\n‚Ä¢ Week 1 \r\n‚Ä¢ Implementation \r\n‚Ä¢ Agreements with supervisor. \r\n‚Ä¢ Week 2 \r\n‚Ä¢ Implementation \r\n‚Ä¢ Week 3 \r\n‚Ä¢ Implementation, Full draft of article, \r\ndissemination. \r\n‚Ä¢ Week 4 \r\n‚Ä¢ Final refinements \r\n‚Ä¢ Prepare presentation\r\n7\r\n\r\nProject ideas\r\n‚Ä¢ A1. Prototype cross-machine comparable benchmarks \r\n‚Ä¢ A2. Add energy metrics to LMstudio/Ollama \r\n‚Ä¢ A3. Visualizations built-in with EnergiBridge \r\n‚Ä¢ A4. Service-based version of EnergiBridge\r\n\r\nProject ideas\r\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \r\n‚Ä¢ B2. Study test generation energy consumption \r\n‚Ä¢ B3. Energy profiling of static analysis tools \r\n‚Ä¢ B4. Detailed energy profiling of build pipelines \r\n‚Ä¢ B5. Tool supporting SusAF workshop / process \r\n‚Ä¢ B6. Dataset of government-developed OS software \r\n‚Ä¢ B7. Queue - but better for the student / TA society\r\nQuality Assurance & Testing\r\nSocial & Individual \u2028\r\nSustainability\r\n\r\nProject ideas\r\n‚Ä¢ C1. Compare energy consumption of docker images for ML workloads. \r\n‚Ä¢ C2. Create a plugin to visualize Hugging Face carbon emissions in detail. \r\n‚Ä¢ C3. Plugin for ChatGPT (footprint per chat window) \r\n‚Ä¢ C4. NutriScore for software libraries. \r\n‚Ä¢ C5. Add energy-awareness to existing software \r\n‚Ä¢ C6. Green Shift Left \r\n‚Ä¢ C7. Education for Sustainable SE\r\n\r\nA1. Prototype cross-machine comparable benchmarks\r\n‚Ä¢ Energy-usage comparisons require running both baseline + software on the \r\nsame machine ‚Üí limits how extensive our experiments can be \r\n‚Ä¢ Research community is in need of benchmarks that make energy \r\nmeasurements comparable even if executed on different machines \r\n‚Ä¢ Focus on a single task or model (i.e. computing vision, classification)\r\n\r\nA2. Adding energy metrics to LMstudio/Ollama\r\n‚Ä¢ Make energy consumption visible to users \r\nwithin local chat-interface for LLMs \r\n‚Ä¢ LMstudio/Ollama are tools for easy \r\ndeployment of LLMs \r\n‚Ä¢ Do not show energy metrics \r\n‚Ä¢ Add energy metrics to LMstudio-python \r\nor Ollama\r\nhttps://lmstudio.ai/\r\n\r\nA3. Visualizations built-in with EnergiBridge\r\n‚Ä¢ EnergiBridge simplifies energy measurement, but analysis & visualization is \r\nstill left to the user \r\n‚Ä¢ Extend the tool with well-chosen visualizations and analyses directly from the \r\nprovided data\r\n\r\nA4. Service-based version of EnergiBridge\r\n‚Ä¢ Simplify interaction & setup with EnergiBridge \r\n‚Ä¢ Service that runs independently, start/stop signals over RPC to manage \r\nexperiments \r\n‚Ä¢ Potential: create EnergiBridge interface for other prog. lang\r\n\r\nB1. Measure energy consumption of single JUnit tests\r\n‚Ä¢ We‚Äôd like to identify energy anti patterns in unit tests \r\n‚Ä¢ As a first step, we need tooling to measure and compare the energy \r\nconsumption of single unit tests \r\n‚Ä¢ Ideally including preliminary analysis looking at potential reasons for high-\r\nenergy-consuming tests\r\n\r\nB2. Study test generation energy consumption\r\n‚Ä¢ Automatic test generation mainly focuses on making strong test suites \r\n‚Ä¢ Do different techniques and configurations impact the energy consumption \r\nduring generation? \r\n‚Ä¢ Preferably focus on non-LLM test generation methods (EvoSuite, Pyguin, \r\nDSpot)\r\n\r\nB3. Detailed energy profiling of build pipelines\r\n‚Ä¢ Automatic builds have become a cornerstone of quality assurance.']","[""<1-hop>\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant"", '<2-hop>\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \n(not publicly available) doi:10.1037/h0042519\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568', ""<1-hop>\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant"", '<2-hop>\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \n(not publicly available) doi:10.1037/h0042519\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568', ""<1-hop>\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant"", '<2-hop>\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \n(not publicly available) doi:10.1037/h0042519\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568']","Spiking neural networks (SNNs) and the McCulloch-Pitts model both relate to the concept of neural computation, but they differ significantly in complexity and biological realism.

The McCulloch-Pitts model, developed in the 1940s, is a simplified representation of a neuron that computes basic logic functions using binary outputs (spike = 1, no spike = 0). It laid the groundwork for artificial neural networks by modeling neurons as simple threshold units that sum inputs and produce an output if a certain threshold is exceeded.

Spiking neural networks, on the other hand, are a more biologically realistic model of neural computation. They incorporate the concept of time into their computations, with neurons emitting spikes at specific times rather than producing continuous outputs. This allows SNNs to model more complex temporal dynamics and processes such as coincidence detection, which can be computed with a single spiking neuron but requires multiple units in a McCulloch-Pitts model.

In summary, while the McCulloch-Pitts model provides a foundational, simplified view of neural computation, spiking neural networks offer a more detailed and time-sensitive approach that aligns more closely with biological neural processes.","Spiking neural networks relate to the McCulloch-Pitts model by building upon the foundational concepts of neural computation, where the McCulloch-Pitts model introduced the idea of binary neuron states, which is extended in spiking networks to model more complex information processing through spike timing and patterns.",0.24285714284499998,1.0,1.0,0.9,,0.9369144938783666
How spiking neural networks used in encoding strategies?,"[""- Higher firing rate (spikes per unit time) for \r\n'selected' feature.\r\nAdapted from Hubel & Wiesel, 1959\r\n\r\nFiring rates\r\nClassical view of the brain:\r\n- Each neuron is selective for one specific \r\nfeature in the input.\r\n- Higher firing rate (spikes per unit time) for \r\n'selected' feature.\r\n- Link to modern ANNs: The scalar output of \r\nan artificial neuron is interpreted as the firing \r\nrate.\r\nAdapted from Hubel & Wiesel, 1959\r\n\r\nFiring rates\r\nClassical view of the brain:\r\n- Each neuron is selective for one specific \r\nfeature in the input.\r\n- Higher firing rate (spikes per unit time) for \r\n'selected' feature.\r\n- Link to modern ANNs: The scalar output of \r\nan artificial neuron is interpreted as the firing \r\nrate.\r\nAdapted from Hubel & Wiesel, 1959\r\nBut rate coding is inefficient and slow‚Ä¶\r\n(i.e. each neuron needs to fire many spikes to get good precision)\r\nboth in vivo and in silico.\r\n\r\nDifferent encoding strategies with spiking neurons [8]\r\n7 neurons\r\n7 time bins\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nn\r\n6\r\n(in the general \r\ncase a \r\nnumber \r\nbetween 0-7)\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nn\r\nTotal spike \r\ncount can \r\nencode 3 bits.\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nIndividual rates \r\ncan encode 7 \r\nbits.\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nLatency can \r\nencode ~3*7 or \r\n~19 bits.\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nRank order can \r\nencode ~12 bits.\r\n\r\nDifferent encoding strategies with spiking neurons\r\n\r\nDifferent encoding strategies with spiking neurons\r\nUsing latency or spatio-temporal codes\r\nour encoding is faster and more spike-efficient (sparser)!\r\n\r\nDifferent encoding strategies with spiking neurons\r\nUsing latency or spatio-temporal codes\r\nour encoding is faster and more spike-efficient (sparser)!\r\nQuestions?\r\n\r\nNeuromorphic computing\r\nWhat is the advantage for applications?\r\n-\r\nLess spikes = less energy consumption in specialized neuromorphic hardware\r\n(e.g. Intel Loihi [12])\r\nBrains are energy efficient: \r\n2. Sparse encoding\r\n\r\nMultiply-accumulate (MAC) operations:\r\nNormal neuron: Multiplies input with \r\nweights, then adds.\r\nSpiking neuron: Consider binary input (e.g. input currents are piecewise \r\nconstant and assume values {0,1}). There is no multiplication, only addition.\r\n\r\nAssume one multiplier and one adder circuit uses M and A energy respectively with AÔπ§M\r\n(e.g., for a 45nm CMOS process, standard energy usage is A = 0.9 pJ and M = 3.7 pJ).\r\nNormal neuron: nin x nout multiplications,\r\n(nin‚Äì 1) x nout additions\r\nSpiking neuron: 0 multiplications, (nactive‚Äì 1) x nout \r\nadditions, with nactive ‚â§ nin\r\nEnergy consumption:\r\nEnormal = M nin nout + A (nin‚Äì 1) nout = 17.5 pJ\r\nEnergy consumption:\r\nEspiking = A (nactive‚Äì 1) nout = 2.7 pJ\r\nMultiply-accumulate (MAC) operations:\r\n\r\nAssume one multiplier and one adder circuit uses M and A energy respectively with AÔπ§M\r\n(e.g., for a 45nm CMOS process, standard energy usage is A = 0.9 pJ and M = 3.7 pJ)."", ""Spiking neural network (SNN): The 'input current' Œµ(t) is integrated over time.\r\nspike\r\n\r\nHow to model spiking neurons?\r\nEquivalence to perceptron: Computation at least as complex as a perceptron.\r\n\r\nNon-leaky integrate-and-fire (IF) neuron\r\nThe temporal profile of the input current Œµ(t) can be chosen differently, for different computations.\r\n\r\nQuestions?\r\n\r\nComputation with spiking neurons\r\nCoincidence detection\r\n\r\nComputation with spiking neurons\r\nCoincidence detection\r\nx, y ‚àà {0, 1}n\r\nExample: n = 2\r\ninput = \r\nx1\r\nx2\r\ny1\r\ny2\r\n= \r\n0\r\n1\r\n1\r\n1\r\noutput? \r\n\r\nCoincidence detection\r\nComputation with spiking neurons\r\n\r\nCoincidence detection\r\nCan be trivially computed with a single spiking neuron! Requires at least n/log(n+1) hidden \r\nunits for a perceptron (proof in [7]).\r\nComputation with spiking neurons\r\n\r\nCoincidence detection\r\nCan be trivially computed with a single spiking neuron! Requires at least n/log(n+1) hidden \r\nunits for a perceptron (proof in [7]).\r\nBrains are energy efficient: \r\n1.\r\nHigh temporal resolution (more computation with less neurons)\r\nComputation with spiking neurons\r\n\r\nEncoding strategies\r\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\r\nHow should we encode information about 'features' in a large network with many spikes?\r\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\r\nElephant?\r\nhttps://www.nationalgeographic.com/anim\r\nals/mammals/facts/african-elephant\r\n\r\nFiring rates\r\nClassical view of the brain:\r\n- Each neuron is selective for one specific \r\nfeature in the input.\r\n- Higher firing rate (spikes per unit time) for \r\n'selected' feature.\r\nAdapted from Hubel & Wiesel, 1959\r\n\r\nFiring rates\r\nClassical view of the brain:\r\n- Each neuron is selective for one specific \r\nfeature in the input.\r\n- Higher firing rate (spikes per unit time) for \r\n'selected' feature.\r\n- Link to modern ANNs: The scalar output of \r\nan artificial neuron is interpreted as the firing \r\nrate.\r\nAdapted from Hubel & Wiesel, 1959\r\n\r\nFiring rates\r\nClassical view of the brain:\r\n- Each neuron is selective for one specific \r\nfeature in the input.\r\n- Higher firing rate (spikes per unit time) for \r\n'selected' feature.\r\n- Link to modern ANNs: The scalar output of \r\nan artificial neuron is interpreted as the firing \r\nrate.\r\nAdapted from Hubel & Wiesel, 1959\r\nBut rate coding is inefficient and slow‚Ä¶\r\n(i.e. each neuron needs to fire many spikes to get good precision)\r\nboth in vivo and in silico.\r\n\r\nDifferent encoding strategies with spiking neurons [8]\r\n7 neurons\r\n7 time bins\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nn\r\n6\r\n(in the general \r\ncase a \r\nnumber \r\nbetween 0-7)\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nn\r\nTotal spike \r\ncount can \r\nencode 3 bits.\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nIndividual rates \r\ncan encode 7 \r\nbits.\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nLatency can \r\nencode ~3*7 or \r\n~19 bits.\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nRank order can \r\nencode ~12 bits."", 'Different encoding strategies with spiking neurons\r\n\r\nDifferent encoding strategies with spiking neurons\r\nUsing latency or spatio-temporal codes\r\nour encoding is faster and more spike-efficient (sparser)!\r\n\r\nDifferent encoding strategies with spiking neurons\r\nUsing latency or spatio-temporal codes\r\nour encoding is faster and more spike-efficient (sparser)!\r\nQuestions?\r\n\r\nNeuromorphic computing\r\nWhat is the advantage for applications?\r\n-\r\nLess spikes = less energy consumption in specialized neuromorphic hardware\r\n(e.g. Intel Loihi [12])\r\nBrains are energy efficient: \r\n2. Sparse encoding\r\n\r\nMultiply-accumulate (MAC) operations:\r\nNormal neuron: Multiplies input with \r\nweights, then adds.\r\nSpiking neuron: Consider binary input (e.g. input currents are piecewise \r\nconstant and assume values {0,1}). There is no multiplication, only addition.\r\n\r\nAssume one multiplier and one adder circuit uses M and A energy respectively with AÔπ§M\r\n(e.g., for a 45nm CMOS process, standard energy usage is A = 0.9 pJ and M = 3.7 pJ).\r\nNormal neuron: nin x nout multiplications,\r\n(nin‚Äì 1) x nout additions\r\nSpiking neuron: 0 multiplications, (nactive‚Äì 1) x nout \r\nadditions, with nactive ‚â§ nin\r\nEnergy consumption:\r\nEnormal = M nin nout + A (nin‚Äì 1) nout = 17.5 pJ\r\nEnergy consumption:\r\nEspiking = A (nactive‚Äì 1) nout = 2.7 pJ\r\nMultiply-accumulate (MAC) operations:\r\n\r\nAssume one multiplier and one adder circuit uses M and A energy respectively with AÔπ§M\r\n(e.g., for a 45nm CMOS process, standard energy usage is A = 0.9 pJ and M = 3.7 pJ).\r\nNormal neuron: nin x nout multiplications,\r\n(nin‚Äì 1) x nout additions\r\nSpiking neuron: 0 multiplications, (nactive‚Äì 1) x nout \r\nadditions, with nactive ‚â§ nin\r\nEnergy consumption:\r\nEnormal = M nin nout + A (nin‚Äì 1) nout = 17.5 pJ\r\nEnergy consumption:\r\nEspiking = A (nactive‚Äì 1) nout = 2.7 pJ\r\nMultiply-accumulate (MAC) operations:\r\nSNN challenge: how to \r\ncompute with the least \r\namount of spikes!\r\n\r\nOften, we observe a \r\nsparsity (energy)-\r\ntask accuracy trade-off\r\n(Left: results for image \r\nclassification)\r\nSNN challenge: how to \r\ncompute with the least \r\namount of spikes!\r\nhttps://arxiv.org/pdf/2409.08290\r\n\r\nIn practice, energy \r\nconsumption computations \r\nare complex. \r\nNeed to take into account\r\n- memory access,\r\n- addressing,\r\n- auxiliary operations,\r\nin addition to MACs.\r\nEstimated energy consumption for 3 different datasets (CIFAR10, GSC, NCARS; image, sound \r\nand video classification respectively). FNN‚Äôs are conventional feed-forward neural networks.\r\nIn this example: SNNs are 6 to 8 times more energy efficient than FNNs.\r\nhttps://arxiv.org/pdf/2210.13107\r\nComputing energy consumption\r\n\r\nIn practice, energy \r\nconsumption computations \r\nare complex. \r\nNeed to take into account\r\n- memory access,\r\n- addressing,\r\n- auxiliary operations,\r\nin addition to MACs.\r\nEstimated energy consumption for 3 different datasets (CIFAR10, GSC, NCARS; image, sound \r\nand video classification respectively). FNN‚Äôs are conventional feed-forward neural networks.\r\nIn this example: SNNs are 6 to 8 times more energy efficient than FNNs.', 'Normal neuron: nin x nout multiplications,\r\n(nin‚Äì 1) x nout additions\r\nSpiking neuron: 0 multiplications, (nactive‚Äì 1) x nout \r\nadditions, with nactive ‚â§ nin\r\nEnergy consumption:\r\nEnormal = M nin nout + A (nin‚Äì 1) nout = 17.5 pJ\r\nEnergy consumption:\r\nEspiking = A (nactive‚Äì 1) nout = 2.7 pJ\r\nMultiply-accumulate (MAC) operations:\r\nSNN challenge: how to \r\ncompute with the least \r\namount of spikes!\r\n\r\nOften, we observe a \r\nsparsity (energy)-\r\ntask accuracy trade-off\r\n(Left: results for image \r\nclassification)\r\nSNN challenge: how to \r\ncompute with the least \r\namount of spikes!\r\nhttps://arxiv.org/pdf/2409.08290\r\n\r\nIn practice, energy \r\nconsumption computations \r\nare complex. \r\nNeed to take into account\r\n- memory access,\r\n- addressing,\r\n- auxiliary operations,\r\nin addition to MACs.\r\nEstimated energy consumption for 3 different datasets (CIFAR10, GSC, NCARS; image, sound \r\nand video classification respectively). FNN‚Äôs are conventional feed-forward neural networks.\r\nIn this example: SNNs are 6 to 8 times more energy efficient than FNNs.\r\nhttps://arxiv.org/pdf/2210.13107\r\nComputing energy consumption\r\n\r\nIn practice, energy \r\nconsumption computations \r\nare complex. \r\nNeed to take into account\r\n- memory access,\r\n- addressing,\r\n- auxiliary operations,\r\nin addition to MACs.\r\nEstimated energy consumption for 3 different datasets (CIFAR10, GSC, NCARS; image, sound \r\nand video classification respectively). FNN‚Äôs are conventional feed-forward neural networks.\r\nIn this example: SNNs are 6 to 8 times more energy efficient than FNNs.\r\nComputing energy consumption\r\nQuestions?\r\n\r\nReading materials\r\nMain reading:\r\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \r\nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\r\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\r\n- Neuromorphic computing:\r\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \r\nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\r\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \r\noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\r\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019.', ""Oversimplification\r\nThere are also multiple other advantages‚Ä¶\r\n\r\nHuman vs. computer computation\r\n- Fast real-time decision making, e.g. sports, e-sports\r\n- Adaptive, e.g. context-aware and employs selective attention\r\n- Energy efficient: Close to 100 billion neurons in the brain\r\n- Robust, for example to changes in illumination or obstructions in object tracking\r\n\r\nHuman vs. computer computation\r\nBrains are energy efficient: Why?\r\n1.\r\nHigh temporal resolution (more computation with less neurons)\r\n2.\r\nSparse encoding\r\n\r\nHuman vs. computer computation\r\nQuestions?\r\nBrains are energy efficient: Why?\r\n1.\r\nHigh temporal resolution (more computation with less neurons)\r\n2.\r\nSparse encoding\r\n\r\nHow do biological neurons communicate?\r\nAnalogy to artificial neural networks\r\nReal neuron\r\nArtificial neuron\r\nCurrent\r\n\r\nHow do biological neurons communicate?\r\nHow does the electrical activity propagate?\r\n?\r\nCurrent\r\n\r\nHow do biological neurons work?\r\ntime\r\nelectrode\r\nhttps://tinmard.github.io/spike-sorting-animation.html\r\nQuick electrical pulses trigger chemical signals for the next neuron ‚Üí Spikes\r\n\r\nHow do biological neurons work?\r\nQuick electrical pulses trigger chemical signals for the next neuron ‚Üí Spikes\r\nhttps://tinmard.github.io/spike-sorting-animation.html\r\ntime\r\nelectrode\r\nFrom CS perspective:\r\nSparse binary \r\nencoding\r\n\r\nBiologically realistic spiking neuron models\r\nBiologically realistic neuron models have \r\na new dimension: Time!\r\nSpiking neural networks (SNNs):\r\nThe input x  (t  ) to each neuron is summed \r\n(integrated) over time.\r\nscalar\r\nfunction of \r\ntime\r\n(t)\r\n(t)\r\nhttps://www.mdpi.com/2076-3425/12/7/863\r\n\r\nHow to model spiking neurons?\r\nANN: Perceptron, threshold activation function:\r\n\r\nHow to model spiking neurons?\r\nANN: Perceptron, threshold activation function:\r\n\r\nHow to model spiking neurons?\r\nSpiking neural network (SNN): The 'input current' Œµ(t) is integrated over time.\r\nspike\r\n\r\nHow to model spiking neurons?\r\nEquivalence to perceptron: Computation at least as complex as a perceptron.\r\n\r\nNon-leaky integrate-and-fire (IF) neuron\r\nThe temporal profile of the input current Œµ(t) can be chosen differently, for different computations.\r\n\r\nQuestions?\r\n\r\nComputation with spiking neurons\r\nCoincidence detection\r\n\r\nComputation with spiking neurons\r\nCoincidence detection\r\nx, y ‚àà {0, 1}n\r\nExample: n = 2\r\ninput = \r\nx1\r\nx2\r\ny1\r\ny2\r\n= \r\n0\r\n1\r\n1\r\n1\r\noutput? \r\n\r\nCoincidence detection\r\nComputation with spiking neurons\r\n\r\nCoincidence detection\r\nCan be trivially computed with a single spiking neuron! Requires at least n/log(n+1) hidden \r\nunits for a perceptron (proof in [7]).\r\nComputation with spiking neurons\r\n\r\nCoincidence detection\r\nCan be trivially computed with a single spiking neuron! Requires at least n/log(n+1) hidden \r\nunits for a perceptron (proof in [7]).\r\nBrains are energy efficient: \r\n1.\r\nHigh temporal resolution (more computation with less neurons)\r\nComputation with spiking neurons\r\n\r\nEncoding strategies\r\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\r\nHow should we encode information about 'features' in a large network with many spikes?\r\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\r\nElephant?\r\nhttps://www.nationalgeographic.com/anim\r\nals/mammals/facts/african-elephant\r\n\r\nFiring rates\r\nClassical view of the brain:\r\n- Each neuron is selective for one specific \r\nfeature in the input."", 'Power-efficiency at scale\r\nModern, deep neural networks*\r\nare trained using GPUs.\r\n* It is estimated that ChatGPT was trained on \r\n10,000-20,000 GPUs and that it will require\r\n30,000 GPUs to keep running stably in the future.\r\n* It is estimated that ChatGPT has 10-20 billion \r\nparameters.\r\nhttps://www.anandtech.com/show/4008/nvidias-geforce-gtx-580/17\r\n\r\nPower-efficiency at scale\r\nModern, deep neural networks*\r\nare trained using GPUs.\r\n* It is estimated that ChatGPT was trained on \r\n10,000-20,000 GPUs and that it will require\r\n30,000 GPUs to keep running stably in the future.\r\n* It is estimated that ChatGPT has 10-20 billion \r\nparameters.\r\nSingle model with 20 billion parameters:\r\n200 Watts x 30,000 GPUs = 6M Watts\r\n\r\nPower-efficiency at scale\r\nhttps://hai.stanford.edu/ai-index/2024-ai-index-report\r\nTraining a single large language model can \r\ngenerate greater CO2 emissions than the \r\ntotal lifetime emissions of 8 cars (in 2020)!\r\n\r\nPower-efficiency at scale\r\nhttps://hai.stanford.edu/ai-index/2024-ai-index-report\r\nTraining a single model can consume \r\nmore than 1000 MWh of power!\r\n\r\nPower-efficiency at scale\r\nhttps://hai.stanford.edu/ai-index/2024-ai-index-report\r\nTraining a single model can consume \r\nmore than 1000 MWh of power!\r\n‚Ä¶ with energy costs reaching 200M USD!\r\n\r\nPower-efficiency at scale\r\nYour brain runs on:\r\n\r\nPower-efficiency at scale\r\nYour brain runs on:\r\nHigh estimate ~3000 kcal a day\r\n   ‚âà145 Watts\r\n* Human brain has ~600 trillion synapses \r\n(‚âàparameters).\r\n\r\nPower-efficiency at scale\r\nYour brain runs on:\r\nHigh estimate ~3000 kcal a day\r\n   ‚âà145 Watts\r\n* Human brain has ~600 trillion synapses \r\n(‚âàparameters).\r\nOversimplification\r\nThere are also multiple other advantages‚Ä¶\r\n\r\nHuman vs. computer computation\r\n- Fast real-time decision making, e.g. sports, e-sports\r\n- Adaptive, e.g. context-aware and employs selective attention\r\n- Energy efficient: Close to 100 billion neurons in the brain\r\n- Robust, for example to changes in illumination or obstructions in object tracking\r\n\r\nHuman vs. computer computation\r\nBrains are energy efficient: Why?\r\n1.\r\nHigh temporal resolution (more computation with less neurons)\r\n2.\r\nSparse encoding\r\n\r\nHuman vs. computer computation\r\nQuestions?\r\nBrains are energy efficient: Why?\r\n1.\r\nHigh temporal resolution (more computation with less neurons)\r\n2.\r\nSparse encoding\r\n\r\nHow do biological neurons communicate?\r\nAnalogy to artificial neural networks\r\nReal neuron\r\nArtificial neuron\r\nCurrent\r\n\r\nHow do biological neurons communicate?\r\nHow does the electrical activity propagate?\r\n?\r\nCurrent\r\n\r\nHow do biological neurons work?\r\ntime\r\nelectrode\r\nhttps://tinmard.github.io/spike-sorting-animation.html\r\nQuick electrical pulses trigger chemical signals for the next neuron ‚Üí Spikes\r\n\r\nHow do biological neurons work?\r\nQuick electrical pulses trigger chemical signals for the next neuron ‚Üí Spikes\r\nhttps://tinmard.github.io/spike-sorting-animation.html\r\ntime\r\nelectrode\r\nFrom CS perspective:\r\nSparse binary \r\nencoding\r\n\r\nBiologically realistic spiking neuron models\r\nBiologically realistic neuron models have \r\na new dimension: Time!\r\nSpiking neural networks (SNNs):\r\nThe input x  (t  ) to each neuron is summed \r\n(integrated) over time.\r\nscalar\r\nfunction of \r\ntime\r\n(t)\r\n(t)\r\nhttps://www.mdpi.com/2076-3425/12/7/863\r\n\r\nHow to model spiking neurons?', '9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\r\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \r\nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\r\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \r\n(not publicly available) doi:10.1037/h0042519\r\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \r\nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\r\n6) https://github.com/idsc-frazzoli/retina\r\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \r\nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\r\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \r\nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\r\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \r\nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\r\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \r\nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\r\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \r\nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\r\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\r\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\r\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \r\n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568', ""‚Ä¢ Our question: Can we save energy with alternative approaches? \r\n‚Ä¢ We studied Grid Search, Random Search and Bayesian \r\nOptimisation.\r\n27\r\nTim's MSc Thesis, 2022 \r\nAccepted at CAIN‚Äô23\r\n\r\n\r\nResults\r\n29\r\nConclusions? \r\n‚Ä¢ Bayesian converges faster. \r\n‚Ä¢ No clear winner between Grid and Random\r\n\r\nDeepSeekMoE\r\n30\r\nPreprint at ArXiv, 2024 https://arxiv.org/pdf/\r\n2401.06066\r\n\r\nMixture of Experts\r\n‚Ä¢ Llama3.1 has 405B parameters, DeepSeek V3 671B \r\n‚Ä¢ Yet DeepSeek has quicker inference times and claims less energy \r\nconsumption (?) \r\n‚Ä¢ Divide the model into smaller blocks of experts \r\n‚Ä¢ Tokens get routed to certain experts based on the query \r\n‚Ä¢ Only part of the network is active during inference \r\n‚Ä¢ DeepSeek claims only 37B out of 671B parameters get active\r\n31\r\n\r\nDeepSeekMoE\r\n32\r\n\r\nDeepSeekMoE\r\n33\r\n‚Ä¢ Comparable performance to \r\nLLaMA2 7B effectively using \r\nless half the parameters \r\n‚Ä¢ Less computational power \r\n‚Ä¢ Problems (?) \r\n‚Ä¢ Still need to load all the \r\nparameters \r\n‚Ä¢ High memory -> high \r\nembodied carbon\r\n\r\nGreen AI at FacebookMeta\r\n34\r\nSustainable AI: Environmental Implications, \r\nChallenges and Opportunities (2022)\r\n\r\nCarbon footprint mapped to the AI lifecycle\r\n‚Ä¢ There are 4 main overarching stages where carbon emissions need to be isolated: data \r\ncollection, experimentation, training, inference. \r\n‚Ä¢ At Facebook, recommendation systems split energy consumption evenly between \r\ntraining and inference; text translation models have a 35%/65% split. (Operational cost) \r\n‚Ä¢ Operational/embodied cost split: 30%/70%\r\n35\r\n\r\nOpen issues according to Meta\r\n‚Ä¢ A vast portion of projects only use GPUs at 30%.\u2028\r\nShould be higher to attenuate embodied carbon.\r\n36\r\nBased on 10K AI projects\r\n\r\nData Jan\r\nInformed Adaptation\r\nData Feb\r\nData Mar\r\nData Apr\r\nData May\r\n‚Ä¶\r\n~Data Dec\r\n~Data Dec\r\nData Jan\r\nData Feb\r\nData Mar\r\nData Apr\r\nData May\r\n‚Ä¶\r\nModel update Model update Model update\r\nCheck if \r\ndata change\r\nCheck if \r\ndata change\r\nCheck if \r\ndata change\r\nModel update\r\nBlind Adaptation\r\nThe AI Model will be \r\nupdated fewer times and \r\nonly when necessary.\r\nKnow when to retrain models\r\nNeither too early nor too late\r\n37\r\nAdaptation Techniques\r\n?\r\n\r\nGreen Architectural Tactics for ML-Enabled \r\nSystem\r\n38\r\nICSE-SEIS 2024\r\n\r\nArchitectural tactics\r\n39\r\n\r\nData-centric\r\n40\r\n‚Ä¢ Reduce data size \r\n‚Ä¢ Sampling \r\n‚Ä¢ Dimensionality reduction \r\n‚Ä¢ Quantization\r\n\r\nAlgorithm Design\r\n41\r\n‚Ä¢ Carefully select your algorithm \r\n‚Ä¢ You don‚Äôt need the fanciest \r\ntechniques\r\n\r\nModel Optimization\r\n42\r\n‚Ä¢ Add energy to training parameters \r\n‚Ä¢ Reduce FLOPs \r\n‚Ä¢ Pruning, sparsity \r\n‚Ä¢  Take advantage of existing models\r\n\r\nModel Training\r\n43\r\n‚Ä¢ Quantization\r\n‚Ä¢ SAVE TRAINING PROGRESS\r\n\r\nModel Deployment\r\n44\r\n‚Ä¢ Distributed deployment \r\n‚Ä¢ Energy efficient hardware and \r\nconfigurations\r\n\r\nModel Management\r\n45\r\n‚Ä¢ Reuse the model as much as possible \r\n\r\nRethinking the Architecture: Spiking Neural Networks\r\n46\r\n\r\nRethinking the Architecture: Spiking Neural Networks\r\n47\r\n\r\nSELF Lab\r\n48\r\n\r\nrecap"", '575(7784):607-17. \r\nhttps://www.nature.com/articles/s41586-019-1677-2\r\nExtra reading:\r\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \r\nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\r\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \r\nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \r\nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\r\nBasics of \'conventional\' neural networks:\r\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\r\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.\r\n\r\nReferences\r\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \r\nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\r\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \r\n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\r\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \r\nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\r\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \r\n(not publicly available) doi:10.1037/h0042519\r\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \r\nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\r\n6) https://github.com/idsc-frazzoli/retina\r\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \r\nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\r\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \r\nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\r\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \r\nNeural Networks.', 'In this example: SNNs are 6 to 8 times more energy efficient than FNNs.\r\nComputing energy consumption\r\nQuestions?\r\n\r\nReading materials\r\nMain reading:\r\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \r\nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\r\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\r\n- Neuromorphic computing:\r\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \r\nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\r\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \r\noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\r\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \r\nhttps://www.nature.com/articles/s41586-019-1677-2\r\nExtra reading:\r\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \r\nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\r\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \r\nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \r\nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\r\nBasics of \'conventional\' neural networks:\r\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\r\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.\r\n\r\nReferences\r\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \r\nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\r\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947.', 'McCulloch-Pitts neuron [1, 2]\r\n1940s: How do biological neurons compute basic \r\nlogic functions? (e.g. logic gates)\r\nNote: Ref. [3] gives a nice brief history on the ideas which lead to the \r\nMcCulloch-Pitts neuron.\r\n\r\nWhat is a neural network?\r\n1950s: How are neurons organized to perform \r\nsensory perception?\r\n\r\nWhat is a neural network?\r\n1950s: How are neurons organized to perform \r\nsensory perception?\r\nThe first ""neural network"": Perceptron (1958). [4]\r\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\r\nFrank Rosenblatt (Psychologist)\r\nwith a Mark I Perceptron computer in 1960\r\n\r\nWhat is a neural network?\r\n1950s: How are neurons organized to perform \r\nsensory perception?\r\nThe first ""neural network"": Perceptron (1958). [4]\r\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\r\nFrank Rosenblatt (Psychologist)\r\nwith a Mark I Perceptron computer in 1960\r\nPower-efficient\r\n\r\nNeuromorphic computing\r\nWhy neuromorphic computing?\r\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\r\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\r\n\r\nNeuromorphic computing\r\nWhy neuromorphic computing?\r\n‚ÄòBiological inspiration‚Äô for artificial neural networks (ANNs) is not a new idea.\r\nEmulation (as opposed to simulation) of neural networks in hardware is not a new idea.\r\nQuestion: What can we gain from increasing biological realism in existing neural networks?\r\n\r\nPower-efficiency at scale\r\nModern, deep neural networks*\r\nare trained using GPUs.\r\n* It is estimated that ChatGPT was trained on \r\n10,000-20,000 GPUs and that it will require\r\n30,000 GPUs to keep running stably in the future.\r\n* It is estimated that ChatGPT has 10-20 billion \r\nparameters.\r\nhttps://www.anandtech.com/show/4008/nvidias-geforce-gtx-580/17\r\n\r\nPower-efficiency at scale\r\nModern, deep neural networks*\r\nare trained using GPUs.\r\n* It is estimated that ChatGPT was trained on \r\n10,000-20,000 GPUs and that it will require\r\n30,000 GPUs to keep running stably in the future.\r\n* It is estimated that ChatGPT has 10-20 billion \r\nparameters.\r\nSingle model with 20 billion parameters:\r\n200 Watts x 30,000 GPUs = 6M Watts\r\n\r\nPower-efficiency at scale\r\nhttps://hai.stanford.edu/ai-index/2024-ai-index-report\r\nTraining a single large language model can \r\ngenerate greater CO2 emissions than the \r\ntotal lifetime emissions of 8 cars (in 2020)!\r\n\r\nPower-efficiency at scale\r\nhttps://hai.stanford.edu/ai-index/2024-ai-index-report\r\nTraining a single model can consume \r\nmore than 1000 MWh of power!\r\n\r\nPower-efficiency at scale\r\nhttps://hai.stanford.edu/ai-index/2024-ai-index-report\r\nTraining a single model can consume \r\nmore than 1000 MWh of power!\r\n‚Ä¶ with energy costs reaching 200M USD!\r\n\r\nPower-efficiency at scale\r\nYour brain runs on:\r\n\r\nPower-efficiency at scale\r\nYour brain runs on:\r\nHigh estimate ~3000 kcal a day\r\n   ‚âà145 Watts\r\n* Human brain has ~600 trillion synapses \r\n(‚âàparameters).', 'Neuromorphic computing\r\nCS4575\r\nSustainable Software Engineering\r\n05.03.2025\r\nNergis T√∂men\r\n\r\nIntroduction\r\nComputer Vision Lab\r\nBiomorphic Intelligence Lab\r\nBiomedical Intervention Optimisation Lab\r\nNergis\r\n\r\nNeuromorphic computing\r\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\r\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\r\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing\r\n\r\nHow many of you are familiar \r\nwith neural networks?\r\n\r\nSimple model of an artificial neuron\r\nhttps://medium.com/@cprasenjit32/perceptron-a-simple-yet-mighty-machine-learning-algorithm-9ff6b7d86a71\r\n\r\nWhat is a neural network?\r\nhttps://www.tibco.com/reference-center/what-is-a-neural-network\r\n\r\nWhy is it called a \'neural network\'?\r\nhttps://www.tibco.com/reference-center/what-is-a-neural-network\r\n\r\nWhat is a neural network?\r\nWhy is it called a \'neural network\'?\r\nMcCulloch-Pitts neuron [1, 2] (1943)\r\nWarren Sturgis McCulloch\r\n(Neurophysiologist)\r\nWalter Pitts\r\n(Logician)\r\n\r\nHow do biological neurons work?\r\nhttps://commons.wikimedia.org/wiki/File:Coincidence_detection_in_dendrites_of_pyramidal_neurons.gif\r\n\'Input current\' travels down the dendrites (top),\r\nget integrated (summed!) in the cell body\r\nwhich generates an \'output current\' (bottom)\r\nwhich is chemically transmitted to the dendrites of \r\nother neurons.\r\n\r\nSimplified picture\r\nReal neuron\r\nArtificial neuron\r\nhttps://vajiramandravi.com/quest-upsc-notes/artificial-neural-network/\r\n\r\nWhat is a neural network?\r\nMcCulloch-Pitts neuron [1, 2]\r\n1940s: How do biological neurons compute basic \r\nlogic functions? (e.g. logic gates)\r\nNote: Ref. [3] gives a nice brief history on the ideas which lead to the \r\nMcCulloch-Pitts neuron.\r\n\r\nWhat is a neural network?\r\n1950s: How are neurons organized to perform \r\nsensory perception?\r\n\r\nWhat is a neural network?\r\n1950s: How are neurons organized to perform \r\nsensory perception?\r\nThe first ""neural network"": Perceptron (1958). [4]\r\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\r\nFrank Rosenblatt (Psychologist)\r\nwith a Mark I Perceptron computer in 1960\r\n\r\nWhat is a neural network?\r\n1950s: How are neurons organized to perform \r\nsensory perception?\r\nThe first ""neural network"": Perceptron (1958). [4]\r\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\r\nFrank Rosenblatt (Psychologist)\r\nwith a Mark I Perceptron computer in 1960\r\nPower-efficient\r\n\r\nNeuromorphic computing\r\nWhy neuromorphic computing?\r\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\r\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\r\n\r\nNeuromorphic computing\r\nWhy neuromorphic computing?\r\n‚ÄòBiological inspiration‚Äô for artificial neural networks (ANNs) is not a new idea.\r\nEmulation (as opposed to simulation) of neural networks in hardware is not a new idea.', '‚Ä¢ Improve parameter-tuning strategy.\r\n11\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ We need benchmarks. \r\n‚Ä¢ AllenAI leaderboard\u2028\r\nhttps://leaderboard.allenai.org \r\n‚Ä¢ No carbon metrics, yet \r\n‚Ä¢ Report comparable proxies for energy \r\nconsumption. \r\n‚Ä¢ ‚ö† Learning algorithms behave in a non-\r\ndeterministic \r\n‚Ä¢ ‚ö† Different data-points lead to different \r\nenergy consumption\r\n12\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ Reporting measured energy consumption \r\n‚Ä¢ + Accurate \r\n‚Ä¢ + Easy to map to carbon emissions \r\n‚Ä¢ - Hard to measure \r\n‚Ä¢ - Low replicability \r\n‚Ä¢ Reporting time / estimation based on time & hardware \r\n‚Ä¢ + Easy to measure \r\n‚Ä¢ + Correlates with energy consumption in most cases. \r\n‚Ä¢ -  Difficult to compare with measurements from other setups \r\n‚Ä¢ E.g., floating point operations (FPOs) (?) \r\n‚Ä¢ + comparable across different setups \r\n‚Ä¢ + cheap \r\n‚Ä¢ - does not factor in memory energy consumption \r\n‚Ä¢ - does not reflect carbon emissions\r\n13\r\n\r\nData-centric AI\r\n\r\nData-centric AI\r\n‚Ä¢ Emerging discipline that deals with systematically engineering data to build AI \r\nsystems. \r\n‚Ä¢ Shift from improving the training strategy to improving the data. \r\n‚Ä¢ It is better to have small but reliable datasets than large but noisy \r\ndatasets. \r\n‚Ä¢ => Improve data collection, data labelling, and data preprocessing. \r\n‚Ä¢ More about data-centric AI by Andrew Ng:\u2028\r\nhttps://www.youtube.com/watch?v=06-AZXmwHjo\r\n15\r\n\r\n\r\nGreen Data-centric AI\r\n‚Ä¢ How do different ML algorithms compare \r\nin terms of energy consumption? \r\n‚Ä¢ How does number of rows relate to the \r\nenergy consumption of ML models? \r\n‚Ä¢ How does number of features relate to \r\nthe energy consumption of ML models? \r\n‚Ä¢ What is the impact of reducing data in the \r\nperformance of the model? \r\n‚Ä¢ Method -> results -> discussion\r\n17\r\n\r\nMethod\r\n‚Ä¢ Single object of study: natural language model to detect spam messages. \r\n‚Ä¢ 6 machine learning algorithms: SVM, Decision Tree, KNN, Random Forrest, \r\nAdaBoost, Bagging Classifier. \r\n‚Ä¢ Reduce the number of rows. 10%, 20%, .., 100% \r\n‚Ä¢ Stratified random sampling (?) \r\n‚Ä¢ Reduce the number of features. 10%, 20%, .., 100% \r\n‚Ä¢ Feature importance metric based on the Chi-Square Test (Chi2) \r\n‚Ä¢ Estimate energy consumption using a RAPL-based tool. (?)\r\n18\r\n\r\n‚Ä¢ Repeat 30 times \r\n‚Ä¢ Fix random seeds \r\n‚Ä¢ ‚Ä¶ \r\n‚Ä¢ Data was not Normal => tailed Normal distribution.\r\n19\r\n(?)\r\n\r\nResults: energy consumption of algorithms\r\n\r\nResults: energy vs data shape\r\n\r\nResults: performance vs data shape\r\n\r\nDiscussion\r\n‚Ä¢ Other data properties should be investigated. \r\n‚Ä¢ E.g., data types \r\n‚Ä¢ Reporting energy data is essential. It can lead to different model selection \r\nwithout hindering model performance. \r\n‚Ä¢ There is a big opportunity in Model and Data Simplification.\r\n23\r\n\r\nData/Model Simplification\r\n‚Ä¢ (?) \r\n‚Ä¢ Data selection \r\n‚Ä¢ Data quantisation. Posit? \r\n‚Ä¢ Data distillation \r\n‚Ä¢ Coreset extraction (?) \r\n‚Ä¢ Model distillation \r\n‚Ä¢ Model quantisation \r\n‚Ä¢ Model pruning \r\n‚Ä¢ ‚Ä¶\r\n24\r\n\r\nPosit vs Float\r\nMore about this: https://spectrum.ieee.org/floating-point-numbers-posits-processor\r\nBetter for DL use cases\r\n\r\nHow can we tune \r\nlearning \r\nparameters \r\nefficiently?\r\n\r\nHyper parameter tuning\r\n‚Ä¢ When training an ML model, there are several parameters that need to be \r\ntuned. \r\n‚Ä¢ E.g., in SVM we have the Regularization parameter C, the kernel function, \r\nthe degree of the kernel function, and depending on the case, many other. \r\n‚Ä¢ The common approach revolves around grid search.', '8. Green AI\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nLu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\nCarolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl\r\n\r\n- Overview of Green AI \r\n- Large language models \r\n- Green data-centric AI \r\n- Model simplification \r\n- Hyper parameter tuning \r\n- Mixture of Experts and DeepSeek \r\n- Green AI at Meta \r\n\r\nAI\r\n‚Ä¢ Artificial Intelligence (AI) is the branch of computer science that deals with \r\nautomating tasks that typically require human intelligence. \r\n‚Ä¢ In the past years AI has been widely applied across different domains.\u2028\r\nE.g., health care, transportation, finance. \r\n‚Ä¢ To deploy AI systems, we test them against benchmarks (or validation sets). \r\n‚Ä¢ The goal is to outperform the previous existing models. \r\n‚Ä¢ E.g., in Machine Learning we usually resort to accuracy metrics. The \r\nhighest the accuracy, the better the model.\r\n3\r\n\r\nSince 2012, the amount of computing used for AI \r\ntraining has been doubling every 6 months\r\n‚Ä¢ https://epoch.ai/blog/compute-trends\r\n4\r\n\r\n‚Ä¢ To create better AI systems we are currently adding \r\n‚Ä¢ More data \r\n‚Ä¢ More experiments \r\n‚Ä¢ Larger models\r\n5\r\n\r\nThe Equation of Red AI\r\nCost(R) ‚àùE¬∑D¬∑H\r\nCost of a single (E)xample\r\nSize of (D)ataset\r\nNumber of (H)yperparameters\r\nBy Schwartz et al. (2020)\r\n\r\nIssues of Red AI\r\n‚Ä¢ High costs (hardware, electricity, data access, etc.) \r\n‚Ä¢ Limited reproducibility.  \r\n‚Ä¢ Energy consumption. \r\n‚Ä¢ Carbon emissions. \r\n‚Ä¢ SMEs can hardly be competitive. \r\n‚Ä¢ Groundbreaking AI research is mostly done by tech giants.\r\n7\r\n\r\nA few examples of Red AI\r\n‚Ä¢ Google‚Äôs BERT-large \r\n‚Ä¢ 350 million features \r\n‚Ä¢ Trained for 2.5 days using 512 TPU chips, costing $60K+ \r\n‚Ä¢ Open-GPT3 (now GPT-4/o1) \r\n‚Ä¢ 550 tonnes CO2-eq (Patterson, 2021) \r\n‚Ä¢ 175 billion features \r\n‚Ä¢ API is open but no-pretrained model is available \r\n‚Ä¢ AlphaGo \r\n‚Ä¢ 1920 CPUs, 280 GPUs, costing $35M\r\n8\r\n\r\nRed AI in Large Language Models (LLMs)\r\n‚Ä¢ OPT by Meta reports 75 tons CO2-eq (1/7 of OpenGPT‚Äôs footprint).\u2028\r\n(Also 175billion params) \r\n‚Ä¢ However, Llama 3 reported 2,290 tons of CO2-eq (7.7M GPU hours \r\ntraining ) \r\n‚Ä¢ Open science: release includes both the pretrained models and the code \r\nneeded to train and use them. \r\n‚Ä¢ DeepSeek-V3 claims ‚Äúonly‚Äù 2.78M GPU hours \r\n‚Ä¢ Bloom by Huggingface reports 25 tons, 51 when considering embodied \r\nand operational carbon footprint. (176billion params)\r\n9\r\n\r\nRed AI\r\nAccuracy: 0.999999999\r\nGreen AI\r\n‚Ä¢ Energy \r\n‚Ä¢ Time \r\n‚Ä¢ Reproducibility \r\n‚Ä¢ Reusage\r\n\r\nHow can we adopt Green AI\r\n‚Ä¢ Check whether AI is needed. \r\n‚Ä¢ Select green datacenters. \r\n‚Ä¢ Run on low carbon intensity hours. \r\n‚Ä¢ Opt for GPU-optimised solutions (?) \r\n‚Ä¢ Opt for low-power hardware (e.g., Nvidia Jetson boards) \r\n‚Ä¢ Or GPUs that provide energy metrics (e.g., NVIDIA GPUs via the nvidia-smi tool) \r\n‚Ä¢ Report energy/carbon metrics (e.g., embed in MLFlow?)', ""‚Ä¢ 6 machine learning algorithms: SVM, Decision Tree, KNN, Random Forrest, \r\nAdaBoost, Bagging Classifier. \r\n‚Ä¢ Reduce the number of rows. 10%, 20%, .., 100% \r\n‚Ä¢ Stratified random sampling (?) \r\n‚Ä¢ Reduce the number of features. 10%, 20%, .., 100% \r\n‚Ä¢ Feature importance metric based on the Chi-Square Test (Chi2) \r\n‚Ä¢ Estimate energy consumption using a RAPL-based tool. (?)\r\n18\r\n\r\n‚Ä¢ Repeat 30 times \r\n‚Ä¢ Fix random seeds \r\n‚Ä¢ ‚Ä¶ \r\n‚Ä¢ Data was not Normal => tailed Normal distribution.\r\n19\r\n(?)\r\n\r\nResults: energy consumption of algorithms\r\n\r\nResults: energy vs data shape\r\n\r\nResults: performance vs data shape\r\n\r\nDiscussion\r\n‚Ä¢ Other data properties should be investigated. \r\n‚Ä¢ E.g., data types \r\n‚Ä¢ Reporting energy data is essential. It can lead to different model selection \r\nwithout hindering model performance. \r\n‚Ä¢ There is a big opportunity in Model and Data Simplification.\r\n23\r\n\r\nData/Model Simplification\r\n‚Ä¢ (?) \r\n‚Ä¢ Data selection \r\n‚Ä¢ Data quantisation. Posit? \r\n‚Ä¢ Data distillation \r\n‚Ä¢ Coreset extraction (?) \r\n‚Ä¢ Model distillation \r\n‚Ä¢ Model quantisation \r\n‚Ä¢ Model pruning \r\n‚Ä¢ ‚Ä¶\r\n24\r\n\r\nPosit vs Float\r\nMore about this: https://spectrum.ieee.org/floating-point-numbers-posits-processor\r\nBetter for DL use cases\r\n\r\nHow can we tune \r\nlearning \r\nparameters \r\nefficiently?\r\n\r\nHyper parameter tuning\r\n‚Ä¢ When training an ML model, there are several parameters that need to be \r\ntuned. \r\n‚Ä¢ E.g., in SVM we have the Regularization parameter C, the kernel function, \r\nthe degree of the kernel function, and depending on the case, many other. \r\n‚Ä¢ The common approach revolves around grid search. The user provides a \r\nsequence of possible values for each parameter and the pipeline runs all \r\npossible combinations. \r\n‚Ä¢ Our question: Can we save energy with alternative approaches? \r\n‚Ä¢ We studied Grid Search, Random Search and Bayesian \r\nOptimisation.\r\n27\r\nTim's MSc Thesis, 2022 \r\nAccepted at CAIN‚Äô23\r\n\r\n\r\nResults\r\n29\r\nConclusions? \r\n‚Ä¢ Bayesian converges faster. \r\n‚Ä¢ No clear winner between Grid and Random\r\n\r\nDeepSeekMoE\r\n30\r\nPreprint at ArXiv, 2024 https://arxiv.org/pdf/\r\n2401.06066\r\n\r\nMixture of Experts\r\n‚Ä¢ Llama3.1 has 405B parameters, DeepSeek V3 671B \r\n‚Ä¢ Yet DeepSeek has quicker inference times and claims less energy \r\nconsumption (?) \r\n‚Ä¢ Divide the model into smaller blocks of experts \r\n‚Ä¢ Tokens get routed to certain experts based on the query \r\n‚Ä¢ Only part of the network is active during inference \r\n‚Ä¢ DeepSeek claims only 37B out of 671B parameters get active\r\n31\r\n\r\nDeepSeekMoE\r\n32\r\n\r\nDeepSeekMoE\r\n33\r\n‚Ä¢ Comparable performance to \r\nLLaMA2 7B effectively using \r\nless half the parameters \r\n‚Ä¢ Less computational power \r\n‚Ä¢ Problems (?) \r\n‚Ä¢ Still need to load all the \r\nparameters \r\n‚Ä¢ High memory -> high \r\nembodied carbon\r\n\r\nGreen AI at FacebookMeta\r\n34\r\nSustainable AI: Environmental Implications, \r\nChallenges and Opportunities (2022)\r\n\r\nCarbon footprint mapped to the AI lifecycle\r\n‚Ä¢ There are 4 main overarching stages where carbon emissions need to be isolated: data \r\ncollection, experimentation, training, inference. \r\n‚Ä¢ At Facebook, recommendation systems split energy consumption evenly between \r\ntraining and inference; text translation models have a 35%/65% split. (Operational cost) \r\n‚Ä¢ Operational/embodied cost split: 30%/70%\r\n35\r\n\r\nOpen issues according to Meta\r\n‚Ä¢ A vast portion of projects only use GPUs at 30%.\u2028\r\nShould be higher to attenuate embodied carbon."", '‚Ä¢ Groundbreaking AI research is mostly done by tech giants.\r\n7\r\n\r\nA few examples of Red AI\r\n‚Ä¢ Google‚Äôs BERT-large \r\n‚Ä¢ 350 million features \r\n‚Ä¢ Trained for 2.5 days using 512 TPU chips, costing $60K+ \r\n‚Ä¢ Open-GPT3 (now GPT-4/o1) \r\n‚Ä¢ 550 tonnes CO2-eq (Patterson, 2021) \r\n‚Ä¢ 175 billion features \r\n‚Ä¢ API is open but no-pretrained model is available \r\n‚Ä¢ AlphaGo \r\n‚Ä¢ 1920 CPUs, 280 GPUs, costing $35M\r\n8\r\n\r\nRed AI in Large Language Models (LLMs)\r\n‚Ä¢ OPT by Meta reports 75 tons CO2-eq (1/7 of OpenGPT‚Äôs footprint).\u2028\r\n(Also 175billion params) \r\n‚Ä¢ However, Llama 3 reported 2,290 tons of CO2-eq (7.7M GPU hours \r\ntraining ) \r\n‚Ä¢ Open science: release includes both the pretrained models and the code \r\nneeded to train and use them. \r\n‚Ä¢ DeepSeek-V3 claims ‚Äúonly‚Äù 2.78M GPU hours \r\n‚Ä¢ Bloom by Huggingface reports 25 tons, 51 when considering embodied \r\nand operational carbon footprint. (176billion params)\r\n9\r\n\r\nRed AI\r\nAccuracy: 0.999999999\r\nGreen AI\r\n‚Ä¢ Energy \r\n‚Ä¢ Time \r\n‚Ä¢ Reproducibility \r\n‚Ä¢ Reusage\r\n\r\nHow can we adopt Green AI\r\n‚Ä¢ Check whether AI is needed. \r\n‚Ä¢ Select green datacenters. \r\n‚Ä¢ Run on low carbon intensity hours. \r\n‚Ä¢ Opt for GPU-optimised solutions (?) \r\n‚Ä¢ Opt for low-power hardware (e.g., Nvidia Jetson boards) \r\n‚Ä¢ Or GPUs that provide energy metrics (e.g., NVIDIA GPUs via the nvidia-smi tool) \r\n‚Ä¢ Report energy/carbon metrics (e.g., embed in MLFlow?) \r\n‚Ä¢ Use pre-trained models (Transfer Learning) \r\n‚Ä¢ Preprocess dataset to reduce size. \r\n‚Ä¢ Improve parameter-tuning strategy.\r\n11\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ We need benchmarks. \r\n‚Ä¢ AllenAI leaderboard\u2028\r\nhttps://leaderboard.allenai.org \r\n‚Ä¢ No carbon metrics, yet \r\n‚Ä¢ Report comparable proxies for energy \r\nconsumption. \r\n‚Ä¢ ‚ö† Learning algorithms behave in a non-\r\ndeterministic \r\n‚Ä¢ ‚ö† Different data-points lead to different \r\nenergy consumption\r\n12\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ Reporting measured energy consumption \r\n‚Ä¢ + Accurate \r\n‚Ä¢ + Easy to map to carbon emissions \r\n‚Ä¢ - Hard to measure \r\n‚Ä¢ - Low replicability \r\n‚Ä¢ Reporting time / estimation based on time & hardware \r\n‚Ä¢ + Easy to measure \r\n‚Ä¢ + Correlates with energy consumption in most cases. \r\n‚Ä¢ -  Difficult to compare with measurements from other setups \r\n‚Ä¢ E.g., floating point operations (FPOs) (?) \r\n‚Ä¢ + comparable across different setups \r\n‚Ä¢ + cheap \r\n‚Ä¢ - does not factor in memory energy consumption \r\n‚Ä¢ - does not reflect carbon emissions\r\n13\r\n\r\nData-centric AI\r\n\r\nData-centric AI\r\n‚Ä¢ Emerging discipline that deals with systematically engineering data to build AI \r\nsystems. \r\n‚Ä¢ Shift from improving the training strategy to improving the data. \r\n‚Ä¢ It is better to have small but reliable datasets than large but noisy \r\ndatasets. \r\n‚Ä¢ => Improve data collection, data labelling, and data preprocessing. \r\n‚Ä¢ More about data-centric AI by Andrew Ng:\u2028\r\nhttps://www.youtube.com/watch?v=06-AZXmwHjo\r\n15\r\n\r\n\r\nGreen Data-centric AI\r\n‚Ä¢ How do different ML algorithms compare \r\nin terms of energy consumption? \r\n‚Ä¢ How does number of rows relate to the \r\nenergy consumption of ML models? \r\n‚Ä¢ How does number of features relate to \r\nthe energy consumption of ML models? \r\n‚Ä¢ What is the impact of reducing data in the \r\nperformance of the model?', ""‚Ä¢ Visualise distribution shape: violin plots, histograms, density plot.\u2028\r\n \r\n‚Ä¢ Shapiro-Wilk test.\u2028\r\ndata is not normal;\u2028\r\nwe are not sure but it is okay to assume that data is \r\nnormal.\r\np-value < 0.05 ‚áí\r\np-value ‚â•0.05 ‚áí\r\n19\r\n\r\nAfter having all data ready, which artefact \r\nis more energy efficient(?) \r\nFirst approach: compare sample means. \r\n‚ö† assuming normal distribution\r\n\r\nStatistical significance\r\n‚Ä¢ Even if, on average, one artefact has lower \r\nenergy consumption than other,  it might be just \r\na random difference. \r\n‚Ä¢ When we extract a sample from a normal \r\ndistribution it will never be the exact same \r\n‚Ä¢ Statistical significance tests help you \r\nunderstand the differences in the average are \r\nconclusive/significant or inconclusive/\r\ninsignificant.\r\n21\r\n‚ö† assuming normal distribution\r\n\r\nStatistical significance test\r\n‚Ä¢ Two-sided parametric test Welch‚Äôs t-test. \r\n‚Ä¢ Less known alternative to student‚Äôs t-test.\r\n22\r\nWelch‚Äôs t-test in Python\r\nfrom scipy.stats import ttest_ind \r\n_,pvalue = ttest_ind(sample_a, sample_b, \r\n                     equal_var=False, \r\n                     alternative='two-sided')\r\n(?)\r\n‚ö† assuming normal distribution\r\n\r\nEffect Size analysis\r\n‚Ä¢ Now that we know that results are statistically significant we need to \r\nmeasure the difference between the two samples. \r\n‚Ä¢ Mean difference: \r\n \r\n‚Ä¢ Percent change: \r\n \r\n‚Ä¢ Cohen‚Äôs d (informal definition: mean difference normalized by a combined \r\nstandard deviation): \r\nŒî¬Øx\r\nxB ‚àíxA\r\nxA\r\n√ó 100 % = Œî¬Øx\r\nxA\r\n√ó 100 %\r\nŒî¬Øx\r\n1\r\n2\r\ns21 + s22\r\n23\r\n‚ö† assuming normal distribution\r\n\r\nImagine that version A spends 70J and \r\nversion B spends 69J with a \r\n.\r\np-value = 0.04\r\nOn average, version B spent less energy than version A  ‚Äî  ‚úÖ \r\nThere is statistical significance ‚Äî  ‚úÖ \r\nEffect size, percent-change is ‚âà1% ‚Äî ü§î \r\n‚ö† Do we care?\r\n(?)\r\n\r\nPractical Significance\r\n‚Ä¢ Depending on the case, a 2% improvement might be either wonderful or completely \r\nuseless. \r\n‚Ä¢ Effect size analyses help assess practical significance but might not be enough. \r\n‚Ä¢ A critical discussion always needs to be performed. Consider context and explain in what \r\nsense the effect size might be relevant. \r\n‚Ä¢ E.g.: \r\n‚Ä¢  to improve 2% in energy efficiency the code will be less readable or the user \r\nexperience is not so appealing. \r\n‚Ä¢ A particular method improves 2% but it will only be used 1% of the time. \r\n‚Ä¢ There is no particular metric or structure, but this kind of critical analysis is very important.\r\n25\r\n\r\nWhat if data is not Normal?\r\nSame approach but different tests/metrics!\r\n\r\nNon-normal data\r\n‚Ä¢ Statistical significance: non-parametric test (?) \r\n‚Ä¢ Mann-Whitney U test. Instead of looking at standard deviation or mean, it orders \r\nsamples and compares with each other. \r\n‚Ä¢ Less power than parametric-tests (?) \r\n‚Ä¢ Effect size \r\n‚Ä¢ Median difference: \r\n \r\n‚Ä¢ Percentage of pairs supporting a conclusion\u2028\r\n(i.e., # pairs where version A > version B/ total pairs) \r\n‚Ä¢ Common language effect size: \r\nŒîM\r\nU1\r\nN1N2\r\n27\r\n\r\nRecap\r\nImpossible to \r\nfix but \r\nexplainable."", ""Unless there‚Äôs a \r\ngood reason. \r\n‚Ä¢ E.g., somewhere amongst the 30 executions, \r\nthere might be 1 or 2 that failed to finish due \r\nto some unexpected error. \r\n‚Ä¢ (It happens and that‚Äôs ok!)‚Äì consequently, \r\nthe execution is shorter and spends less \r\nenergy ‚Äì falsely appearing as more \r\nenergy efficient. \r\n‚Ä¢ If data is not Normal there might be some \r\nissues affecting the measurements that \r\nmight be ruining results. It is important to \r\ninvestigate this.\r\n16\r\n\r\nEnergy data is not normal. Why?\r\n‚Ä¢ It might be caused by one of the following reasons: \r\n‚Ä¢ There was an error in some of the executions. If not detected and fixed it \r\nmight ruin results. \r\n‚Ä¢ Your tests are not fully replicable or are not deterministic. Quite frequent \r\nwhen you have internet requests or random-based algorithms. \r\n‚Ä¢ There is an unusual task being run by the system during some experiments. \r\n‚Ä¢ The computer entered a different power mode. \r\n‚Ä¢ External physical conditions have changed. E.g., someone opened a \r\nwindow.\r\n17\r\n\r\nEnergy data is not normal. How to fix?\r\n‚Ä¢ We have 2+1 options: \r\n1. Remove outliers. If there are only a few points that deviate from the normal \r\ndistribution, it is okay to simply remove them. \r\n‚Ä¢ Use the z-score outlier removal. (?) \r\n‚Ä¢ Remove all data points that deviate from the mean more than 3 standard \r\ndeviations: \r\n \r\n2. Fix the issue and rerun experiments. \r\n3. Conclude that nothing can be done about it and data will never be normal. (e.g., \r\nin AI, executions are rarely deterministic). ‚ö† Only after ruling out the previous \r\npoints.\r\n| ¬Øx ‚àíx| > 3s\r\n18\r\n\r\nHow do we know whether data is Normal?\r\n‚Ä¢ Visualise distribution shape: violin plots, histograms, density plot.\u2028\r\n \r\n‚Ä¢ Shapiro-Wilk test.\u2028\r\ndata is not normal;\u2028\r\nwe are not sure but it is okay to assume that data is \r\nnormal.\r\np-value < 0.05 ‚áí\r\np-value ‚â•0.05 ‚áí\r\n19\r\n\r\nAfter having all data ready, which artefact \r\nis more energy efficient(?) \r\nFirst approach: compare sample means. \r\n‚ö† assuming normal distribution\r\n\r\nStatistical significance\r\n‚Ä¢ Even if, on average, one artefact has lower \r\nenergy consumption than other,  it might be just \r\na random difference. \r\n‚Ä¢ When we extract a sample from a normal \r\ndistribution it will never be the exact same \r\n‚Ä¢ Statistical significance tests help you \r\nunderstand the differences in the average are \r\nconclusive/significant or inconclusive/\r\ninsignificant.\r\n21\r\n‚ö† assuming normal distribution\r\n\r\nStatistical significance test\r\n‚Ä¢ Two-sided parametric test Welch‚Äôs t-test. \r\n‚Ä¢ Less known alternative to student‚Äôs t-test.\r\n22\r\nWelch‚Äôs t-test in Python\r\nfrom scipy.stats import ttest_ind \r\n_,pvalue = ttest_ind(sample_a, sample_b, \r\n                     equal_var=False, \r\n                     alternative='two-sided')\r\n(?)\r\n‚ö† assuming normal distribution\r\n\r\nEffect Size analysis\r\n‚Ä¢ Now that we know that results are statistically significant we need to \r\nmeasure the difference between the two samples. \r\n‚Ä¢ Mean difference: \r\n \r\n‚Ä¢ Percent change: \r\n \r\n‚Ä¢ Cohen‚Äôs d (informal definition: mean difference normalized by a combined \r\nstandard deviation): \r\nŒî¬Øx\r\nxB ‚àíxA\r\nxA\r\n√ó 100 % = Œî¬Øx\r\nxA\r\n√ó 100 %\r\nŒî¬Øx\r\n1\r\n2\r\ns21 + s22\r\n23\r\n‚ö† assuming normal distribution\r\n\r\nImagine that version A spends 70J and \r\nversion B spends 69J with a \r\n."", 'p-value = 0.04\r\nOn average, version B spent less energy than version A  ‚Äî  ‚úÖ \r\nThere is statistical significance ‚Äî  ‚úÖ \r\nEffect size, percent-change is ‚âà1% ‚Äî ü§î \r\n‚ö† Do we care?\r\n(?)\r\n\r\nPractical Significance\r\n‚Ä¢ Depending on the case, a 2% improvement might be either wonderful or completely \r\nuseless. \r\n‚Ä¢ Effect size analyses help assess practical significance but might not be enough. \r\n‚Ä¢ A critical discussion always needs to be performed. Consider context and explain in what \r\nsense the effect size might be relevant. \r\n‚Ä¢ E.g.: \r\n‚Ä¢  to improve 2% in energy efficiency the code will be less readable or the user \r\nexperience is not so appealing. \r\n‚Ä¢ A particular method improves 2% but it will only be used 1% of the time. \r\n‚Ä¢ There is no particular metric or structure, but this kind of critical analysis is very important.\r\n25\r\n\r\nWhat if data is not Normal?\r\nSame approach but different tests/metrics!\r\n\r\nNon-normal data\r\n‚Ä¢ Statistical significance: non-parametric test (?) \r\n‚Ä¢ Mann-Whitney U test. Instead of looking at standard deviation or mean, it orders \r\nsamples and compares with each other. \r\n‚Ä¢ Less power than parametric-tests (?) \r\n‚Ä¢ Effect size \r\n‚Ä¢ Median difference: \r\n \r\n‚Ä¢ Percentage of pairs supporting a conclusion\u2028\r\n(i.e., # pairs where version A > version B/ total pairs) \r\n‚Ä¢ Common language effect size: \r\nŒîM\r\nU1\r\nN1N2\r\n27\r\n\r\nRecap\r\nImpossible to \r\nfix but \r\nexplainable.\r\n\r\nEnergy Efficiency Across \r\nProgramming Languages\r\nhttps://sites.google.com/view/energy-efficiency-languages\r\n29\r\nRui Pereira, Marco Couto, Francisco Ribeiro, Rui Rua, J√°come \r\nCunha, Jo√£o Paulo Fernandes, and Jo√£o Saraiva\r\n\r\n‚Ä¢ Is a faster programming language also more energy efficient? \r\n‚Ä¢ Comparing different programming languages is not an easy task. \r\n‚Ä¢ They differ in many mechanisms: \r\n‚Ä¢ Interpreted vs Compiled \r\n‚Ä¢ Optimisations at the compiler level \r\n‚Ä¢ Virtual machine \r\n‚Ä¢ Garbage collector \r\n‚Ä¢ Available libraries\r\n30\r\n\r\nResearch Questions\r\n‚Ä¢ Can we compare the energy efficiency of software languages?  \r\n‚Ä¢ Is the faster language always the most energy efficient? \r\n‚Ä¢ How does memory usage relate to energy consumption? (We don‚Äôt cover this one) \r\n‚Ä¢ Can we automatically decide what is the best programming language \r\nconsidering energy, time, and memory usage?  \r\n‚Ä¢ How do the results of our energy consumption analysis of programming \r\nlanguages gathered from rigorous performance benchmarking solutions \r\ncompare to results of average day-to-day solutions? \u2028\r\n31\r\n\r\nMethodology\r\n\r\nThe Computer Language Benchmarks Game \r\n‚Ä¢ https://benchmarksgame-team.pages.debian.net/benchmarksgame/\r\n33\r\n\r\nProblems in the Computer Language Benchmarks Game\r\n34\r\n\r\n‚Ä¢ 27 Programming languages across different paradigms  \r\n‚Ä¢ Functional (e.g., Ocaml, F#, Haskell) \r\n‚Ä¢ Imperative (e.g., C, Go, Python) \r\n‚Ä¢ Object-oriented (e.g., C++, C#, Java) \r\n‚Ä¢ Scripting (or interpretative) (e.g., JavaScript, Python, Ruby) \r\n‚Ä¢ (These are not mutual exclusive) \r\n‚Ä¢ Intel RAPL‚Äôs C library to measure energy consumption\r\n35\r\n\r\n‚Ä¢ Execute each benchmark solution 10 times. \r\n‚Ä¢ Collect energy data and timestamps. \r\n‚Ä¢ Two-minute interval between executions\r\n36\r\n\r\n\r\n\r\n\r\nCritical thinking\r\n‚Ä¢ There is no doubt this is an excellent study. Yet, as any excellent study, there‚Äôs \r\na lot we can discuss and criticise constructively. \r\n‚Ä¢ What kind of issues you see in drawing conclusions from such a table of \r\nresults?', 'Energy profiling of static analysis tools\r\n‚Ä¢ What is the energy consumption of a ""typical run"" for a few OSS projects? \r\n‚Ä¢ Does the type of analysis matter? Are certain analysis more expensive? Does \r\nthe number of rules that are activated in a static analysis tool important for the \r\nenergy consumption? \r\n‚Ä¢ Differences between static analysis tools [lower priority]\r\n\r\nB5. Tool supporting SusAF workshop / process\r\n‚Ä¢ Lead engineers through process & questions \r\n‚Ä¢ Interface to create & document the two diagrams \r\n‚Ä¢ (!) Should be easy to start using & set up \r\n‚Ä¢ You may also create a simplified version / \u2028\r\nyour favorite sustainability framework\r\nEnvironmental\r\nEconomic\r\nTechnical\r\nIndividual\r\nSocial\r\nImmediate\r\nEnabling\r\nStructural\r\nAirbnb\r\ngreater \r\nearnings\r\nincrease \r\nin rents\r\ngentrification\r\ngreater racial \r\ndisparities\r\nrent \r\nrooms\r\n5\r\n1\r\n3\r\n4\r\n2\r\n \r\n \r\n \r\n \r\n \r\n \r\nVery \r\nunlikely \r\nVery \r\nlikely \r\n\r\nB6. Dataset of government-developed OS software\r\n‚Ä¢ Governments develop & use software for supporting society\u2028\r\nOpen-source development & policies are on the rise \r\n‚Ä¢ But studying government software is difficult b/c we don‚Äôt know what is out \r\nthere\u2028\r\n‚Üí Lack of incentive to make popular \u2028\r\n‚Üí Language barriers \r\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \r\nbuildable?, open dev. history?, requirements documentation? \r\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!\r\n\r\nB7. Queue - but better for the student / TA society\r\n‚Ä¢ Requirements analysis regarding social and individual sustainability effects \r\nof Queue \r\n‚Ä¢ Other EIP / TUD used software also possible: e.g., Answers EWI \r\n‚Ä¢ Non-technical project ‚Üí proper process (workshops? Interviews?) & rich \r\ndescription of outcomes focus of grading\r\nhttps://eip.pages.ewi.tudelft.nl/eip-website/queue.html\r\n\r\nC1. Compare energy consumption of docker images for \r\nML workloads.\r\n‚Ä¢ Similar to what we have seen in the lectures but for ML-specific workloads. \r\n‚Ä¢ We can reuse existing experiment replication packages.\r\n22\r\n\r\nC2. Plugin to visualize Hugging Face carbon emissions.\r\n‚Ä¢ https://huggingface.co/blog/leaderboard-emissions-\r\nanalysis \r\n‚Ä¢\r\nYoo, Taewon, et al. ""Visualizing the Carbon Intensity of Machine Learning Inference for Image Analysis on TensorFlow Hub.""\r\n\r\nC3. Plugin for ChatGPT\r\n‚Ä¢ Users seldom know how much carbon they are emitting when they interact \r\nwith chat GPT. \r\n‚Ä¢ Let‚Äôs make it transparent to the users. Browser plugin?\r\n24\r\nCO2\r\n\r\nC4. NutriScore for software libraries\r\n25\r\n‚Ä¢ NutriScore labels are not perfect but they are a good starting point! \r\n‚Ä¢ What if we could do the same thing for the energy efficiency of software. \r\n‚Ä¢ (Also open to individual or social sustainability) \r\n‚Ä¢ This work can be scoped in particular domains/ecossystems/use cases. \r\n‚Ä¢ Libraries for stats? ML? Web Dev? Cloud?\r\n\r\nC5. Add energy-awareness to existing software\r\n26\r\n‚Ä¢ Streamlit, Notebooks, JSFiddle, \r\nPyScript, zsh, etc. \r\n‚Ä¢\r\n\r\nC6 - Green Shift Left\r\n‚Ä¢ Estimate energy efficiency using static code analysis. \r\n‚Ä¢ We don‚Äôt need an accurate value. \r\n‚Ä¢ It is useful to know which code is more likely to \r\nintroduce energy hotspots and that should be \r\nreviewed with more attention. \r\n‚Ä¢ Can be scoped to a particular domain (react, php, data \r\nscience, web, etc., etc.)']","[""<1-hop>\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant"", '<2-hop>\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \n(not publicly available) doi:10.1037/h0042519\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568']","Spiking neural networks (SNNs) use various encoding strategies to efficiently represent information. These strategies include:

1. **Rate Coding**: This classical view suggests that each neuron is selective for a specific feature in the input, and the firing rate (spikes per unit time) increases for the 'selected' feature. However, rate coding is considered inefficient and slow because it requires many spikes to achieve good precision.

2. **Latency Coding**: This strategy encodes information based on the timing of the first spike. It can encode approximately 19 bits using 7 neurons and 7 time bins, making it faster and more spike-efficient.

3. **Rank Order Coding**: This method encodes information based on the order in which neurons fire. It can encode about 12 bits with the same setup.

4. **Spatio-Temporal Coding**: This approach uses both spatial and temporal dimensions to encode information, resulting in faster and more spike-efficient encoding.

These encoding strategies aim to make SNNs more efficient by reducing the number of spikes required, thus saving energy and improving computational speed.",Spiking neural networks use single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0) to encode information about 'features' in a large network with many spikes. This approach is supported by foundational works such as McCulloch and Pitts' logical calculus of nervous activity and later developments in spiking neuron models.,0.4432539682428869,1.0,1.0,0.0,0.0,0.9408314683753937
What are the benefits of neuromorphic computing in the context of green software practices?,"['Different encoding strategies with spiking neurons\r\n\r\nDifferent encoding strategies with spiking neurons\r\nUsing latency or spatio-temporal codes\r\nour encoding is faster and more spike-efficient (sparser)!\r\n\r\nDifferent encoding strategies with spiking neurons\r\nUsing latency or spatio-temporal codes\r\nour encoding is faster and more spike-efficient (sparser)!\r\nQuestions?\r\n\r\nNeuromorphic computing\r\nWhat is the advantage for applications?\r\n-\r\nLess spikes = less energy consumption in specialized neuromorphic hardware\r\n(e.g. Intel Loihi [12])\r\nBrains are energy efficient: \r\n2. Sparse encoding\r\n\r\nMultiply-accumulate (MAC) operations:\r\nNormal neuron: Multiplies input with \r\nweights, then adds.\r\nSpiking neuron: Consider binary input (e.g. input currents are piecewise \r\nconstant and assume values {0,1}). There is no multiplication, only addition.\r\n\r\nAssume one multiplier and one adder circuit uses M and A energy respectively with AÔπ§M\r\n(e.g., for a 45nm CMOS process, standard energy usage is A = 0.9 pJ and M = 3.7 pJ).\r\nNormal neuron: nin x nout multiplications,\r\n(nin‚Äì 1) x nout additions\r\nSpiking neuron: 0 multiplications, (nactive‚Äì 1) x nout \r\nadditions, with nactive ‚â§ nin\r\nEnergy consumption:\r\nEnormal = M nin nout + A (nin‚Äì 1) nout = 17.5 pJ\r\nEnergy consumption:\r\nEspiking = A (nactive‚Äì 1) nout = 2.7 pJ\r\nMultiply-accumulate (MAC) operations:\r\n\r\nAssume one multiplier and one adder circuit uses M and A energy respectively with AÔπ§M\r\n(e.g., for a 45nm CMOS process, standard energy usage is A = 0.9 pJ and M = 3.7 pJ).\r\nNormal neuron: nin x nout multiplications,\r\n(nin‚Äì 1) x nout additions\r\nSpiking neuron: 0 multiplications, (nactive‚Äì 1) x nout \r\nadditions, with nactive ‚â§ nin\r\nEnergy consumption:\r\nEnormal = M nin nout + A (nin‚Äì 1) nout = 17.5 pJ\r\nEnergy consumption:\r\nEspiking = A (nactive‚Äì 1) nout = 2.7 pJ\r\nMultiply-accumulate (MAC) operations:\r\nSNN challenge: how to \r\ncompute with the least \r\namount of spikes!\r\n\r\nOften, we observe a \r\nsparsity (energy)-\r\ntask accuracy trade-off\r\n(Left: results for image \r\nclassification)\r\nSNN challenge: how to \r\ncompute with the least \r\namount of spikes!\r\nhttps://arxiv.org/pdf/2409.08290\r\n\r\nIn practice, energy \r\nconsumption computations \r\nare complex. \r\nNeed to take into account\r\n- memory access,\r\n- addressing,\r\n- auxiliary operations,\r\nin addition to MACs.\r\nEstimated energy consumption for 3 different datasets (CIFAR10, GSC, NCARS; image, sound \r\nand video classification respectively). FNN‚Äôs are conventional feed-forward neural networks.\r\nIn this example: SNNs are 6 to 8 times more energy efficient than FNNs.\r\nhttps://arxiv.org/pdf/2210.13107\r\nComputing energy consumption\r\n\r\nIn practice, energy \r\nconsumption computations \r\nare complex. \r\nNeed to take into account\r\n- memory access,\r\n- addressing,\r\n- auxiliary operations,\r\nin addition to MACs.\r\nEstimated energy consumption for 3 different datasets (CIFAR10, GSC, NCARS; image, sound \r\nand video classification respectively). FNN‚Äôs are conventional feed-forward neural networks.\r\nIn this example: SNNs are 6 to 8 times more energy efficient than FNNs.', ""- Higher firing rate (spikes per unit time) for \r\n'selected' feature.\r\nAdapted from Hubel & Wiesel, 1959\r\n\r\nFiring rates\r\nClassical view of the brain:\r\n- Each neuron is selective for one specific \r\nfeature in the input.\r\n- Higher firing rate (spikes per unit time) for \r\n'selected' feature.\r\n- Link to modern ANNs: The scalar output of \r\nan artificial neuron is interpreted as the firing \r\nrate.\r\nAdapted from Hubel & Wiesel, 1959\r\n\r\nFiring rates\r\nClassical view of the brain:\r\n- Each neuron is selective for one specific \r\nfeature in the input.\r\n- Higher firing rate (spikes per unit time) for \r\n'selected' feature.\r\n- Link to modern ANNs: The scalar output of \r\nan artificial neuron is interpreted as the firing \r\nrate.\r\nAdapted from Hubel & Wiesel, 1959\r\nBut rate coding is inefficient and slow‚Ä¶\r\n(i.e. each neuron needs to fire many spikes to get good precision)\r\nboth in vivo and in silico.\r\n\r\nDifferent encoding strategies with spiking neurons [8]\r\n7 neurons\r\n7 time bins\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nn\r\n6\r\n(in the general \r\ncase a \r\nnumber \r\nbetween 0-7)\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nn\r\nTotal spike \r\ncount can \r\nencode 3 bits.\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nIndividual rates \r\ncan encode 7 \r\nbits.\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nLatency can \r\nencode ~3*7 or \r\n~19 bits.\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nRank order can \r\nencode ~12 bits.\r\n\r\nDifferent encoding strategies with spiking neurons\r\n\r\nDifferent encoding strategies with spiking neurons\r\nUsing latency or spatio-temporal codes\r\nour encoding is faster and more spike-efficient (sparser)!\r\n\r\nDifferent encoding strategies with spiking neurons\r\nUsing latency or spatio-temporal codes\r\nour encoding is faster and more spike-efficient (sparser)!\r\nQuestions?\r\n\r\nNeuromorphic computing\r\nWhat is the advantage for applications?\r\n-\r\nLess spikes = less energy consumption in specialized neuromorphic hardware\r\n(e.g. Intel Loihi [12])\r\nBrains are energy efficient: \r\n2. Sparse encoding\r\n\r\nMultiply-accumulate (MAC) operations:\r\nNormal neuron: Multiplies input with \r\nweights, then adds.\r\nSpiking neuron: Consider binary input (e.g. input currents are piecewise \r\nconstant and assume values {0,1}). There is no multiplication, only addition.\r\n\r\nAssume one multiplier and one adder circuit uses M and A energy respectively with AÔπ§M\r\n(e.g., for a 45nm CMOS process, standard energy usage is A = 0.9 pJ and M = 3.7 pJ).\r\nNormal neuron: nin x nout multiplications,\r\n(nin‚Äì 1) x nout additions\r\nSpiking neuron: 0 multiplications, (nactive‚Äì 1) x nout \r\nadditions, with nactive ‚â§ nin\r\nEnergy consumption:\r\nEnormal = M nin nout + A (nin‚Äì 1) nout = 17.5 pJ\r\nEnergy consumption:\r\nEspiking = A (nactive‚Äì 1) nout = 2.7 pJ\r\nMultiply-accumulate (MAC) operations:\r\n\r\nAssume one multiplier and one adder circuit uses M and A energy respectively with AÔπ§M\r\n(e.g., for a 45nm CMOS process, standard energy usage is A = 0.9 pJ and M = 3.7 pJ)."", ""‚Ä¢ Our question: Can we save energy with alternative approaches? \r\n‚Ä¢ We studied Grid Search, Random Search and Bayesian \r\nOptimisation.\r\n27\r\nTim's MSc Thesis, 2022 \r\nAccepted at CAIN‚Äô23\r\n\r\n\r\nResults\r\n29\r\nConclusions? \r\n‚Ä¢ Bayesian converges faster. \r\n‚Ä¢ No clear winner between Grid and Random\r\n\r\nDeepSeekMoE\r\n30\r\nPreprint at ArXiv, 2024 https://arxiv.org/pdf/\r\n2401.06066\r\n\r\nMixture of Experts\r\n‚Ä¢ Llama3.1 has 405B parameters, DeepSeek V3 671B \r\n‚Ä¢ Yet DeepSeek has quicker inference times and claims less energy \r\nconsumption (?) \r\n‚Ä¢ Divide the model into smaller blocks of experts \r\n‚Ä¢ Tokens get routed to certain experts based on the query \r\n‚Ä¢ Only part of the network is active during inference \r\n‚Ä¢ DeepSeek claims only 37B out of 671B parameters get active\r\n31\r\n\r\nDeepSeekMoE\r\n32\r\n\r\nDeepSeekMoE\r\n33\r\n‚Ä¢ Comparable performance to \r\nLLaMA2 7B effectively using \r\nless half the parameters \r\n‚Ä¢ Less computational power \r\n‚Ä¢ Problems (?) \r\n‚Ä¢ Still need to load all the \r\nparameters \r\n‚Ä¢ High memory -> high \r\nembodied carbon\r\n\r\nGreen AI at FacebookMeta\r\n34\r\nSustainable AI: Environmental Implications, \r\nChallenges and Opportunities (2022)\r\n\r\nCarbon footprint mapped to the AI lifecycle\r\n‚Ä¢ There are 4 main overarching stages where carbon emissions need to be isolated: data \r\ncollection, experimentation, training, inference. \r\n‚Ä¢ At Facebook, recommendation systems split energy consumption evenly between \r\ntraining and inference; text translation models have a 35%/65% split. (Operational cost) \r\n‚Ä¢ Operational/embodied cost split: 30%/70%\r\n35\r\n\r\nOpen issues according to Meta\r\n‚Ä¢ A vast portion of projects only use GPUs at 30%.\u2028\r\nShould be higher to attenuate embodied carbon.\r\n36\r\nBased on 10K AI projects\r\n\r\nData Jan\r\nInformed Adaptation\r\nData Feb\r\nData Mar\r\nData Apr\r\nData May\r\n‚Ä¶\r\n~Data Dec\r\n~Data Dec\r\nData Jan\r\nData Feb\r\nData Mar\r\nData Apr\r\nData May\r\n‚Ä¶\r\nModel update Model update Model update\r\nCheck if \r\ndata change\r\nCheck if \r\ndata change\r\nCheck if \r\ndata change\r\nModel update\r\nBlind Adaptation\r\nThe AI Model will be \r\nupdated fewer times and \r\nonly when necessary.\r\nKnow when to retrain models\r\nNeither too early nor too late\r\n37\r\nAdaptation Techniques\r\n?\r\n\r\nGreen Architectural Tactics for ML-Enabled \r\nSystem\r\n38\r\nICSE-SEIS 2024\r\n\r\nArchitectural tactics\r\n39\r\n\r\nData-centric\r\n40\r\n‚Ä¢ Reduce data size \r\n‚Ä¢ Sampling \r\n‚Ä¢ Dimensionality reduction \r\n‚Ä¢ Quantization\r\n\r\nAlgorithm Design\r\n41\r\n‚Ä¢ Carefully select your algorithm \r\n‚Ä¢ You don‚Äôt need the fanciest \r\ntechniques\r\n\r\nModel Optimization\r\n42\r\n‚Ä¢ Add energy to training parameters \r\n‚Ä¢ Reduce FLOPs \r\n‚Ä¢ Pruning, sparsity \r\n‚Ä¢  Take advantage of existing models\r\n\r\nModel Training\r\n43\r\n‚Ä¢ Quantization\r\n‚Ä¢ SAVE TRAINING PROGRESS\r\n\r\nModel Deployment\r\n44\r\n‚Ä¢ Distributed deployment \r\n‚Ä¢ Energy efficient hardware and \r\nconfigurations\r\n\r\nModel Management\r\n45\r\n‚Ä¢ Reuse the model as much as possible \r\n\r\nRethinking the Architecture: Spiking Neural Networks\r\n46\r\n\r\nRethinking the Architecture: Spiking Neural Networks\r\n47\r\n\r\nSELF Lab\r\n48\r\n\r\nrecap"", 'Normal neuron: nin x nout multiplications,\r\n(nin‚Äì 1) x nout additions\r\nSpiking neuron: 0 multiplications, (nactive‚Äì 1) x nout \r\nadditions, with nactive ‚â§ nin\r\nEnergy consumption:\r\nEnormal = M nin nout + A (nin‚Äì 1) nout = 17.5 pJ\r\nEnergy consumption:\r\nEspiking = A (nactive‚Äì 1) nout = 2.7 pJ\r\nMultiply-accumulate (MAC) operations:\r\nSNN challenge: how to \r\ncompute with the least \r\namount of spikes!\r\n\r\nOften, we observe a \r\nsparsity (energy)-\r\ntask accuracy trade-off\r\n(Left: results for image \r\nclassification)\r\nSNN challenge: how to \r\ncompute with the least \r\namount of spikes!\r\nhttps://arxiv.org/pdf/2409.08290\r\n\r\nIn practice, energy \r\nconsumption computations \r\nare complex. \r\nNeed to take into account\r\n- memory access,\r\n- addressing,\r\n- auxiliary operations,\r\nin addition to MACs.\r\nEstimated energy consumption for 3 different datasets (CIFAR10, GSC, NCARS; image, sound \r\nand video classification respectively). FNN‚Äôs are conventional feed-forward neural networks.\r\nIn this example: SNNs are 6 to 8 times more energy efficient than FNNs.\r\nhttps://arxiv.org/pdf/2210.13107\r\nComputing energy consumption\r\n\r\nIn practice, energy \r\nconsumption computations \r\nare complex. \r\nNeed to take into account\r\n- memory access,\r\n- addressing,\r\n- auxiliary operations,\r\nin addition to MACs.\r\nEstimated energy consumption for 3 different datasets (CIFAR10, GSC, NCARS; image, sound \r\nand video classification respectively). FNN‚Äôs are conventional feed-forward neural networks.\r\nIn this example: SNNs are 6 to 8 times more energy efficient than FNNs.\r\nComputing energy consumption\r\nQuestions?\r\n\r\nReading materials\r\nMain reading:\r\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \r\nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\r\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\r\n- Neuromorphic computing:\r\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \r\nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\r\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \r\noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\r\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019.', 'McCulloch-Pitts neuron [1, 2]\r\n1940s: How do biological neurons compute basic \r\nlogic functions? (e.g. logic gates)\r\nNote: Ref. [3] gives a nice brief history on the ideas which lead to the \r\nMcCulloch-Pitts neuron.\r\n\r\nWhat is a neural network?\r\n1950s: How are neurons organized to perform \r\nsensory perception?\r\n\r\nWhat is a neural network?\r\n1950s: How are neurons organized to perform \r\nsensory perception?\r\nThe first ""neural network"": Perceptron (1958). [4]\r\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\r\nFrank Rosenblatt (Psychologist)\r\nwith a Mark I Perceptron computer in 1960\r\n\r\nWhat is a neural network?\r\n1950s: How are neurons organized to perform \r\nsensory perception?\r\nThe first ""neural network"": Perceptron (1958). [4]\r\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\r\nFrank Rosenblatt (Psychologist)\r\nwith a Mark I Perceptron computer in 1960\r\nPower-efficient\r\n\r\nNeuromorphic computing\r\nWhy neuromorphic computing?\r\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\r\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\r\n\r\nNeuromorphic computing\r\nWhy neuromorphic computing?\r\n‚ÄòBiological inspiration‚Äô for artificial neural networks (ANNs) is not a new idea.\r\nEmulation (as opposed to simulation) of neural networks in hardware is not a new idea.\r\nQuestion: What can we gain from increasing biological realism in existing neural networks?\r\n\r\nPower-efficiency at scale\r\nModern, deep neural networks*\r\nare trained using GPUs.\r\n* It is estimated that ChatGPT was trained on \r\n10,000-20,000 GPUs and that it will require\r\n30,000 GPUs to keep running stably in the future.\r\n* It is estimated that ChatGPT has 10-20 billion \r\nparameters.\r\nhttps://www.anandtech.com/show/4008/nvidias-geforce-gtx-580/17\r\n\r\nPower-efficiency at scale\r\nModern, deep neural networks*\r\nare trained using GPUs.\r\n* It is estimated that ChatGPT was trained on \r\n10,000-20,000 GPUs and that it will require\r\n30,000 GPUs to keep running stably in the future.\r\n* It is estimated that ChatGPT has 10-20 billion \r\nparameters.\r\nSingle model with 20 billion parameters:\r\n200 Watts x 30,000 GPUs = 6M Watts\r\n\r\nPower-efficiency at scale\r\nhttps://hai.stanford.edu/ai-index/2024-ai-index-report\r\nTraining a single large language model can \r\ngenerate greater CO2 emissions than the \r\ntotal lifetime emissions of 8 cars (in 2020)!\r\n\r\nPower-efficiency at scale\r\nhttps://hai.stanford.edu/ai-index/2024-ai-index-report\r\nTraining a single model can consume \r\nmore than 1000 MWh of power!\r\n\r\nPower-efficiency at scale\r\nhttps://hai.stanford.edu/ai-index/2024-ai-index-report\r\nTraining a single model can consume \r\nmore than 1000 MWh of power!\r\n‚Ä¶ with energy costs reaching 200M USD!\r\n\r\nPower-efficiency at scale\r\nYour brain runs on:\r\n\r\nPower-efficiency at scale\r\nYour brain runs on:\r\nHigh estimate ~3000 kcal a day\r\n   ‚âà145 Watts\r\n* Human brain has ~600 trillion synapses \r\n(‚âàparameters).', 'In this example: SNNs are 6 to 8 times more energy efficient than FNNs.\r\nComputing energy consumption\r\nQuestions?\r\n\r\nReading materials\r\nMain reading:\r\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \r\nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\r\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\r\n- Neuromorphic computing:\r\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \r\nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\r\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \r\noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\r\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \r\nhttps://www.nature.com/articles/s41586-019-1677-2\r\nExtra reading:\r\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \r\nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\r\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \r\nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \r\nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\r\nBasics of \'conventional\' neural networks:\r\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\r\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.\r\n\r\nReferences\r\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \r\nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\r\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947.', '8. Green AI\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nLu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\nCarolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl\r\n\r\n- Overview of Green AI \r\n- Large language models \r\n- Green data-centric AI \r\n- Model simplification \r\n- Hyper parameter tuning \r\n- Mixture of Experts and DeepSeek \r\n- Green AI at Meta \r\n\r\nAI\r\n‚Ä¢ Artificial Intelligence (AI) is the branch of computer science that deals with \r\nautomating tasks that typically require human intelligence. \r\n‚Ä¢ In the past years AI has been widely applied across different domains.\u2028\r\nE.g., health care, transportation, finance. \r\n‚Ä¢ To deploy AI systems, we test them against benchmarks (or validation sets). \r\n‚Ä¢ The goal is to outperform the previous existing models. \r\n‚Ä¢ E.g., in Machine Learning we usually resort to accuracy metrics. The \r\nhighest the accuracy, the better the model.\r\n3\r\n\r\nSince 2012, the amount of computing used for AI \r\ntraining has been doubling every 6 months\r\n‚Ä¢ https://epoch.ai/blog/compute-trends\r\n4\r\n\r\n‚Ä¢ To create better AI systems we are currently adding \r\n‚Ä¢ More data \r\n‚Ä¢ More experiments \r\n‚Ä¢ Larger models\r\n5\r\n\r\nThe Equation of Red AI\r\nCost(R) ‚àùE¬∑D¬∑H\r\nCost of a single (E)xample\r\nSize of (D)ataset\r\nNumber of (H)yperparameters\r\nBy Schwartz et al. (2020)\r\n\r\nIssues of Red AI\r\n‚Ä¢ High costs (hardware, electricity, data access, etc.) \r\n‚Ä¢ Limited reproducibility.  \r\n‚Ä¢ Energy consumption. \r\n‚Ä¢ Carbon emissions. \r\n‚Ä¢ SMEs can hardly be competitive. \r\n‚Ä¢ Groundbreaking AI research is mostly done by tech giants.\r\n7\r\n\r\nA few examples of Red AI\r\n‚Ä¢ Google‚Äôs BERT-large \r\n‚Ä¢ 350 million features \r\n‚Ä¢ Trained for 2.5 days using 512 TPU chips, costing $60K+ \r\n‚Ä¢ Open-GPT3 (now GPT-4/o1) \r\n‚Ä¢ 550 tonnes CO2-eq (Patterson, 2021) \r\n‚Ä¢ 175 billion features \r\n‚Ä¢ API is open but no-pretrained model is available \r\n‚Ä¢ AlphaGo \r\n‚Ä¢ 1920 CPUs, 280 GPUs, costing $35M\r\n8\r\n\r\nRed AI in Large Language Models (LLMs)\r\n‚Ä¢ OPT by Meta reports 75 tons CO2-eq (1/7 of OpenGPT‚Äôs footprint).\u2028\r\n(Also 175billion params) \r\n‚Ä¢ However, Llama 3 reported 2,290 tons of CO2-eq (7.7M GPU hours \r\ntraining ) \r\n‚Ä¢ Open science: release includes both the pretrained models and the code \r\nneeded to train and use them. \r\n‚Ä¢ DeepSeek-V3 claims ‚Äúonly‚Äù 2.78M GPU hours \r\n‚Ä¢ Bloom by Huggingface reports 25 tons, 51 when considering embodied \r\nand operational carbon footprint. (176billion params)\r\n9\r\n\r\nRed AI\r\nAccuracy: 0.999999999\r\nGreen AI\r\n‚Ä¢ Energy \r\n‚Ä¢ Time \r\n‚Ä¢ Reproducibility \r\n‚Ä¢ Reusage\r\n\r\nHow can we adopt Green AI\r\n‚Ä¢ Check whether AI is needed. \r\n‚Ä¢ Select green datacenters. \r\n‚Ä¢ Run on low carbon intensity hours. \r\n‚Ä¢ Opt for GPU-optimised solutions (?) \r\n‚Ä¢ Opt for low-power hardware (e.g., Nvidia Jetson boards) \r\n‚Ä¢ Or GPUs that provide energy metrics (e.g., NVIDIA GPUs via the nvidia-smi tool) \r\n‚Ä¢ Report energy/carbon metrics (e.g., embed in MLFlow?)', ""Oversimplification\r\nThere are also multiple other advantages‚Ä¶\r\n\r\nHuman vs. computer computation\r\n- Fast real-time decision making, e.g. sports, e-sports\r\n- Adaptive, e.g. context-aware and employs selective attention\r\n- Energy efficient: Close to 100 billion neurons in the brain\r\n- Robust, for example to changes in illumination or obstructions in object tracking\r\n\r\nHuman vs. computer computation\r\nBrains are energy efficient: Why?\r\n1.\r\nHigh temporal resolution (more computation with less neurons)\r\n2.\r\nSparse encoding\r\n\r\nHuman vs. computer computation\r\nQuestions?\r\nBrains are energy efficient: Why?\r\n1.\r\nHigh temporal resolution (more computation with less neurons)\r\n2.\r\nSparse encoding\r\n\r\nHow do biological neurons communicate?\r\nAnalogy to artificial neural networks\r\nReal neuron\r\nArtificial neuron\r\nCurrent\r\n\r\nHow do biological neurons communicate?\r\nHow does the electrical activity propagate?\r\n?\r\nCurrent\r\n\r\nHow do biological neurons work?\r\ntime\r\nelectrode\r\nhttps://tinmard.github.io/spike-sorting-animation.html\r\nQuick electrical pulses trigger chemical signals for the next neuron ‚Üí Spikes\r\n\r\nHow do biological neurons work?\r\nQuick electrical pulses trigger chemical signals for the next neuron ‚Üí Spikes\r\nhttps://tinmard.github.io/spike-sorting-animation.html\r\ntime\r\nelectrode\r\nFrom CS perspective:\r\nSparse binary \r\nencoding\r\n\r\nBiologically realistic spiking neuron models\r\nBiologically realistic neuron models have \r\na new dimension: Time!\r\nSpiking neural networks (SNNs):\r\nThe input x  (t  ) to each neuron is summed \r\n(integrated) over time.\r\nscalar\r\nfunction of \r\ntime\r\n(t)\r\n(t)\r\nhttps://www.mdpi.com/2076-3425/12/7/863\r\n\r\nHow to model spiking neurons?\r\nANN: Perceptron, threshold activation function:\r\n\r\nHow to model spiking neurons?\r\nANN: Perceptron, threshold activation function:\r\n\r\nHow to model spiking neurons?\r\nSpiking neural network (SNN): The 'input current' Œµ(t) is integrated over time.\r\nspike\r\n\r\nHow to model spiking neurons?\r\nEquivalence to perceptron: Computation at least as complex as a perceptron.\r\n\r\nNon-leaky integrate-and-fire (IF) neuron\r\nThe temporal profile of the input current Œµ(t) can be chosen differently, for different computations.\r\n\r\nQuestions?\r\n\r\nComputation with spiking neurons\r\nCoincidence detection\r\n\r\nComputation with spiking neurons\r\nCoincidence detection\r\nx, y ‚àà {0, 1}n\r\nExample: n = 2\r\ninput = \r\nx1\r\nx2\r\ny1\r\ny2\r\n= \r\n0\r\n1\r\n1\r\n1\r\noutput? \r\n\r\nCoincidence detection\r\nComputation with spiking neurons\r\n\r\nCoincidence detection\r\nCan be trivially computed with a single spiking neuron! Requires at least n/log(n+1) hidden \r\nunits for a perceptron (proof in [7]).\r\nComputation with spiking neurons\r\n\r\nCoincidence detection\r\nCan be trivially computed with a single spiking neuron! Requires at least n/log(n+1) hidden \r\nunits for a perceptron (proof in [7]).\r\nBrains are energy efficient: \r\n1.\r\nHigh temporal resolution (more computation with less neurons)\r\nComputation with spiking neurons\r\n\r\nEncoding strategies\r\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\r\nHow should we encode information about 'features' in a large network with many spikes?\r\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\r\nElephant?\r\nhttps://www.nationalgeographic.com/anim\r\nals/mammals/facts/african-elephant\r\n\r\nFiring rates\r\nClassical view of the brain:\r\n- Each neuron is selective for one specific \r\nfeature in the input."", '‚Ä¢ Improve parameter-tuning strategy.\r\n11\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ We need benchmarks. \r\n‚Ä¢ AllenAI leaderboard\u2028\r\nhttps://leaderboard.allenai.org \r\n‚Ä¢ No carbon metrics, yet \r\n‚Ä¢ Report comparable proxies for energy \r\nconsumption. \r\n‚Ä¢ ‚ö† Learning algorithms behave in a non-\r\ndeterministic \r\n‚Ä¢ ‚ö† Different data-points lead to different \r\nenergy consumption\r\n12\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ Reporting measured energy consumption \r\n‚Ä¢ + Accurate \r\n‚Ä¢ + Easy to map to carbon emissions \r\n‚Ä¢ - Hard to measure \r\n‚Ä¢ - Low replicability \r\n‚Ä¢ Reporting time / estimation based on time & hardware \r\n‚Ä¢ + Easy to measure \r\n‚Ä¢ + Correlates with energy consumption in most cases. \r\n‚Ä¢ -  Difficult to compare with measurements from other setups \r\n‚Ä¢ E.g., floating point operations (FPOs) (?) \r\n‚Ä¢ + comparable across different setups \r\n‚Ä¢ + cheap \r\n‚Ä¢ - does not factor in memory energy consumption \r\n‚Ä¢ - does not reflect carbon emissions\r\n13\r\n\r\nData-centric AI\r\n\r\nData-centric AI\r\n‚Ä¢ Emerging discipline that deals with systematically engineering data to build AI \r\nsystems. \r\n‚Ä¢ Shift from improving the training strategy to improving the data. \r\n‚Ä¢ It is better to have small but reliable datasets than large but noisy \r\ndatasets. \r\n‚Ä¢ => Improve data collection, data labelling, and data preprocessing. \r\n‚Ä¢ More about data-centric AI by Andrew Ng:\u2028\r\nhttps://www.youtube.com/watch?v=06-AZXmwHjo\r\n15\r\n\r\n\r\nGreen Data-centric AI\r\n‚Ä¢ How do different ML algorithms compare \r\nin terms of energy consumption? \r\n‚Ä¢ How does number of rows relate to the \r\nenergy consumption of ML models? \r\n‚Ä¢ How does number of features relate to \r\nthe energy consumption of ML models? \r\n‚Ä¢ What is the impact of reducing data in the \r\nperformance of the model? \r\n‚Ä¢ Method -> results -> discussion\r\n17\r\n\r\nMethod\r\n‚Ä¢ Single object of study: natural language model to detect spam messages. \r\n‚Ä¢ 6 machine learning algorithms: SVM, Decision Tree, KNN, Random Forrest, \r\nAdaBoost, Bagging Classifier. \r\n‚Ä¢ Reduce the number of rows. 10%, 20%, .., 100% \r\n‚Ä¢ Stratified random sampling (?) \r\n‚Ä¢ Reduce the number of features. 10%, 20%, .., 100% \r\n‚Ä¢ Feature importance metric based on the Chi-Square Test (Chi2) \r\n‚Ä¢ Estimate energy consumption using a RAPL-based tool. (?)\r\n18\r\n\r\n‚Ä¢ Repeat 30 times \r\n‚Ä¢ Fix random seeds \r\n‚Ä¢ ‚Ä¶ \r\n‚Ä¢ Data was not Normal => tailed Normal distribution.\r\n19\r\n(?)\r\n\r\nResults: energy consumption of algorithms\r\n\r\nResults: energy vs data shape\r\n\r\nResults: performance vs data shape\r\n\r\nDiscussion\r\n‚Ä¢ Other data properties should be investigated. \r\n‚Ä¢ E.g., data types \r\n‚Ä¢ Reporting energy data is essential. It can lead to different model selection \r\nwithout hindering model performance. \r\n‚Ä¢ There is a big opportunity in Model and Data Simplification.\r\n23\r\n\r\nData/Model Simplification\r\n‚Ä¢ (?) \r\n‚Ä¢ Data selection \r\n‚Ä¢ Data quantisation. Posit? \r\n‚Ä¢ Data distillation \r\n‚Ä¢ Coreset extraction (?) \r\n‚Ä¢ Model distillation \r\n‚Ä¢ Model quantisation \r\n‚Ä¢ Model pruning \r\n‚Ä¢ ‚Ä¶\r\n24\r\n\r\nPosit vs Float\r\nMore about this: https://spectrum.ieee.org/floating-point-numbers-posits-processor\r\nBetter for DL use cases\r\n\r\nHow can we tune \r\nlearning \r\nparameters \r\nefficiently?\r\n\r\nHyper parameter tuning\r\n‚Ä¢ When training an ML model, there are several parameters that need to be \r\ntuned. \r\n‚Ä¢ E.g., in SVM we have the Regularization parameter C, the kernel function, \r\nthe degree of the kernel function, and depending on the case, many other. \r\n‚Ä¢ The common approach revolves around grid search.', 'Interviews?) & rich \r\ndescription of outcomes focus of grading\r\nhttps://eip.pages.ewi.tudelft.nl/eip-website/queue.html\r\n\r\nC1. Compare energy consumption of docker images for \r\nML workloads.\r\n‚Ä¢ Similar to what we have seen in the lectures but for ML-specific workloads. \r\n‚Ä¢ We can reuse existing experiment replication packages.\r\n22\r\n\r\nC2. Plugin to visualize Hugging Face carbon emissions.\r\n‚Ä¢ https://huggingface.co/blog/leaderboard-emissions-\r\nanalysis \r\n‚Ä¢\r\nYoo, Taewon, et al. ""Visualizing the Carbon Intensity of Machine Learning Inference for Image Analysis on TensorFlow Hub.""\r\n\r\nC3. Plugin for ChatGPT\r\n‚Ä¢ Users seldom know how much carbon they are emitting when they interact \r\nwith chat GPT. \r\n‚Ä¢ Let‚Äôs make it transparent to the users. Browser plugin?\r\n24\r\nCO2\r\n\r\nC4. NutriScore for software libraries\r\n25\r\n‚Ä¢ NutriScore labels are not perfect but they are a good starting point! \r\n‚Ä¢ What if we could do the same thing for the energy efficiency of software. \r\n‚Ä¢ (Also open to individual or social sustainability) \r\n‚Ä¢ This work can be scoped in particular domains/ecossystems/use cases. \r\n‚Ä¢ Libraries for stats? ML? Web Dev? Cloud?\r\n\r\nC5. Add energy-awareness to existing software\r\n26\r\n‚Ä¢ Streamlit, Notebooks, JSFiddle, \r\nPyScript, zsh, etc. \r\n‚Ä¢\r\n\r\nC6 - Green Shift Left\r\n‚Ä¢ Estimate energy efficiency using static code analysis. \r\n‚Ä¢ We don‚Äôt need an accurate value. \r\n‚Ä¢ It is useful to know which code is more likely to \r\nintroduce energy hotspots and that should be \r\nreviewed with more attention. \r\n‚Ä¢ Can be scoped to a particular domain (react, php, data \r\nscience, web, etc., etc.)\r\n27\r\n\r\nC7 - Education\r\n‚Ä¢ Educational game for Software \r\nSustainability practices \r\n‚Ä¢ Purpose: use within software teams to \r\ndiscuss or learn about different sustainable \r\nIT practices: at the organisation level, \r\nsoftware, etc.\r\n28\r\nhttps://github.com/OttoKaaij/Ticket-To-Sustainability/?tab=readme-ov-file\r\n\r\nProject ideas (old)\r\n‚Ä¢ Plugin from EnergiBridge (GUI, report generator, python library, etc.) \r\n‚Ä¢ Plugin for ChatGPT (carbon emissions per chat window) \r\n‚Ä¢ Seamless measurements for AI libraries \r\n‚Ä¢ Energy patterns for Green AI \r\n‚Ä¢ Sustainable SW dev gamification \r\n‚Ä¢ Sustainability auditor for AI projects \r\n‚Ä¢ Energy Profiling of screen colour filter tools (or display settings) \r\n‚Ä¢ ‚Ä¶ you can also propose yours!\r\n\r\nhttps://edu.nl/64gpk\r\nedu.nl/64gpk', '‚Ä¢ Groundbreaking AI research is mostly done by tech giants.\r\n7\r\n\r\nA few examples of Red AI\r\n‚Ä¢ Google‚Äôs BERT-large \r\n‚Ä¢ 350 million features \r\n‚Ä¢ Trained for 2.5 days using 512 TPU chips, costing $60K+ \r\n‚Ä¢ Open-GPT3 (now GPT-4/o1) \r\n‚Ä¢ 550 tonnes CO2-eq (Patterson, 2021) \r\n‚Ä¢ 175 billion features \r\n‚Ä¢ API is open but no-pretrained model is available \r\n‚Ä¢ AlphaGo \r\n‚Ä¢ 1920 CPUs, 280 GPUs, costing $35M\r\n8\r\n\r\nRed AI in Large Language Models (LLMs)\r\n‚Ä¢ OPT by Meta reports 75 tons CO2-eq (1/7 of OpenGPT‚Äôs footprint).\u2028\r\n(Also 175billion params) \r\n‚Ä¢ However, Llama 3 reported 2,290 tons of CO2-eq (7.7M GPU hours \r\ntraining ) \r\n‚Ä¢ Open science: release includes both the pretrained models and the code \r\nneeded to train and use them. \r\n‚Ä¢ DeepSeek-V3 claims ‚Äúonly‚Äù 2.78M GPU hours \r\n‚Ä¢ Bloom by Huggingface reports 25 tons, 51 when considering embodied \r\nand operational carbon footprint. (176billion params)\r\n9\r\n\r\nRed AI\r\nAccuracy: 0.999999999\r\nGreen AI\r\n‚Ä¢ Energy \r\n‚Ä¢ Time \r\n‚Ä¢ Reproducibility \r\n‚Ä¢ Reusage\r\n\r\nHow can we adopt Green AI\r\n‚Ä¢ Check whether AI is needed. \r\n‚Ä¢ Select green datacenters. \r\n‚Ä¢ Run on low carbon intensity hours. \r\n‚Ä¢ Opt for GPU-optimised solutions (?) \r\n‚Ä¢ Opt for low-power hardware (e.g., Nvidia Jetson boards) \r\n‚Ä¢ Or GPUs that provide energy metrics (e.g., NVIDIA GPUs via the nvidia-smi tool) \r\n‚Ä¢ Report energy/carbon metrics (e.g., embed in MLFlow?) \r\n‚Ä¢ Use pre-trained models (Transfer Learning) \r\n‚Ä¢ Preprocess dataset to reduce size. \r\n‚Ä¢ Improve parameter-tuning strategy.\r\n11\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ We need benchmarks. \r\n‚Ä¢ AllenAI leaderboard\u2028\r\nhttps://leaderboard.allenai.org \r\n‚Ä¢ No carbon metrics, yet \r\n‚Ä¢ Report comparable proxies for energy \r\nconsumption. \r\n‚Ä¢ ‚ö† Learning algorithms behave in a non-\r\ndeterministic \r\n‚Ä¢ ‚ö† Different data-points lead to different \r\nenergy consumption\r\n12\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ Reporting measured energy consumption \r\n‚Ä¢ + Accurate \r\n‚Ä¢ + Easy to map to carbon emissions \r\n‚Ä¢ - Hard to measure \r\n‚Ä¢ - Low replicability \r\n‚Ä¢ Reporting time / estimation based on time & hardware \r\n‚Ä¢ + Easy to measure \r\n‚Ä¢ + Correlates with energy consumption in most cases. \r\n‚Ä¢ -  Difficult to compare with measurements from other setups \r\n‚Ä¢ E.g., floating point operations (FPOs) (?) \r\n‚Ä¢ + comparable across different setups \r\n‚Ä¢ + cheap \r\n‚Ä¢ - does not factor in memory energy consumption \r\n‚Ä¢ - does not reflect carbon emissions\r\n13\r\n\r\nData-centric AI\r\n\r\nData-centric AI\r\n‚Ä¢ Emerging discipline that deals with systematically engineering data to build AI \r\nsystems. \r\n‚Ä¢ Shift from improving the training strategy to improving the data. \r\n‚Ä¢ It is better to have small but reliable datasets than large but noisy \r\ndatasets. \r\n‚Ä¢ => Improve data collection, data labelling, and data preprocessing. \r\n‚Ä¢ More about data-centric AI by Andrew Ng:\u2028\r\nhttps://www.youtube.com/watch?v=06-AZXmwHjo\r\n15\r\n\r\n\r\nGreen Data-centric AI\r\n‚Ä¢ How do different ML algorithms compare \r\nin terms of energy consumption? \r\n‚Ä¢ How does number of rows relate to the \r\nenergy consumption of ML models? \r\n‚Ä¢ How does number of features relate to \r\nthe energy consumption of ML models? \r\n‚Ä¢ What is the impact of reducing data in the \r\nperformance of the model?', '‚Ä¢ Examples: \r\n‚Ä¢ Technical Debt \r\n‚Ä¢ Does it scale? \r\n‚Ä¢ Software testing \r\n‚Ä¢ Bus-factor \r\n‚Ä¢ Data integrity \r\n‚Ä¢ Innovation \r\n‚Ä¢ ‚Ä¶\r\n10\r\n\r\nIndividual\r\n‚Ä¢ Well-being of the individuals in an organisation.\u2028\r\nNote that it also includes how well individuals interact \r\nwith each other within the org. \r\n‚Ä¢ Examples: \r\n‚Ä¢ mental and physical well-being \r\n‚Ä¢ self-respect \r\n‚Ä¢ education/skills \r\n‚Ä¢ career development \r\n‚Ä¢ ‚Ä¶\r\n11\r\n\r\nSocial\r\n‚Ä¢ concerned with societal communities (groups of people, \r\norganisations) and the factors that erode trust in society. \r\n‚Ä¢ Examples: \r\n‚Ä¢ Social equity \r\n‚Ä¢ Justice \r\n‚Ä¢ Employment \r\n‚Ä¢ Democracy \r\n‚Ä¢ ‚Ä¶ \r\n‚Ä¢ Also includes compliance with policies and regulations \r\n12\r\n\r\nEnvironmental Sustainability\r\n‚Ä¢ the branch of Software Engineering that studies \r\nthe development of software that has minimal \r\nimpact in our planet throughout its whole \r\nlifecycle. \r\n‚Ä¢ Looking at software at different levels: \r\n‚Ä¢ Developing, Using, Serving, ‚Ä¶ \r\n‚Ä¢ Also includes e-waste. \r\n‚Ä¢ Almost identical to Green Software. (?)\r\n13\r\nBordallo II\r\n\r\nGreen Software\r\n‚Ä¢ Sustainability and energy efficiency. \r\n‚Ä¢ Building energy-efficient software is important also from a \r\ntechnical sustainability POV. \r\n‚Ä¢ Smartphones, smart wearables, IoT devices, etc. run on limited \r\npower resources. \r\n‚Ä¢ Developing software to these devices require energy-efficiency \r\ntesting and improvement. \r\n‚Ä¢ It also leads to environmental sustainability (e.g., less battery \r\ncycles) \r\n‚Ä¢ Important for UX (e.g., no need to walk around with power banks)\r\n14\r\n\r\nhttps://www.menti.com/uns9d89kzn\r\nWhat is the sustainability \r\ndimension you are most \r\ninterested in?\r\n?\r\n15\r\n\r\nEconomical sustainability tops the environment\r\n‚Ä¢ In general, a software project will not survive if it‚Äôs not economical \r\nsustainable \r\n‚Ä¢ Yet, a project can survive even if it is not environmental sustainable \r\n‚Ä¢ The mindset is changing! \r\n‚Ä¢ Software consumers have started to worry about the climate impact \r\nof their behaviour as users. \r\n‚Ä¢ Being environmentally sustainable is now an important competitive \r\nfactor \r\n‚Ä¢ Marketing teams are already using all eco-friendly labels. Technical \r\nteams are not there yet, though. \r\n‚Ä¢ It‚Äôs easier said than done!\r\n$\r\n16\r\n\r\nGreen Washing\r\n‚Ä¢ Deceptively use marketing techniques to \r\nclaim being eco-friendly. \r\n‚Ä¢ Opting for green-coloured designs. \r\n‚Ä¢ Red/orange is usually perceived as \r\ntasty. \r\n‚Ä¢ Green is perceived as eco-friendly. \r\n‚Ä¢ The VW case. (?)\r\n17\r\n\r\nThe VW scandal\r\nGreenwashing\r\n‚Ä¢ Used software to cheat on vehicle emissions \r\ntests. \r\n‚Ä¢ The vehicle‚Äôs software could detect whether they \r\nwere being tested, changing the performance \r\naccordingly to improve results. \r\n‚Ä¢ Affected 11M cars worldwide, 8M in Europe.\r\n18\r\n\r\nHow can we drive sustainability \r\nin the SE industry?\r\n\r\nGreen Procurement\r\n‚Ä¢ Customers decide on providers that share their values \r\n‚Ä¢ This is currently the main trigger reason why organisations \r\nworry about Sustainability and Green Software. \r\n‚Ä¢ Examples of green procurement: \r\n‚Ä¢ Customers that only buy green services/products \r\n‚Ä¢ Companies that only use green providers \r\n‚Ä¢ Developers that only work for green companies \r\n‚Ä¢ Green procurement makes environmental sustainability \r\nessential for economical sustainability.\r\n20\r\n\r\nSustainability via compliance\r\n‚Ä¢ EU wants to be carbon neutral by 2030 \r\n‚Ä¢ This also affects the ICT sector. Estimated to impact \r\n14% of the global carbon footprint by 2040. \r\n‚Ä¢ Some initiatives are already being negotiated. \r\n‚Ä¢ Extending the smartphone lifetime to 7 years. \r\n‚Ä¢ Right-to-repair movement. https://repair.eu \r\n‚Ä¢ Making IT services relying on clean energy more \r\naccessible (e.g., less taxes).\r\n21\r\n\r\nSoftware for Sustainability \r\n‚Ä¢ We are not covering it in this course.', ""‚Ä¢ 6 machine learning algorithms: SVM, Decision Tree, KNN, Random Forrest, \r\nAdaBoost, Bagging Classifier. \r\n‚Ä¢ Reduce the number of rows. 10%, 20%, .., 100% \r\n‚Ä¢ Stratified random sampling (?) \r\n‚Ä¢ Reduce the number of features. 10%, 20%, .., 100% \r\n‚Ä¢ Feature importance metric based on the Chi-Square Test (Chi2) \r\n‚Ä¢ Estimate energy consumption using a RAPL-based tool. (?)\r\n18\r\n\r\n‚Ä¢ Repeat 30 times \r\n‚Ä¢ Fix random seeds \r\n‚Ä¢ ‚Ä¶ \r\n‚Ä¢ Data was not Normal => tailed Normal distribution.\r\n19\r\n(?)\r\n\r\nResults: energy consumption of algorithms\r\n\r\nResults: energy vs data shape\r\n\r\nResults: performance vs data shape\r\n\r\nDiscussion\r\n‚Ä¢ Other data properties should be investigated. \r\n‚Ä¢ E.g., data types \r\n‚Ä¢ Reporting energy data is essential. It can lead to different model selection \r\nwithout hindering model performance. \r\n‚Ä¢ There is a big opportunity in Model and Data Simplification.\r\n23\r\n\r\nData/Model Simplification\r\n‚Ä¢ (?) \r\n‚Ä¢ Data selection \r\n‚Ä¢ Data quantisation. Posit? \r\n‚Ä¢ Data distillation \r\n‚Ä¢ Coreset extraction (?) \r\n‚Ä¢ Model distillation \r\n‚Ä¢ Model quantisation \r\n‚Ä¢ Model pruning \r\n‚Ä¢ ‚Ä¶\r\n24\r\n\r\nPosit vs Float\r\nMore about this: https://spectrum.ieee.org/floating-point-numbers-posits-processor\r\nBetter for DL use cases\r\n\r\nHow can we tune \r\nlearning \r\nparameters \r\nefficiently?\r\n\r\nHyper parameter tuning\r\n‚Ä¢ When training an ML model, there are several parameters that need to be \r\ntuned. \r\n‚Ä¢ E.g., in SVM we have the Regularization parameter C, the kernel function, \r\nthe degree of the kernel function, and depending on the case, many other. \r\n‚Ä¢ The common approach revolves around grid search. The user provides a \r\nsequence of possible values for each parameter and the pipeline runs all \r\npossible combinations. \r\n‚Ä¢ Our question: Can we save energy with alternative approaches? \r\n‚Ä¢ We studied Grid Search, Random Search and Bayesian \r\nOptimisation.\r\n27\r\nTim's MSc Thesis, 2022 \r\nAccepted at CAIN‚Äô23\r\n\r\n\r\nResults\r\n29\r\nConclusions? \r\n‚Ä¢ Bayesian converges faster. \r\n‚Ä¢ No clear winner between Grid and Random\r\n\r\nDeepSeekMoE\r\n30\r\nPreprint at ArXiv, 2024 https://arxiv.org/pdf/\r\n2401.06066\r\n\r\nMixture of Experts\r\n‚Ä¢ Llama3.1 has 405B parameters, DeepSeek V3 671B \r\n‚Ä¢ Yet DeepSeek has quicker inference times and claims less energy \r\nconsumption (?) \r\n‚Ä¢ Divide the model into smaller blocks of experts \r\n‚Ä¢ Tokens get routed to certain experts based on the query \r\n‚Ä¢ Only part of the network is active during inference \r\n‚Ä¢ DeepSeek claims only 37B out of 671B parameters get active\r\n31\r\n\r\nDeepSeekMoE\r\n32\r\n\r\nDeepSeekMoE\r\n33\r\n‚Ä¢ Comparable performance to \r\nLLaMA2 7B effectively using \r\nless half the parameters \r\n‚Ä¢ Less computational power \r\n‚Ä¢ Problems (?) \r\n‚Ä¢ Still need to load all the \r\nparameters \r\n‚Ä¢ High memory -> high \r\nembodied carbon\r\n\r\nGreen AI at FacebookMeta\r\n34\r\nSustainable AI: Environmental Implications, \r\nChallenges and Opportunities (2022)\r\n\r\nCarbon footprint mapped to the AI lifecycle\r\n‚Ä¢ There are 4 main overarching stages where carbon emissions need to be isolated: data \r\ncollection, experimentation, training, inference. \r\n‚Ä¢ At Facebook, recommendation systems split energy consumption evenly between \r\ntraining and inference; text translation models have a 35%/65% split. (Operational cost) \r\n‚Ä¢ Operational/embodied cost split: 30%/70%\r\n35\r\n\r\nOpen issues according to Meta\r\n‚Ä¢ A vast portion of projects only use GPUs at 30%.\u2028\r\nShould be higher to attenuate embodied carbon."", 'google.com/view/energy-efficiency-languages\r\n21\r\nAna Radovanovic ÃÅ, Ross Koningstein, Ian Schneider, Bokan \r\nChen, Alexandre Duarte, Binz Roy, Diyue Xiao, Maya \r\nHaridasan, Patrick Hung, Nick Care, Saurav Talukdar, Eric \r\nMullen, Kendal Smith, MariEllen Cottman, and Walfredo Cirne \r\n\r\n\r\n‚Ä¢ Google‚Äôs Carbon-Intelligent Computing System (CICS) \r\n‚Ä¢ Main idea: use carbon-intensity data to shift datacenter jobs in time \r\n‚Ä¢ Typically, job schedulers use a metric of cluster capacity to schedule a job in \r\na particular cluster. \r\n‚Ä¢ CICS overrides this metric with the virtual capacity curve (VCC) that \r\nfactors in Carbon intensity \r\n‚Ä¢ When a new job comes in, the scheduler estimates its CPU load and power \r\nusage and assigns it to a cluster if the VCC is not exceeded.\r\n23\r\n\r\n‚Ä¢ Jobs are divided between flexible and inflexible. \r\n‚Ä¢ Flexible load is considered shapeable/shiftable as long as its total daily \r\ncompute (CPU) demand is preserved \r\n‚Ä¢ The system needs to consider that, while running a job, the virtual capacity \r\ncurve (VCC) might drop. Hence, this job should not start in the first place. \r\n‚Ä¢ They forecast VCC for the next day\r\n24\r\n\r\n\r\nVirtual Cluster Capacity (VCC)\r\n‚Ä¢ Aims at reducing the peak load at carbon intensive hours but in total it should allow for the \r\nsome amount of daily computation! \r\n‚Ä¢ Considers Carbon intensity \r\n‚Ä¢ Using data from electricityMap.org \r\n‚Ä¢ It does not use carbon intensity directly.\u2028\r\nCarbon intensity is converted to a cost (kgCO2 -> $$) \r\n‚Ä¢ This way, they can factor in other metrics that can also be converted to money. E.g., the \r\ncost saved by preventing peak load \r\n‚Ä¢ Peak workload entails extra cost at the infrastructure level (e.g., control faclities‚Äô \r\ntemperature). \r\n‚Ä¢ By using money cost instead of carbon cost, they have more data available.\r\n26\r\n\r\nVirtual Cluster Capacity (VCC)\r\n‚Ä¢ If the forecast of VCC fails it shift flexible workload more than expected.  \r\n‚Ä¢ This happens because the amount of workload forecasted was below the \r\nworkload needed, and VCC was ‚Äúaggressively‚Äù low. \r\n‚Ä¢ The systems fall back to the real cluster capacity for 1 week until results \r\nstart being realistic again.\r\n27\r\n\r\nNext steps\r\n‚Ä¢ They will consider spatial flexibility. \r\n‚Ä¢ I.e., tasks that can be shifted over time and over space. \r\n‚Ä¢ It needs to factor in relocation overheads, though.\r\n28\r\n\r\nCritical questions\r\n‚Ä¢ Who defines what is flexible and inflexible? \r\n‚Ä¢ How do you estimate the CPU load of a given task?\r\n29\r\n\r\nEnergy Regression Testing\r\n‚ÜíEnergy?\r\nGreener? Greener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\n\r\nE-compare\r\nGithub Actions\r\n‚ûú https://koenhagen.github.io/E-Compare/\r\n\r\nEnergy Regression Testing \r\n\r\n4. Debugging Energy with \r\nDocker Images\r\n\r\nUnveiling the Energy Vampires \r\nA methodology for debugging Software \r\nEnergy Consumption\r\n ‚úÖ ICSE 2025\r\n\r\nData Centers and Docker\r\n‚Ä¢ Containers are the most popular way to deploy apps into the cloud \r\n‚Ä¢ Base image is an important choice when building an image \r\n‚Ä¢ Criteria \r\n‚Ä¢ Linux distribution and binaries \r\n‚Ä¢ Image size \r\n‚Ä¢ Energy?\r\n35\r\n\r\nRedis energy consumption\r\n‚Ä¢ Ubuntu/Alpine base images have different energy consumption for Redis\r\n36\r\n\r\nRedis Energy Consumption\r\n‚Ä¢RQ1: What is the difference \r\nin energy consumption \r\nbetween glibc and musl? \r\n‚Ä¢RQ2: Can we use tracing \r\nto compare energy \r\nconsumption in shared \r\nlibraries?', 'Neuromorphic computing\r\nCS4575\r\nSustainable Software Engineering\r\n05.03.2025\r\nNergis T√∂men\r\n\r\nIntroduction\r\nComputer Vision Lab\r\nBiomorphic Intelligence Lab\r\nBiomedical Intervention Optimisation Lab\r\nNergis\r\n\r\nNeuromorphic computing\r\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\r\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\r\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing\r\n\r\nHow many of you are familiar \r\nwith neural networks?\r\n\r\nSimple model of an artificial neuron\r\nhttps://medium.com/@cprasenjit32/perceptron-a-simple-yet-mighty-machine-learning-algorithm-9ff6b7d86a71\r\n\r\nWhat is a neural network?\r\nhttps://www.tibco.com/reference-center/what-is-a-neural-network\r\n\r\nWhy is it called a \'neural network\'?\r\nhttps://www.tibco.com/reference-center/what-is-a-neural-network\r\n\r\nWhat is a neural network?\r\nWhy is it called a \'neural network\'?\r\nMcCulloch-Pitts neuron [1, 2] (1943)\r\nWarren Sturgis McCulloch\r\n(Neurophysiologist)\r\nWalter Pitts\r\n(Logician)\r\n\r\nHow do biological neurons work?\r\nhttps://commons.wikimedia.org/wiki/File:Coincidence_detection_in_dendrites_of_pyramidal_neurons.gif\r\n\'Input current\' travels down the dendrites (top),\r\nget integrated (summed!) in the cell body\r\nwhich generates an \'output current\' (bottom)\r\nwhich is chemically transmitted to the dendrites of \r\nother neurons.\r\n\r\nSimplified picture\r\nReal neuron\r\nArtificial neuron\r\nhttps://vajiramandravi.com/quest-upsc-notes/artificial-neural-network/\r\n\r\nWhat is a neural network?\r\nMcCulloch-Pitts neuron [1, 2]\r\n1940s: How do biological neurons compute basic \r\nlogic functions? (e.g. logic gates)\r\nNote: Ref. [3] gives a nice brief history on the ideas which lead to the \r\nMcCulloch-Pitts neuron.\r\n\r\nWhat is a neural network?\r\n1950s: How are neurons organized to perform \r\nsensory perception?\r\n\r\nWhat is a neural network?\r\n1950s: How are neurons organized to perform \r\nsensory perception?\r\nThe first ""neural network"": Perceptron (1958). [4]\r\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\r\nFrank Rosenblatt (Psychologist)\r\nwith a Mark I Perceptron computer in 1960\r\n\r\nWhat is a neural network?\r\n1950s: How are neurons organized to perform \r\nsensory perception?\r\nThe first ""neural network"": Perceptron (1958). [4]\r\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\r\nFrank Rosenblatt (Psychologist)\r\nwith a Mark I Perceptron computer in 1960\r\nPower-efficient\r\n\r\nNeuromorphic computing\r\nWhy neuromorphic computing?\r\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\r\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\r\n\r\nNeuromorphic computing\r\nWhy neuromorphic computing?\r\n‚ÄòBiological inspiration‚Äô for artificial neural networks (ANNs) is not a new idea.\r\nEmulation (as opposed to simulation) of neural networks in hardware is not a new idea.', '‚Ä¢ By using money cost instead of carbon cost, they have more data available.\r\n26\r\n\r\nVirtual Cluster Capacity (VCC)\r\n‚Ä¢ If the forecast of VCC fails it shift flexible workload more than expected.  \r\n‚Ä¢ This happens because the amount of workload forecasted was below the \r\nworkload needed, and VCC was ‚Äúaggressively‚Äù low. \r\n‚Ä¢ The systems fall back to the real cluster capacity for 1 week until results \r\nstart being realistic again.\r\n27\r\n\r\nNext steps\r\n‚Ä¢ They will consider spatial flexibility. \r\n‚Ä¢ I.e., tasks that can be shifted over time and over space. \r\n‚Ä¢ It needs to factor in relocation overheads, though.\r\n28\r\n\r\nCritical questions\r\n‚Ä¢ Who defines what is flexible and inflexible? \r\n‚Ä¢ How do you estimate the CPU load of a given task?\r\n29\r\n\r\nEnergy Regression Testing\r\n‚ÜíEnergy?\r\nGreener? Greener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\n\r\nE-compare\r\nGithub Actions\r\n‚ûú https://koenhagen.github.io/E-Compare/\r\n\r\nEnergy Regression Testing \r\n\r\n4. Debugging Energy with \r\nDocker Images\r\n\r\nUnveiling the Energy Vampires \r\nA methodology for debugging Software \r\nEnergy Consumption\r\n ‚úÖ ICSE 2025\r\n\r\nData Centers and Docker\r\n‚Ä¢ Containers are the most popular way to deploy apps into the cloud \r\n‚Ä¢ Base image is an important choice when building an image \r\n‚Ä¢ Criteria \r\n‚Ä¢ Linux distribution and binaries \r\n‚Ä¢ Image size \r\n‚Ä¢ Energy?\r\n35\r\n\r\nRedis energy consumption\r\n‚Ä¢ Ubuntu/Alpine base images have different energy consumption for Redis\r\n36\r\n\r\nRedis Energy Consumption\r\n‚Ä¢RQ1: What is the difference \r\nin energy consumption \r\nbetween glibc and musl? \r\n‚Ä¢RQ2: Can we use tracing \r\nto compare energy \r\nconsumption in shared \r\nlibraries? \r\n‚Ä¢RQ3: Can we verify the \r\norigin of energy \r\nconsumption differences by \r\nrecreating the workload \r\nbehavior closely?\r\n37\r\n\r\nTracing\r\n‚Ä¢ Find libc function running at the end of the benchmark \r\n‚Ä¢ Tracing: Capture calls made to libc \r\n‚Ä¢ Introduces non-linear overhead\r\n38\r\n\r\nSynchronization\r\n‚Ä¢ Tracing slows down execution and increase energy consumption \r\n‚Ä¢ Run separately and synchronize with logs\r\n39\r\n\r\nTracing Analysis\r\n40\r\n\r\nTracing Analysis\r\n41\r\n\r\nBenchmarking memcpy\r\n‚Ä¢ Copy bytes from one part of memory to \r\nanother \r\n‚Ä¢ Depending on function parameters, different \r\nassembly-level optimizations \r\n‚Ä¢ Some not included in musl\r\n42\r\n\r\nBenchmarking memcpy\r\n‚Ä¢ Copy 4 bytes from fixed \r\npointer to moving pointer \r\n‚Ä¢ (100,300,500,600) x 1M \r\nrequests \r\n‚Ä¢  15% more power and 3X time\r\n43\r\n\r\nConclusions\r\n‚Ä¢ Significant difference in energy consumption for memcpy \r\n‚Ä¢ 8.6% difference for Redis workload and 13% in our benchmark \r\n‚Ä¢ musl trades performance for a smaller codebase \r\n‚Ä¢ No official documentation \r\n‚Ä¢ No awareness about energy performance\r\n44\r\n\r\n5. Energy Efficiency vs Code \r\nQuality\r\n\r\nMeasuring Maintainability\r\n‚Ä¢ According to ISO/IEC 25010, Maintainability is ‚Äúthe degree of \r\neffectiveness and efficiency with which a software product or \r\nsystem can be modified to improve it, correct it or adapt it to \r\nchanges in environment, and in requirements‚Äù \r\n‚Ä¢ We use the code analysis tool Better Code Hub to assess \r\nmaintainability \r\n‚Ä¢ Better Code Hub maps the ISO/IEC 25010 standard on \r\nmaintainability into a set of guidelines derived from static analysis\r\n46\r\n\r\nMaintainability of Energy Changes\r\n‚Ä¢ What is the impact of making energy-oriented code changes on \r\nthe maintainability of mobile apps?', '‚Ä¢ Deadline April 4.\r\n6\r\n\r\nStrategy\r\n‚Ä¢ Week 0 \r\n‚Ä¢ Decide project idea (today) \r\n‚Ä¢ Define steering meeting schedule \r\n‚Ä¢ Create working document of the \r\narticle: Problem statement and solution \r\nproposal! \r\n‚Ä¢ Define and assign tasks for each week. \r\n‚Ä¢ Week 1 \r\n‚Ä¢ Implementation \r\n‚Ä¢ Agreements with supervisor. \r\n‚Ä¢ Week 2 \r\n‚Ä¢ Implementation \r\n‚Ä¢ Week 3 \r\n‚Ä¢ Implementation, Full draft of article, \r\ndissemination. \r\n‚Ä¢ Week 4 \r\n‚Ä¢ Final refinements \r\n‚Ä¢ Prepare presentation\r\n7\r\n\r\nProject ideas\r\n‚Ä¢ A1. Prototype cross-machine comparable benchmarks \r\n‚Ä¢ A2. Add energy metrics to LMstudio/Ollama \r\n‚Ä¢ A3. Visualizations built-in with EnergiBridge \r\n‚Ä¢ A4. Service-based version of EnergiBridge\r\n\r\nProject ideas\r\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \r\n‚Ä¢ B2. Study test generation energy consumption \r\n‚Ä¢ B3. Energy profiling of static analysis tools \r\n‚Ä¢ B4. Detailed energy profiling of build pipelines \r\n‚Ä¢ B5. Tool supporting SusAF workshop / process \r\n‚Ä¢ B6. Dataset of government-developed OS software \r\n‚Ä¢ B7. Queue - but better for the student / TA society\r\nQuality Assurance & Testing\r\nSocial & Individual \u2028\r\nSustainability\r\n\r\nProject ideas\r\n‚Ä¢ C1. Compare energy consumption of docker images for ML workloads. \r\n‚Ä¢ C2. Create a plugin to visualize Hugging Face carbon emissions in detail. \r\n‚Ä¢ C3. Plugin for ChatGPT (footprint per chat window) \r\n‚Ä¢ C4. NutriScore for software libraries. \r\n‚Ä¢ C5. Add energy-awareness to existing software \r\n‚Ä¢ C6. Green Shift Left \r\n‚Ä¢ C7. Education for Sustainable SE\r\n\r\nA1. Prototype cross-machine comparable benchmarks\r\n‚Ä¢ Energy-usage comparisons require running both baseline + software on the \r\nsame machine ‚Üí limits how extensive our experiments can be \r\n‚Ä¢ Research community is in need of benchmarks that make energy \r\nmeasurements comparable even if executed on different machines \r\n‚Ä¢ Focus on a single task or model (i.e. computing vision, classification)\r\n\r\nA2. Adding energy metrics to LMstudio/Ollama\r\n‚Ä¢ Make energy consumption visible to users \r\nwithin local chat-interface for LLMs \r\n‚Ä¢ LMstudio/Ollama are tools for easy \r\ndeployment of LLMs \r\n‚Ä¢ Do not show energy metrics \r\n‚Ä¢ Add energy metrics to LMstudio-python \r\nor Ollama\r\nhttps://lmstudio.ai/\r\n\r\nA3. Visualizations built-in with EnergiBridge\r\n‚Ä¢ EnergiBridge simplifies energy measurement, but analysis & visualization is \r\nstill left to the user \r\n‚Ä¢ Extend the tool with well-chosen visualizations and analyses directly from the \r\nprovided data\r\n\r\nA4. Service-based version of EnergiBridge\r\n‚Ä¢ Simplify interaction & setup with EnergiBridge \r\n‚Ä¢ Service that runs independently, start/stop signals over RPC to manage \r\nexperiments \r\n‚Ä¢ Potential: create EnergiBridge interface for other prog. lang\r\n\r\nB1. Measure energy consumption of single JUnit tests\r\n‚Ä¢ We‚Äôd like to identify energy anti patterns in unit tests \r\n‚Ä¢ As a first step, we need tooling to measure and compare the energy \r\nconsumption of single unit tests \r\n‚Ä¢ Ideally including preliminary analysis looking at potential reasons for high-\r\nenergy-consuming tests\r\n\r\nB2. Study test generation energy consumption\r\n‚Ä¢ Automatic test generation mainly focuses on making strong test suites \r\n‚Ä¢ Do different techniques and configurations impact the energy consumption \r\nduring generation? \r\n‚Ä¢ Preferably focus on non-LLM test generation methods (EvoSuite, Pyguin, \r\nDSpot)\r\n\r\nB3. Detailed energy profiling of build pipelines\r\n‚Ä¢ Automatic builds have become a cornerstone of quality assurance.', 'Energy profiling of static analysis tools\r\n‚Ä¢ What is the energy consumption of a ""typical run"" for a few OSS projects? \r\n‚Ä¢ Does the type of analysis matter? Are certain analysis more expensive? Does \r\nthe number of rules that are activated in a static analysis tool important for the \r\nenergy consumption? \r\n‚Ä¢ Differences between static analysis tools [lower priority]\r\n\r\nB5. Tool supporting SusAF workshop / process\r\n‚Ä¢ Lead engineers through process & questions \r\n‚Ä¢ Interface to create & document the two diagrams \r\n‚Ä¢ (!) Should be easy to start using & set up \r\n‚Ä¢ You may also create a simplified version / \u2028\r\nyour favorite sustainability framework\r\nEnvironmental\r\nEconomic\r\nTechnical\r\nIndividual\r\nSocial\r\nImmediate\r\nEnabling\r\nStructural\r\nAirbnb\r\ngreater \r\nearnings\r\nincrease \r\nin rents\r\ngentrification\r\ngreater racial \r\ndisparities\r\nrent \r\nrooms\r\n5\r\n1\r\n3\r\n4\r\n2\r\n \r\n \r\n \r\n \r\n \r\n \r\nVery \r\nunlikely \r\nVery \r\nlikely \r\n\r\nB6. Dataset of government-developed OS software\r\n‚Ä¢ Governments develop & use software for supporting society\u2028\r\nOpen-source development & policies are on the rise \r\n‚Ä¢ But studying government software is difficult b/c we don‚Äôt know what is out \r\nthere\u2028\r\n‚Üí Lack of incentive to make popular \u2028\r\n‚Üí Language barriers \r\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \r\nbuildable?, open dev. history?, requirements documentation? \r\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!\r\n\r\nB7. Queue - but better for the student / TA society\r\n‚Ä¢ Requirements analysis regarding social and individual sustainability effects \r\nof Queue \r\n‚Ä¢ Other EIP / TUD used software also possible: e.g., Answers EWI \r\n‚Ä¢ Non-technical project ‚Üí proper process (workshops? Interviews?) & rich \r\ndescription of outcomes focus of grading\r\nhttps://eip.pages.ewi.tudelft.nl/eip-website/queue.html\r\n\r\nC1. Compare energy consumption of docker images for \r\nML workloads.\r\n‚Ä¢ Similar to what we have seen in the lectures but for ML-specific workloads. \r\n‚Ä¢ We can reuse existing experiment replication packages.\r\n22\r\n\r\nC2. Plugin to visualize Hugging Face carbon emissions.\r\n‚Ä¢ https://huggingface.co/blog/leaderboard-emissions-\r\nanalysis \r\n‚Ä¢\r\nYoo, Taewon, et al. ""Visualizing the Carbon Intensity of Machine Learning Inference for Image Analysis on TensorFlow Hub.""\r\n\r\nC3. Plugin for ChatGPT\r\n‚Ä¢ Users seldom know how much carbon they are emitting when they interact \r\nwith chat GPT. \r\n‚Ä¢ Let‚Äôs make it transparent to the users. Browser plugin?\r\n24\r\nCO2\r\n\r\nC4. NutriScore for software libraries\r\n25\r\n‚Ä¢ NutriScore labels are not perfect but they are a good starting point! \r\n‚Ä¢ What if we could do the same thing for the energy efficiency of software. \r\n‚Ä¢ (Also open to individual or social sustainability) \r\n‚Ä¢ This work can be scoped in particular domains/ecossystems/use cases. \r\n‚Ä¢ Libraries for stats? ML? Web Dev? Cloud?\r\n\r\nC5. Add energy-awareness to existing software\r\n26\r\n‚Ä¢ Streamlit, Notebooks, JSFiddle, \r\nPyScript, zsh, etc. \r\n‚Ä¢\r\n\r\nC6 - Green Shift Left\r\n‚Ä¢ Estimate energy efficiency using static code analysis. \r\n‚Ä¢ We don‚Äôt need an accurate value. \r\n‚Ä¢ It is useful to know which code is more likely to \r\nintroduce energy hotspots and that should be \r\nreviewed with more attention. \r\n‚Ä¢ Can be scoped to a particular domain (react, php, data \r\nscience, web, etc., etc.)', '[‚Ä¶]\r\n13\r\n\r\nAvoid Extraneous Graphics and \r\nAnimations  \r\n‚Ä¢ Context: Mobile apps that feature impressive graphics \r\nand animations. [‚Ä¶] \r\n‚Ä¢ Solution: Study the importance of graphics and \r\nanimations to the user experience and reduce them when \r\napplicable. [‚Ä¶]\r\n‚Ä¢ Example: Resort to low frame rates for animations when \r\npossible. \r\nDespite being important to improve user experience, graphics \r\nand animations are battery intensive and should be used with \r\nmoderation.  \r\n14\r\n\r\nEnergy Patterns are \r\nmore Frequent\r\nin Android Apps\r\n\r\nExample case: Nextcloud\r\nFOSS\r\n\r\nExample case: Nextcloud\r\n‚Ä¢ Users complain that sometimes they go on a trip and  Nextcloud drains their \r\nbattery. Users consider uninstalling the app when battery life is essential. \r\n‚Ä¢ File sync can be energy-greedy. Send large files to the server, long 3G/4G data connections. \r\n‚Ä¢ It is mostly used for backup. No real-time collaboration is needed. \r\n‚Ä¢ Energy requirements vary depending on context and user. Some days you really \r\nneed all the battery you can get. \r\n‚Ä¢ https://github.com/nextcloud/android/commit/\r\n8bc432027e0d33e8043cf40192203203a40ca29c\r\nSolutions?\r\n17\r\n\r\nExample case: K-9 mail\r\n18\r\n\r\nExample case: K-9 mail\r\n19\r\nSolutions?\r\n‚Ä¢ Some users noticed that K-9 mail was spending more energy than usual. üôâ \r\n‚Ä¢ A user that was having issues with a personal mail server  noticed that K-9 \r\nmail was the one of the most energy-greedy apps. IMAP IDLE protocol for real-time \r\nnotifications. \r\n‚Ä¢ When a connection is not possible, the app automatically retries later. \r\n‚Ä¢ https://github.com/k9mail/k-9/commit/\r\n86f3b28f79509d1a4d613eb39f60603e08579ea3\r\n\r\nEcoAndroid\r\n‚Ä¢ Plugin for IntelliJ (Android Studio) \r\n‚Ä¢ Dynamic Retry Delay \r\n‚Ä¢ Push Over Poll \r\n‚Ä¢ Reduce Size \r\n‚Ä¢ Cache \r\n‚Ä¢ Avoid Graphics and Animations\r\n20\r\n\r\nCarbon-Aware Computing for \r\nDatacenters \r\nhttps://sites.google.com/view/energy-efficiency-languages\r\n21\r\nAna Radovanovic ÃÅ, Ross Koningstein, Ian Schneider, Bokan \r\nChen, Alexandre Duarte, Binz Roy, Diyue Xiao, Maya \r\nHaridasan, Patrick Hung, Nick Care, Saurav Talukdar, Eric \r\nMullen, Kendal Smith, MariEllen Cottman, and Walfredo Cirne \r\n\r\n\r\n‚Ä¢ Google‚Äôs Carbon-Intelligent Computing System (CICS) \r\n‚Ä¢ Main idea: use carbon-intensity data to shift datacenter jobs in time \r\n‚Ä¢ Typically, job schedulers use a metric of cluster capacity to schedule a job in \r\na particular cluster. \r\n‚Ä¢ CICS overrides this metric with the virtual capacity curve (VCC) that \r\nfactors in Carbon intensity \r\n‚Ä¢ When a new job comes in, the scheduler estimates its CPU load and power \r\nusage and assigns it to a cluster if the VCC is not exceeded.\r\n23\r\n\r\n‚Ä¢ Jobs are divided between flexible and inflexible. \r\n‚Ä¢ Flexible load is considered shapeable/shiftable as long as its total daily \r\ncompute (CPU) demand is preserved \r\n‚Ä¢ The system needs to consider that, while running a job, the virtual capacity \r\ncurve (VCC) might drop. Hence, this job should not start in the first place. \r\n‚Ä¢ They forecast VCC for the next day\r\n24\r\n\r\n\r\nVirtual Cluster Capacity (VCC)\r\n‚Ä¢ Aims at reducing the peak load at carbon intensive hours but in total it should allow for the \r\nsome amount of daily computation!', 'Carbon-free giants\r\n‚Ä¢ Google, Microsoft, Meta/Facebook want to be carbon free by 2030 \r\n‚Ä¢ Carbon free is different from carbon neutral \r\n‚Ä¢ Green IT experts are needed to meet these goals\r\n23\r\n\r\n\r\nRebound effect*\r\n‚Ä¢ Energy consumption decreases ‚Üì‚Üì but demand also increases ‚Üë‚Üë. \r\n‚Ä¢ *a.k.a. Jevons Paradox in economics; Downs‚ÄìThomson paradox in\xa0mobility.\r\nEnergy per prompt\r\nPrompts\r\n100\r\n80\r\n30\r\n38\r\nChat \r\nGPT\r\n‚ÄúEnergy-efficient‚Äù \r\nChat GPT\r\n0\r\n\r\nIs sustainability an\u2028\r\nethical issue?\r\n‚Ä¢ Climate change is more likely to affect the \r\npoorest countries. \r\n‚Ä¢ Less financial resources to adapt \r\n‚Ä¢ Climate-impact does not necessarily affect \r\npolluting countries. \r\n‚Ä¢ Poorest countries have contributed less to the \r\nclimate change. \r\n‚Ä¢ We need to figure out how to do more using \r\nless resources.\r\n26\r\n\r\nMorality ‚â† Moralising\r\n‚Ä¢ We should not use climate action as a \r\nshaming weapon \r\n‚Ä¢ Climate action should be agnostic of political \r\nviews, ideology, social status, etc. \r\n‚Ä¢ We need everyone to take action!\r\n27\r\n\r\nWhy?\r\n‚Ä¢ Throughout your career you might: \r\n‚Ä¢ Design/maintain/contract data centers \r\n‚Ä¢ Set up operations/devops \r\n‚Ä¢ Develop AI for IoT devices \r\n‚Ä¢ Be the next CEO/CTO of a software company \r\n‚Ä¢ Sustainability can be your main role: \r\n‚Ä¢ Green Software Developer \r\n‚Ä¢ Sustainability Consultant \r\n‚Ä¢ Green Advocate  \r\n‚Ä¢ Founder of a Green Tech startup (B2B?)\r\n28\r\n\r\nFormat of classes\r\n‚Ä¢ In-person. \r\n‚Ä¢ Collegerama recordings. \r\n‚Ä¢ Lectures and Labs. \r\n‚Ä¢ Guest lectures. \r\n‚Ä¢ Steering meetings (after week 5, new schedule)\r\n29\r\n\r\nFormat of classes\r\n‚Ä¢ There‚Äôs no exam in this course. It‚Äôs more important that we learn how to \r\ndiscuss this topic and come up with new ideas than learning all the theory. \r\nCritical thinking over checkboxes. \r\n‚Ä¢ Mix of content and discussion \r\n‚Ä¢ Ultimately, the lectures aim to give you food for thought and the necessary \r\nknowledge to excel in Project 2. (We will talk about it later)\r\n30\r\n\r\nhttps://luiscruz.github.io/course_sustainableSE/\r\n31\r\nContent of the course üëá\r\n\r\n32\r\nhttps://mattermost.tudelft.nl/signup_user_complete/?id=1nj9tk6usjf8xmsws8wpq3s5uy&md=link&sbr=su\r\n\r\nProject 1\r\n‚Ä¢ Goal: Measure the energy consumption of software applications. \r\n‚Ä¢ Approach: energy measurement tools; use case testing. \r\n‚Ä¢ Deliverable: blog-style report (approx. 2500 words) \r\n‚Ä¢ Deadline: Week 3, Feb 28, 2025 \r\n‚Ä¢ Group size: 4‚Äì5\r\n33\r\n\r\nProject 2\r\n‚Ä¢ Goal: Create a solution/tool/technique that helps building green software. (You \r\ncan come up with your own idea or choose one from a list of suggestions). \r\n‚Ä¢ Approach: open-source software development; literature review. \r\n‚Ä¢ Deliverable: library/tool/app; paper; presentation. \r\n‚Ä¢ Two deadlines:\u2028\r\n1. Paper and software: Week 8, April 4, 2025\u2028\r\n2. Presentation: Week 9, April 11, 2025 \r\n‚Ä¢ Group size: 4‚Äì5\r\n34\r\n\r\nGuest Lectures\r\nNergis T√∂men \r\nComputer Vision lab | TU Delft \r\nWeek 4, Wed, Mar 5, 2025\r\n35\r\n\r\nCommunity \r\nHow to get involved?']","['<1-hop>\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing', '<2-hop>\n\nReading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.', '<1-hop>\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing', '<2-hop>\n\nReading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.', '<1-hop>\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing', '<2-hop>\n\nReading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.']","Neuromorphic computing offers several benefits in the context of green software practices:

1. **Energy Efficiency**: Neuromorphic computing is inspired by the human brain, which is highly energy-efficient. Spiking neural networks (SNNs), a key component of neuromorphic computing, consume significantly less energy compared to traditional feed-forward neural networks (FNNs). For example, SNNs can be 6 to 8 times more energy-efficient than FNNs (Sources: Different encoding strategies with spiking neurons, Neuromorphic computing).

2. **Sparse Encoding**: Neuromorphic systems use sparse encoding, which reduces the number of spikes (or activations) needed for computation. This leads to lower energy consumption, as fewer operations are required (Sources: Different encoding strategies with spiking neurons).

3. **Reduced Multiply-Accumulate Operations**: Spiking neurons in neuromorphic systems do not require multiplications, only additions, which further reduces energy usage. This is because the energy cost of addition is lower than multiplication (Sources: Different encoding strategies with spiking neurons).

4. **Biological Inspiration**: By emulating the structure and function of the human brain, neuromorphic computing can achieve high computational efficiency with less hardware and energy, aligning with the goals of green software practices (Sources: Neuromorphic computing).

These benefits make neuromorphic computing a promising approach for developing energy-efficient and sustainable software systems.","Neuromorphic computing offers several benefits in the context of green software practices. It is inspired by the structure and function of the human brain, making it highly energy-efficient compared to traditional computing methods. This efficiency is particularly relevant for sustainable software development, as it reduces the environmental impact of computing systems. Additionally, neuromorphic systems can process information in a way that mimics biological neural networks, which can lead to more efficient and sustainable computing solutions. These aspects make neuromorphic computing a promising approach for developers looking to implement green software practices.",0.8555555555412963,,0.36363636363636365,0.46,,1.0000000000000009
What are the challenges in creating a dataset of government-developed OS software?,"['Energy profiling of static analysis tools\r\n‚Ä¢ What is the energy consumption of a ""typical run"" for a few OSS projects? \r\n‚Ä¢ Does the type of analysis matter? Are certain analysis more expensive? Does \r\nthe number of rules that are activated in a static analysis tool important for the \r\nenergy consumption? \r\n‚Ä¢ Differences between static analysis tools [lower priority]\r\n\r\nB5. Tool supporting SusAF workshop / process\r\n‚Ä¢ Lead engineers through process & questions \r\n‚Ä¢ Interface to create & document the two diagrams \r\n‚Ä¢ (!) Should be easy to start using & set up \r\n‚Ä¢ You may also create a simplified version / \u2028\r\nyour favorite sustainability framework\r\nEnvironmental\r\nEconomic\r\nTechnical\r\nIndividual\r\nSocial\r\nImmediate\r\nEnabling\r\nStructural\r\nAirbnb\r\ngreater \r\nearnings\r\nincrease \r\nin rents\r\ngentrification\r\ngreater racial \r\ndisparities\r\nrent \r\nrooms\r\n5\r\n1\r\n3\r\n4\r\n2\r\n \r\n \r\n \r\n \r\n \r\n \r\nVery \r\nunlikely \r\nVery \r\nlikely \r\n\r\nB6. Dataset of government-developed OS software\r\n‚Ä¢ Governments develop & use software for supporting society\u2028\r\nOpen-source development & policies are on the rise \r\n‚Ä¢ But studying government software is difficult b/c we don‚Äôt know what is out \r\nthere\u2028\r\n‚Üí Lack of incentive to make popular \u2028\r\n‚Üí Language barriers \r\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \r\nbuildable?, open dev. history?, requirements documentation? \r\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!\r\n\r\nB7. Queue - but better for the student / TA society\r\n‚Ä¢ Requirements analysis regarding social and individual sustainability effects \r\nof Queue \r\n‚Ä¢ Other EIP / TUD used software also possible: e.g., Answers EWI \r\n‚Ä¢ Non-technical project ‚Üí proper process (workshops? Interviews?) & rich \r\ndescription of outcomes focus of grading\r\nhttps://eip.pages.ewi.tudelft.nl/eip-website/queue.html\r\n\r\nC1. Compare energy consumption of docker images for \r\nML workloads.\r\n‚Ä¢ Similar to what we have seen in the lectures but for ML-specific workloads. \r\n‚Ä¢ We can reuse existing experiment replication packages.\r\n22\r\n\r\nC2. Plugin to visualize Hugging Face carbon emissions.\r\n‚Ä¢ https://huggingface.co/blog/leaderboard-emissions-\r\nanalysis \r\n‚Ä¢\r\nYoo, Taewon, et al. ""Visualizing the Carbon Intensity of Machine Learning Inference for Image Analysis on TensorFlow Hub.""\r\n\r\nC3. Plugin for ChatGPT\r\n‚Ä¢ Users seldom know how much carbon they are emitting when they interact \r\nwith chat GPT. \r\n‚Ä¢ Let‚Äôs make it transparent to the users. Browser plugin?\r\n24\r\nCO2\r\n\r\nC4. NutriScore for software libraries\r\n25\r\n‚Ä¢ NutriScore labels are not perfect but they are a good starting point! \r\n‚Ä¢ What if we could do the same thing for the energy efficiency of software. \r\n‚Ä¢ (Also open to individual or social sustainability) \r\n‚Ä¢ This work can be scoped in particular domains/ecossystems/use cases. \r\n‚Ä¢ Libraries for stats? ML? Web Dev? Cloud?\r\n\r\nC5. Add energy-awareness to existing software\r\n26\r\n‚Ä¢ Streamlit, Notebooks, JSFiddle, \r\nPyScript, zsh, etc. \r\n‚Ä¢\r\n\r\nC6 - Green Shift Left\r\n‚Ä¢ Estimate energy efficiency using static code analysis. \r\n‚Ä¢ We don‚Äôt need an accurate value. \r\n‚Ä¢ It is useful to know which code is more likely to \r\nintroduce energy hotspots and that should be \r\nreviewed with more attention. \r\n‚Ä¢ Can be scoped to a particular domain (react, php, data \r\nscience, web, etc., etc.)', 'computing vision, classification)\r\n\r\nA2. Adding energy metrics to LMstudio/Ollama\r\n‚Ä¢ Make energy consumption visible to users \r\nwithin local chat-interface for LLMs \r\n‚Ä¢ LMstudio/Ollama are tools for easy \r\ndeployment of LLMs \r\n‚Ä¢ Do not show energy metrics \r\n‚Ä¢ Add energy metrics to LMstudio-python \r\nor Ollama\r\nhttps://lmstudio.ai/\r\n\r\nA3. Visualizations built-in with EnergiBridge\r\n‚Ä¢ EnergiBridge simplifies energy measurement, but analysis & visualization is \r\nstill left to the user \r\n‚Ä¢ Extend the tool with well-chosen visualizations and analyses directly from the \r\nprovided data\r\n\r\nA4. Service-based version of EnergiBridge\r\n‚Ä¢ Simplify interaction & setup with EnergiBridge \r\n‚Ä¢ Service that runs independently, start/stop signals over RPC to manage \r\nexperiments \r\n‚Ä¢ Potential: create EnergiBridge interface for other prog. lang\r\n\r\nB1. Measure energy consumption of single JUnit tests\r\n‚Ä¢ We‚Äôd like to identify energy anti patterns in unit tests \r\n‚Ä¢ As a first step, we need tooling to measure and compare the energy \r\nconsumption of single unit tests \r\n‚Ä¢ Ideally including preliminary analysis looking at potential reasons for high-\r\nenergy-consuming tests\r\n\r\nB2. Study test generation energy consumption\r\n‚Ä¢ Automatic test generation mainly focuses on making strong test suites \r\n‚Ä¢ Do different techniques and configurations impact the energy consumption \r\nduring generation? \r\n‚Ä¢ Preferably focus on non-LLM test generation methods (EvoSuite, Pyguin, \r\nDSpot)\r\n\r\nB3. Detailed energy profiling of build pipelines\r\n‚Ä¢ Automatic builds have become a cornerstone of quality assurance. But how \r\nmuch energy do they even consume? \r\n‚Ä¢ Create a tool that reports on the energy consumed during the (different stages \r\nof the) whole build (compile, build, test, package, ‚Ä¶) \r\n‚Ä¢ Should be integrated with build system(s), making setup for developers easy \r\n‚Ä¢ For local setup (to enable true energy measurements)\r\n\r\nB4. Energy profiling of static analysis tools\r\n‚Ä¢ What is the energy consumption of a ""typical run"" for a few OSS projects? \r\n‚Ä¢ Does the type of analysis matter? Are certain analysis more expensive? Does \r\nthe number of rules that are activated in a static analysis tool important for the \r\nenergy consumption? \r\n‚Ä¢ Differences between static analysis tools [lower priority]\r\n\r\nB5. Tool supporting SusAF workshop / process\r\n‚Ä¢ Lead engineers through process & questions \r\n‚Ä¢ Interface to create & document the two diagrams \r\n‚Ä¢ (!) Should be easy to start using & set up \r\n‚Ä¢ You may also create a simplified version / \u2028\r\nyour favorite sustainability framework\r\nEnvironmental\r\nEconomic\r\nTechnical\r\nIndividual\r\nSocial\r\nImmediate\r\nEnabling\r\nStructural\r\nAirbnb\r\ngreater \r\nearnings\r\nincrease \r\nin rents\r\ngentrification\r\ngreater racial \r\ndisparities\r\nrent \r\nrooms\r\n5\r\n1\r\n3\r\n4\r\n2\r\n \r\n \r\n \r\n \r\n \r\n \r\nVery \r\nunlikely \r\nVery \r\nlikely \r\n\r\nB6. Dataset of government-developed OS software\r\n‚Ä¢ Governments develop & use software for supporting society\u2028\r\nOpen-source development & policies are on the rise \r\n‚Ä¢ But studying government software is difficult b/c we don‚Äôt know what is out \r\nthere\u2028\r\n‚Üí Lack of incentive to make popular \u2028\r\n‚Üí Language barriers \r\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \r\nbuildable?, open dev. history?, requirements documentation? \r\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!\r\n\r\nB7. Queue - but better for the student / TA society\r\n‚Ä¢ Requirements analysis regarding social and individual sustainability effects \r\nof Queue \r\n‚Ä¢ Other EIP / TUD used software also possible: e.g., Answers EWI \r\n‚Ä¢ Non-technical project ‚Üí proper process (workshops?', '‚Ä¢ Deadline April 4.\r\n6\r\n\r\nStrategy\r\n‚Ä¢ Week 0 \r\n‚Ä¢ Decide project idea (today) \r\n‚Ä¢ Define steering meeting schedule \r\n‚Ä¢ Create working document of the \r\narticle: Problem statement and solution \r\nproposal! \r\n‚Ä¢ Define and assign tasks for each week. \r\n‚Ä¢ Week 1 \r\n‚Ä¢ Implementation \r\n‚Ä¢ Agreements with supervisor. \r\n‚Ä¢ Week 2 \r\n‚Ä¢ Implementation \r\n‚Ä¢ Week 3 \r\n‚Ä¢ Implementation, Full draft of article, \r\ndissemination. \r\n‚Ä¢ Week 4 \r\n‚Ä¢ Final refinements \r\n‚Ä¢ Prepare presentation\r\n7\r\n\r\nProject ideas\r\n‚Ä¢ A1. Prototype cross-machine comparable benchmarks \r\n‚Ä¢ A2. Add energy metrics to LMstudio/Ollama \r\n‚Ä¢ A3. Visualizations built-in with EnergiBridge \r\n‚Ä¢ A4. Service-based version of EnergiBridge\r\n\r\nProject ideas\r\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \r\n‚Ä¢ B2. Study test generation energy consumption \r\n‚Ä¢ B3. Energy profiling of static analysis tools \r\n‚Ä¢ B4. Detailed energy profiling of build pipelines \r\n‚Ä¢ B5. Tool supporting SusAF workshop / process \r\n‚Ä¢ B6. Dataset of government-developed OS software \r\n‚Ä¢ B7. Queue - but better for the student / TA society\r\nQuality Assurance & Testing\r\nSocial & Individual \u2028\r\nSustainability\r\n\r\nProject ideas\r\n‚Ä¢ C1. Compare energy consumption of docker images for ML workloads. \r\n‚Ä¢ C2. Create a plugin to visualize Hugging Face carbon emissions in detail. \r\n‚Ä¢ C3. Plugin for ChatGPT (footprint per chat window) \r\n‚Ä¢ C4. NutriScore for software libraries. \r\n‚Ä¢ C5. Add energy-awareness to existing software \r\n‚Ä¢ C6. Green Shift Left \r\n‚Ä¢ C7. Education for Sustainable SE\r\n\r\nA1. Prototype cross-machine comparable benchmarks\r\n‚Ä¢ Energy-usage comparisons require running both baseline + software on the \r\nsame machine ‚Üí limits how extensive our experiments can be \r\n‚Ä¢ Research community is in need of benchmarks that make energy \r\nmeasurements comparable even if executed on different machines \r\n‚Ä¢ Focus on a single task or model (i.e. computing vision, classification)\r\n\r\nA2. Adding energy metrics to LMstudio/Ollama\r\n‚Ä¢ Make energy consumption visible to users \r\nwithin local chat-interface for LLMs \r\n‚Ä¢ LMstudio/Ollama are tools for easy \r\ndeployment of LLMs \r\n‚Ä¢ Do not show energy metrics \r\n‚Ä¢ Add energy metrics to LMstudio-python \r\nor Ollama\r\nhttps://lmstudio.ai/\r\n\r\nA3. Visualizations built-in with EnergiBridge\r\n‚Ä¢ EnergiBridge simplifies energy measurement, but analysis & visualization is \r\nstill left to the user \r\n‚Ä¢ Extend the tool with well-chosen visualizations and analyses directly from the \r\nprovided data\r\n\r\nA4. Service-based version of EnergiBridge\r\n‚Ä¢ Simplify interaction & setup with EnergiBridge \r\n‚Ä¢ Service that runs independently, start/stop signals over RPC to manage \r\nexperiments \r\n‚Ä¢ Potential: create EnergiBridge interface for other prog. lang\r\n\r\nB1. Measure energy consumption of single JUnit tests\r\n‚Ä¢ We‚Äôd like to identify energy anti patterns in unit tests \r\n‚Ä¢ As a first step, we need tooling to measure and compare the energy \r\nconsumption of single unit tests \r\n‚Ä¢ Ideally including preliminary analysis looking at potential reasons for high-\r\nenergy-consuming tests\r\n\r\nB2. Study test generation energy consumption\r\n‚Ä¢ Automatic test generation mainly focuses on making strong test suites \r\n‚Ä¢ Do different techniques and configurations impact the energy consumption \r\nduring generation? \r\n‚Ä¢ Preferably focus on non-LLM test generation methods (EvoSuite, Pyguin, \r\nDSpot)\r\n\r\nB3. Detailed energy profiling of build pipelines\r\n‚Ä¢ Automatic builds have become a cornerstone of quality assurance.', '‚Ä¢ Comparing different programming languages is not an easy task. \r\n‚Ä¢ They differ in many mechanisms: \r\n‚Ä¢ Interpreted vs Compiled \r\n‚Ä¢ Optimisations at the compiler level \r\n‚Ä¢ Virtual machine \r\n‚Ä¢ Garbage collector \r\n‚Ä¢ Available libraries\r\n30\r\n\r\nResearch Questions\r\n‚Ä¢ Can we compare the energy efficiency of software languages?  \r\n‚Ä¢ Is the faster language always the most energy efficient? \r\n‚Ä¢ How does memory usage relate to energy consumption? (We don‚Äôt cover this one) \r\n‚Ä¢ Can we automatically decide what is the best programming language \r\nconsidering energy, time, and memory usage?  \r\n‚Ä¢ How do the results of our energy consumption analysis of programming \r\nlanguages gathered from rigorous performance benchmarking solutions \r\ncompare to results of average day-to-day solutions? \u2028\r\n31\r\n\r\nMethodology\r\n\r\nThe Computer Language Benchmarks Game \r\n‚Ä¢ https://benchmarksgame-team.pages.debian.net/benchmarksgame/\r\n33\r\n\r\nProblems in the Computer Language Benchmarks Game\r\n34\r\n\r\n‚Ä¢ 27 Programming languages across different paradigms  \r\n‚Ä¢ Functional (e.g., Ocaml, F#, Haskell) \r\n‚Ä¢ Imperative (e.g., C, Go, Python) \r\n‚Ä¢ Object-oriented (e.g., C++, C#, Java) \r\n‚Ä¢ Scripting (or interpretative) (e.g., JavaScript, Python, Ruby) \r\n‚Ä¢ (These are not mutual exclusive) \r\n‚Ä¢ Intel RAPL‚Äôs C library to measure energy consumption\r\n35\r\n\r\n‚Ä¢ Execute each benchmark solution 10 times. \r\n‚Ä¢ Collect energy data and timestamps. \r\n‚Ä¢ Two-minute interval between executions\r\n36\r\n\r\n\r\n\r\n\r\nCritical thinking\r\n‚Ä¢ There is no doubt this is an excellent study. Yet, as any excellent study, there‚Äôs \r\na lot we can discuss and criticise constructively. \r\n‚Ä¢ What kind of issues you see in drawing conclusions from such a table of \r\nresults? \r\n‚Ä¢ Is the benchmark representative of the most common usage behaviour? \r\n‚Ä¢ Are the implemented solutions representative? \r\n‚Ä¢ Does it make sense to use the average to compare energy consumption \r\nacross different problems? \r\n‚Ä¢ ‚Ä¶\r\n40\r\n\r\nReproducing with Rosetta Code \r\n‚Ä¢ Rosetta Code is a programming chrestomathy repository \r\n \r\n‚Ä¢ 900 usecases/tasks solved across 700 different programming languages \r\n‚Ä¢ Purpose: if you know a programming language we can easily learn how the \r\nsame task is solved in a language you are not familiar with.\r\n41\r\n(?)\r\n\r\n\r\n\r\nRevisiting Research Questions\r\n‚Ä¢ Can we compare the energy efficiency of software languages?  \r\n‚Ä¢ Is the faster language always the most energy efficient? \r\n‚Ä¢ How does memory usage relate to energy consumption?  \r\n‚Ä¢ Can we automatically decide what is the best programming language considering \r\nenergy, time, and memory usage?  \r\n‚Ä¢ How do the results of our energy consumption analysis of programming \r\nlanguages gathered from rigorous performance benchmarking solutions \r\ncompare to results of average day-to-day solutions?  \r\n‚Ä¢ What would happen if we cherry picked the tasks?\u2028\r\n44\r\n\r\n\r\nLu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\n3. Scientific Guide for Reliable \r\nEnergy Experiments\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nCarolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl', 'Lu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\n10. Project 2\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nCarolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl\r\n\r\n1. Goal/assignment \r\n2. Deliverables \r\n3. Strategy \r\n4. Ideas\r\n\r\nAssignment\r\n‚Ä¢ Goal: Solve a Sustainable Software Engineering problem. \r\n‚Ä¢ Identify 1 problem that should be fixed to help enabling sustainability in \r\nthe software engineering industry/community. \r\n‚Ä¢ Propose a solution. A tool, framework, guidelines, etc. \r\n‚Ä¢ Implementation. \r\n‚Ä¢ Validation. (Depending on the idea) \r\n‚Ä¢ Dissemination/social impact. (Solution should be open source, welcome \r\ncontributors, post on social media? Tool website? Available in a package \r\nmanager?)\r\n3\r\n\r\nDeliverables\r\n‚Ä¢ Paper-like article. (Min 4 pages, max 10) \r\n‚Ä¢ Online git repo with open source codebase and/or replication package. \r\n‚Ä¢ Presentation: 5 min + 5min Q&A\r\n4\r\n\r\nArticle\r\n‚Ä¢ Different projects will have different expectations -> Make agreements with \r\nyour coach. \r\n‚Ä¢ Some projects are more technical and some projects more theoretical. \r\n‚Ä¢ Common requirements: \r\n‚Ä¢ Motivation, formulation of the problem being addressed, etc. \r\n‚Ä¢ Description of the solution. \r\n‚Ä¢ Validation of the solution (if applicable -> discuss with coach) \r\n‚Ä¢ Discussion of the solution. (Including limitations)\r\n5\r\n\r\nStrategy\r\n‚Ä¢ Starting next week, there are no lectures  \r\n‚Ä¢ Steering meetings from week 5 till week 9 (either online or in person).  \r\n‚Ä¢ 1 steering meeting per week. (4+1 sprints) \r\n‚Ä¢ Every week, you need to plan different tasks and assignments. \r\n‚Ä¢ Deadline April 4.\r\n6\r\n\r\nStrategy\r\n‚Ä¢ Week 0 \r\n‚Ä¢ Decide project idea (today) \r\n‚Ä¢ Define steering meeting schedule \r\n‚Ä¢ Create working document of the \r\narticle: Problem statement and solution \r\nproposal! \r\n‚Ä¢ Define and assign tasks for each week. \r\n‚Ä¢ Week 1 \r\n‚Ä¢ Implementation \r\n‚Ä¢ Agreements with supervisor. \r\n‚Ä¢ Week 2 \r\n‚Ä¢ Implementation \r\n‚Ä¢ Week 3 \r\n‚Ä¢ Implementation, Full draft of article, \r\ndissemination. \r\n‚Ä¢ Week 4 \r\n‚Ä¢ Final refinements \r\n‚Ä¢ Prepare presentation\r\n7\r\n\r\nProject ideas\r\n‚Ä¢ A1. Prototype cross-machine comparable benchmarks \r\n‚Ä¢ A2. Add energy metrics to LMstudio/Ollama \r\n‚Ä¢ A3. Visualizations built-in with EnergiBridge \r\n‚Ä¢ A4. Service-based version of EnergiBridge\r\n\r\nProject ideas\r\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \r\n‚Ä¢ B2. Study test generation energy consumption \r\n‚Ä¢ B3. Energy profiling of static analysis tools \r\n‚Ä¢ B4. Detailed energy profiling of build pipelines \r\n‚Ä¢ B5. Tool supporting SusAF workshop / process \r\n‚Ä¢ B6. Dataset of government-developed OS software \r\n‚Ä¢ B7. Queue - but better for the student / TA society\r\nQuality Assurance & Testing\r\nSocial & Individual \u2028\r\nSustainability\r\n\r\nProject ideas\r\n‚Ä¢ C1. Compare energy consumption of docker images for ML workloads. \r\n‚Ä¢ C2. Create a plugin to visualize Hugging Face carbon emissions in detail. \r\n‚Ä¢ C3. Plugin for ChatGPT (footprint per chat window) \r\n‚Ä¢ C4. NutriScore for software libraries. \r\n‚Ä¢ C5. Add energy-awareness to existing software \r\n‚Ä¢ C6. Green Shift Left \r\n‚Ä¢ C7. Education for Sustainable SE\r\n\r\nA1.', '8. Green AI\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nLu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\nCarolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl\r\n\r\n- Overview of Green AI \r\n- Large language models \r\n- Green data-centric AI \r\n- Model simplification \r\n- Hyper parameter tuning \r\n- Mixture of Experts and DeepSeek \r\n- Green AI at Meta \r\n\r\nAI\r\n‚Ä¢ Artificial Intelligence (AI) is the branch of computer science that deals with \r\nautomating tasks that typically require human intelligence. \r\n‚Ä¢ In the past years AI has been widely applied across different domains.\u2028\r\nE.g., health care, transportation, finance. \r\n‚Ä¢ To deploy AI systems, we test them against benchmarks (or validation sets). \r\n‚Ä¢ The goal is to outperform the previous existing models. \r\n‚Ä¢ E.g., in Machine Learning we usually resort to accuracy metrics. The \r\nhighest the accuracy, the better the model.\r\n3\r\n\r\nSince 2012, the amount of computing used for AI \r\ntraining has been doubling every 6 months\r\n‚Ä¢ https://epoch.ai/blog/compute-trends\r\n4\r\n\r\n‚Ä¢ To create better AI systems we are currently adding \r\n‚Ä¢ More data \r\n‚Ä¢ More experiments \r\n‚Ä¢ Larger models\r\n5\r\n\r\nThe Equation of Red AI\r\nCost(R) ‚àùE¬∑D¬∑H\r\nCost of a single (E)xample\r\nSize of (D)ataset\r\nNumber of (H)yperparameters\r\nBy Schwartz et al. (2020)\r\n\r\nIssues of Red AI\r\n‚Ä¢ High costs (hardware, electricity, data access, etc.) \r\n‚Ä¢ Limited reproducibility.  \r\n‚Ä¢ Energy consumption. \r\n‚Ä¢ Carbon emissions. \r\n‚Ä¢ SMEs can hardly be competitive. \r\n‚Ä¢ Groundbreaking AI research is mostly done by tech giants.\r\n7\r\n\r\nA few examples of Red AI\r\n‚Ä¢ Google‚Äôs BERT-large \r\n‚Ä¢ 350 million features \r\n‚Ä¢ Trained for 2.5 days using 512 TPU chips, costing $60K+ \r\n‚Ä¢ Open-GPT3 (now GPT-4/o1) \r\n‚Ä¢ 550 tonnes CO2-eq (Patterson, 2021) \r\n‚Ä¢ 175 billion features \r\n‚Ä¢ API is open but no-pretrained model is available \r\n‚Ä¢ AlphaGo \r\n‚Ä¢ 1920 CPUs, 280 GPUs, costing $35M\r\n8\r\n\r\nRed AI in Large Language Models (LLMs)\r\n‚Ä¢ OPT by Meta reports 75 tons CO2-eq (1/7 of OpenGPT‚Äôs footprint).\u2028\r\n(Also 175billion params) \r\n‚Ä¢ However, Llama 3 reported 2,290 tons of CO2-eq (7.7M GPU hours \r\ntraining ) \r\n‚Ä¢ Open science: release includes both the pretrained models and the code \r\nneeded to train and use them. \r\n‚Ä¢ DeepSeek-V3 claims ‚Äúonly‚Äù 2.78M GPU hours \r\n‚Ä¢ Bloom by Huggingface reports 25 tons, 51 when considering embodied \r\nand operational carbon footprint. (176billion params)\r\n9\r\n\r\nRed AI\r\nAccuracy: 0.999999999\r\nGreen AI\r\n‚Ä¢ Energy \r\n‚Ä¢ Time \r\n‚Ä¢ Reproducibility \r\n‚Ä¢ Reusage\r\n\r\nHow can we adopt Green AI\r\n‚Ä¢ Check whether AI is needed. \r\n‚Ä¢ Select green datacenters. \r\n‚Ä¢ Run on low carbon intensity hours. \r\n‚Ä¢ Opt for GPU-optimised solutions (?) \r\n‚Ä¢ Opt for low-power hardware (e.g., Nvidia Jetson boards) \r\n‚Ä¢ Or GPUs that provide energy metrics (e.g., NVIDIA GPUs via the nvidia-smi tool) \r\n‚Ä¢ Report energy/carbon metrics (e.g., embed in MLFlow?)', '‚Ä¢ By using money cost instead of carbon cost, they have more data available.\r\n26\r\n\r\nVirtual Cluster Capacity (VCC)\r\n‚Ä¢ If the forecast of VCC fails it shift flexible workload more than expected.  \r\n‚Ä¢ This happens because the amount of workload forecasted was below the \r\nworkload needed, and VCC was ‚Äúaggressively‚Äù low. \r\n‚Ä¢ The systems fall back to the real cluster capacity for 1 week until results \r\nstart being realistic again.\r\n27\r\n\r\nNext steps\r\n‚Ä¢ They will consider spatial flexibility. \r\n‚Ä¢ I.e., tasks that can be shifted over time and over space. \r\n‚Ä¢ It needs to factor in relocation overheads, though.\r\n28\r\n\r\nCritical questions\r\n‚Ä¢ Who defines what is flexible and inflexible? \r\n‚Ä¢ How do you estimate the CPU load of a given task?\r\n29\r\n\r\nEnergy Regression Testing\r\n‚ÜíEnergy?\r\nGreener? Greener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\n\r\nE-compare\r\nGithub Actions\r\n‚ûú https://koenhagen.github.io/E-Compare/\r\n\r\nEnergy Regression Testing \r\n\r\n4. Debugging Energy with \r\nDocker Images\r\n\r\nUnveiling the Energy Vampires \r\nA methodology for debugging Software \r\nEnergy Consumption\r\n ‚úÖ ICSE 2025\r\n\r\nData Centers and Docker\r\n‚Ä¢ Containers are the most popular way to deploy apps into the cloud \r\n‚Ä¢ Base image is an important choice when building an image \r\n‚Ä¢ Criteria \r\n‚Ä¢ Linux distribution and binaries \r\n‚Ä¢ Image size \r\n‚Ä¢ Energy?\r\n35\r\n\r\nRedis energy consumption\r\n‚Ä¢ Ubuntu/Alpine base images have different energy consumption for Redis\r\n36\r\n\r\nRedis Energy Consumption\r\n‚Ä¢RQ1: What is the difference \r\nin energy consumption \r\nbetween glibc and musl? \r\n‚Ä¢RQ2: Can we use tracing \r\nto compare energy \r\nconsumption in shared \r\nlibraries? \r\n‚Ä¢RQ3: Can we verify the \r\norigin of energy \r\nconsumption differences by \r\nrecreating the workload \r\nbehavior closely?\r\n37\r\n\r\nTracing\r\n‚Ä¢ Find libc function running at the end of the benchmark \r\n‚Ä¢ Tracing: Capture calls made to libc \r\n‚Ä¢ Introduces non-linear overhead\r\n38\r\n\r\nSynchronization\r\n‚Ä¢ Tracing slows down execution and increase energy consumption \r\n‚Ä¢ Run separately and synchronize with logs\r\n39\r\n\r\nTracing Analysis\r\n40\r\n\r\nTracing Analysis\r\n41\r\n\r\nBenchmarking memcpy\r\n‚Ä¢ Copy bytes from one part of memory to \r\nanother \r\n‚Ä¢ Depending on function parameters, different \r\nassembly-level optimizations \r\n‚Ä¢ Some not included in musl\r\n42\r\n\r\nBenchmarking memcpy\r\n‚Ä¢ Copy 4 bytes from fixed \r\npointer to moving pointer \r\n‚Ä¢ (100,300,500,600) x 1M \r\nrequests \r\n‚Ä¢  15% more power and 3X time\r\n43\r\n\r\nConclusions\r\n‚Ä¢ Significant difference in energy consumption for memcpy \r\n‚Ä¢ 8.6% difference for Redis workload and 13% in our benchmark \r\n‚Ä¢ musl trades performance for a smaller codebase \r\n‚Ä¢ No official documentation \r\n‚Ä¢ No awareness about energy performance\r\n44\r\n\r\n5. Energy Efficiency vs Code \r\nQuality\r\n\r\nMeasuring Maintainability\r\n‚Ä¢ According to ISO/IEC 25010, Maintainability is ‚Äúthe degree of \r\neffectiveness and efficiency with which a software product or \r\nsystem can be modified to improve it, correct it or adapt it to \r\nchanges in environment, and in requirements‚Äù \r\n‚Ä¢ We use the code analysis tool Better Code Hub to assess \r\nmaintainability \r\n‚Ä¢ Better Code Hub maps the ISO/IEC 25010 standard on \r\nmaintainability into a set of guidelines derived from static analysis\r\n46\r\n\r\nMaintainability of Energy Changes\r\n‚Ä¢ What is the impact of making energy-oriented code changes on \r\nthe maintainability of mobile apps?', '‚Ä¢RQ3: Can we verify the \r\norigin of energy \r\nconsumption differences by \r\nrecreating the workload \r\nbehavior closely?\r\n37\r\n\r\nTracing\r\n‚Ä¢ Find libc function running at the end of the benchmark \r\n‚Ä¢ Tracing: Capture calls made to libc \r\n‚Ä¢ Introduces non-linear overhead\r\n38\r\n\r\nSynchronization\r\n‚Ä¢ Tracing slows down execution and increase energy consumption \r\n‚Ä¢ Run separately and synchronize with logs\r\n39\r\n\r\nTracing Analysis\r\n40\r\n\r\nTracing Analysis\r\n41\r\n\r\nBenchmarking memcpy\r\n‚Ä¢ Copy bytes from one part of memory to \r\nanother \r\n‚Ä¢ Depending on function parameters, different \r\nassembly-level optimizations \r\n‚Ä¢ Some not included in musl\r\n42\r\n\r\nBenchmarking memcpy\r\n‚Ä¢ Copy 4 bytes from fixed \r\npointer to moving pointer \r\n‚Ä¢ (100,300,500,600) x 1M \r\nrequests \r\n‚Ä¢  15% more power and 3X time\r\n43\r\n\r\nConclusions\r\n‚Ä¢ Significant difference in energy consumption for memcpy \r\n‚Ä¢ 8.6% difference for Redis workload and 13% in our benchmark \r\n‚Ä¢ musl trades performance for a smaller codebase \r\n‚Ä¢ No official documentation \r\n‚Ä¢ No awareness about energy performance\r\n44\r\n\r\n5. Energy Efficiency vs Code \r\nQuality\r\n\r\nMeasuring Maintainability\r\n‚Ä¢ According to ISO/IEC 25010, Maintainability is ‚Äúthe degree of \r\neffectiveness and efficiency with which a software product or \r\nsystem can be modified to improve it, correct it or adapt it to \r\nchanges in environment, and in requirements‚Äù \r\n‚Ä¢ We use the code analysis tool Better Code Hub to assess \r\nmaintainability \r\n‚Ä¢ Better Code Hub maps the ISO/IEC 25010 standard on \r\nmaintainability into a set of guidelines derived from static analysis\r\n46\r\n\r\nMaintainability of Energy Changes\r\n‚Ä¢ What is the impact of making energy-oriented code changes on \r\nthe maintainability of mobile apps? \r\nMaintainability \r\nDifference \r\nvE-2\r\nvE-1\r\nvE\r\nEnergy \r\nCommit\r\nvE+1\r\nM(vE-1)\r\nM(vE)\r\nParent \r\nCommit\r\n‚àÜM\r\n47\r\n\r\nThreshold Marks\r\n48\r\n\r\nBetter Code Hub\r\nMaintainability\r\nCombine\r\ndatasets\r\nEnergy\r\nCommits\r\nBaseline\r\nCommits\r\nBao et al. \r\n(2015)\r\nMoura et al. \r\n(2016)\r\nCruz et al. \r\n(2018)\r\nCruz et al. \r\n(2019)\r\nEnergy Code Changes \r\nDataset\r\n539 commits\u2028\r\nfrom 306 mobile apps\r\n539 baseline commits\u2028\r\nfrom 306 mobile apps\r\n49\r\n\r\nImpact of energy changes on \r\nmaintainability\r\n50\r\n\r\nWhich energy \r\npatterns are more \r\nlikely to affect \r\nmaintainability?\r\n51\r\n\r\nTypical maintainability issue I\r\nhttps://github.com/einmalfel/PodListen/commit/2ed5a65\r\n4 changed files with 28 additions and 0 deletions.\r\n‚Ä¶\r\n‚Ä¶\r\n52\r\n\r\nTypical maintainability issue II\r\nhttps://github.com/mozilla/MozStumbler/commit/6ea0268\r\n5 changed files with 66 additions and 14 deletions.\r\n53\r\n\r\n54', ""‚Ä¢ Our question: Can we save energy with alternative approaches? \r\n‚Ä¢ We studied Grid Search, Random Search and Bayesian \r\nOptimisation.\r\n27\r\nTim's MSc Thesis, 2022 \r\nAccepted at CAIN‚Äô23\r\n\r\n\r\nResults\r\n29\r\nConclusions? \r\n‚Ä¢ Bayesian converges faster. \r\n‚Ä¢ No clear winner between Grid and Random\r\n\r\nDeepSeekMoE\r\n30\r\nPreprint at ArXiv, 2024 https://arxiv.org/pdf/\r\n2401.06066\r\n\r\nMixture of Experts\r\n‚Ä¢ Llama3.1 has 405B parameters, DeepSeek V3 671B \r\n‚Ä¢ Yet DeepSeek has quicker inference times and claims less energy \r\nconsumption (?) \r\n‚Ä¢ Divide the model into smaller blocks of experts \r\n‚Ä¢ Tokens get routed to certain experts based on the query \r\n‚Ä¢ Only part of the network is active during inference \r\n‚Ä¢ DeepSeek claims only 37B out of 671B parameters get active\r\n31\r\n\r\nDeepSeekMoE\r\n32\r\n\r\nDeepSeekMoE\r\n33\r\n‚Ä¢ Comparable performance to \r\nLLaMA2 7B effectively using \r\nless half the parameters \r\n‚Ä¢ Less computational power \r\n‚Ä¢ Problems (?) \r\n‚Ä¢ Still need to load all the \r\nparameters \r\n‚Ä¢ High memory -> high \r\nembodied carbon\r\n\r\nGreen AI at FacebookMeta\r\n34\r\nSustainable AI: Environmental Implications, \r\nChallenges and Opportunities (2022)\r\n\r\nCarbon footprint mapped to the AI lifecycle\r\n‚Ä¢ There are 4 main overarching stages where carbon emissions need to be isolated: data \r\ncollection, experimentation, training, inference. \r\n‚Ä¢ At Facebook, recommendation systems split energy consumption evenly between \r\ntraining and inference; text translation models have a 35%/65% split. (Operational cost) \r\n‚Ä¢ Operational/embodied cost split: 30%/70%\r\n35\r\n\r\nOpen issues according to Meta\r\n‚Ä¢ A vast portion of projects only use GPUs at 30%.\u2028\r\nShould be higher to attenuate embodied carbon.\r\n36\r\nBased on 10K AI projects\r\n\r\nData Jan\r\nInformed Adaptation\r\nData Feb\r\nData Mar\r\nData Apr\r\nData May\r\n‚Ä¶\r\n~Data Dec\r\n~Data Dec\r\nData Jan\r\nData Feb\r\nData Mar\r\nData Apr\r\nData May\r\n‚Ä¶\r\nModel update Model update Model update\r\nCheck if \r\ndata change\r\nCheck if \r\ndata change\r\nCheck if \r\ndata change\r\nModel update\r\nBlind Adaptation\r\nThe AI Model will be \r\nupdated fewer times and \r\nonly when necessary.\r\nKnow when to retrain models\r\nNeither too early nor too late\r\n37\r\nAdaptation Techniques\r\n?\r\n\r\nGreen Architectural Tactics for ML-Enabled \r\nSystem\r\n38\r\nICSE-SEIS 2024\r\n\r\nArchitectural tactics\r\n39\r\n\r\nData-centric\r\n40\r\n‚Ä¢ Reduce data size \r\n‚Ä¢ Sampling \r\n‚Ä¢ Dimensionality reduction \r\n‚Ä¢ Quantization\r\n\r\nAlgorithm Design\r\n41\r\n‚Ä¢ Carefully select your algorithm \r\n‚Ä¢ You don‚Äôt need the fanciest \r\ntechniques\r\n\r\nModel Optimization\r\n42\r\n‚Ä¢ Add energy to training parameters \r\n‚Ä¢ Reduce FLOPs \r\n‚Ä¢ Pruning, sparsity \r\n‚Ä¢  Take advantage of existing models\r\n\r\nModel Training\r\n43\r\n‚Ä¢ Quantization\r\n‚Ä¢ SAVE TRAINING PROGRESS\r\n\r\nModel Deployment\r\n44\r\n‚Ä¢ Distributed deployment \r\n‚Ä¢ Energy efficient hardware and \r\nconfigurations\r\n\r\nModel Management\r\n45\r\n‚Ä¢ Reuse the model as much as possible \r\n\r\nRethinking the Architecture: Spiking Neural Networks\r\n46\r\n\r\nRethinking the Architecture: Spiking Neural Networks\r\n47\r\n\r\nSELF Lab\r\n48\r\n\r\nrecap"", '‚Ä¢ Examples: \r\n‚Ä¢ Technical Debt \r\n‚Ä¢ Does it scale? \r\n‚Ä¢ Software testing \r\n‚Ä¢ Bus-factor \r\n‚Ä¢ Data integrity \r\n‚Ä¢ Innovation \r\n‚Ä¢ ‚Ä¶\r\n10\r\n\r\nIndividual\r\n‚Ä¢ Well-being of the individuals in an organisation.\u2028\r\nNote that it also includes how well individuals interact \r\nwith each other within the org. \r\n‚Ä¢ Examples: \r\n‚Ä¢ mental and physical well-being \r\n‚Ä¢ self-respect \r\n‚Ä¢ education/skills \r\n‚Ä¢ career development \r\n‚Ä¢ ‚Ä¶\r\n11\r\n\r\nSocial\r\n‚Ä¢ concerned with societal communities (groups of people, \r\norganisations) and the factors that erode trust in society. \r\n‚Ä¢ Examples: \r\n‚Ä¢ Social equity \r\n‚Ä¢ Justice \r\n‚Ä¢ Employment \r\n‚Ä¢ Democracy \r\n‚Ä¢ ‚Ä¶ \r\n‚Ä¢ Also includes compliance with policies and regulations \r\n12\r\n\r\nEnvironmental Sustainability\r\n‚Ä¢ the branch of Software Engineering that studies \r\nthe development of software that has minimal \r\nimpact in our planet throughout its whole \r\nlifecycle. \r\n‚Ä¢ Looking at software at different levels: \r\n‚Ä¢ Developing, Using, Serving, ‚Ä¶ \r\n‚Ä¢ Also includes e-waste. \r\n‚Ä¢ Almost identical to Green Software. (?)\r\n13\r\nBordallo II\r\n\r\nGreen Software\r\n‚Ä¢ Sustainability and energy efficiency. \r\n‚Ä¢ Building energy-efficient software is important also from a \r\ntechnical sustainability POV. \r\n‚Ä¢ Smartphones, smart wearables, IoT devices, etc. run on limited \r\npower resources. \r\n‚Ä¢ Developing software to these devices require energy-efficiency \r\ntesting and improvement. \r\n‚Ä¢ It also leads to environmental sustainability (e.g., less battery \r\ncycles) \r\n‚Ä¢ Important for UX (e.g., no need to walk around with power banks)\r\n14\r\n\r\nhttps://www.menti.com/uns9d89kzn\r\nWhat is the sustainability \r\ndimension you are most \r\ninterested in?\r\n?\r\n15\r\n\r\nEconomical sustainability tops the environment\r\n‚Ä¢ In general, a software project will not survive if it‚Äôs not economical \r\nsustainable \r\n‚Ä¢ Yet, a project can survive even if it is not environmental sustainable \r\n‚Ä¢ The mindset is changing! \r\n‚Ä¢ Software consumers have started to worry about the climate impact \r\nof their behaviour as users. \r\n‚Ä¢ Being environmentally sustainable is now an important competitive \r\nfactor \r\n‚Ä¢ Marketing teams are already using all eco-friendly labels. Technical \r\nteams are not there yet, though. \r\n‚Ä¢ It‚Äôs easier said than done!\r\n$\r\n16\r\n\r\nGreen Washing\r\n‚Ä¢ Deceptively use marketing techniques to \r\nclaim being eco-friendly. \r\n‚Ä¢ Opting for green-coloured designs. \r\n‚Ä¢ Red/orange is usually perceived as \r\ntasty. \r\n‚Ä¢ Green is perceived as eco-friendly. \r\n‚Ä¢ The VW case. (?)\r\n17\r\n\r\nThe VW scandal\r\nGreenwashing\r\n‚Ä¢ Used software to cheat on vehicle emissions \r\ntests. \r\n‚Ä¢ The vehicle‚Äôs software could detect whether they \r\nwere being tested, changing the performance \r\naccordingly to improve results. \r\n‚Ä¢ Affected 11M cars worldwide, 8M in Europe.\r\n18\r\n\r\nHow can we drive sustainability \r\nin the SE industry?\r\n\r\nGreen Procurement\r\n‚Ä¢ Customers decide on providers that share their values \r\n‚Ä¢ This is currently the main trigger reason why organisations \r\nworry about Sustainability and Green Software. \r\n‚Ä¢ Examples of green procurement: \r\n‚Ä¢ Customers that only buy green services/products \r\n‚Ä¢ Companies that only use green providers \r\n‚Ä¢ Developers that only work for green companies \r\n‚Ä¢ Green procurement makes environmental sustainability \r\nessential for economical sustainability.\r\n20\r\n\r\nSustainability via compliance\r\n‚Ä¢ EU wants to be carbon neutral by 2030 \r\n‚Ä¢ This also affects the ICT sector. Estimated to impact \r\n14% of the global carbon footprint by 2040. \r\n‚Ä¢ Some initiatives are already being negotiated. \r\n‚Ä¢ Extending the smartphone lifetime to 7 years. \r\n‚Ä¢ Right-to-repair movement. https://repair.eu \r\n‚Ä¢ Making IT services relying on clean energy more \r\naccessible (e.g., less taxes).\r\n21\r\n\r\nSoftware for Sustainability \r\n‚Ä¢ We are not covering it in this course.', ""‚Ä¢ 6 machine learning algorithms: SVM, Decision Tree, KNN, Random Forrest, \r\nAdaBoost, Bagging Classifier. \r\n‚Ä¢ Reduce the number of rows. 10%, 20%, .., 100% \r\n‚Ä¢ Stratified random sampling (?) \r\n‚Ä¢ Reduce the number of features. 10%, 20%, .., 100% \r\n‚Ä¢ Feature importance metric based on the Chi-Square Test (Chi2) \r\n‚Ä¢ Estimate energy consumption using a RAPL-based tool. (?)\r\n18\r\n\r\n‚Ä¢ Repeat 30 times \r\n‚Ä¢ Fix random seeds \r\n‚Ä¢ ‚Ä¶ \r\n‚Ä¢ Data was not Normal => tailed Normal distribution.\r\n19\r\n(?)\r\n\r\nResults: energy consumption of algorithms\r\n\r\nResults: energy vs data shape\r\n\r\nResults: performance vs data shape\r\n\r\nDiscussion\r\n‚Ä¢ Other data properties should be investigated. \r\n‚Ä¢ E.g., data types \r\n‚Ä¢ Reporting energy data is essential. It can lead to different model selection \r\nwithout hindering model performance. \r\n‚Ä¢ There is a big opportunity in Model and Data Simplification.\r\n23\r\n\r\nData/Model Simplification\r\n‚Ä¢ (?) \r\n‚Ä¢ Data selection \r\n‚Ä¢ Data quantisation. Posit? \r\n‚Ä¢ Data distillation \r\n‚Ä¢ Coreset extraction (?) \r\n‚Ä¢ Model distillation \r\n‚Ä¢ Model quantisation \r\n‚Ä¢ Model pruning \r\n‚Ä¢ ‚Ä¶\r\n24\r\n\r\nPosit vs Float\r\nMore about this: https://spectrum.ieee.org/floating-point-numbers-posits-processor\r\nBetter for DL use cases\r\n\r\nHow can we tune \r\nlearning \r\nparameters \r\nefficiently?\r\n\r\nHyper parameter tuning\r\n‚Ä¢ When training an ML model, there are several parameters that need to be \r\ntuned. \r\n‚Ä¢ E.g., in SVM we have the Regularization parameter C, the kernel function, \r\nthe degree of the kernel function, and depending on the case, many other. \r\n‚Ä¢ The common approach revolves around grid search. The user provides a \r\nsequence of possible values for each parameter and the pipeline runs all \r\npossible combinations. \r\n‚Ä¢ Our question: Can we save energy with alternative approaches? \r\n‚Ä¢ We studied Grid Search, Random Search and Bayesian \r\nOptimisation.\r\n27\r\nTim's MSc Thesis, 2022 \r\nAccepted at CAIN‚Äô23\r\n\r\n\r\nResults\r\n29\r\nConclusions? \r\n‚Ä¢ Bayesian converges faster. \r\n‚Ä¢ No clear winner between Grid and Random\r\n\r\nDeepSeekMoE\r\n30\r\nPreprint at ArXiv, 2024 https://arxiv.org/pdf/\r\n2401.06066\r\n\r\nMixture of Experts\r\n‚Ä¢ Llama3.1 has 405B parameters, DeepSeek V3 671B \r\n‚Ä¢ Yet DeepSeek has quicker inference times and claims less energy \r\nconsumption (?) \r\n‚Ä¢ Divide the model into smaller blocks of experts \r\n‚Ä¢ Tokens get routed to certain experts based on the query \r\n‚Ä¢ Only part of the network is active during inference \r\n‚Ä¢ DeepSeek claims only 37B out of 671B parameters get active\r\n31\r\n\r\nDeepSeekMoE\r\n32\r\n\r\nDeepSeekMoE\r\n33\r\n‚Ä¢ Comparable performance to \r\nLLaMA2 7B effectively using \r\nless half the parameters \r\n‚Ä¢ Less computational power \r\n‚Ä¢ Problems (?) \r\n‚Ä¢ Still need to load all the \r\nparameters \r\n‚Ä¢ High memory -> high \r\nembodied carbon\r\n\r\nGreen AI at FacebookMeta\r\n34\r\nSustainable AI: Environmental Implications, \r\nChallenges and Opportunities (2022)\r\n\r\nCarbon footprint mapped to the AI lifecycle\r\n‚Ä¢ There are 4 main overarching stages where carbon emissions need to be isolated: data \r\ncollection, experimentation, training, inference. \r\n‚Ä¢ At Facebook, recommendation systems split energy consumption evenly between \r\ntraining and inference; text translation models have a 35%/65% split. (Operational cost) \r\n‚Ä¢ Operational/embodied cost split: 30%/70%\r\n35\r\n\r\nOpen issues according to Meta\r\n‚Ä¢ A vast portion of projects only use GPUs at 30%.\u2028\r\nShould be higher to attenuate embodied carbon."", 'Different \r\nscreen brightness, different results. \r\n‚Ä¢ You need to reduce tasks to the bare minimum: \r\n‚Ä¢ Set brightness to a fixed value; turn off notifications, kill all user-owned \r\nprocesses, turn off cellular data, bluetooth, location services, account \r\nsyncs; uninstall all unnecessary apps, etc.\r\n11\r\n\r\nWhen it comes to desktop/cloud software, the sources \r\nof noise are different but the same concerns apply. \r\n \r\nEach case is different ‚Äì think it through!\r\n‚ö†\r\n\r\nEnergy Profilers\r\n‚Ä¢ Simple setup! Quite reliable (if you choose the profiler wisely). \r\n‚Ä¢ Recently, they are starting to rely on internal power sensors. \r\n‚Ä¢ Still sensitive to noise from concurrent processes/tasks! ‚ö†\r\n13\r\n\r\nExamples of Energy Profilers\r\n\r\n15\r\nhttps://www.websitecarbon.com\r\n\r\n16\r\nhttps://mlco2.github.io/impact/\r\n\r\nIntel Power Monitor\r\n‚Ä¢ Install: https://software.intel.com/content/www/us/en/\r\ndevelop/articles/intel-power-gadget.html \r\n‚Ä¢ To collect: Logging > Log to File \r\n \r\n‚Ä¢ It will store a CSV file with all the collected power data. \r\n(File location is specified in the settings) \r\n‚Ä¢ Based on Intel RAPL. Works with Intel-based Windows \r\nand Macs. \r\n‚Ä¢ Alternative-twin for M1-based Macs: Mx Power Gadget.\u2028\r\nhttps://www.seense.com/menubarstats/mxpg/\r\n17\r\n‚ö† No longer supported by Intel ‚ö†  \r\n\r\n18\r\nüîó https://luiscruz.github.io/\r\n2021/07/20/measuring-energy.html\r\n(Missing Apple m1 tools: mxpg, powermetrics)\r\n\r\n19\r\nEnergiBridge\r\nhttps://github.com/tdurieux/energibridge\r\n> target/release/energibridge -o results.csv --summary sleep 10\r\n\r\nHands-on 1\r\n‚Ä¢ Install your energy profiler (EnergiBridge). \r\n‚Ä¢ Collect the energy data of using Coral BodyPix for 30 seconds.\u2028\r\nhttps://storage.googleapis.com/tfjs-models/demos/body-pix/index.html \r\n‚Ä¢ Report the total energy consumption. \r\n‚Ä¢ Extra-mile: \r\n‚Ä¢ Compare the energy consumption in different browsers. \r\n‚Ä¢ Check the spikes and drops in Power and Temperature.\r\n20\r\n\r\nRetrospection\r\nHands-on 1\r\n‚Ä¢ Are the measurements repeatable? \r\n‚Ä¢ What were the confounding factors? \r\n‚Ä¢ How can we automate this process?\r\n21\r\n\r\nEnergy testing\r\n(Different from energy monitoring)\r\n1. Create a reproducible scenario of the execution of your software. Preferably \r\nthis should be an automated script ‚Äì e.g., using a bash or python script. \r\n2. Execute the scenario in a version of your software. Use the energy profiler to \r\nmeasure the energy consumption. \r\n3. Improve your software in parts of the code that you suspect have low \r\nperformance. \r\n4. Execute the same scenario with the new version. Compare the energy data \r\nin this version with the previous one.\u2028\r\nEnergy is lower, test passes; energy is higher test fails.\r\n22\r\n\r\nHands-on 2\r\n‚Ä¢ Create a reproducible scenario. (Usually easier with command-line interfaces) \r\n‚Ä¢ Automatically start/stop energy profiling.\r\n23\r\n\r\nProject 1\r\n‚Ä¢ Deadline: March 1 \r\n‚Ä¢  Compare energy consumption in common software use cases. \r\n‚Ä¢ Examples: \r\n‚Ä¢ Different versions of the same app; \r\n‚Ä¢ Same use case but different apps \r\n‚Ä¢ Same version, same app, but different user settings (e.g., enable/disable GPU optimisation) \r\n‚Ä¢ Same version, same app, but different running environment \r\n‚Ä¢ Submission via PR (markdown). \r\n‚Ä¢ Blog-style report (markdown, approx 2500 words). \r\n‚Ä¢ Replication package. \r\n‚Ä¢ Points if the experiment is automated.', 'p-value = 0.04\r\nOn average, version B spent less energy than version A  ‚Äî  ‚úÖ \r\nThere is statistical significance ‚Äî  ‚úÖ \r\nEffect size, percent-change is ‚âà1% ‚Äî ü§î \r\n‚ö† Do we care?\r\n(?)\r\n\r\nPractical Significance\r\n‚Ä¢ Depending on the case, a 2% improvement might be either wonderful or completely \r\nuseless. \r\n‚Ä¢ Effect size analyses help assess practical significance but might not be enough. \r\n‚Ä¢ A critical discussion always needs to be performed. Consider context and explain in what \r\nsense the effect size might be relevant. \r\n‚Ä¢ E.g.: \r\n‚Ä¢  to improve 2% in energy efficiency the code will be less readable or the user \r\nexperience is not so appealing. \r\n‚Ä¢ A particular method improves 2% but it will only be used 1% of the time. \r\n‚Ä¢ There is no particular metric or structure, but this kind of critical analysis is very important.\r\n25\r\n\r\nWhat if data is not Normal?\r\nSame approach but different tests/metrics!\r\n\r\nNon-normal data\r\n‚Ä¢ Statistical significance: non-parametric test (?) \r\n‚Ä¢ Mann-Whitney U test. Instead of looking at standard deviation or mean, it orders \r\nsamples and compares with each other. \r\n‚Ä¢ Less power than parametric-tests (?) \r\n‚Ä¢ Effect size \r\n‚Ä¢ Median difference: \r\n \r\n‚Ä¢ Percentage of pairs supporting a conclusion\u2028\r\n(i.e., # pairs where version A > version B/ total pairs) \r\n‚Ä¢ Common language effect size: \r\nŒîM\r\nU1\r\nN1N2\r\n27\r\n\r\nRecap\r\nImpossible to \r\nfix but \r\nexplainable.\r\n\r\nEnergy Efficiency Across \r\nProgramming Languages\r\nhttps://sites.google.com/view/energy-efficiency-languages\r\n29\r\nRui Pereira, Marco Couto, Francisco Ribeiro, Rui Rua, J√°come \r\nCunha, Jo√£o Paulo Fernandes, and Jo√£o Saraiva\r\n\r\n‚Ä¢ Is a faster programming language also more energy efficient? \r\n‚Ä¢ Comparing different programming languages is not an easy task. \r\n‚Ä¢ They differ in many mechanisms: \r\n‚Ä¢ Interpreted vs Compiled \r\n‚Ä¢ Optimisations at the compiler level \r\n‚Ä¢ Virtual machine \r\n‚Ä¢ Garbage collector \r\n‚Ä¢ Available libraries\r\n30\r\n\r\nResearch Questions\r\n‚Ä¢ Can we compare the energy efficiency of software languages?  \r\n‚Ä¢ Is the faster language always the most energy efficient? \r\n‚Ä¢ How does memory usage relate to energy consumption? (We don‚Äôt cover this one) \r\n‚Ä¢ Can we automatically decide what is the best programming language \r\nconsidering energy, time, and memory usage?  \r\n‚Ä¢ How do the results of our energy consumption analysis of programming \r\nlanguages gathered from rigorous performance benchmarking solutions \r\ncompare to results of average day-to-day solutions? \u2028\r\n31\r\n\r\nMethodology\r\n\r\nThe Computer Language Benchmarks Game \r\n‚Ä¢ https://benchmarksgame-team.pages.debian.net/benchmarksgame/\r\n33\r\n\r\nProblems in the Computer Language Benchmarks Game\r\n34\r\n\r\n‚Ä¢ 27 Programming languages across different paradigms  \r\n‚Ä¢ Functional (e.g., Ocaml, F#, Haskell) \r\n‚Ä¢ Imperative (e.g., C, Go, Python) \r\n‚Ä¢ Object-oriented (e.g., C++, C#, Java) \r\n‚Ä¢ Scripting (or interpretative) (e.g., JavaScript, Python, Ruby) \r\n‚Ä¢ (These are not mutual exclusive) \r\n‚Ä¢ Intel RAPL‚Äôs C library to measure energy consumption\r\n35\r\n\r\n‚Ä¢ Execute each benchmark solution 10 times. \r\n‚Ä¢ Collect energy data and timestamps. \r\n‚Ä¢ Two-minute interval between executions\r\n36\r\n\r\n\r\n\r\n\r\nCritical thinking\r\n‚Ä¢ There is no doubt this is an excellent study. Yet, as any excellent study, there‚Äôs \r\na lot we can discuss and criticise constructively. \r\n‚Ä¢ What kind of issues you see in drawing conclusions from such a table of \r\nresults?', '‚Ä¢ Collect the energy data of using Coral BodyPix for 30 seconds.\u2028\r\nhttps://storage.googleapis.com/tfjs-models/demos/body-pix/index.html \r\n‚Ä¢ Report the total energy consumption. \r\n‚Ä¢ Extra-mile: \r\n‚Ä¢ Compare the energy consumption in different browsers. \r\n‚Ä¢ Check the spikes and drops in Power and Temperature.\r\n20\r\n\r\nRetrospection\r\nHands-on 1\r\n‚Ä¢ Are the measurements repeatable? \r\n‚Ä¢ What were the confounding factors? \r\n‚Ä¢ How can we automate this process?\r\n21\r\n\r\nEnergy testing\r\n(Different from energy monitoring)\r\n1. Create a reproducible scenario of the execution of your software. Preferably \r\nthis should be an automated script ‚Äì e.g., using a bash or python script. \r\n2. Execute the scenario in a version of your software. Use the energy profiler to \r\nmeasure the energy consumption. \r\n3. Improve your software in parts of the code that you suspect have low \r\nperformance. \r\n4. Execute the same scenario with the new version. Compare the energy data \r\nin this version with the previous one.\u2028\r\nEnergy is lower, test passes; energy is higher test fails.\r\n22\r\n\r\nHands-on 2\r\n‚Ä¢ Create a reproducible scenario. (Usually easier with command-line interfaces) \r\n‚Ä¢ Automatically start/stop energy profiling.\r\n23\r\n\r\nProject 1\r\n‚Ä¢ Deadline: March 1 \r\n‚Ä¢  Compare energy consumption in common software use cases. \r\n‚Ä¢ Examples: \r\n‚Ä¢ Different versions of the same app; \r\n‚Ä¢ Same use case but different apps \r\n‚Ä¢ Same version, same app, but different user settings (e.g., enable/disable GPU optimisation) \r\n‚Ä¢ Same version, same app, but different running environment \r\n‚Ä¢ Submission via PR (markdown). \r\n‚Ä¢ Blog-style report (markdown, approx 2500 words). \r\n‚Ä¢ Replication package. \r\n‚Ä¢ Points if the experiment is automated.\r\n24\r\n\r\nGroup registration\r\n‚Ä¢ Brightspace > Collaboration > Groups and sign up for one of the groups \r\nunder ""Project Groups (P1 and P2)""  \r\n‚Ä¢ If you are looking for a group or teamembers, use the mattermost channel \r\n‚Äú~Searching-group-members‚Äù. \r\n‚Ä¢ The deadline for self-registering as a group is end of this week, so by Sunday, \r\n16th of February, 23:59. \r\n‚Ä¢ We might do final adjustments afterwards.\r\n25\r\n\r\n26\r\nKay Singh. Apple Silicon M1 Power Consumption Deep Dive Part 1: Safari vs Chrome\u2028\r\nhttps://singhkays.com/blog/apple-silicon-m1-video-power-consumption-pt-1/\r\n(For project 1, you don‚Äôt need to dive deep into hardware details)\r\n\r\n27', 'Interviews?) & rich \r\ndescription of outcomes focus of grading\r\nhttps://eip.pages.ewi.tudelft.nl/eip-website/queue.html\r\n\r\nC1. Compare energy consumption of docker images for \r\nML workloads.\r\n‚Ä¢ Similar to what we have seen in the lectures but for ML-specific workloads. \r\n‚Ä¢ We can reuse existing experiment replication packages.\r\n22\r\n\r\nC2. Plugin to visualize Hugging Face carbon emissions.\r\n‚Ä¢ https://huggingface.co/blog/leaderboard-emissions-\r\nanalysis \r\n‚Ä¢\r\nYoo, Taewon, et al. ""Visualizing the Carbon Intensity of Machine Learning Inference for Image Analysis on TensorFlow Hub.""\r\n\r\nC3. Plugin for ChatGPT\r\n‚Ä¢ Users seldom know how much carbon they are emitting when they interact \r\nwith chat GPT. \r\n‚Ä¢ Let‚Äôs make it transparent to the users. Browser plugin?\r\n24\r\nCO2\r\n\r\nC4. NutriScore for software libraries\r\n25\r\n‚Ä¢ NutriScore labels are not perfect but they are a good starting point! \r\n‚Ä¢ What if we could do the same thing for the energy efficiency of software. \r\n‚Ä¢ (Also open to individual or social sustainability) \r\n‚Ä¢ This work can be scoped in particular domains/ecossystems/use cases. \r\n‚Ä¢ Libraries for stats? ML? Web Dev? Cloud?\r\n\r\nC5. Add energy-awareness to existing software\r\n26\r\n‚Ä¢ Streamlit, Notebooks, JSFiddle, \r\nPyScript, zsh, etc. \r\n‚Ä¢\r\n\r\nC6 - Green Shift Left\r\n‚Ä¢ Estimate energy efficiency using static code analysis. \r\n‚Ä¢ We don‚Äôt need an accurate value. \r\n‚Ä¢ It is useful to know which code is more likely to \r\nintroduce energy hotspots and that should be \r\nreviewed with more attention. \r\n‚Ä¢ Can be scoped to a particular domain (react, php, data \r\nscience, web, etc., etc.)\r\n27\r\n\r\nC7 - Education\r\n‚Ä¢ Educational game for Software \r\nSustainability practices \r\n‚Ä¢ Purpose: use within software teams to \r\ndiscuss or learn about different sustainable \r\nIT practices: at the organisation level, \r\nsoftware, etc.\r\n28\r\nhttps://github.com/OttoKaaij/Ticket-To-Sustainability/?tab=readme-ov-file\r\n\r\nProject ideas (old)\r\n‚Ä¢ Plugin from EnergiBridge (GUI, report generator, python library, etc.) \r\n‚Ä¢ Plugin for ChatGPT (carbon emissions per chat window) \r\n‚Ä¢ Seamless measurements for AI libraries \r\n‚Ä¢ Energy patterns for Green AI \r\n‚Ä¢ Sustainable SW dev gamification \r\n‚Ä¢ Sustainability auditor for AI projects \r\n‚Ä¢ Energy Profiling of screen colour filter tools (or display settings) \r\n‚Ä¢ ‚Ä¶ you can also propose yours!\r\n\r\nhttps://edu.nl/64gpk\r\nedu.nl/64gpk', 'It‚Äôs more important that we learn how to \r\ndiscuss this topic and come up with new ideas than learning all the theory. \r\nCritical thinking over checkboxes. \r\n‚Ä¢ Mix of content and discussion \r\n‚Ä¢ Ultimately, the lectures aim to give you food for thought and the necessary \r\nknowledge to excel in Project 2. (We will talk about it later)\r\n30\r\n\r\nhttps://luiscruz.github.io/course_sustainableSE/\r\n31\r\nContent of the course üëá\r\n\r\n32\r\nhttps://mattermost.tudelft.nl/signup_user_complete/?id=1nj9tk6usjf8xmsws8wpq3s5uy&md=link&sbr=su\r\n\r\nProject 1\r\n‚Ä¢ Goal: Measure the energy consumption of software applications. \r\n‚Ä¢ Approach: energy measurement tools; use case testing. \r\n‚Ä¢ Deliverable: blog-style report (approx. 2500 words) \r\n‚Ä¢ Deadline: Week 3, Feb 28, 2025 \r\n‚Ä¢ Group size: 4‚Äì5\r\n33\r\n\r\nProject 2\r\n‚Ä¢ Goal: Create a solution/tool/technique that helps building green software. (You \r\ncan come up with your own idea or choose one from a list of suggestions). \r\n‚Ä¢ Approach: open-source software development; literature review. \r\n‚Ä¢ Deliverable: library/tool/app; paper; presentation. \r\n‚Ä¢ Two deadlines:\u2028\r\n1. Paper and software: Week 8, April 4, 2025\u2028\r\n2. Presentation: Week 9, April 11, 2025 \r\n‚Ä¢ Group size: 4‚Äì5\r\n34\r\n\r\nGuest Lectures\r\nNergis T√∂men \r\nComputer Vision lab | TU Delft \r\nWeek 4, Wed, Mar 5, 2025\r\n35\r\n\r\nCommunity \r\nHow to get involved?\r\n36\r\n\r\nGreen TU\r\n‚Ä¢ https://www.tudelft.nl/sustainability/get-\r\ninvolved/greentu \r\n‚Ä¢ Student organisation at the TU Delft devoted \r\nto stimulating sustainability in education, \r\nresearch, university operations and \r\ncommunity engagement.\r\n37\r\n\r\nClimateAction.tech\r\n‚Ä¢ Great community for outreach \r\n‚Ä¢ Based on Slack  \r\n‚Ä¢ Regular meetings, talks, social events \r\n‚Ä¢ You can join as a volunteer or simply to \r\nconnect to other techies \r\n‚Ä¢ Also good to for job hunting on green tech.\r\n38\r\n\r\nClimateAction.tech\r\n39\r\n\r\nBranch magazine\r\n‚Ä¢ Stay up-to-date on sustainable tech \r\n‚Ä¢ Creativity booster \r\n‚Ä¢ Carbon-aware UI \r\n‚Ä¢ https://branch.climateaction.tech üîó\r\n40\r\n\r\nThis is the fourth edition\r\n‚Ä¢ Any feedback is welcome! Email or DM!\r\n41\r\n\r\n42\r\n\r\nCarolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nLu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\n1. Intro Class\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl', 'Carbon-free giants\r\n‚Ä¢ Google, Microsoft, Meta/Facebook want to be carbon free by 2030 \r\n‚Ä¢ Carbon free is different from carbon neutral \r\n‚Ä¢ Green IT experts are needed to meet these goals\r\n23\r\n\r\n\r\nRebound effect*\r\n‚Ä¢ Energy consumption decreases ‚Üì‚Üì but demand also increases ‚Üë‚Üë. \r\n‚Ä¢ *a.k.a. Jevons Paradox in economics; Downs‚ÄìThomson paradox in\xa0mobility.\r\nEnergy per prompt\r\nPrompts\r\n100\r\n80\r\n30\r\n38\r\nChat \r\nGPT\r\n‚ÄúEnergy-efficient‚Äù \r\nChat GPT\r\n0\r\n\r\nIs sustainability an\u2028\r\nethical issue?\r\n‚Ä¢ Climate change is more likely to affect the \r\npoorest countries. \r\n‚Ä¢ Less financial resources to adapt \r\n‚Ä¢ Climate-impact does not necessarily affect \r\npolluting countries. \r\n‚Ä¢ Poorest countries have contributed less to the \r\nclimate change. \r\n‚Ä¢ We need to figure out how to do more using \r\nless resources.\r\n26\r\n\r\nMorality ‚â† Moralising\r\n‚Ä¢ We should not use climate action as a \r\nshaming weapon \r\n‚Ä¢ Climate action should be agnostic of political \r\nviews, ideology, social status, etc. \r\n‚Ä¢ We need everyone to take action!\r\n27\r\n\r\nWhy?\r\n‚Ä¢ Throughout your career you might: \r\n‚Ä¢ Design/maintain/contract data centers \r\n‚Ä¢ Set up operations/devops \r\n‚Ä¢ Develop AI for IoT devices \r\n‚Ä¢ Be the next CEO/CTO of a software company \r\n‚Ä¢ Sustainability can be your main role: \r\n‚Ä¢ Green Software Developer \r\n‚Ä¢ Sustainability Consultant \r\n‚Ä¢ Green Advocate  \r\n‚Ä¢ Founder of a Green Tech startup (B2B?)\r\n28\r\n\r\nFormat of classes\r\n‚Ä¢ In-person. \r\n‚Ä¢ Collegerama recordings. \r\n‚Ä¢ Lectures and Labs. \r\n‚Ä¢ Guest lectures. \r\n‚Ä¢ Steering meetings (after week 5, new schedule)\r\n29\r\n\r\nFormat of classes\r\n‚Ä¢ There‚Äôs no exam in this course. It‚Äôs more important that we learn how to \r\ndiscuss this topic and come up with new ideas than learning all the theory. \r\nCritical thinking over checkboxes. \r\n‚Ä¢ Mix of content and discussion \r\n‚Ä¢ Ultimately, the lectures aim to give you food for thought and the necessary \r\nknowledge to excel in Project 2. (We will talk about it later)\r\n30\r\n\r\nhttps://luiscruz.github.io/course_sustainableSE/\r\n31\r\nContent of the course üëá\r\n\r\n32\r\nhttps://mattermost.tudelft.nl/signup_user_complete/?id=1nj9tk6usjf8xmsws8wpq3s5uy&md=link&sbr=su\r\n\r\nProject 1\r\n‚Ä¢ Goal: Measure the energy consumption of software applications. \r\n‚Ä¢ Approach: energy measurement tools; use case testing. \r\n‚Ä¢ Deliverable: blog-style report (approx. 2500 words) \r\n‚Ä¢ Deadline: Week 3, Feb 28, 2025 \r\n‚Ä¢ Group size: 4‚Äì5\r\n33\r\n\r\nProject 2\r\n‚Ä¢ Goal: Create a solution/tool/technique that helps building green software. (You \r\ncan come up with your own idea or choose one from a list of suggestions). \r\n‚Ä¢ Approach: open-source software development; literature review. \r\n‚Ä¢ Deliverable: library/tool/app; paper; presentation. \r\n‚Ä¢ Two deadlines:\u2028\r\n1. Paper and software: Week 8, April 4, 2025\u2028\r\n2. Presentation: Week 9, April 11, 2025 \r\n‚Ä¢ Group size: 4‚Äì5\r\n34\r\n\r\nGuest Lectures\r\nNergis T√∂men \r\nComputer Vision lab | TU Delft \r\nWeek 4, Wed, Mar 5, 2025\r\n35\r\n\r\nCommunity \r\nHow to get involved?', '‚Ä¢ Groundbreaking AI research is mostly done by tech giants.\r\n7\r\n\r\nA few examples of Red AI\r\n‚Ä¢ Google‚Äôs BERT-large \r\n‚Ä¢ 350 million features \r\n‚Ä¢ Trained for 2.5 days using 512 TPU chips, costing $60K+ \r\n‚Ä¢ Open-GPT3 (now GPT-4/o1) \r\n‚Ä¢ 550 tonnes CO2-eq (Patterson, 2021) \r\n‚Ä¢ 175 billion features \r\n‚Ä¢ API is open but no-pretrained model is available \r\n‚Ä¢ AlphaGo \r\n‚Ä¢ 1920 CPUs, 280 GPUs, costing $35M\r\n8\r\n\r\nRed AI in Large Language Models (LLMs)\r\n‚Ä¢ OPT by Meta reports 75 tons CO2-eq (1/7 of OpenGPT‚Äôs footprint).\u2028\r\n(Also 175billion params) \r\n‚Ä¢ However, Llama 3 reported 2,290 tons of CO2-eq (7.7M GPU hours \r\ntraining ) \r\n‚Ä¢ Open science: release includes both the pretrained models and the code \r\nneeded to train and use them. \r\n‚Ä¢ DeepSeek-V3 claims ‚Äúonly‚Äù 2.78M GPU hours \r\n‚Ä¢ Bloom by Huggingface reports 25 tons, 51 when considering embodied \r\nand operational carbon footprint. (176billion params)\r\n9\r\n\r\nRed AI\r\nAccuracy: 0.999999999\r\nGreen AI\r\n‚Ä¢ Energy \r\n‚Ä¢ Time \r\n‚Ä¢ Reproducibility \r\n‚Ä¢ Reusage\r\n\r\nHow can we adopt Green AI\r\n‚Ä¢ Check whether AI is needed. \r\n‚Ä¢ Select green datacenters. \r\n‚Ä¢ Run on low carbon intensity hours. \r\n‚Ä¢ Opt for GPU-optimised solutions (?) \r\n‚Ä¢ Opt for low-power hardware (e.g., Nvidia Jetson boards) \r\n‚Ä¢ Or GPUs that provide energy metrics (e.g., NVIDIA GPUs via the nvidia-smi tool) \r\n‚Ä¢ Report energy/carbon metrics (e.g., embed in MLFlow?) \r\n‚Ä¢ Use pre-trained models (Transfer Learning) \r\n‚Ä¢ Preprocess dataset to reduce size. \r\n‚Ä¢ Improve parameter-tuning strategy.\r\n11\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ We need benchmarks. \r\n‚Ä¢ AllenAI leaderboard\u2028\r\nhttps://leaderboard.allenai.org \r\n‚Ä¢ No carbon metrics, yet \r\n‚Ä¢ Report comparable proxies for energy \r\nconsumption. \r\n‚Ä¢ ‚ö† Learning algorithms behave in a non-\r\ndeterministic \r\n‚Ä¢ ‚ö† Different data-points lead to different \r\nenergy consumption\r\n12\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ Reporting measured energy consumption \r\n‚Ä¢ + Accurate \r\n‚Ä¢ + Easy to map to carbon emissions \r\n‚Ä¢ - Hard to measure \r\n‚Ä¢ - Low replicability \r\n‚Ä¢ Reporting time / estimation based on time & hardware \r\n‚Ä¢ + Easy to measure \r\n‚Ä¢ + Correlates with energy consumption in most cases. \r\n‚Ä¢ -  Difficult to compare with measurements from other setups \r\n‚Ä¢ E.g., floating point operations (FPOs) (?) \r\n‚Ä¢ + comparable across different setups \r\n‚Ä¢ + cheap \r\n‚Ä¢ - does not factor in memory energy consumption \r\n‚Ä¢ - does not reflect carbon emissions\r\n13\r\n\r\nData-centric AI\r\n\r\nData-centric AI\r\n‚Ä¢ Emerging discipline that deals with systematically engineering data to build AI \r\nsystems. \r\n‚Ä¢ Shift from improving the training strategy to improving the data. \r\n‚Ä¢ It is better to have small but reliable datasets than large but noisy \r\ndatasets. \r\n‚Ä¢ => Improve data collection, data labelling, and data preprocessing. \r\n‚Ä¢ More about data-centric AI by Andrew Ng:\u2028\r\nhttps://www.youtube.com/watch?v=06-AZXmwHjo\r\n15\r\n\r\n\r\nGreen Data-centric AI\r\n‚Ä¢ How do different ML algorithms compare \r\nin terms of energy consumption? \r\n‚Ä¢ How does number of rows relate to the \r\nenergy consumption of ML models? \r\n‚Ä¢ How does number of features relate to \r\nthe energy consumption of ML models? \r\n‚Ä¢ What is the impact of reducing data in the \r\nperformance of the model?', 'google.com/view/energy-efficiency-languages\r\n21\r\nAna Radovanovic ÃÅ, Ross Koningstein, Ian Schneider, Bokan \r\nChen, Alexandre Duarte, Binz Roy, Diyue Xiao, Maya \r\nHaridasan, Patrick Hung, Nick Care, Saurav Talukdar, Eric \r\nMullen, Kendal Smith, MariEllen Cottman, and Walfredo Cirne \r\n\r\n\r\n‚Ä¢ Google‚Äôs Carbon-Intelligent Computing System (CICS) \r\n‚Ä¢ Main idea: use carbon-intensity data to shift datacenter jobs in time \r\n‚Ä¢ Typically, job schedulers use a metric of cluster capacity to schedule a job in \r\na particular cluster. \r\n‚Ä¢ CICS overrides this metric with the virtual capacity curve (VCC) that \r\nfactors in Carbon intensity \r\n‚Ä¢ When a new job comes in, the scheduler estimates its CPU load and power \r\nusage and assigns it to a cluster if the VCC is not exceeded.\r\n23\r\n\r\n‚Ä¢ Jobs are divided between flexible and inflexible. \r\n‚Ä¢ Flexible load is considered shapeable/shiftable as long as its total daily \r\ncompute (CPU) demand is preserved \r\n‚Ä¢ The system needs to consider that, while running a job, the virtual capacity \r\ncurve (VCC) might drop. Hence, this job should not start in the first place. \r\n‚Ä¢ They forecast VCC for the next day\r\n24\r\n\r\n\r\nVirtual Cluster Capacity (VCC)\r\n‚Ä¢ Aims at reducing the peak load at carbon intensive hours but in total it should allow for the \r\nsome amount of daily computation! \r\n‚Ä¢ Considers Carbon intensity \r\n‚Ä¢ Using data from electricityMap.org \r\n‚Ä¢ It does not use carbon intensity directly.\u2028\r\nCarbon intensity is converted to a cost (kgCO2 -> $$) \r\n‚Ä¢ This way, they can factor in other metrics that can also be converted to money. E.g., the \r\ncost saved by preventing peak load \r\n‚Ä¢ Peak workload entails extra cost at the infrastructure level (e.g., control faclities‚Äô \r\ntemperature). \r\n‚Ä¢ By using money cost instead of carbon cost, they have more data available.\r\n26\r\n\r\nVirtual Cluster Capacity (VCC)\r\n‚Ä¢ If the forecast of VCC fails it shift flexible workload more than expected.  \r\n‚Ä¢ This happens because the amount of workload forecasted was below the \r\nworkload needed, and VCC was ‚Äúaggressively‚Äù low. \r\n‚Ä¢ The systems fall back to the real cluster capacity for 1 week until results \r\nstart being realistic again.\r\n27\r\n\r\nNext steps\r\n‚Ä¢ They will consider spatial flexibility. \r\n‚Ä¢ I.e., tasks that can be shifted over time and over space. \r\n‚Ä¢ It needs to factor in relocation overheads, though.\r\n28\r\n\r\nCritical questions\r\n‚Ä¢ Who defines what is flexible and inflexible? \r\n‚Ä¢ How do you estimate the CPU load of a given task?\r\n29\r\n\r\nEnergy Regression Testing\r\n‚ÜíEnergy?\r\nGreener? Greener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\n\r\nE-compare\r\nGithub Actions\r\n‚ûú https://koenhagen.github.io/E-Compare/\r\n\r\nEnergy Regression Testing \r\n\r\n4. Debugging Energy with \r\nDocker Images\r\n\r\nUnveiling the Energy Vampires \r\nA methodology for debugging Software \r\nEnergy Consumption\r\n ‚úÖ ICSE 2025\r\n\r\nData Centers and Docker\r\n‚Ä¢ Containers are the most popular way to deploy apps into the cloud \r\n‚Ä¢ Base image is an important choice when building an image \r\n‚Ä¢ Criteria \r\n‚Ä¢ Linux distribution and binaries \r\n‚Ä¢ Image size \r\n‚Ä¢ Energy?\r\n35\r\n\r\nRedis energy consumption\r\n‚Ä¢ Ubuntu/Alpine base images have different energy consumption for Redis\r\n36\r\n\r\nRedis Energy Consumption\r\n‚Ä¢RQ1: What is the difference \r\nin energy consumption \r\nbetween glibc and musl? \r\n‚Ä¢RQ2: Can we use tracing \r\nto compare energy \r\nconsumption in shared \r\nlibraries?', 'Carolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nLu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\n1. Intro Class\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl\r\n\r\n1. Intro to Sustainable SE \r\n2. Intro to the course\r\n2\r\n\r\nof the electricity consumed worldwide \r\nby 2040 will stem from ICT\r\n14%\r\n\r\n4\r\nhttps://xkcd.com/1007/\r\n\r\nBuzz words\r\n‚Ä¢ Eco-friendly \r\n‚Ä¢ Climate change, action, adaption \r\n‚Ä¢ Energy efficiency \r\n‚Ä¢ Environmental-responsible \r\n‚Ä¢ Carbon-neutral; Climate-neutral; Net zero \r\n‚Ä¢ Carbon-offsetting \r\n‚Ä¢ Carbon-free \r\n‚Ä¢ Clean technology \r\n‚Ä¢ E-waste\r\n5\r\n\r\nhttps://www.menti.com/uns9d89kzn\r\nWhat is Sustainable \r\nSoftware Engineering?\r\n?\r\n6\r\n\r\nSustainable Software \r\nEngineering is‚Ä¶\r\n7\r\n‚Ä¶the discipline that studies the process of creating software systems that are able \r\nto create value in the long term without hindering its surrounding environment.\r\n\r\n8\r\nEconomical\r\nSocial\r\nTechnical\r\nIndividual\r\nEnvironmental\r\nSustainable\r\nSoftware\r\nEngineering\r\n‚≠ê\r\nTechnical\u2028\r\n‚öô\r\nEconomical\u2028\r\nüí∞\r\nSocial\u2028\r\nüë©üíºüë®üíºüë©üíºüë©üíº\r\nIndividual\u2028\r\nüë©üíª\r\nEnvironmental\u2028\r\nüå±\r\nSustainable\u2028\r\nSoftware \r\nEngineering\r\n\r\nEconomical\r\n‚Ä¢ Focused on assets, capital and added value\u2028\r\n(wealth creation, prosperity, profitability, capital \r\ninvestment, income, etc.) \r\n‚Ä¢ Nr of customers  \r\n‚Ä¢ Man-day-rate estimate \r\n‚Ä¢ Next round of funding \r\n‚Ä¢ Meet requirements in the contract\r\n9\r\n\r\nTechnical\r\n‚Ä¢ Longevity of information, systems, and infrastructure and their \r\nadequate evolution with changing surrounding conditions. \r\n‚Ä¢ Examples: \r\n‚Ä¢ Technical Debt \r\n‚Ä¢ Does it scale? \r\n‚Ä¢ Software testing \r\n‚Ä¢ Bus-factor \r\n‚Ä¢ Data integrity \r\n‚Ä¢ Innovation \r\n‚Ä¢ ‚Ä¶\r\n10\r\n\r\nIndividual\r\n‚Ä¢ Well-being of the individuals in an organisation.\u2028\r\nNote that it also includes how well individuals interact \r\nwith each other within the org. \r\n‚Ä¢ Examples: \r\n‚Ä¢ mental and physical well-being \r\n‚Ä¢ self-respect \r\n‚Ä¢ education/skills \r\n‚Ä¢ career development \r\n‚Ä¢ ‚Ä¶\r\n11\r\n\r\nSocial\r\n‚Ä¢ concerned with societal communities (groups of people, \r\norganisations) and the factors that erode trust in society. \r\n‚Ä¢ Examples: \r\n‚Ä¢ Social equity \r\n‚Ä¢ Justice \r\n‚Ä¢ Employment \r\n‚Ä¢ Democracy \r\n‚Ä¢ ‚Ä¶ \r\n‚Ä¢ Also includes compliance with policies and regulations \r\n12\r\n\r\nEnvironmental Sustainability\r\n‚Ä¢ the branch of Software Engineering that studies \r\nthe development of software that has minimal \r\nimpact in our planet throughout its whole \r\nlifecycle. \r\n‚Ä¢ Looking at software at different levels: \r\n‚Ä¢ Developing, Using, Serving, ‚Ä¶ \r\n‚Ä¢ Also includes e-waste. \r\n‚Ä¢ Almost identical to Green Software. (?)\r\n13\r\nBordallo II\r\n\r\nGreen Software\r\n‚Ä¢ Sustainability and energy efficiency. \r\n‚Ä¢ Building energy-efficient software is important also from a \r\ntechnical sustainability POV. \r\n‚Ä¢ Smartphones, smart wearables, IoT devices, etc. run on limited \r\npower resources. \r\n‚Ä¢ Developing software to these devices require energy-efficiency \r\ntesting and improvement. \r\n‚Ä¢ It also leads to environmental sustainability (e.g., less battery \r\ncycles) \r\n‚Ä¢ Important for UX (e.g., no need to walk around with power banks)\r\n14\r\n\r\nhttps://www.menti.com/uns9d89kzn\r\nWhat is the sustainability \r\ndimension you are most \r\ninterested in?\r\n?']","['<1-hop>\n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise\n‚Ä¢ But studying government software is diÔ¨Écult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation?\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!', '<2-hop>\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption\n‚Ä¢ B3. Energy proÔ¨Åling of static analysis tools\n‚Ä¢ B4. Detailed energy proÔ¨Åling of build pipelines\n‚Ä¢ B5. Tool supporting SusAF workshop / process\n‚Ä¢ B6. Dataset of government-developed OS software\n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability', '<1-hop>\n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise\n‚Ä¢ But studying government software is diÔ¨Écult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation?\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!', '<2-hop>\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption\n‚Ä¢ B3. Energy proÔ¨Åling of static analysis tools\n‚Ä¢ B4. Detailed energy proÔ¨Åling of build pipelines\n‚Ä¢ B5. Tool supporting SusAF workshop / process\n‚Ä¢ B6. Dataset of government-developed OS software\n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability', '<1-hop>\n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise\n‚Ä¢ But studying government software is diÔ¨Écult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation?\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!', '<2-hop>\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption\n‚Ä¢ B3. Energy proÔ¨Åling of static analysis tools\n‚Ä¢ B4. Detailed energy proÔ¨Åling of build pipelines\n‚Ä¢ B5. Tool supporting SusAF workshop / process\n‚Ä¢ B6. Dataset of government-developed OS software\n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability']","The challenges in creating a dataset of government-developed open-source software include:

1. **Lack of Incentive to Make Popular**: There is often little motivation for governments to promote their software projects, which can lead to a lack of visibility and accessibility.

2. **Language Barriers**: Government software projects may be documented in various languages, making it difficult to compile and understand the data across different regions.

3. **Understanding the State of Software**: It is challenging to gather comprehensive data that includes whether the software is buildable, has an open development history, or includes requirements documentation.

These challenges make it difficult to study and compile a comprehensive dataset of government-developed open-source software.","Creating a dataset of government-developed OS software faces challenges such as a lack of incentive to make the software popular and language barriers, which hinder comprehensive understanding of the software's buildability, open development history, and requirements documentation.",0.99999999995,,,1.0,,0.9696189674637212
"What are the practical applications of neuromorphic computing, and how does its biological inspiration influence its implementation in modern computing systems?","['McCulloch-Pitts neuron [1, 2]\r\n1940s: How do biological neurons compute basic \r\nlogic functions? (e.g. logic gates)\r\nNote: Ref. [3] gives a nice brief history on the ideas which lead to the \r\nMcCulloch-Pitts neuron.\r\n\r\nWhat is a neural network?\r\n1950s: How are neurons organized to perform \r\nsensory perception?\r\n\r\nWhat is a neural network?\r\n1950s: How are neurons organized to perform \r\nsensory perception?\r\nThe first ""neural network"": Perceptron (1958). [4]\r\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\r\nFrank Rosenblatt (Psychologist)\r\nwith a Mark I Perceptron computer in 1960\r\n\r\nWhat is a neural network?\r\n1950s: How are neurons organized to perform \r\nsensory perception?\r\nThe first ""neural network"": Perceptron (1958). [4]\r\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\r\nFrank Rosenblatt (Psychologist)\r\nwith a Mark I Perceptron computer in 1960\r\nPower-efficient\r\n\r\nNeuromorphic computing\r\nWhy neuromorphic computing?\r\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\r\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\r\n\r\nNeuromorphic computing\r\nWhy neuromorphic computing?\r\n‚ÄòBiological inspiration‚Äô for artificial neural networks (ANNs) is not a new idea.\r\nEmulation (as opposed to simulation) of neural networks in hardware is not a new idea.\r\nQuestion: What can we gain from increasing biological realism in existing neural networks?\r\n\r\nPower-efficiency at scale\r\nModern, deep neural networks*\r\nare trained using GPUs.\r\n* It is estimated that ChatGPT was trained on \r\n10,000-20,000 GPUs and that it will require\r\n30,000 GPUs to keep running stably in the future.\r\n* It is estimated that ChatGPT has 10-20 billion \r\nparameters.\r\nhttps://www.anandtech.com/show/4008/nvidias-geforce-gtx-580/17\r\n\r\nPower-efficiency at scale\r\nModern, deep neural networks*\r\nare trained using GPUs.\r\n* It is estimated that ChatGPT was trained on \r\n10,000-20,000 GPUs and that it will require\r\n30,000 GPUs to keep running stably in the future.\r\n* It is estimated that ChatGPT has 10-20 billion \r\nparameters.\r\nSingle model with 20 billion parameters:\r\n200 Watts x 30,000 GPUs = 6M Watts\r\n\r\nPower-efficiency at scale\r\nhttps://hai.stanford.edu/ai-index/2024-ai-index-report\r\nTraining a single large language model can \r\ngenerate greater CO2 emissions than the \r\ntotal lifetime emissions of 8 cars (in 2020)!\r\n\r\nPower-efficiency at scale\r\nhttps://hai.stanford.edu/ai-index/2024-ai-index-report\r\nTraining a single model can consume \r\nmore than 1000 MWh of power!\r\n\r\nPower-efficiency at scale\r\nhttps://hai.stanford.edu/ai-index/2024-ai-index-report\r\nTraining a single model can consume \r\nmore than 1000 MWh of power!\r\n‚Ä¶ with energy costs reaching 200M USD!\r\n\r\nPower-efficiency at scale\r\nYour brain runs on:\r\n\r\nPower-efficiency at scale\r\nYour brain runs on:\r\nHigh estimate ~3000 kcal a day\r\n   ‚âà145 Watts\r\n* Human brain has ~600 trillion synapses \r\n(‚âàparameters).', 'Different encoding strategies with spiking neurons\r\n\r\nDifferent encoding strategies with spiking neurons\r\nUsing latency or spatio-temporal codes\r\nour encoding is faster and more spike-efficient (sparser)!\r\n\r\nDifferent encoding strategies with spiking neurons\r\nUsing latency or spatio-temporal codes\r\nour encoding is faster and more spike-efficient (sparser)!\r\nQuestions?\r\n\r\nNeuromorphic computing\r\nWhat is the advantage for applications?\r\n-\r\nLess spikes = less energy consumption in specialized neuromorphic hardware\r\n(e.g. Intel Loihi [12])\r\nBrains are energy efficient: \r\n2. Sparse encoding\r\n\r\nMultiply-accumulate (MAC) operations:\r\nNormal neuron: Multiplies input with \r\nweights, then adds.\r\nSpiking neuron: Consider binary input (e.g. input currents are piecewise \r\nconstant and assume values {0,1}). There is no multiplication, only addition.\r\n\r\nAssume one multiplier and one adder circuit uses M and A energy respectively with AÔπ§M\r\n(e.g., for a 45nm CMOS process, standard energy usage is A = 0.9 pJ and M = 3.7 pJ).\r\nNormal neuron: nin x nout multiplications,\r\n(nin‚Äì 1) x nout additions\r\nSpiking neuron: 0 multiplications, (nactive‚Äì 1) x nout \r\nadditions, with nactive ‚â§ nin\r\nEnergy consumption:\r\nEnormal = M nin nout + A (nin‚Äì 1) nout = 17.5 pJ\r\nEnergy consumption:\r\nEspiking = A (nactive‚Äì 1) nout = 2.7 pJ\r\nMultiply-accumulate (MAC) operations:\r\n\r\nAssume one multiplier and one adder circuit uses M and A energy respectively with AÔπ§M\r\n(e.g., for a 45nm CMOS process, standard energy usage is A = 0.9 pJ and M = 3.7 pJ).\r\nNormal neuron: nin x nout multiplications,\r\n(nin‚Äì 1) x nout additions\r\nSpiking neuron: 0 multiplications, (nactive‚Äì 1) x nout \r\nadditions, with nactive ‚â§ nin\r\nEnergy consumption:\r\nEnormal = M nin nout + A (nin‚Äì 1) nout = 17.5 pJ\r\nEnergy consumption:\r\nEspiking = A (nactive‚Äì 1) nout = 2.7 pJ\r\nMultiply-accumulate (MAC) operations:\r\nSNN challenge: how to \r\ncompute with the least \r\namount of spikes!\r\n\r\nOften, we observe a \r\nsparsity (energy)-\r\ntask accuracy trade-off\r\n(Left: results for image \r\nclassification)\r\nSNN challenge: how to \r\ncompute with the least \r\namount of spikes!\r\nhttps://arxiv.org/pdf/2409.08290\r\n\r\nIn practice, energy \r\nconsumption computations \r\nare complex. \r\nNeed to take into account\r\n- memory access,\r\n- addressing,\r\n- auxiliary operations,\r\nin addition to MACs.\r\nEstimated energy consumption for 3 different datasets (CIFAR10, GSC, NCARS; image, sound \r\nand video classification respectively). FNN‚Äôs are conventional feed-forward neural networks.\r\nIn this example: SNNs are 6 to 8 times more energy efficient than FNNs.\r\nhttps://arxiv.org/pdf/2210.13107\r\nComputing energy consumption\r\n\r\nIn practice, energy \r\nconsumption computations \r\nare complex. \r\nNeed to take into account\r\n- memory access,\r\n- addressing,\r\n- auxiliary operations,\r\nin addition to MACs.\r\nEstimated energy consumption for 3 different datasets (CIFAR10, GSC, NCARS; image, sound \r\nand video classification respectively). FNN‚Äôs are conventional feed-forward neural networks.\r\nIn this example: SNNs are 6 to 8 times more energy efficient than FNNs.', 'Normal neuron: nin x nout multiplications,\r\n(nin‚Äì 1) x nout additions\r\nSpiking neuron: 0 multiplications, (nactive‚Äì 1) x nout \r\nadditions, with nactive ‚â§ nin\r\nEnergy consumption:\r\nEnormal = M nin nout + A (nin‚Äì 1) nout = 17.5 pJ\r\nEnergy consumption:\r\nEspiking = A (nactive‚Äì 1) nout = 2.7 pJ\r\nMultiply-accumulate (MAC) operations:\r\nSNN challenge: how to \r\ncompute with the least \r\namount of spikes!\r\n\r\nOften, we observe a \r\nsparsity (energy)-\r\ntask accuracy trade-off\r\n(Left: results for image \r\nclassification)\r\nSNN challenge: how to \r\ncompute with the least \r\namount of spikes!\r\nhttps://arxiv.org/pdf/2409.08290\r\n\r\nIn practice, energy \r\nconsumption computations \r\nare complex. \r\nNeed to take into account\r\n- memory access,\r\n- addressing,\r\n- auxiliary operations,\r\nin addition to MACs.\r\nEstimated energy consumption for 3 different datasets (CIFAR10, GSC, NCARS; image, sound \r\nand video classification respectively). FNN‚Äôs are conventional feed-forward neural networks.\r\nIn this example: SNNs are 6 to 8 times more energy efficient than FNNs.\r\nhttps://arxiv.org/pdf/2210.13107\r\nComputing energy consumption\r\n\r\nIn practice, energy \r\nconsumption computations \r\nare complex. \r\nNeed to take into account\r\n- memory access,\r\n- addressing,\r\n- auxiliary operations,\r\nin addition to MACs.\r\nEstimated energy consumption for 3 different datasets (CIFAR10, GSC, NCARS; image, sound \r\nand video classification respectively). FNN‚Äôs are conventional feed-forward neural networks.\r\nIn this example: SNNs are 6 to 8 times more energy efficient than FNNs.\r\nComputing energy consumption\r\nQuestions?\r\n\r\nReading materials\r\nMain reading:\r\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \r\nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\r\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\r\n- Neuromorphic computing:\r\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \r\nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\r\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \r\noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\r\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019.', ""- Higher firing rate (spikes per unit time) for \r\n'selected' feature.\r\nAdapted from Hubel & Wiesel, 1959\r\n\r\nFiring rates\r\nClassical view of the brain:\r\n- Each neuron is selective for one specific \r\nfeature in the input.\r\n- Higher firing rate (spikes per unit time) for \r\n'selected' feature.\r\n- Link to modern ANNs: The scalar output of \r\nan artificial neuron is interpreted as the firing \r\nrate.\r\nAdapted from Hubel & Wiesel, 1959\r\n\r\nFiring rates\r\nClassical view of the brain:\r\n- Each neuron is selective for one specific \r\nfeature in the input.\r\n- Higher firing rate (spikes per unit time) for \r\n'selected' feature.\r\n- Link to modern ANNs: The scalar output of \r\nan artificial neuron is interpreted as the firing \r\nrate.\r\nAdapted from Hubel & Wiesel, 1959\r\nBut rate coding is inefficient and slow‚Ä¶\r\n(i.e. each neuron needs to fire many spikes to get good precision)\r\nboth in vivo and in silico.\r\n\r\nDifferent encoding strategies with spiking neurons [8]\r\n7 neurons\r\n7 time bins\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nn\r\n6\r\n(in the general \r\ncase a \r\nnumber \r\nbetween 0-7)\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nn\r\nTotal spike \r\ncount can \r\nencode 3 bits.\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nIndividual rates \r\ncan encode 7 \r\nbits.\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nLatency can \r\nencode ~3*7 or \r\n~19 bits.\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nRank order can \r\nencode ~12 bits.\r\n\r\nDifferent encoding strategies with spiking neurons\r\n\r\nDifferent encoding strategies with spiking neurons\r\nUsing latency or spatio-temporal codes\r\nour encoding is faster and more spike-efficient (sparser)!\r\n\r\nDifferent encoding strategies with spiking neurons\r\nUsing latency or spatio-temporal codes\r\nour encoding is faster and more spike-efficient (sparser)!\r\nQuestions?\r\n\r\nNeuromorphic computing\r\nWhat is the advantage for applications?\r\n-\r\nLess spikes = less energy consumption in specialized neuromorphic hardware\r\n(e.g. Intel Loihi [12])\r\nBrains are energy efficient: \r\n2. Sparse encoding\r\n\r\nMultiply-accumulate (MAC) operations:\r\nNormal neuron: Multiplies input with \r\nweights, then adds.\r\nSpiking neuron: Consider binary input (e.g. input currents are piecewise \r\nconstant and assume values {0,1}). There is no multiplication, only addition.\r\n\r\nAssume one multiplier and one adder circuit uses M and A energy respectively with AÔπ§M\r\n(e.g., for a 45nm CMOS process, standard energy usage is A = 0.9 pJ and M = 3.7 pJ).\r\nNormal neuron: nin x nout multiplications,\r\n(nin‚Äì 1) x nout additions\r\nSpiking neuron: 0 multiplications, (nactive‚Äì 1) x nout \r\nadditions, with nactive ‚â§ nin\r\nEnergy consumption:\r\nEnormal = M nin nout + A (nin‚Äì 1) nout = 17.5 pJ\r\nEnergy consumption:\r\nEspiking = A (nactive‚Äì 1) nout = 2.7 pJ\r\nMultiply-accumulate (MAC) operations:\r\n\r\nAssume one multiplier and one adder circuit uses M and A energy respectively with AÔπ§M\r\n(e.g., for a 45nm CMOS process, standard energy usage is A = 0.9 pJ and M = 3.7 pJ)."", 'Neuromorphic computing\r\nCS4575\r\nSustainable Software Engineering\r\n05.03.2025\r\nNergis T√∂men\r\n\r\nIntroduction\r\nComputer Vision Lab\r\nBiomorphic Intelligence Lab\r\nBiomedical Intervention Optimisation Lab\r\nNergis\r\n\r\nNeuromorphic computing\r\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\r\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\r\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing\r\n\r\nHow many of you are familiar \r\nwith neural networks?\r\n\r\nSimple model of an artificial neuron\r\nhttps://medium.com/@cprasenjit32/perceptron-a-simple-yet-mighty-machine-learning-algorithm-9ff6b7d86a71\r\n\r\nWhat is a neural network?\r\nhttps://www.tibco.com/reference-center/what-is-a-neural-network\r\n\r\nWhy is it called a \'neural network\'?\r\nhttps://www.tibco.com/reference-center/what-is-a-neural-network\r\n\r\nWhat is a neural network?\r\nWhy is it called a \'neural network\'?\r\nMcCulloch-Pitts neuron [1, 2] (1943)\r\nWarren Sturgis McCulloch\r\n(Neurophysiologist)\r\nWalter Pitts\r\n(Logician)\r\n\r\nHow do biological neurons work?\r\nhttps://commons.wikimedia.org/wiki/File:Coincidence_detection_in_dendrites_of_pyramidal_neurons.gif\r\n\'Input current\' travels down the dendrites (top),\r\nget integrated (summed!) in the cell body\r\nwhich generates an \'output current\' (bottom)\r\nwhich is chemically transmitted to the dendrites of \r\nother neurons.\r\n\r\nSimplified picture\r\nReal neuron\r\nArtificial neuron\r\nhttps://vajiramandravi.com/quest-upsc-notes/artificial-neural-network/\r\n\r\nWhat is a neural network?\r\nMcCulloch-Pitts neuron [1, 2]\r\n1940s: How do biological neurons compute basic \r\nlogic functions? (e.g. logic gates)\r\nNote: Ref. [3] gives a nice brief history on the ideas which lead to the \r\nMcCulloch-Pitts neuron.\r\n\r\nWhat is a neural network?\r\n1950s: How are neurons organized to perform \r\nsensory perception?\r\n\r\nWhat is a neural network?\r\n1950s: How are neurons organized to perform \r\nsensory perception?\r\nThe first ""neural network"": Perceptron (1958). [4]\r\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\r\nFrank Rosenblatt (Psychologist)\r\nwith a Mark I Perceptron computer in 1960\r\n\r\nWhat is a neural network?\r\n1950s: How are neurons organized to perform \r\nsensory perception?\r\nThe first ""neural network"": Perceptron (1958). [4]\r\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\r\nFrank Rosenblatt (Psychologist)\r\nwith a Mark I Perceptron computer in 1960\r\nPower-efficient\r\n\r\nNeuromorphic computing\r\nWhy neuromorphic computing?\r\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\r\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\r\n\r\nNeuromorphic computing\r\nWhy neuromorphic computing?\r\n‚ÄòBiological inspiration‚Äô for artificial neural networks (ANNs) is not a new idea.\r\nEmulation (as opposed to simulation) of neural networks in hardware is not a new idea.', 'In this example: SNNs are 6 to 8 times more energy efficient than FNNs.\r\nComputing energy consumption\r\nQuestions?\r\n\r\nReading materials\r\nMain reading:\r\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \r\nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\r\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\r\n- Neuromorphic computing:\r\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \r\nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\r\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \r\noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\r\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \r\nhttps://www.nature.com/articles/s41586-019-1677-2\r\nExtra reading:\r\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \r\nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\r\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \r\nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \r\nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\r\nBasics of \'conventional\' neural networks:\r\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\r\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.\r\n\r\nReferences\r\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \r\nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\r\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947.', '9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\r\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \r\nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\r\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \r\n(not publicly available) doi:10.1037/h0042519\r\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \r\nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\r\n6) https://github.com/idsc-frazzoli/retina\r\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \r\nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\r\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \r\nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\r\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \r\nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\r\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \r\nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\r\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \r\nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\r\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\r\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\r\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \r\n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568', ""Oversimplification\r\nThere are also multiple other advantages‚Ä¶\r\n\r\nHuman vs. computer computation\r\n- Fast real-time decision making, e.g. sports, e-sports\r\n- Adaptive, e.g. context-aware and employs selective attention\r\n- Energy efficient: Close to 100 billion neurons in the brain\r\n- Robust, for example to changes in illumination or obstructions in object tracking\r\n\r\nHuman vs. computer computation\r\nBrains are energy efficient: Why?\r\n1.\r\nHigh temporal resolution (more computation with less neurons)\r\n2.\r\nSparse encoding\r\n\r\nHuman vs. computer computation\r\nQuestions?\r\nBrains are energy efficient: Why?\r\n1.\r\nHigh temporal resolution (more computation with less neurons)\r\n2.\r\nSparse encoding\r\n\r\nHow do biological neurons communicate?\r\nAnalogy to artificial neural networks\r\nReal neuron\r\nArtificial neuron\r\nCurrent\r\n\r\nHow do biological neurons communicate?\r\nHow does the electrical activity propagate?\r\n?\r\nCurrent\r\n\r\nHow do biological neurons work?\r\ntime\r\nelectrode\r\nhttps://tinmard.github.io/spike-sorting-animation.html\r\nQuick electrical pulses trigger chemical signals for the next neuron ‚Üí Spikes\r\n\r\nHow do biological neurons work?\r\nQuick electrical pulses trigger chemical signals for the next neuron ‚Üí Spikes\r\nhttps://tinmard.github.io/spike-sorting-animation.html\r\ntime\r\nelectrode\r\nFrom CS perspective:\r\nSparse binary \r\nencoding\r\n\r\nBiologically realistic spiking neuron models\r\nBiologically realistic neuron models have \r\na new dimension: Time!\r\nSpiking neural networks (SNNs):\r\nThe input x  (t  ) to each neuron is summed \r\n(integrated) over time.\r\nscalar\r\nfunction of \r\ntime\r\n(t)\r\n(t)\r\nhttps://www.mdpi.com/2076-3425/12/7/863\r\n\r\nHow to model spiking neurons?\r\nANN: Perceptron, threshold activation function:\r\n\r\nHow to model spiking neurons?\r\nANN: Perceptron, threshold activation function:\r\n\r\nHow to model spiking neurons?\r\nSpiking neural network (SNN): The 'input current' Œµ(t) is integrated over time.\r\nspike\r\n\r\nHow to model spiking neurons?\r\nEquivalence to perceptron: Computation at least as complex as a perceptron.\r\n\r\nNon-leaky integrate-and-fire (IF) neuron\r\nThe temporal profile of the input current Œµ(t) can be chosen differently, for different computations.\r\n\r\nQuestions?\r\n\r\nComputation with spiking neurons\r\nCoincidence detection\r\n\r\nComputation with spiking neurons\r\nCoincidence detection\r\nx, y ‚àà {0, 1}n\r\nExample: n = 2\r\ninput = \r\nx1\r\nx2\r\ny1\r\ny2\r\n= \r\n0\r\n1\r\n1\r\n1\r\noutput? \r\n\r\nCoincidence detection\r\nComputation with spiking neurons\r\n\r\nCoincidence detection\r\nCan be trivially computed with a single spiking neuron! Requires at least n/log(n+1) hidden \r\nunits for a perceptron (proof in [7]).\r\nComputation with spiking neurons\r\n\r\nCoincidence detection\r\nCan be trivially computed with a single spiking neuron! Requires at least n/log(n+1) hidden \r\nunits for a perceptron (proof in [7]).\r\nBrains are energy efficient: \r\n1.\r\nHigh temporal resolution (more computation with less neurons)\r\nComputation with spiking neurons\r\n\r\nEncoding strategies\r\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\r\nHow should we encode information about 'features' in a large network with many spikes?\r\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\r\nElephant?\r\nhttps://www.nationalgeographic.com/anim\r\nals/mammals/facts/african-elephant\r\n\r\nFiring rates\r\nClassical view of the brain:\r\n- Each neuron is selective for one specific \r\nfeature in the input."", ""Spiking neural network (SNN): The 'input current' Œµ(t) is integrated over time.\r\nspike\r\n\r\nHow to model spiking neurons?\r\nEquivalence to perceptron: Computation at least as complex as a perceptron.\r\n\r\nNon-leaky integrate-and-fire (IF) neuron\r\nThe temporal profile of the input current Œµ(t) can be chosen differently, for different computations.\r\n\r\nQuestions?\r\n\r\nComputation with spiking neurons\r\nCoincidence detection\r\n\r\nComputation with spiking neurons\r\nCoincidence detection\r\nx, y ‚àà {0, 1}n\r\nExample: n = 2\r\ninput = \r\nx1\r\nx2\r\ny1\r\ny2\r\n= \r\n0\r\n1\r\n1\r\n1\r\noutput? \r\n\r\nCoincidence detection\r\nComputation with spiking neurons\r\n\r\nCoincidence detection\r\nCan be trivially computed with a single spiking neuron! Requires at least n/log(n+1) hidden \r\nunits for a perceptron (proof in [7]).\r\nComputation with spiking neurons\r\n\r\nCoincidence detection\r\nCan be trivially computed with a single spiking neuron! Requires at least n/log(n+1) hidden \r\nunits for a perceptron (proof in [7]).\r\nBrains are energy efficient: \r\n1.\r\nHigh temporal resolution (more computation with less neurons)\r\nComputation with spiking neurons\r\n\r\nEncoding strategies\r\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\r\nHow should we encode information about 'features' in a large network with many spikes?\r\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\r\nElephant?\r\nhttps://www.nationalgeographic.com/anim\r\nals/mammals/facts/african-elephant\r\n\r\nFiring rates\r\nClassical view of the brain:\r\n- Each neuron is selective for one specific \r\nfeature in the input.\r\n- Higher firing rate (spikes per unit time) for \r\n'selected' feature.\r\nAdapted from Hubel & Wiesel, 1959\r\n\r\nFiring rates\r\nClassical view of the brain:\r\n- Each neuron is selective for one specific \r\nfeature in the input.\r\n- Higher firing rate (spikes per unit time) for \r\n'selected' feature.\r\n- Link to modern ANNs: The scalar output of \r\nan artificial neuron is interpreted as the firing \r\nrate.\r\nAdapted from Hubel & Wiesel, 1959\r\n\r\nFiring rates\r\nClassical view of the brain:\r\n- Each neuron is selective for one specific \r\nfeature in the input.\r\n- Higher firing rate (spikes per unit time) for \r\n'selected' feature.\r\n- Link to modern ANNs: The scalar output of \r\nan artificial neuron is interpreted as the firing \r\nrate.\r\nAdapted from Hubel & Wiesel, 1959\r\nBut rate coding is inefficient and slow‚Ä¶\r\n(i.e. each neuron needs to fire many spikes to get good precision)\r\nboth in vivo and in silico.\r\n\r\nDifferent encoding strategies with spiking neurons [8]\r\n7 neurons\r\n7 time bins\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nn\r\n6\r\n(in the general \r\ncase a \r\nnumber \r\nbetween 0-7)\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nn\r\nTotal spike \r\ncount can \r\nencode 3 bits.\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nIndividual rates \r\ncan encode 7 \r\nbits.\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nLatency can \r\nencode ~3*7 or \r\n~19 bits.\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nRank order can \r\nencode ~12 bits."", 'Power-efficiency at scale\r\nModern, deep neural networks*\r\nare trained using GPUs.\r\n* It is estimated that ChatGPT was trained on \r\n10,000-20,000 GPUs and that it will require\r\n30,000 GPUs to keep running stably in the future.\r\n* It is estimated that ChatGPT has 10-20 billion \r\nparameters.\r\nhttps://www.anandtech.com/show/4008/nvidias-geforce-gtx-580/17\r\n\r\nPower-efficiency at scale\r\nModern, deep neural networks*\r\nare trained using GPUs.\r\n* It is estimated that ChatGPT was trained on \r\n10,000-20,000 GPUs and that it will require\r\n30,000 GPUs to keep running stably in the future.\r\n* It is estimated that ChatGPT has 10-20 billion \r\nparameters.\r\nSingle model with 20 billion parameters:\r\n200 Watts x 30,000 GPUs = 6M Watts\r\n\r\nPower-efficiency at scale\r\nhttps://hai.stanford.edu/ai-index/2024-ai-index-report\r\nTraining a single large language model can \r\ngenerate greater CO2 emissions than the \r\ntotal lifetime emissions of 8 cars (in 2020)!\r\n\r\nPower-efficiency at scale\r\nhttps://hai.stanford.edu/ai-index/2024-ai-index-report\r\nTraining a single model can consume \r\nmore than 1000 MWh of power!\r\n\r\nPower-efficiency at scale\r\nhttps://hai.stanford.edu/ai-index/2024-ai-index-report\r\nTraining a single model can consume \r\nmore than 1000 MWh of power!\r\n‚Ä¶ with energy costs reaching 200M USD!\r\n\r\nPower-efficiency at scale\r\nYour brain runs on:\r\n\r\nPower-efficiency at scale\r\nYour brain runs on:\r\nHigh estimate ~3000 kcal a day\r\n   ‚âà145 Watts\r\n* Human brain has ~600 trillion synapses \r\n(‚âàparameters).\r\n\r\nPower-efficiency at scale\r\nYour brain runs on:\r\nHigh estimate ~3000 kcal a day\r\n   ‚âà145 Watts\r\n* Human brain has ~600 trillion synapses \r\n(‚âàparameters).\r\nOversimplification\r\nThere are also multiple other advantages‚Ä¶\r\n\r\nHuman vs. computer computation\r\n- Fast real-time decision making, e.g. sports, e-sports\r\n- Adaptive, e.g. context-aware and employs selective attention\r\n- Energy efficient: Close to 100 billion neurons in the brain\r\n- Robust, for example to changes in illumination or obstructions in object tracking\r\n\r\nHuman vs. computer computation\r\nBrains are energy efficient: Why?\r\n1.\r\nHigh temporal resolution (more computation with less neurons)\r\n2.\r\nSparse encoding\r\n\r\nHuman vs. computer computation\r\nQuestions?\r\nBrains are energy efficient: Why?\r\n1.\r\nHigh temporal resolution (more computation with less neurons)\r\n2.\r\nSparse encoding\r\n\r\nHow do biological neurons communicate?\r\nAnalogy to artificial neural networks\r\nReal neuron\r\nArtificial neuron\r\nCurrent\r\n\r\nHow do biological neurons communicate?\r\nHow does the electrical activity propagate?\r\n?\r\nCurrent\r\n\r\nHow do biological neurons work?\r\ntime\r\nelectrode\r\nhttps://tinmard.github.io/spike-sorting-animation.html\r\nQuick electrical pulses trigger chemical signals for the next neuron ‚Üí Spikes\r\n\r\nHow do biological neurons work?\r\nQuick electrical pulses trigger chemical signals for the next neuron ‚Üí Spikes\r\nhttps://tinmard.github.io/spike-sorting-animation.html\r\ntime\r\nelectrode\r\nFrom CS perspective:\r\nSparse binary \r\nencoding\r\n\r\nBiologically realistic spiking neuron models\r\nBiologically realistic neuron models have \r\na new dimension: Time!\r\nSpiking neural networks (SNNs):\r\nThe input x  (t  ) to each neuron is summed \r\n(integrated) over time.\r\nscalar\r\nfunction of \r\ntime\r\n(t)\r\n(t)\r\nhttps://www.mdpi.com/2076-3425/12/7/863\r\n\r\nHow to model spiking neurons?', '575(7784):607-17. \r\nhttps://www.nature.com/articles/s41586-019-1677-2\r\nExtra reading:\r\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \r\nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\r\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \r\nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \r\nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\r\nBasics of \'conventional\' neural networks:\r\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\r\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.\r\n\r\nReferences\r\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \r\nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\r\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \r\n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\r\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \r\nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\r\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \r\n(not publicly available) doi:10.1037/h0042519\r\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \r\nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\r\n6) https://github.com/idsc-frazzoli/retina\r\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \r\nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\r\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \r\nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\r\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \r\nNeural Networks.', '8. Green AI\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nLu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\nCarolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl\r\n\r\n- Overview of Green AI \r\n- Large language models \r\n- Green data-centric AI \r\n- Model simplification \r\n- Hyper parameter tuning \r\n- Mixture of Experts and DeepSeek \r\n- Green AI at Meta \r\n\r\nAI\r\n‚Ä¢ Artificial Intelligence (AI) is the branch of computer science that deals with \r\nautomating tasks that typically require human intelligence. \r\n‚Ä¢ In the past years AI has been widely applied across different domains.\u2028\r\nE.g., health care, transportation, finance. \r\n‚Ä¢ To deploy AI systems, we test them against benchmarks (or validation sets). \r\n‚Ä¢ The goal is to outperform the previous existing models. \r\n‚Ä¢ E.g., in Machine Learning we usually resort to accuracy metrics. The \r\nhighest the accuracy, the better the model.\r\n3\r\n\r\nSince 2012, the amount of computing used for AI \r\ntraining has been doubling every 6 months\r\n‚Ä¢ https://epoch.ai/blog/compute-trends\r\n4\r\n\r\n‚Ä¢ To create better AI systems we are currently adding \r\n‚Ä¢ More data \r\n‚Ä¢ More experiments \r\n‚Ä¢ Larger models\r\n5\r\n\r\nThe Equation of Red AI\r\nCost(R) ‚àùE¬∑D¬∑H\r\nCost of a single (E)xample\r\nSize of (D)ataset\r\nNumber of (H)yperparameters\r\nBy Schwartz et al. (2020)\r\n\r\nIssues of Red AI\r\n‚Ä¢ High costs (hardware, electricity, data access, etc.) \r\n‚Ä¢ Limited reproducibility.  \r\n‚Ä¢ Energy consumption. \r\n‚Ä¢ Carbon emissions. \r\n‚Ä¢ SMEs can hardly be competitive. \r\n‚Ä¢ Groundbreaking AI research is mostly done by tech giants.\r\n7\r\n\r\nA few examples of Red AI\r\n‚Ä¢ Google‚Äôs BERT-large \r\n‚Ä¢ 350 million features \r\n‚Ä¢ Trained for 2.5 days using 512 TPU chips, costing $60K+ \r\n‚Ä¢ Open-GPT3 (now GPT-4/o1) \r\n‚Ä¢ 550 tonnes CO2-eq (Patterson, 2021) \r\n‚Ä¢ 175 billion features \r\n‚Ä¢ API is open but no-pretrained model is available \r\n‚Ä¢ AlphaGo \r\n‚Ä¢ 1920 CPUs, 280 GPUs, costing $35M\r\n8\r\n\r\nRed AI in Large Language Models (LLMs)\r\n‚Ä¢ OPT by Meta reports 75 tons CO2-eq (1/7 of OpenGPT‚Äôs footprint).\u2028\r\n(Also 175billion params) \r\n‚Ä¢ However, Llama 3 reported 2,290 tons of CO2-eq (7.7M GPU hours \r\ntraining ) \r\n‚Ä¢ Open science: release includes both the pretrained models and the code \r\nneeded to train and use them. \r\n‚Ä¢ DeepSeek-V3 claims ‚Äúonly‚Äù 2.78M GPU hours \r\n‚Ä¢ Bloom by Huggingface reports 25 tons, 51 when considering embodied \r\nand operational carbon footprint. (176billion params)\r\n9\r\n\r\nRed AI\r\nAccuracy: 0.999999999\r\nGreen AI\r\n‚Ä¢ Energy \r\n‚Ä¢ Time \r\n‚Ä¢ Reproducibility \r\n‚Ä¢ Reusage\r\n\r\nHow can we adopt Green AI\r\n‚Ä¢ Check whether AI is needed. \r\n‚Ä¢ Select green datacenters. \r\n‚Ä¢ Run on low carbon intensity hours. \r\n‚Ä¢ Opt for GPU-optimised solutions (?) \r\n‚Ä¢ Opt for low-power hardware (e.g., Nvidia Jetson boards) \r\n‚Ä¢ Or GPUs that provide energy metrics (e.g., NVIDIA GPUs via the nvidia-smi tool) \r\n‚Ä¢ Report energy/carbon metrics (e.g., embed in MLFlow?)', 'Interviews?) & rich \r\ndescription of outcomes focus of grading\r\nhttps://eip.pages.ewi.tudelft.nl/eip-website/queue.html\r\n\r\nC1. Compare energy consumption of docker images for \r\nML workloads.\r\n‚Ä¢ Similar to what we have seen in the lectures but for ML-specific workloads. \r\n‚Ä¢ We can reuse existing experiment replication packages.\r\n22\r\n\r\nC2. Plugin to visualize Hugging Face carbon emissions.\r\n‚Ä¢ https://huggingface.co/blog/leaderboard-emissions-\r\nanalysis \r\n‚Ä¢\r\nYoo, Taewon, et al. ""Visualizing the Carbon Intensity of Machine Learning Inference for Image Analysis on TensorFlow Hub.""\r\n\r\nC3. Plugin for ChatGPT\r\n‚Ä¢ Users seldom know how much carbon they are emitting when they interact \r\nwith chat GPT. \r\n‚Ä¢ Let‚Äôs make it transparent to the users. Browser plugin?\r\n24\r\nCO2\r\n\r\nC4. NutriScore for software libraries\r\n25\r\n‚Ä¢ NutriScore labels are not perfect but they are a good starting point! \r\n‚Ä¢ What if we could do the same thing for the energy efficiency of software. \r\n‚Ä¢ (Also open to individual or social sustainability) \r\n‚Ä¢ This work can be scoped in particular domains/ecossystems/use cases. \r\n‚Ä¢ Libraries for stats? ML? Web Dev? Cloud?\r\n\r\nC5. Add energy-awareness to existing software\r\n26\r\n‚Ä¢ Streamlit, Notebooks, JSFiddle, \r\nPyScript, zsh, etc. \r\n‚Ä¢\r\n\r\nC6 - Green Shift Left\r\n‚Ä¢ Estimate energy efficiency using static code analysis. \r\n‚Ä¢ We don‚Äôt need an accurate value. \r\n‚Ä¢ It is useful to know which code is more likely to \r\nintroduce energy hotspots and that should be \r\nreviewed with more attention. \r\n‚Ä¢ Can be scoped to a particular domain (react, php, data \r\nscience, web, etc., etc.)\r\n27\r\n\r\nC7 - Education\r\n‚Ä¢ Educational game for Software \r\nSustainability practices \r\n‚Ä¢ Purpose: use within software teams to \r\ndiscuss or learn about different sustainable \r\nIT practices: at the organisation level, \r\nsoftware, etc.\r\n28\r\nhttps://github.com/OttoKaaij/Ticket-To-Sustainability/?tab=readme-ov-file\r\n\r\nProject ideas (old)\r\n‚Ä¢ Plugin from EnergiBridge (GUI, report generator, python library, etc.) \r\n‚Ä¢ Plugin for ChatGPT (carbon emissions per chat window) \r\n‚Ä¢ Seamless measurements for AI libraries \r\n‚Ä¢ Energy patterns for Green AI \r\n‚Ä¢ Sustainable SW dev gamification \r\n‚Ä¢ Sustainability auditor for AI projects \r\n‚Ä¢ Energy Profiling of screen colour filter tools (or display settings) \r\n‚Ä¢ ‚Ä¶ you can also propose yours!\r\n\r\nhttps://edu.nl/64gpk\r\nedu.nl/64gpk', '‚Ä¢ Improve parameter-tuning strategy.\r\n11\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ We need benchmarks. \r\n‚Ä¢ AllenAI leaderboard\u2028\r\nhttps://leaderboard.allenai.org \r\n‚Ä¢ No carbon metrics, yet \r\n‚Ä¢ Report comparable proxies for energy \r\nconsumption. \r\n‚Ä¢ ‚ö† Learning algorithms behave in a non-\r\ndeterministic \r\n‚Ä¢ ‚ö† Different data-points lead to different \r\nenergy consumption\r\n12\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ Reporting measured energy consumption \r\n‚Ä¢ + Accurate \r\n‚Ä¢ + Easy to map to carbon emissions \r\n‚Ä¢ - Hard to measure \r\n‚Ä¢ - Low replicability \r\n‚Ä¢ Reporting time / estimation based on time & hardware \r\n‚Ä¢ + Easy to measure \r\n‚Ä¢ + Correlates with energy consumption in most cases. \r\n‚Ä¢ -  Difficult to compare with measurements from other setups \r\n‚Ä¢ E.g., floating point operations (FPOs) (?) \r\n‚Ä¢ + comparable across different setups \r\n‚Ä¢ + cheap \r\n‚Ä¢ - does not factor in memory energy consumption \r\n‚Ä¢ - does not reflect carbon emissions\r\n13\r\n\r\nData-centric AI\r\n\r\nData-centric AI\r\n‚Ä¢ Emerging discipline that deals with systematically engineering data to build AI \r\nsystems. \r\n‚Ä¢ Shift from improving the training strategy to improving the data. \r\n‚Ä¢ It is better to have small but reliable datasets than large but noisy \r\ndatasets. \r\n‚Ä¢ => Improve data collection, data labelling, and data preprocessing. \r\n‚Ä¢ More about data-centric AI by Andrew Ng:\u2028\r\nhttps://www.youtube.com/watch?v=06-AZXmwHjo\r\n15\r\n\r\n\r\nGreen Data-centric AI\r\n‚Ä¢ How do different ML algorithms compare \r\nin terms of energy consumption? \r\n‚Ä¢ How does number of rows relate to the \r\nenergy consumption of ML models? \r\n‚Ä¢ How does number of features relate to \r\nthe energy consumption of ML models? \r\n‚Ä¢ What is the impact of reducing data in the \r\nperformance of the model? \r\n‚Ä¢ Method -> results -> discussion\r\n17\r\n\r\nMethod\r\n‚Ä¢ Single object of study: natural language model to detect spam messages. \r\n‚Ä¢ 6 machine learning algorithms: SVM, Decision Tree, KNN, Random Forrest, \r\nAdaBoost, Bagging Classifier. \r\n‚Ä¢ Reduce the number of rows. 10%, 20%, .., 100% \r\n‚Ä¢ Stratified random sampling (?) \r\n‚Ä¢ Reduce the number of features. 10%, 20%, .., 100% \r\n‚Ä¢ Feature importance metric based on the Chi-Square Test (Chi2) \r\n‚Ä¢ Estimate energy consumption using a RAPL-based tool. (?)\r\n18\r\n\r\n‚Ä¢ Repeat 30 times \r\n‚Ä¢ Fix random seeds \r\n‚Ä¢ ‚Ä¶ \r\n‚Ä¢ Data was not Normal => tailed Normal distribution.\r\n19\r\n(?)\r\n\r\nResults: energy consumption of algorithms\r\n\r\nResults: energy vs data shape\r\n\r\nResults: performance vs data shape\r\n\r\nDiscussion\r\n‚Ä¢ Other data properties should be investigated. \r\n‚Ä¢ E.g., data types \r\n‚Ä¢ Reporting energy data is essential. It can lead to different model selection \r\nwithout hindering model performance. \r\n‚Ä¢ There is a big opportunity in Model and Data Simplification.\r\n23\r\n\r\nData/Model Simplification\r\n‚Ä¢ (?) \r\n‚Ä¢ Data selection \r\n‚Ä¢ Data quantisation. Posit? \r\n‚Ä¢ Data distillation \r\n‚Ä¢ Coreset extraction (?) \r\n‚Ä¢ Model distillation \r\n‚Ä¢ Model quantisation \r\n‚Ä¢ Model pruning \r\n‚Ä¢ ‚Ä¶\r\n24\r\n\r\nPosit vs Float\r\nMore about this: https://spectrum.ieee.org/floating-point-numbers-posits-processor\r\nBetter for DL use cases\r\n\r\nHow can we tune \r\nlearning \r\nparameters \r\nefficiently?\r\n\r\nHyper parameter tuning\r\n‚Ä¢ When training an ML model, there are several parameters that need to be \r\ntuned. \r\n‚Ä¢ E.g., in SVM we have the Regularization parameter C, the kernel function, \r\nthe degree of the kernel function, and depending on the case, many other. \r\n‚Ä¢ The common approach revolves around grid search.', '‚Ä¢ Groundbreaking AI research is mostly done by tech giants.\r\n7\r\n\r\nA few examples of Red AI\r\n‚Ä¢ Google‚Äôs BERT-large \r\n‚Ä¢ 350 million features \r\n‚Ä¢ Trained for 2.5 days using 512 TPU chips, costing $60K+ \r\n‚Ä¢ Open-GPT3 (now GPT-4/o1) \r\n‚Ä¢ 550 tonnes CO2-eq (Patterson, 2021) \r\n‚Ä¢ 175 billion features \r\n‚Ä¢ API is open but no-pretrained model is available \r\n‚Ä¢ AlphaGo \r\n‚Ä¢ 1920 CPUs, 280 GPUs, costing $35M\r\n8\r\n\r\nRed AI in Large Language Models (LLMs)\r\n‚Ä¢ OPT by Meta reports 75 tons CO2-eq (1/7 of OpenGPT‚Äôs footprint).\u2028\r\n(Also 175billion params) \r\n‚Ä¢ However, Llama 3 reported 2,290 tons of CO2-eq (7.7M GPU hours \r\ntraining ) \r\n‚Ä¢ Open science: release includes both the pretrained models and the code \r\nneeded to train and use them. \r\n‚Ä¢ DeepSeek-V3 claims ‚Äúonly‚Äù 2.78M GPU hours \r\n‚Ä¢ Bloom by Huggingface reports 25 tons, 51 when considering embodied \r\nand operational carbon footprint. (176billion params)\r\n9\r\n\r\nRed AI\r\nAccuracy: 0.999999999\r\nGreen AI\r\n‚Ä¢ Energy \r\n‚Ä¢ Time \r\n‚Ä¢ Reproducibility \r\n‚Ä¢ Reusage\r\n\r\nHow can we adopt Green AI\r\n‚Ä¢ Check whether AI is needed. \r\n‚Ä¢ Select green datacenters. \r\n‚Ä¢ Run on low carbon intensity hours. \r\n‚Ä¢ Opt for GPU-optimised solutions (?) \r\n‚Ä¢ Opt for low-power hardware (e.g., Nvidia Jetson boards) \r\n‚Ä¢ Or GPUs that provide energy metrics (e.g., NVIDIA GPUs via the nvidia-smi tool) \r\n‚Ä¢ Report energy/carbon metrics (e.g., embed in MLFlow?) \r\n‚Ä¢ Use pre-trained models (Transfer Learning) \r\n‚Ä¢ Preprocess dataset to reduce size. \r\n‚Ä¢ Improve parameter-tuning strategy.\r\n11\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ We need benchmarks. \r\n‚Ä¢ AllenAI leaderboard\u2028\r\nhttps://leaderboard.allenai.org \r\n‚Ä¢ No carbon metrics, yet \r\n‚Ä¢ Report comparable proxies for energy \r\nconsumption. \r\n‚Ä¢ ‚ö† Learning algorithms behave in a non-\r\ndeterministic \r\n‚Ä¢ ‚ö† Different data-points lead to different \r\nenergy consumption\r\n12\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ Reporting measured energy consumption \r\n‚Ä¢ + Accurate \r\n‚Ä¢ + Easy to map to carbon emissions \r\n‚Ä¢ - Hard to measure \r\n‚Ä¢ - Low replicability \r\n‚Ä¢ Reporting time / estimation based on time & hardware \r\n‚Ä¢ + Easy to measure \r\n‚Ä¢ + Correlates with energy consumption in most cases. \r\n‚Ä¢ -  Difficult to compare with measurements from other setups \r\n‚Ä¢ E.g., floating point operations (FPOs) (?) \r\n‚Ä¢ + comparable across different setups \r\n‚Ä¢ + cheap \r\n‚Ä¢ - does not factor in memory energy consumption \r\n‚Ä¢ - does not reflect carbon emissions\r\n13\r\n\r\nData-centric AI\r\n\r\nData-centric AI\r\n‚Ä¢ Emerging discipline that deals with systematically engineering data to build AI \r\nsystems. \r\n‚Ä¢ Shift from improving the training strategy to improving the data. \r\n‚Ä¢ It is better to have small but reliable datasets than large but noisy \r\ndatasets. \r\n‚Ä¢ => Improve data collection, data labelling, and data preprocessing. \r\n‚Ä¢ More about data-centric AI by Andrew Ng:\u2028\r\nhttps://www.youtube.com/watch?v=06-AZXmwHjo\r\n15\r\n\r\n\r\nGreen Data-centric AI\r\n‚Ä¢ How do different ML algorithms compare \r\nin terms of energy consumption? \r\n‚Ä¢ How does number of rows relate to the \r\nenergy consumption of ML models? \r\n‚Ä¢ How does number of features relate to \r\nthe energy consumption of ML models? \r\n‚Ä¢ What is the impact of reducing data in the \r\nperformance of the model?', ""‚Ä¢ 6 machine learning algorithms: SVM, Decision Tree, KNN, Random Forrest, \r\nAdaBoost, Bagging Classifier. \r\n‚Ä¢ Reduce the number of rows. 10%, 20%, .., 100% \r\n‚Ä¢ Stratified random sampling (?) \r\n‚Ä¢ Reduce the number of features. 10%, 20%, .., 100% \r\n‚Ä¢ Feature importance metric based on the Chi-Square Test (Chi2) \r\n‚Ä¢ Estimate energy consumption using a RAPL-based tool. (?)\r\n18\r\n\r\n‚Ä¢ Repeat 30 times \r\n‚Ä¢ Fix random seeds \r\n‚Ä¢ ‚Ä¶ \r\n‚Ä¢ Data was not Normal => tailed Normal distribution.\r\n19\r\n(?)\r\n\r\nResults: energy consumption of algorithms\r\n\r\nResults: energy vs data shape\r\n\r\nResults: performance vs data shape\r\n\r\nDiscussion\r\n‚Ä¢ Other data properties should be investigated. \r\n‚Ä¢ E.g., data types \r\n‚Ä¢ Reporting energy data is essential. It can lead to different model selection \r\nwithout hindering model performance. \r\n‚Ä¢ There is a big opportunity in Model and Data Simplification.\r\n23\r\n\r\nData/Model Simplification\r\n‚Ä¢ (?) \r\n‚Ä¢ Data selection \r\n‚Ä¢ Data quantisation. Posit? \r\n‚Ä¢ Data distillation \r\n‚Ä¢ Coreset extraction (?) \r\n‚Ä¢ Model distillation \r\n‚Ä¢ Model quantisation \r\n‚Ä¢ Model pruning \r\n‚Ä¢ ‚Ä¶\r\n24\r\n\r\nPosit vs Float\r\nMore about this: https://spectrum.ieee.org/floating-point-numbers-posits-processor\r\nBetter for DL use cases\r\n\r\nHow can we tune \r\nlearning \r\nparameters \r\nefficiently?\r\n\r\nHyper parameter tuning\r\n‚Ä¢ When training an ML model, there are several parameters that need to be \r\ntuned. \r\n‚Ä¢ E.g., in SVM we have the Regularization parameter C, the kernel function, \r\nthe degree of the kernel function, and depending on the case, many other. \r\n‚Ä¢ The common approach revolves around grid search. The user provides a \r\nsequence of possible values for each parameter and the pipeline runs all \r\npossible combinations. \r\n‚Ä¢ Our question: Can we save energy with alternative approaches? \r\n‚Ä¢ We studied Grid Search, Random Search and Bayesian \r\nOptimisation.\r\n27\r\nTim's MSc Thesis, 2022 \r\nAccepted at CAIN‚Äô23\r\n\r\n\r\nResults\r\n29\r\nConclusions? \r\n‚Ä¢ Bayesian converges faster. \r\n‚Ä¢ No clear winner between Grid and Random\r\n\r\nDeepSeekMoE\r\n30\r\nPreprint at ArXiv, 2024 https://arxiv.org/pdf/\r\n2401.06066\r\n\r\nMixture of Experts\r\n‚Ä¢ Llama3.1 has 405B parameters, DeepSeek V3 671B \r\n‚Ä¢ Yet DeepSeek has quicker inference times and claims less energy \r\nconsumption (?) \r\n‚Ä¢ Divide the model into smaller blocks of experts \r\n‚Ä¢ Tokens get routed to certain experts based on the query \r\n‚Ä¢ Only part of the network is active during inference \r\n‚Ä¢ DeepSeek claims only 37B out of 671B parameters get active\r\n31\r\n\r\nDeepSeekMoE\r\n32\r\n\r\nDeepSeekMoE\r\n33\r\n‚Ä¢ Comparable performance to \r\nLLaMA2 7B effectively using \r\nless half the parameters \r\n‚Ä¢ Less computational power \r\n‚Ä¢ Problems (?) \r\n‚Ä¢ Still need to load all the \r\nparameters \r\n‚Ä¢ High memory -> high \r\nembodied carbon\r\n\r\nGreen AI at FacebookMeta\r\n34\r\nSustainable AI: Environmental Implications, \r\nChallenges and Opportunities (2022)\r\n\r\nCarbon footprint mapped to the AI lifecycle\r\n‚Ä¢ There are 4 main overarching stages where carbon emissions need to be isolated: data \r\ncollection, experimentation, training, inference. \r\n‚Ä¢ At Facebook, recommendation systems split energy consumption evenly between \r\ntraining and inference; text translation models have a 35%/65% split. (Operational cost) \r\n‚Ä¢ Operational/embodied cost split: 30%/70%\r\n35\r\n\r\nOpen issues according to Meta\r\n‚Ä¢ A vast portion of projects only use GPUs at 30%.\u2028\r\nShould be higher to attenuate embodied carbon."", '5. Green Software Metrics\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nLu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\nCarolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl\r\nSustainableSE 2025\r\n\r\nBitcoin example\r\n‚Ä¢ 1 bitcoin transaction is equivalent to more than 1.5 million VISA transactions. \r\n \r\n   \r\n \r\n‚Ä¢ Day-to-day metrics are easy to grasp \r\n‚Ä¢ If we say 8 gigajoules, it‚Äôs a bit more difficult to understand. \r\n‚Ä¢ These numbers keep changing (check it here: https://www.statista.com/\r\nstatistics/881541/bitcoin-energy-consumption-transaction-comparison-visa/)\r\n2\r\n\r\n3\r\n\r\n(Electrical) Energy\r\n‚Ä¢ Work required to move charged particles. \r\n‚Ä¢ Same concept but different perspective when talking about thermal, \r\nmechanical, or nuclear energy. \r\n‚Ä¢ Most common units: \r\n‚Ä¢ joule (J) -  recommended; scientific communications; metric from the \r\nInternational System of Units \r\n‚Ä¢ kilowatt-hour (kWh) - more common, e.g., used for household electricity \r\nconsumption\r\n4\r\n+q\r\n-q\r\nF\r\nF\r\n\r\nPower\r\n‚Ä¢ Amount of work being done per unit of time. \r\n‚Ä¢ Commonly measured in watts (W).\r\n5\r\n\r\n‚à´\r\ntf=9\r\nti=1\r\nP(t)dt\r\n\r\n‚à´\r\ntf=9\r\nti=1\r\nP(t)dt\r\n\r\nA = a + b\r\n2\r\nh\r\nMeasured Energy \r\nConsumption\r\n=\r\nPtn + Ptn+1\r\n2\r\n‚ãÖŒît = 3.5W + 2.0W\r\n2\r\n‚ãÖ1s = 2.75J\r\nA = ?\r\na\r\nb\r\nh\r\n\r\n‚à´\r\ntn\r\nt0\r\nP(t)dt ‚âàŒît\r\n2 [P(t0) + 2P(t1) + 2P(t2) + . . . + 2P(tn‚àí1) + P(tn)]\r\nMeasured Energy \r\nConsumption\r\n‚ö† Sometimes you cannot assume that the sampling interval (\r\n) is always the same. ‚ö†\r\nŒît\r\nTrapezoid Rule\r\n\r\nTrapezoid Rule in Python\r\nimport numpy as np \r\nenergy_consumption = np.trapz(power_sample, timestamps) \r\n\r\nAverage power\r\n‚Ä¢ Easy to convert to energy consumption \r\n‚Ä¢ Simply multiply by the elapsed time. \r\n‚Ä¢ (This is another reason to always collect time data along with energy \r\nmetrics.)\r\n11\r\nEnergy = Pavg¬∑Œît\r\n\r\nPower or Energy?\r\n‚Ä¢ Average power consumption makes sense when we report the \r\nconsumption of a continuous use case. E.g., reading an ebook in your \r\ncomputer. \r\n‚Ä¢ Energy consumption makes sense in one-off use cases. E.g., energy \r\nconsumption of a bitcoin transaction. \r\n‚ö†\r\n\r\nLearning activity\r\n‚Ä¢ Pair up with one colleague and discuss potential software use cases where \r\none should test energy efficiency. \r\n‚Ä¢ Choose one use case where energy consumption is the best metric to \r\ndiscuss/test energy efficiency. \r\n‚Ä¢ Choose one use case where average power consumption is the best \r\nmetric to discuss/test energy efficiency.\r\n13\r\n\r\nEnergy Delay Product (EDP)\r\n‚Ä¢ In some cases, to achieve less energy consumption, one simply runs the \r\nsoftware on a low power mode of the CPU. \r\n‚Ä¢ E.g., setting the CPU at a low frequency will make execution slow but more \r\nenergy-efficient. \r\n‚Ä¢ Energy consumption metric that penalizes slow runs \r\n \r\n \r\n‚Ä¢ Gives more importance to application runtime, with the goal of making both \r\nlow energy and fast runtime applications.', '‚Ä¢ Deadline April 4.\r\n6\r\n\r\nStrategy\r\n‚Ä¢ Week 0 \r\n‚Ä¢ Decide project idea (today) \r\n‚Ä¢ Define steering meeting schedule \r\n‚Ä¢ Create working document of the \r\narticle: Problem statement and solution \r\nproposal! \r\n‚Ä¢ Define and assign tasks for each week. \r\n‚Ä¢ Week 1 \r\n‚Ä¢ Implementation \r\n‚Ä¢ Agreements with supervisor. \r\n‚Ä¢ Week 2 \r\n‚Ä¢ Implementation \r\n‚Ä¢ Week 3 \r\n‚Ä¢ Implementation, Full draft of article, \r\ndissemination. \r\n‚Ä¢ Week 4 \r\n‚Ä¢ Final refinements \r\n‚Ä¢ Prepare presentation\r\n7\r\n\r\nProject ideas\r\n‚Ä¢ A1. Prototype cross-machine comparable benchmarks \r\n‚Ä¢ A2. Add energy metrics to LMstudio/Ollama \r\n‚Ä¢ A3. Visualizations built-in with EnergiBridge \r\n‚Ä¢ A4. Service-based version of EnergiBridge\r\n\r\nProject ideas\r\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \r\n‚Ä¢ B2. Study test generation energy consumption \r\n‚Ä¢ B3. Energy profiling of static analysis tools \r\n‚Ä¢ B4. Detailed energy profiling of build pipelines \r\n‚Ä¢ B5. Tool supporting SusAF workshop / process \r\n‚Ä¢ B6. Dataset of government-developed OS software \r\n‚Ä¢ B7. Queue - but better for the student / TA society\r\nQuality Assurance & Testing\r\nSocial & Individual \u2028\r\nSustainability\r\n\r\nProject ideas\r\n‚Ä¢ C1. Compare energy consumption of docker images for ML workloads. \r\n‚Ä¢ C2. Create a plugin to visualize Hugging Face carbon emissions in detail. \r\n‚Ä¢ C3. Plugin for ChatGPT (footprint per chat window) \r\n‚Ä¢ C4. NutriScore for software libraries. \r\n‚Ä¢ C5. Add energy-awareness to existing software \r\n‚Ä¢ C6. Green Shift Left \r\n‚Ä¢ C7. Education for Sustainable SE\r\n\r\nA1. Prototype cross-machine comparable benchmarks\r\n‚Ä¢ Energy-usage comparisons require running both baseline + software on the \r\nsame machine ‚Üí limits how extensive our experiments can be \r\n‚Ä¢ Research community is in need of benchmarks that make energy \r\nmeasurements comparable even if executed on different machines \r\n‚Ä¢ Focus on a single task or model (i.e. computing vision, classification)\r\n\r\nA2. Adding energy metrics to LMstudio/Ollama\r\n‚Ä¢ Make energy consumption visible to users \r\nwithin local chat-interface for LLMs \r\n‚Ä¢ LMstudio/Ollama are tools for easy \r\ndeployment of LLMs \r\n‚Ä¢ Do not show energy metrics \r\n‚Ä¢ Add energy metrics to LMstudio-python \r\nor Ollama\r\nhttps://lmstudio.ai/\r\n\r\nA3. Visualizations built-in with EnergiBridge\r\n‚Ä¢ EnergiBridge simplifies energy measurement, but analysis & visualization is \r\nstill left to the user \r\n‚Ä¢ Extend the tool with well-chosen visualizations and analyses directly from the \r\nprovided data\r\n\r\nA4. Service-based version of EnergiBridge\r\n‚Ä¢ Simplify interaction & setup with EnergiBridge \r\n‚Ä¢ Service that runs independently, start/stop signals over RPC to manage \r\nexperiments \r\n‚Ä¢ Potential: create EnergiBridge interface for other prog. lang\r\n\r\nB1. Measure energy consumption of single JUnit tests\r\n‚Ä¢ We‚Äôd like to identify energy anti patterns in unit tests \r\n‚Ä¢ As a first step, we need tooling to measure and compare the energy \r\nconsumption of single unit tests \r\n‚Ä¢ Ideally including preliminary analysis looking at potential reasons for high-\r\nenergy-consuming tests\r\n\r\nB2. Study test generation energy consumption\r\n‚Ä¢ Automatic test generation mainly focuses on making strong test suites \r\n‚Ä¢ Do different techniques and configurations impact the energy consumption \r\nduring generation? \r\n‚Ä¢ Preferably focus on non-LLM test generation methods (EvoSuite, Pyguin, \r\nDSpot)\r\n\r\nB3. Detailed energy profiling of build pipelines\r\n‚Ä¢ Automatic builds have become a cornerstone of quality assurance.', 'google.com/view/energy-efficiency-languages\r\n21\r\nAna Radovanovic ÃÅ, Ross Koningstein, Ian Schneider, Bokan \r\nChen, Alexandre Duarte, Binz Roy, Diyue Xiao, Maya \r\nHaridasan, Patrick Hung, Nick Care, Saurav Talukdar, Eric \r\nMullen, Kendal Smith, MariEllen Cottman, and Walfredo Cirne \r\n\r\n\r\n‚Ä¢ Google‚Äôs Carbon-Intelligent Computing System (CICS) \r\n‚Ä¢ Main idea: use carbon-intensity data to shift datacenter jobs in time \r\n‚Ä¢ Typically, job schedulers use a metric of cluster capacity to schedule a job in \r\na particular cluster. \r\n‚Ä¢ CICS overrides this metric with the virtual capacity curve (VCC) that \r\nfactors in Carbon intensity \r\n‚Ä¢ When a new job comes in, the scheduler estimates its CPU load and power \r\nusage and assigns it to a cluster if the VCC is not exceeded.\r\n23\r\n\r\n‚Ä¢ Jobs are divided between flexible and inflexible. \r\n‚Ä¢ Flexible load is considered shapeable/shiftable as long as its total daily \r\ncompute (CPU) demand is preserved \r\n‚Ä¢ The system needs to consider that, while running a job, the virtual capacity \r\ncurve (VCC) might drop. Hence, this job should not start in the first place. \r\n‚Ä¢ They forecast VCC for the next day\r\n24\r\n\r\n\r\nVirtual Cluster Capacity (VCC)\r\n‚Ä¢ Aims at reducing the peak load at carbon intensive hours but in total it should allow for the \r\nsome amount of daily computation! \r\n‚Ä¢ Considers Carbon intensity \r\n‚Ä¢ Using data from electricityMap.org \r\n‚Ä¢ It does not use carbon intensity directly.\u2028\r\nCarbon intensity is converted to a cost (kgCO2 -> $$) \r\n‚Ä¢ This way, they can factor in other metrics that can also be converted to money. E.g., the \r\ncost saved by preventing peak load \r\n‚Ä¢ Peak workload entails extra cost at the infrastructure level (e.g., control faclities‚Äô \r\ntemperature). \r\n‚Ä¢ By using money cost instead of carbon cost, they have more data available.\r\n26\r\n\r\nVirtual Cluster Capacity (VCC)\r\n‚Ä¢ If the forecast of VCC fails it shift flexible workload more than expected.  \r\n‚Ä¢ This happens because the amount of workload forecasted was below the \r\nworkload needed, and VCC was ‚Äúaggressively‚Äù low. \r\n‚Ä¢ The systems fall back to the real cluster capacity for 1 week until results \r\nstart being realistic again.\r\n27\r\n\r\nNext steps\r\n‚Ä¢ They will consider spatial flexibility. \r\n‚Ä¢ I.e., tasks that can be shifted over time and over space. \r\n‚Ä¢ It needs to factor in relocation overheads, though.\r\n28\r\n\r\nCritical questions\r\n‚Ä¢ Who defines what is flexible and inflexible? \r\n‚Ä¢ How do you estimate the CPU load of a given task?\r\n29\r\n\r\nEnergy Regression Testing\r\n‚ÜíEnergy?\r\nGreener? Greener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\n\r\nE-compare\r\nGithub Actions\r\n‚ûú https://koenhagen.github.io/E-Compare/\r\n\r\nEnergy Regression Testing \r\n\r\n4. Debugging Energy with \r\nDocker Images\r\n\r\nUnveiling the Energy Vampires \r\nA methodology for debugging Software \r\nEnergy Consumption\r\n ‚úÖ ICSE 2025\r\n\r\nData Centers and Docker\r\n‚Ä¢ Containers are the most popular way to deploy apps into the cloud \r\n‚Ä¢ Base image is an important choice when building an image \r\n‚Ä¢ Criteria \r\n‚Ä¢ Linux distribution and binaries \r\n‚Ä¢ Image size \r\n‚Ä¢ Energy?\r\n35\r\n\r\nRedis energy consumption\r\n‚Ä¢ Ubuntu/Alpine base images have different energy consumption for Redis\r\n36\r\n\r\nRedis Energy Consumption\r\n‚Ä¢RQ1: What is the difference \r\nin energy consumption \r\nbetween glibc and musl? \r\n‚Ä¢RQ2: Can we use tracing \r\nto compare energy \r\nconsumption in shared \r\nlibraries?', '‚Ä¢ By using money cost instead of carbon cost, they have more data available.\r\n26\r\n\r\nVirtual Cluster Capacity (VCC)\r\n‚Ä¢ If the forecast of VCC fails it shift flexible workload more than expected.  \r\n‚Ä¢ This happens because the amount of workload forecasted was below the \r\nworkload needed, and VCC was ‚Äúaggressively‚Äù low. \r\n‚Ä¢ The systems fall back to the real cluster capacity for 1 week until results \r\nstart being realistic again.\r\n27\r\n\r\nNext steps\r\n‚Ä¢ They will consider spatial flexibility. \r\n‚Ä¢ I.e., tasks that can be shifted over time and over space. \r\n‚Ä¢ It needs to factor in relocation overheads, though.\r\n28\r\n\r\nCritical questions\r\n‚Ä¢ Who defines what is flexible and inflexible? \r\n‚Ä¢ How do you estimate the CPU load of a given task?\r\n29\r\n\r\nEnergy Regression Testing\r\n‚ÜíEnergy?\r\nGreener? Greener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\n\r\nE-compare\r\nGithub Actions\r\n‚ûú https://koenhagen.github.io/E-Compare/\r\n\r\nEnergy Regression Testing \r\n\r\n4. Debugging Energy with \r\nDocker Images\r\n\r\nUnveiling the Energy Vampires \r\nA methodology for debugging Software \r\nEnergy Consumption\r\n ‚úÖ ICSE 2025\r\n\r\nData Centers and Docker\r\n‚Ä¢ Containers are the most popular way to deploy apps into the cloud \r\n‚Ä¢ Base image is an important choice when building an image \r\n‚Ä¢ Criteria \r\n‚Ä¢ Linux distribution and binaries \r\n‚Ä¢ Image size \r\n‚Ä¢ Energy?\r\n35\r\n\r\nRedis energy consumption\r\n‚Ä¢ Ubuntu/Alpine base images have different energy consumption for Redis\r\n36\r\n\r\nRedis Energy Consumption\r\n‚Ä¢RQ1: What is the difference \r\nin energy consumption \r\nbetween glibc and musl? \r\n‚Ä¢RQ2: Can we use tracing \r\nto compare energy \r\nconsumption in shared \r\nlibraries? \r\n‚Ä¢RQ3: Can we verify the \r\norigin of energy \r\nconsumption differences by \r\nrecreating the workload \r\nbehavior closely?\r\n37\r\n\r\nTracing\r\n‚Ä¢ Find libc function running at the end of the benchmark \r\n‚Ä¢ Tracing: Capture calls made to libc \r\n‚Ä¢ Introduces non-linear overhead\r\n38\r\n\r\nSynchronization\r\n‚Ä¢ Tracing slows down execution and increase energy consumption \r\n‚Ä¢ Run separately and synchronize with logs\r\n39\r\n\r\nTracing Analysis\r\n40\r\n\r\nTracing Analysis\r\n41\r\n\r\nBenchmarking memcpy\r\n‚Ä¢ Copy bytes from one part of memory to \r\nanother \r\n‚Ä¢ Depending on function parameters, different \r\nassembly-level optimizations \r\n‚Ä¢ Some not included in musl\r\n42\r\n\r\nBenchmarking memcpy\r\n‚Ä¢ Copy 4 bytes from fixed \r\npointer to moving pointer \r\n‚Ä¢ (100,300,500,600) x 1M \r\nrequests \r\n‚Ä¢  15% more power and 3X time\r\n43\r\n\r\nConclusions\r\n‚Ä¢ Significant difference in energy consumption for memcpy \r\n‚Ä¢ 8.6% difference for Redis workload and 13% in our benchmark \r\n‚Ä¢ musl trades performance for a smaller codebase \r\n‚Ä¢ No official documentation \r\n‚Ä¢ No awareness about energy performance\r\n44\r\n\r\n5. Energy Efficiency vs Code \r\nQuality\r\n\r\nMeasuring Maintainability\r\n‚Ä¢ According to ISO/IEC 25010, Maintainability is ‚Äúthe degree of \r\neffectiveness and efficiency with which a software product or \r\nsystem can be modified to improve it, correct it or adapt it to \r\nchanges in environment, and in requirements‚Äù \r\n‚Ä¢ We use the code analysis tool Better Code Hub to assess \r\nmaintainability \r\n‚Ä¢ Better Code Hub maps the ISO/IEC 25010 standard on \r\nmaintainability into a set of guidelines derived from static analysis\r\n46\r\n\r\nMaintainability of Energy Changes\r\n‚Ä¢ What is the impact of making energy-oriented code changes on \r\nthe maintainability of mobile apps?']","['<1-hop>\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing', '<2-hop>\n\nReading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.', '<1-hop>\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing', '<2-hop>\n\nReading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.']","Neuromorphic computing is inspired by the structure and function of the human brain and aims to emulate these characteristics in computing systems. Its practical applications include:

1. **Energy Efficiency**: Neuromorphic systems are designed to be highly energy-efficient, making them suitable for applications where power consumption is a critical concern. This is achieved through sparse encoding and spiking neuron models, which reduce the number of operations and energy required compared to traditional computing systems.

2. **Real-time Processing**: Neuromorphic computing excels in tasks requiring real-time processing, such as sensory perception and decision-making, due to its high temporal resolution and ability to process information with fewer neurons.

3. **Adaptive Systems**: These systems can adapt to changing environments and contexts, similar to how the human brain operates. This makes them suitable for applications in robotics, autonomous vehicles, and other adaptive technologies.

4. **Pattern Recognition**: Neuromorphic systems are particularly effective in pattern recognition tasks, such as image and sound classification, due to their ability to process information in a manner akin to biological neural networks.

The biological inspiration influences its implementation by focusing on mimicking the brain's efficiency and processing capabilities. This includes using spiking neurons that communicate via electrical pulses, similar to how neurons in the brain operate, and employing architectures that allow for parallel processing and learning from sparse data inputs. These characteristics make neuromorphic computing a promising approach for developing more efficient and adaptive computing systems.","Neuromorphic computing, inspired by the human brain, offers practical applications such as event-based vision systems and efficient processing of sensory data. Its biological inspiration influences its implementation through the use of spiking neural networks and physical artificial neurons, enabling more energy-efficient and brain-like computation methods.",0.3131313131208754,1.0,1.0,0.54,0.0,0.9524833345398135
"What are the practical applications of neuromorphic computing, and how does its biological inspiration influence its implementation?","['McCulloch-Pitts neuron [1, 2]\r\n1940s: How do biological neurons compute basic \r\nlogic functions? (e.g. logic gates)\r\nNote: Ref. [3] gives a nice brief history on the ideas which lead to the \r\nMcCulloch-Pitts neuron.\r\n\r\nWhat is a neural network?\r\n1950s: How are neurons organized to perform \r\nsensory perception?\r\n\r\nWhat is a neural network?\r\n1950s: How are neurons organized to perform \r\nsensory perception?\r\nThe first ""neural network"": Perceptron (1958). [4]\r\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\r\nFrank Rosenblatt (Psychologist)\r\nwith a Mark I Perceptron computer in 1960\r\n\r\nWhat is a neural network?\r\n1950s: How are neurons organized to perform \r\nsensory perception?\r\nThe first ""neural network"": Perceptron (1958). [4]\r\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\r\nFrank Rosenblatt (Psychologist)\r\nwith a Mark I Perceptron computer in 1960\r\nPower-efficient\r\n\r\nNeuromorphic computing\r\nWhy neuromorphic computing?\r\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\r\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\r\n\r\nNeuromorphic computing\r\nWhy neuromorphic computing?\r\n‚ÄòBiological inspiration‚Äô for artificial neural networks (ANNs) is not a new idea.\r\nEmulation (as opposed to simulation) of neural networks in hardware is not a new idea.\r\nQuestion: What can we gain from increasing biological realism in existing neural networks?\r\n\r\nPower-efficiency at scale\r\nModern, deep neural networks*\r\nare trained using GPUs.\r\n* It is estimated that ChatGPT was trained on \r\n10,000-20,000 GPUs and that it will require\r\n30,000 GPUs to keep running stably in the future.\r\n* It is estimated that ChatGPT has 10-20 billion \r\nparameters.\r\nhttps://www.anandtech.com/show/4008/nvidias-geforce-gtx-580/17\r\n\r\nPower-efficiency at scale\r\nModern, deep neural networks*\r\nare trained using GPUs.\r\n* It is estimated that ChatGPT was trained on \r\n10,000-20,000 GPUs and that it will require\r\n30,000 GPUs to keep running stably in the future.\r\n* It is estimated that ChatGPT has 10-20 billion \r\nparameters.\r\nSingle model with 20 billion parameters:\r\n200 Watts x 30,000 GPUs = 6M Watts\r\n\r\nPower-efficiency at scale\r\nhttps://hai.stanford.edu/ai-index/2024-ai-index-report\r\nTraining a single large language model can \r\ngenerate greater CO2 emissions than the \r\ntotal lifetime emissions of 8 cars (in 2020)!\r\n\r\nPower-efficiency at scale\r\nhttps://hai.stanford.edu/ai-index/2024-ai-index-report\r\nTraining a single model can consume \r\nmore than 1000 MWh of power!\r\n\r\nPower-efficiency at scale\r\nhttps://hai.stanford.edu/ai-index/2024-ai-index-report\r\nTraining a single model can consume \r\nmore than 1000 MWh of power!\r\n‚Ä¶ with energy costs reaching 200M USD!\r\n\r\nPower-efficiency at scale\r\nYour brain runs on:\r\n\r\nPower-efficiency at scale\r\nYour brain runs on:\r\nHigh estimate ~3000 kcal a day\r\n   ‚âà145 Watts\r\n* Human brain has ~600 trillion synapses \r\n(‚âàparameters).', 'Normal neuron: nin x nout multiplications,\r\n(nin‚Äì 1) x nout additions\r\nSpiking neuron: 0 multiplications, (nactive‚Äì 1) x nout \r\nadditions, with nactive ‚â§ nin\r\nEnergy consumption:\r\nEnormal = M nin nout + A (nin‚Äì 1) nout = 17.5 pJ\r\nEnergy consumption:\r\nEspiking = A (nactive‚Äì 1) nout = 2.7 pJ\r\nMultiply-accumulate (MAC) operations:\r\nSNN challenge: how to \r\ncompute with the least \r\namount of spikes!\r\n\r\nOften, we observe a \r\nsparsity (energy)-\r\ntask accuracy trade-off\r\n(Left: results for image \r\nclassification)\r\nSNN challenge: how to \r\ncompute with the least \r\namount of spikes!\r\nhttps://arxiv.org/pdf/2409.08290\r\n\r\nIn practice, energy \r\nconsumption computations \r\nare complex. \r\nNeed to take into account\r\n- memory access,\r\n- addressing,\r\n- auxiliary operations,\r\nin addition to MACs.\r\nEstimated energy consumption for 3 different datasets (CIFAR10, GSC, NCARS; image, sound \r\nand video classification respectively). FNN‚Äôs are conventional feed-forward neural networks.\r\nIn this example: SNNs are 6 to 8 times more energy efficient than FNNs.\r\nhttps://arxiv.org/pdf/2210.13107\r\nComputing energy consumption\r\n\r\nIn practice, energy \r\nconsumption computations \r\nare complex. \r\nNeed to take into account\r\n- memory access,\r\n- addressing,\r\n- auxiliary operations,\r\nin addition to MACs.\r\nEstimated energy consumption for 3 different datasets (CIFAR10, GSC, NCARS; image, sound \r\nand video classification respectively). FNN‚Äôs are conventional feed-forward neural networks.\r\nIn this example: SNNs are 6 to 8 times more energy efficient than FNNs.\r\nComputing energy consumption\r\nQuestions?\r\n\r\nReading materials\r\nMain reading:\r\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \r\nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\r\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\r\n- Neuromorphic computing:\r\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \r\nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\r\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \r\noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\r\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019.', 'Different encoding strategies with spiking neurons\r\n\r\nDifferent encoding strategies with spiking neurons\r\nUsing latency or spatio-temporal codes\r\nour encoding is faster and more spike-efficient (sparser)!\r\n\r\nDifferent encoding strategies with spiking neurons\r\nUsing latency or spatio-temporal codes\r\nour encoding is faster and more spike-efficient (sparser)!\r\nQuestions?\r\n\r\nNeuromorphic computing\r\nWhat is the advantage for applications?\r\n-\r\nLess spikes = less energy consumption in specialized neuromorphic hardware\r\n(e.g. Intel Loihi [12])\r\nBrains are energy efficient: \r\n2. Sparse encoding\r\n\r\nMultiply-accumulate (MAC) operations:\r\nNormal neuron: Multiplies input with \r\nweights, then adds.\r\nSpiking neuron: Consider binary input (e.g. input currents are piecewise \r\nconstant and assume values {0,1}). There is no multiplication, only addition.\r\n\r\nAssume one multiplier and one adder circuit uses M and A energy respectively with AÔπ§M\r\n(e.g., for a 45nm CMOS process, standard energy usage is A = 0.9 pJ and M = 3.7 pJ).\r\nNormal neuron: nin x nout multiplications,\r\n(nin‚Äì 1) x nout additions\r\nSpiking neuron: 0 multiplications, (nactive‚Äì 1) x nout \r\nadditions, with nactive ‚â§ nin\r\nEnergy consumption:\r\nEnormal = M nin nout + A (nin‚Äì 1) nout = 17.5 pJ\r\nEnergy consumption:\r\nEspiking = A (nactive‚Äì 1) nout = 2.7 pJ\r\nMultiply-accumulate (MAC) operations:\r\n\r\nAssume one multiplier and one adder circuit uses M and A energy respectively with AÔπ§M\r\n(e.g., for a 45nm CMOS process, standard energy usage is A = 0.9 pJ and M = 3.7 pJ).\r\nNormal neuron: nin x nout multiplications,\r\n(nin‚Äì 1) x nout additions\r\nSpiking neuron: 0 multiplications, (nactive‚Äì 1) x nout \r\nadditions, with nactive ‚â§ nin\r\nEnergy consumption:\r\nEnormal = M nin nout + A (nin‚Äì 1) nout = 17.5 pJ\r\nEnergy consumption:\r\nEspiking = A (nactive‚Äì 1) nout = 2.7 pJ\r\nMultiply-accumulate (MAC) operations:\r\nSNN challenge: how to \r\ncompute with the least \r\namount of spikes!\r\n\r\nOften, we observe a \r\nsparsity (energy)-\r\ntask accuracy trade-off\r\n(Left: results for image \r\nclassification)\r\nSNN challenge: how to \r\ncompute with the least \r\namount of spikes!\r\nhttps://arxiv.org/pdf/2409.08290\r\n\r\nIn practice, energy \r\nconsumption computations \r\nare complex. \r\nNeed to take into account\r\n- memory access,\r\n- addressing,\r\n- auxiliary operations,\r\nin addition to MACs.\r\nEstimated energy consumption for 3 different datasets (CIFAR10, GSC, NCARS; image, sound \r\nand video classification respectively). FNN‚Äôs are conventional feed-forward neural networks.\r\nIn this example: SNNs are 6 to 8 times more energy efficient than FNNs.\r\nhttps://arxiv.org/pdf/2210.13107\r\nComputing energy consumption\r\n\r\nIn practice, energy \r\nconsumption computations \r\nare complex. \r\nNeed to take into account\r\n- memory access,\r\n- addressing,\r\n- auxiliary operations,\r\nin addition to MACs.\r\nEstimated energy consumption for 3 different datasets (CIFAR10, GSC, NCARS; image, sound \r\nand video classification respectively). FNN‚Äôs are conventional feed-forward neural networks.\r\nIn this example: SNNs are 6 to 8 times more energy efficient than FNNs.', ""- Higher firing rate (spikes per unit time) for \r\n'selected' feature.\r\nAdapted from Hubel & Wiesel, 1959\r\n\r\nFiring rates\r\nClassical view of the brain:\r\n- Each neuron is selective for one specific \r\nfeature in the input.\r\n- Higher firing rate (spikes per unit time) for \r\n'selected' feature.\r\n- Link to modern ANNs: The scalar output of \r\nan artificial neuron is interpreted as the firing \r\nrate.\r\nAdapted from Hubel & Wiesel, 1959\r\n\r\nFiring rates\r\nClassical view of the brain:\r\n- Each neuron is selective for one specific \r\nfeature in the input.\r\n- Higher firing rate (spikes per unit time) for \r\n'selected' feature.\r\n- Link to modern ANNs: The scalar output of \r\nan artificial neuron is interpreted as the firing \r\nrate.\r\nAdapted from Hubel & Wiesel, 1959\r\nBut rate coding is inefficient and slow‚Ä¶\r\n(i.e. each neuron needs to fire many spikes to get good precision)\r\nboth in vivo and in silico.\r\n\r\nDifferent encoding strategies with spiking neurons [8]\r\n7 neurons\r\n7 time bins\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nn\r\n6\r\n(in the general \r\ncase a \r\nnumber \r\nbetween 0-7)\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nn\r\nTotal spike \r\ncount can \r\nencode 3 bits.\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nIndividual rates \r\ncan encode 7 \r\nbits.\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nLatency can \r\nencode ~3*7 or \r\n~19 bits.\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nRank order can \r\nencode ~12 bits.\r\n\r\nDifferent encoding strategies with spiking neurons\r\n\r\nDifferent encoding strategies with spiking neurons\r\nUsing latency or spatio-temporal codes\r\nour encoding is faster and more spike-efficient (sparser)!\r\n\r\nDifferent encoding strategies with spiking neurons\r\nUsing latency or spatio-temporal codes\r\nour encoding is faster and more spike-efficient (sparser)!\r\nQuestions?\r\n\r\nNeuromorphic computing\r\nWhat is the advantage for applications?\r\n-\r\nLess spikes = less energy consumption in specialized neuromorphic hardware\r\n(e.g. Intel Loihi [12])\r\nBrains are energy efficient: \r\n2. Sparse encoding\r\n\r\nMultiply-accumulate (MAC) operations:\r\nNormal neuron: Multiplies input with \r\nweights, then adds.\r\nSpiking neuron: Consider binary input (e.g. input currents are piecewise \r\nconstant and assume values {0,1}). There is no multiplication, only addition.\r\n\r\nAssume one multiplier and one adder circuit uses M and A energy respectively with AÔπ§M\r\n(e.g., for a 45nm CMOS process, standard energy usage is A = 0.9 pJ and M = 3.7 pJ).\r\nNormal neuron: nin x nout multiplications,\r\n(nin‚Äì 1) x nout additions\r\nSpiking neuron: 0 multiplications, (nactive‚Äì 1) x nout \r\nadditions, with nactive ‚â§ nin\r\nEnergy consumption:\r\nEnormal = M nin nout + A (nin‚Äì 1) nout = 17.5 pJ\r\nEnergy consumption:\r\nEspiking = A (nactive‚Äì 1) nout = 2.7 pJ\r\nMultiply-accumulate (MAC) operations:\r\n\r\nAssume one multiplier and one adder circuit uses M and A energy respectively with AÔπ§M\r\n(e.g., for a 45nm CMOS process, standard energy usage is A = 0.9 pJ and M = 3.7 pJ)."", 'Neuromorphic computing\r\nCS4575\r\nSustainable Software Engineering\r\n05.03.2025\r\nNergis T√∂men\r\n\r\nIntroduction\r\nComputer Vision Lab\r\nBiomorphic Intelligence Lab\r\nBiomedical Intervention Optimisation Lab\r\nNergis\r\n\r\nNeuromorphic computing\r\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\r\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\r\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing\r\n\r\nHow many of you are familiar \r\nwith neural networks?\r\n\r\nSimple model of an artificial neuron\r\nhttps://medium.com/@cprasenjit32/perceptron-a-simple-yet-mighty-machine-learning-algorithm-9ff6b7d86a71\r\n\r\nWhat is a neural network?\r\nhttps://www.tibco.com/reference-center/what-is-a-neural-network\r\n\r\nWhy is it called a \'neural network\'?\r\nhttps://www.tibco.com/reference-center/what-is-a-neural-network\r\n\r\nWhat is a neural network?\r\nWhy is it called a \'neural network\'?\r\nMcCulloch-Pitts neuron [1, 2] (1943)\r\nWarren Sturgis McCulloch\r\n(Neurophysiologist)\r\nWalter Pitts\r\n(Logician)\r\n\r\nHow do biological neurons work?\r\nhttps://commons.wikimedia.org/wiki/File:Coincidence_detection_in_dendrites_of_pyramidal_neurons.gif\r\n\'Input current\' travels down the dendrites (top),\r\nget integrated (summed!) in the cell body\r\nwhich generates an \'output current\' (bottom)\r\nwhich is chemically transmitted to the dendrites of \r\nother neurons.\r\n\r\nSimplified picture\r\nReal neuron\r\nArtificial neuron\r\nhttps://vajiramandravi.com/quest-upsc-notes/artificial-neural-network/\r\n\r\nWhat is a neural network?\r\nMcCulloch-Pitts neuron [1, 2]\r\n1940s: How do biological neurons compute basic \r\nlogic functions? (e.g. logic gates)\r\nNote: Ref. [3] gives a nice brief history on the ideas which lead to the \r\nMcCulloch-Pitts neuron.\r\n\r\nWhat is a neural network?\r\n1950s: How are neurons organized to perform \r\nsensory perception?\r\n\r\nWhat is a neural network?\r\n1950s: How are neurons organized to perform \r\nsensory perception?\r\nThe first ""neural network"": Perceptron (1958). [4]\r\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\r\nFrank Rosenblatt (Psychologist)\r\nwith a Mark I Perceptron computer in 1960\r\n\r\nWhat is a neural network?\r\n1950s: How are neurons organized to perform \r\nsensory perception?\r\nThe first ""neural network"": Perceptron (1958). [4]\r\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\r\nFrank Rosenblatt (Psychologist)\r\nwith a Mark I Perceptron computer in 1960\r\nPower-efficient\r\n\r\nNeuromorphic computing\r\nWhy neuromorphic computing?\r\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\r\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\r\n\r\nNeuromorphic computing\r\nWhy neuromorphic computing?\r\n‚ÄòBiological inspiration‚Äô for artificial neural networks (ANNs) is not a new idea.\r\nEmulation (as opposed to simulation) of neural networks in hardware is not a new idea.', ""Oversimplification\r\nThere are also multiple other advantages‚Ä¶\r\n\r\nHuman vs. computer computation\r\n- Fast real-time decision making, e.g. sports, e-sports\r\n- Adaptive, e.g. context-aware and employs selective attention\r\n- Energy efficient: Close to 100 billion neurons in the brain\r\n- Robust, for example to changes in illumination or obstructions in object tracking\r\n\r\nHuman vs. computer computation\r\nBrains are energy efficient: Why?\r\n1.\r\nHigh temporal resolution (more computation with less neurons)\r\n2.\r\nSparse encoding\r\n\r\nHuman vs. computer computation\r\nQuestions?\r\nBrains are energy efficient: Why?\r\n1.\r\nHigh temporal resolution (more computation with less neurons)\r\n2.\r\nSparse encoding\r\n\r\nHow do biological neurons communicate?\r\nAnalogy to artificial neural networks\r\nReal neuron\r\nArtificial neuron\r\nCurrent\r\n\r\nHow do biological neurons communicate?\r\nHow does the electrical activity propagate?\r\n?\r\nCurrent\r\n\r\nHow do biological neurons work?\r\ntime\r\nelectrode\r\nhttps://tinmard.github.io/spike-sorting-animation.html\r\nQuick electrical pulses trigger chemical signals for the next neuron ‚Üí Spikes\r\n\r\nHow do biological neurons work?\r\nQuick electrical pulses trigger chemical signals for the next neuron ‚Üí Spikes\r\nhttps://tinmard.github.io/spike-sorting-animation.html\r\ntime\r\nelectrode\r\nFrom CS perspective:\r\nSparse binary \r\nencoding\r\n\r\nBiologically realistic spiking neuron models\r\nBiologically realistic neuron models have \r\na new dimension: Time!\r\nSpiking neural networks (SNNs):\r\nThe input x  (t  ) to each neuron is summed \r\n(integrated) over time.\r\nscalar\r\nfunction of \r\ntime\r\n(t)\r\n(t)\r\nhttps://www.mdpi.com/2076-3425/12/7/863\r\n\r\nHow to model spiking neurons?\r\nANN: Perceptron, threshold activation function:\r\n\r\nHow to model spiking neurons?\r\nANN: Perceptron, threshold activation function:\r\n\r\nHow to model spiking neurons?\r\nSpiking neural network (SNN): The 'input current' Œµ(t) is integrated over time.\r\nspike\r\n\r\nHow to model spiking neurons?\r\nEquivalence to perceptron: Computation at least as complex as a perceptron.\r\n\r\nNon-leaky integrate-and-fire (IF) neuron\r\nThe temporal profile of the input current Œµ(t) can be chosen differently, for different computations.\r\n\r\nQuestions?\r\n\r\nComputation with spiking neurons\r\nCoincidence detection\r\n\r\nComputation with spiking neurons\r\nCoincidence detection\r\nx, y ‚àà {0, 1}n\r\nExample: n = 2\r\ninput = \r\nx1\r\nx2\r\ny1\r\ny2\r\n= \r\n0\r\n1\r\n1\r\n1\r\noutput? \r\n\r\nCoincidence detection\r\nComputation with spiking neurons\r\n\r\nCoincidence detection\r\nCan be trivially computed with a single spiking neuron! Requires at least n/log(n+1) hidden \r\nunits for a perceptron (proof in [7]).\r\nComputation with spiking neurons\r\n\r\nCoincidence detection\r\nCan be trivially computed with a single spiking neuron! Requires at least n/log(n+1) hidden \r\nunits for a perceptron (proof in [7]).\r\nBrains are energy efficient: \r\n1.\r\nHigh temporal resolution (more computation with less neurons)\r\nComputation with spiking neurons\r\n\r\nEncoding strategies\r\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\r\nHow should we encode information about 'features' in a large network with many spikes?\r\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\r\nElephant?\r\nhttps://www.nationalgeographic.com/anim\r\nals/mammals/facts/african-elephant\r\n\r\nFiring rates\r\nClassical view of the brain:\r\n- Each neuron is selective for one specific \r\nfeature in the input."", '9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\r\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \r\nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\r\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \r\n(not publicly available) doi:10.1037/h0042519\r\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \r\nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\r\n6) https://github.com/idsc-frazzoli/retina\r\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \r\nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\r\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \r\nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\r\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \r\nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\r\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \r\nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\r\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \r\nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\r\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\r\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\r\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \r\n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568', 'In this example: SNNs are 6 to 8 times more energy efficient than FNNs.\r\nComputing energy consumption\r\nQuestions?\r\n\r\nReading materials\r\nMain reading:\r\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \r\nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\r\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\r\n- Neuromorphic computing:\r\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \r\nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\r\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \r\noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\r\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \r\nhttps://www.nature.com/articles/s41586-019-1677-2\r\nExtra reading:\r\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \r\nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\r\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \r\nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \r\nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\r\nBasics of \'conventional\' neural networks:\r\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\r\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.\r\n\r\nReferences\r\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \r\nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\r\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947.', ""Spiking neural network (SNN): The 'input current' Œµ(t) is integrated over time.\r\nspike\r\n\r\nHow to model spiking neurons?\r\nEquivalence to perceptron: Computation at least as complex as a perceptron.\r\n\r\nNon-leaky integrate-and-fire (IF) neuron\r\nThe temporal profile of the input current Œµ(t) can be chosen differently, for different computations.\r\n\r\nQuestions?\r\n\r\nComputation with spiking neurons\r\nCoincidence detection\r\n\r\nComputation with spiking neurons\r\nCoincidence detection\r\nx, y ‚àà {0, 1}n\r\nExample: n = 2\r\ninput = \r\nx1\r\nx2\r\ny1\r\ny2\r\n= \r\n0\r\n1\r\n1\r\n1\r\noutput? \r\n\r\nCoincidence detection\r\nComputation with spiking neurons\r\n\r\nCoincidence detection\r\nCan be trivially computed with a single spiking neuron! Requires at least n/log(n+1) hidden \r\nunits for a perceptron (proof in [7]).\r\nComputation with spiking neurons\r\n\r\nCoincidence detection\r\nCan be trivially computed with a single spiking neuron! Requires at least n/log(n+1) hidden \r\nunits for a perceptron (proof in [7]).\r\nBrains are energy efficient: \r\n1.\r\nHigh temporal resolution (more computation with less neurons)\r\nComputation with spiking neurons\r\n\r\nEncoding strategies\r\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\r\nHow should we encode information about 'features' in a large network with many spikes?\r\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\r\nElephant?\r\nhttps://www.nationalgeographic.com/anim\r\nals/mammals/facts/african-elephant\r\n\r\nFiring rates\r\nClassical view of the brain:\r\n- Each neuron is selective for one specific \r\nfeature in the input.\r\n- Higher firing rate (spikes per unit time) for \r\n'selected' feature.\r\nAdapted from Hubel & Wiesel, 1959\r\n\r\nFiring rates\r\nClassical view of the brain:\r\n- Each neuron is selective for one specific \r\nfeature in the input.\r\n- Higher firing rate (spikes per unit time) for \r\n'selected' feature.\r\n- Link to modern ANNs: The scalar output of \r\nan artificial neuron is interpreted as the firing \r\nrate.\r\nAdapted from Hubel & Wiesel, 1959\r\n\r\nFiring rates\r\nClassical view of the brain:\r\n- Each neuron is selective for one specific \r\nfeature in the input.\r\n- Higher firing rate (spikes per unit time) for \r\n'selected' feature.\r\n- Link to modern ANNs: The scalar output of \r\nan artificial neuron is interpreted as the firing \r\nrate.\r\nAdapted from Hubel & Wiesel, 1959\r\nBut rate coding is inefficient and slow‚Ä¶\r\n(i.e. each neuron needs to fire many spikes to get good precision)\r\nboth in vivo and in silico.\r\n\r\nDifferent encoding strategies with spiking neurons [8]\r\n7 neurons\r\n7 time bins\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nn\r\n6\r\n(in the general \r\ncase a \r\nnumber \r\nbetween 0-7)\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nn\r\nTotal spike \r\ncount can \r\nencode 3 bits.\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nIndividual rates \r\ncan encode 7 \r\nbits.\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nLatency can \r\nencode ~3*7 or \r\n~19 bits.\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nRank order can \r\nencode ~12 bits."", 'Power-efficiency at scale\r\nModern, deep neural networks*\r\nare trained using GPUs.\r\n* It is estimated that ChatGPT was trained on \r\n10,000-20,000 GPUs and that it will require\r\n30,000 GPUs to keep running stably in the future.\r\n* It is estimated that ChatGPT has 10-20 billion \r\nparameters.\r\nhttps://www.anandtech.com/show/4008/nvidias-geforce-gtx-580/17\r\n\r\nPower-efficiency at scale\r\nModern, deep neural networks*\r\nare trained using GPUs.\r\n* It is estimated that ChatGPT was trained on \r\n10,000-20,000 GPUs and that it will require\r\n30,000 GPUs to keep running stably in the future.\r\n* It is estimated that ChatGPT has 10-20 billion \r\nparameters.\r\nSingle model with 20 billion parameters:\r\n200 Watts x 30,000 GPUs = 6M Watts\r\n\r\nPower-efficiency at scale\r\nhttps://hai.stanford.edu/ai-index/2024-ai-index-report\r\nTraining a single large language model can \r\ngenerate greater CO2 emissions than the \r\ntotal lifetime emissions of 8 cars (in 2020)!\r\n\r\nPower-efficiency at scale\r\nhttps://hai.stanford.edu/ai-index/2024-ai-index-report\r\nTraining a single model can consume \r\nmore than 1000 MWh of power!\r\n\r\nPower-efficiency at scale\r\nhttps://hai.stanford.edu/ai-index/2024-ai-index-report\r\nTraining a single model can consume \r\nmore than 1000 MWh of power!\r\n‚Ä¶ with energy costs reaching 200M USD!\r\n\r\nPower-efficiency at scale\r\nYour brain runs on:\r\n\r\nPower-efficiency at scale\r\nYour brain runs on:\r\nHigh estimate ~3000 kcal a day\r\n   ‚âà145 Watts\r\n* Human brain has ~600 trillion synapses \r\n(‚âàparameters).\r\n\r\nPower-efficiency at scale\r\nYour brain runs on:\r\nHigh estimate ~3000 kcal a day\r\n   ‚âà145 Watts\r\n* Human brain has ~600 trillion synapses \r\n(‚âàparameters).\r\nOversimplification\r\nThere are also multiple other advantages‚Ä¶\r\n\r\nHuman vs. computer computation\r\n- Fast real-time decision making, e.g. sports, e-sports\r\n- Adaptive, e.g. context-aware and employs selective attention\r\n- Energy efficient: Close to 100 billion neurons in the brain\r\n- Robust, for example to changes in illumination or obstructions in object tracking\r\n\r\nHuman vs. computer computation\r\nBrains are energy efficient: Why?\r\n1.\r\nHigh temporal resolution (more computation with less neurons)\r\n2.\r\nSparse encoding\r\n\r\nHuman vs. computer computation\r\nQuestions?\r\nBrains are energy efficient: Why?\r\n1.\r\nHigh temporal resolution (more computation with less neurons)\r\n2.\r\nSparse encoding\r\n\r\nHow do biological neurons communicate?\r\nAnalogy to artificial neural networks\r\nReal neuron\r\nArtificial neuron\r\nCurrent\r\n\r\nHow do biological neurons communicate?\r\nHow does the electrical activity propagate?\r\n?\r\nCurrent\r\n\r\nHow do biological neurons work?\r\ntime\r\nelectrode\r\nhttps://tinmard.github.io/spike-sorting-animation.html\r\nQuick electrical pulses trigger chemical signals for the next neuron ‚Üí Spikes\r\n\r\nHow do biological neurons work?\r\nQuick electrical pulses trigger chemical signals for the next neuron ‚Üí Spikes\r\nhttps://tinmard.github.io/spike-sorting-animation.html\r\ntime\r\nelectrode\r\nFrom CS perspective:\r\nSparse binary \r\nencoding\r\n\r\nBiologically realistic spiking neuron models\r\nBiologically realistic neuron models have \r\na new dimension: Time!\r\nSpiking neural networks (SNNs):\r\nThe input x  (t  ) to each neuron is summed \r\n(integrated) over time.\r\nscalar\r\nfunction of \r\ntime\r\n(t)\r\n(t)\r\nhttps://www.mdpi.com/2076-3425/12/7/863\r\n\r\nHow to model spiking neurons?', '575(7784):607-17. \r\nhttps://www.nature.com/articles/s41586-019-1677-2\r\nExtra reading:\r\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \r\nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\r\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \r\nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \r\nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\r\nBasics of \'conventional\' neural networks:\r\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\r\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.\r\n\r\nReferences\r\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \r\nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\r\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \r\n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\r\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \r\nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\r\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \r\n(not publicly available) doi:10.1037/h0042519\r\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \r\nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\r\n6) https://github.com/idsc-frazzoli/retina\r\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \r\nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\r\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \r\nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\r\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \r\nNeural Networks.', '8. Green AI\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nLu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\nCarolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl\r\n\r\n- Overview of Green AI \r\n- Large language models \r\n- Green data-centric AI \r\n- Model simplification \r\n- Hyper parameter tuning \r\n- Mixture of Experts and DeepSeek \r\n- Green AI at Meta \r\n\r\nAI\r\n‚Ä¢ Artificial Intelligence (AI) is the branch of computer science that deals with \r\nautomating tasks that typically require human intelligence. \r\n‚Ä¢ In the past years AI has been widely applied across different domains.\u2028\r\nE.g., health care, transportation, finance. \r\n‚Ä¢ To deploy AI systems, we test them against benchmarks (or validation sets). \r\n‚Ä¢ The goal is to outperform the previous existing models. \r\n‚Ä¢ E.g., in Machine Learning we usually resort to accuracy metrics. The \r\nhighest the accuracy, the better the model.\r\n3\r\n\r\nSince 2012, the amount of computing used for AI \r\ntraining has been doubling every 6 months\r\n‚Ä¢ https://epoch.ai/blog/compute-trends\r\n4\r\n\r\n‚Ä¢ To create better AI systems we are currently adding \r\n‚Ä¢ More data \r\n‚Ä¢ More experiments \r\n‚Ä¢ Larger models\r\n5\r\n\r\nThe Equation of Red AI\r\nCost(R) ‚àùE¬∑D¬∑H\r\nCost of a single (E)xample\r\nSize of (D)ataset\r\nNumber of (H)yperparameters\r\nBy Schwartz et al. (2020)\r\n\r\nIssues of Red AI\r\n‚Ä¢ High costs (hardware, electricity, data access, etc.) \r\n‚Ä¢ Limited reproducibility.  \r\n‚Ä¢ Energy consumption. \r\n‚Ä¢ Carbon emissions. \r\n‚Ä¢ SMEs can hardly be competitive. \r\n‚Ä¢ Groundbreaking AI research is mostly done by tech giants.\r\n7\r\n\r\nA few examples of Red AI\r\n‚Ä¢ Google‚Äôs BERT-large \r\n‚Ä¢ 350 million features \r\n‚Ä¢ Trained for 2.5 days using 512 TPU chips, costing $60K+ \r\n‚Ä¢ Open-GPT3 (now GPT-4/o1) \r\n‚Ä¢ 550 tonnes CO2-eq (Patterson, 2021) \r\n‚Ä¢ 175 billion features \r\n‚Ä¢ API is open but no-pretrained model is available \r\n‚Ä¢ AlphaGo \r\n‚Ä¢ 1920 CPUs, 280 GPUs, costing $35M\r\n8\r\n\r\nRed AI in Large Language Models (LLMs)\r\n‚Ä¢ OPT by Meta reports 75 tons CO2-eq (1/7 of OpenGPT‚Äôs footprint).\u2028\r\n(Also 175billion params) \r\n‚Ä¢ However, Llama 3 reported 2,290 tons of CO2-eq (7.7M GPU hours \r\ntraining ) \r\n‚Ä¢ Open science: release includes both the pretrained models and the code \r\nneeded to train and use them. \r\n‚Ä¢ DeepSeek-V3 claims ‚Äúonly‚Äù 2.78M GPU hours \r\n‚Ä¢ Bloom by Huggingface reports 25 tons, 51 when considering embodied \r\nand operational carbon footprint. (176billion params)\r\n9\r\n\r\nRed AI\r\nAccuracy: 0.999999999\r\nGreen AI\r\n‚Ä¢ Energy \r\n‚Ä¢ Time \r\n‚Ä¢ Reproducibility \r\n‚Ä¢ Reusage\r\n\r\nHow can we adopt Green AI\r\n‚Ä¢ Check whether AI is needed. \r\n‚Ä¢ Select green datacenters. \r\n‚Ä¢ Run on low carbon intensity hours. \r\n‚Ä¢ Opt for GPU-optimised solutions (?) \r\n‚Ä¢ Opt for low-power hardware (e.g., Nvidia Jetson boards) \r\n‚Ä¢ Or GPUs that provide energy metrics (e.g., NVIDIA GPUs via the nvidia-smi tool) \r\n‚Ä¢ Report energy/carbon metrics (e.g., embed in MLFlow?)', '‚Ä¢ Improve parameter-tuning strategy.\r\n11\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ We need benchmarks. \r\n‚Ä¢ AllenAI leaderboard\u2028\r\nhttps://leaderboard.allenai.org \r\n‚Ä¢ No carbon metrics, yet \r\n‚Ä¢ Report comparable proxies for energy \r\nconsumption. \r\n‚Ä¢ ‚ö† Learning algorithms behave in a non-\r\ndeterministic \r\n‚Ä¢ ‚ö† Different data-points lead to different \r\nenergy consumption\r\n12\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ Reporting measured energy consumption \r\n‚Ä¢ + Accurate \r\n‚Ä¢ + Easy to map to carbon emissions \r\n‚Ä¢ - Hard to measure \r\n‚Ä¢ - Low replicability \r\n‚Ä¢ Reporting time / estimation based on time & hardware \r\n‚Ä¢ + Easy to measure \r\n‚Ä¢ + Correlates with energy consumption in most cases. \r\n‚Ä¢ -  Difficult to compare with measurements from other setups \r\n‚Ä¢ E.g., floating point operations (FPOs) (?) \r\n‚Ä¢ + comparable across different setups \r\n‚Ä¢ + cheap \r\n‚Ä¢ - does not factor in memory energy consumption \r\n‚Ä¢ - does not reflect carbon emissions\r\n13\r\n\r\nData-centric AI\r\n\r\nData-centric AI\r\n‚Ä¢ Emerging discipline that deals with systematically engineering data to build AI \r\nsystems. \r\n‚Ä¢ Shift from improving the training strategy to improving the data. \r\n‚Ä¢ It is better to have small but reliable datasets than large but noisy \r\ndatasets. \r\n‚Ä¢ => Improve data collection, data labelling, and data preprocessing. \r\n‚Ä¢ More about data-centric AI by Andrew Ng:\u2028\r\nhttps://www.youtube.com/watch?v=06-AZXmwHjo\r\n15\r\n\r\n\r\nGreen Data-centric AI\r\n‚Ä¢ How do different ML algorithms compare \r\nin terms of energy consumption? \r\n‚Ä¢ How does number of rows relate to the \r\nenergy consumption of ML models? \r\n‚Ä¢ How does number of features relate to \r\nthe energy consumption of ML models? \r\n‚Ä¢ What is the impact of reducing data in the \r\nperformance of the model? \r\n‚Ä¢ Method -> results -> discussion\r\n17\r\n\r\nMethod\r\n‚Ä¢ Single object of study: natural language model to detect spam messages. \r\n‚Ä¢ 6 machine learning algorithms: SVM, Decision Tree, KNN, Random Forrest, \r\nAdaBoost, Bagging Classifier. \r\n‚Ä¢ Reduce the number of rows. 10%, 20%, .., 100% \r\n‚Ä¢ Stratified random sampling (?) \r\n‚Ä¢ Reduce the number of features. 10%, 20%, .., 100% \r\n‚Ä¢ Feature importance metric based on the Chi-Square Test (Chi2) \r\n‚Ä¢ Estimate energy consumption using a RAPL-based tool. (?)\r\n18\r\n\r\n‚Ä¢ Repeat 30 times \r\n‚Ä¢ Fix random seeds \r\n‚Ä¢ ‚Ä¶ \r\n‚Ä¢ Data was not Normal => tailed Normal distribution.\r\n19\r\n(?)\r\n\r\nResults: energy consumption of algorithms\r\n\r\nResults: energy vs data shape\r\n\r\nResults: performance vs data shape\r\n\r\nDiscussion\r\n‚Ä¢ Other data properties should be investigated. \r\n‚Ä¢ E.g., data types \r\n‚Ä¢ Reporting energy data is essential. It can lead to different model selection \r\nwithout hindering model performance. \r\n‚Ä¢ There is a big opportunity in Model and Data Simplification.\r\n23\r\n\r\nData/Model Simplification\r\n‚Ä¢ (?) \r\n‚Ä¢ Data selection \r\n‚Ä¢ Data quantisation. Posit? \r\n‚Ä¢ Data distillation \r\n‚Ä¢ Coreset extraction (?) \r\n‚Ä¢ Model distillation \r\n‚Ä¢ Model quantisation \r\n‚Ä¢ Model pruning \r\n‚Ä¢ ‚Ä¶\r\n24\r\n\r\nPosit vs Float\r\nMore about this: https://spectrum.ieee.org/floating-point-numbers-posits-processor\r\nBetter for DL use cases\r\n\r\nHow can we tune \r\nlearning \r\nparameters \r\nefficiently?\r\n\r\nHyper parameter tuning\r\n‚Ä¢ When training an ML model, there are several parameters that need to be \r\ntuned. \r\n‚Ä¢ E.g., in SVM we have the Regularization parameter C, the kernel function, \r\nthe degree of the kernel function, and depending on the case, many other. \r\n‚Ä¢ The common approach revolves around grid search.', 'Interviews?) & rich \r\ndescription of outcomes focus of grading\r\nhttps://eip.pages.ewi.tudelft.nl/eip-website/queue.html\r\n\r\nC1. Compare energy consumption of docker images for \r\nML workloads.\r\n‚Ä¢ Similar to what we have seen in the lectures but for ML-specific workloads. \r\n‚Ä¢ We can reuse existing experiment replication packages.\r\n22\r\n\r\nC2. Plugin to visualize Hugging Face carbon emissions.\r\n‚Ä¢ https://huggingface.co/blog/leaderboard-emissions-\r\nanalysis \r\n‚Ä¢\r\nYoo, Taewon, et al. ""Visualizing the Carbon Intensity of Machine Learning Inference for Image Analysis on TensorFlow Hub.""\r\n\r\nC3. Plugin for ChatGPT\r\n‚Ä¢ Users seldom know how much carbon they are emitting when they interact \r\nwith chat GPT. \r\n‚Ä¢ Let‚Äôs make it transparent to the users. Browser plugin?\r\n24\r\nCO2\r\n\r\nC4. NutriScore for software libraries\r\n25\r\n‚Ä¢ NutriScore labels are not perfect but they are a good starting point! \r\n‚Ä¢ What if we could do the same thing for the energy efficiency of software. \r\n‚Ä¢ (Also open to individual or social sustainability) \r\n‚Ä¢ This work can be scoped in particular domains/ecossystems/use cases. \r\n‚Ä¢ Libraries for stats? ML? Web Dev? Cloud?\r\n\r\nC5. Add energy-awareness to existing software\r\n26\r\n‚Ä¢ Streamlit, Notebooks, JSFiddle, \r\nPyScript, zsh, etc. \r\n‚Ä¢\r\n\r\nC6 - Green Shift Left\r\n‚Ä¢ Estimate energy efficiency using static code analysis. \r\n‚Ä¢ We don‚Äôt need an accurate value. \r\n‚Ä¢ It is useful to know which code is more likely to \r\nintroduce energy hotspots and that should be \r\nreviewed with more attention. \r\n‚Ä¢ Can be scoped to a particular domain (react, php, data \r\nscience, web, etc., etc.)\r\n27\r\n\r\nC7 - Education\r\n‚Ä¢ Educational game for Software \r\nSustainability practices \r\n‚Ä¢ Purpose: use within software teams to \r\ndiscuss or learn about different sustainable \r\nIT practices: at the organisation level, \r\nsoftware, etc.\r\n28\r\nhttps://github.com/OttoKaaij/Ticket-To-Sustainability/?tab=readme-ov-file\r\n\r\nProject ideas (old)\r\n‚Ä¢ Plugin from EnergiBridge (GUI, report generator, python library, etc.) \r\n‚Ä¢ Plugin for ChatGPT (carbon emissions per chat window) \r\n‚Ä¢ Seamless measurements for AI libraries \r\n‚Ä¢ Energy patterns for Green AI \r\n‚Ä¢ Sustainable SW dev gamification \r\n‚Ä¢ Sustainability auditor for AI projects \r\n‚Ä¢ Energy Profiling of screen colour filter tools (or display settings) \r\n‚Ä¢ ‚Ä¶ you can also propose yours!\r\n\r\nhttps://edu.nl/64gpk\r\nedu.nl/64gpk', ""‚Ä¢ 6 machine learning algorithms: SVM, Decision Tree, KNN, Random Forrest, \r\nAdaBoost, Bagging Classifier. \r\n‚Ä¢ Reduce the number of rows. 10%, 20%, .., 100% \r\n‚Ä¢ Stratified random sampling (?) \r\n‚Ä¢ Reduce the number of features. 10%, 20%, .., 100% \r\n‚Ä¢ Feature importance metric based on the Chi-Square Test (Chi2) \r\n‚Ä¢ Estimate energy consumption using a RAPL-based tool. (?)\r\n18\r\n\r\n‚Ä¢ Repeat 30 times \r\n‚Ä¢ Fix random seeds \r\n‚Ä¢ ‚Ä¶ \r\n‚Ä¢ Data was not Normal => tailed Normal distribution.\r\n19\r\n(?)\r\n\r\nResults: energy consumption of algorithms\r\n\r\nResults: energy vs data shape\r\n\r\nResults: performance vs data shape\r\n\r\nDiscussion\r\n‚Ä¢ Other data properties should be investigated. \r\n‚Ä¢ E.g., data types \r\n‚Ä¢ Reporting energy data is essential. It can lead to different model selection \r\nwithout hindering model performance. \r\n‚Ä¢ There is a big opportunity in Model and Data Simplification.\r\n23\r\n\r\nData/Model Simplification\r\n‚Ä¢ (?) \r\n‚Ä¢ Data selection \r\n‚Ä¢ Data quantisation. Posit? \r\n‚Ä¢ Data distillation \r\n‚Ä¢ Coreset extraction (?) \r\n‚Ä¢ Model distillation \r\n‚Ä¢ Model quantisation \r\n‚Ä¢ Model pruning \r\n‚Ä¢ ‚Ä¶\r\n24\r\n\r\nPosit vs Float\r\nMore about this: https://spectrum.ieee.org/floating-point-numbers-posits-processor\r\nBetter for DL use cases\r\n\r\nHow can we tune \r\nlearning \r\nparameters \r\nefficiently?\r\n\r\nHyper parameter tuning\r\n‚Ä¢ When training an ML model, there are several parameters that need to be \r\ntuned. \r\n‚Ä¢ E.g., in SVM we have the Regularization parameter C, the kernel function, \r\nthe degree of the kernel function, and depending on the case, many other. \r\n‚Ä¢ The common approach revolves around grid search. The user provides a \r\nsequence of possible values for each parameter and the pipeline runs all \r\npossible combinations. \r\n‚Ä¢ Our question: Can we save energy with alternative approaches? \r\n‚Ä¢ We studied Grid Search, Random Search and Bayesian \r\nOptimisation.\r\n27\r\nTim's MSc Thesis, 2022 \r\nAccepted at CAIN‚Äô23\r\n\r\n\r\nResults\r\n29\r\nConclusions? \r\n‚Ä¢ Bayesian converges faster. \r\n‚Ä¢ No clear winner between Grid and Random\r\n\r\nDeepSeekMoE\r\n30\r\nPreprint at ArXiv, 2024 https://arxiv.org/pdf/\r\n2401.06066\r\n\r\nMixture of Experts\r\n‚Ä¢ Llama3.1 has 405B parameters, DeepSeek V3 671B \r\n‚Ä¢ Yet DeepSeek has quicker inference times and claims less energy \r\nconsumption (?) \r\n‚Ä¢ Divide the model into smaller blocks of experts \r\n‚Ä¢ Tokens get routed to certain experts based on the query \r\n‚Ä¢ Only part of the network is active during inference \r\n‚Ä¢ DeepSeek claims only 37B out of 671B parameters get active\r\n31\r\n\r\nDeepSeekMoE\r\n32\r\n\r\nDeepSeekMoE\r\n33\r\n‚Ä¢ Comparable performance to \r\nLLaMA2 7B effectively using \r\nless half the parameters \r\n‚Ä¢ Less computational power \r\n‚Ä¢ Problems (?) \r\n‚Ä¢ Still need to load all the \r\nparameters \r\n‚Ä¢ High memory -> high \r\nembodied carbon\r\n\r\nGreen AI at FacebookMeta\r\n34\r\nSustainable AI: Environmental Implications, \r\nChallenges and Opportunities (2022)\r\n\r\nCarbon footprint mapped to the AI lifecycle\r\n‚Ä¢ There are 4 main overarching stages where carbon emissions need to be isolated: data \r\ncollection, experimentation, training, inference. \r\n‚Ä¢ At Facebook, recommendation systems split energy consumption evenly between \r\ntraining and inference; text translation models have a 35%/65% split. (Operational cost) \r\n‚Ä¢ Operational/embodied cost split: 30%/70%\r\n35\r\n\r\nOpen issues according to Meta\r\n‚Ä¢ A vast portion of projects only use GPUs at 30%.\u2028\r\nShould be higher to attenuate embodied carbon."", '‚Ä¢ Groundbreaking AI research is mostly done by tech giants.\r\n7\r\n\r\nA few examples of Red AI\r\n‚Ä¢ Google‚Äôs BERT-large \r\n‚Ä¢ 350 million features \r\n‚Ä¢ Trained for 2.5 days using 512 TPU chips, costing $60K+ \r\n‚Ä¢ Open-GPT3 (now GPT-4/o1) \r\n‚Ä¢ 550 tonnes CO2-eq (Patterson, 2021) \r\n‚Ä¢ 175 billion features \r\n‚Ä¢ API is open but no-pretrained model is available \r\n‚Ä¢ AlphaGo \r\n‚Ä¢ 1920 CPUs, 280 GPUs, costing $35M\r\n8\r\n\r\nRed AI in Large Language Models (LLMs)\r\n‚Ä¢ OPT by Meta reports 75 tons CO2-eq (1/7 of OpenGPT‚Äôs footprint).\u2028\r\n(Also 175billion params) \r\n‚Ä¢ However, Llama 3 reported 2,290 tons of CO2-eq (7.7M GPU hours \r\ntraining ) \r\n‚Ä¢ Open science: release includes both the pretrained models and the code \r\nneeded to train and use them. \r\n‚Ä¢ DeepSeek-V3 claims ‚Äúonly‚Äù 2.78M GPU hours \r\n‚Ä¢ Bloom by Huggingface reports 25 tons, 51 when considering embodied \r\nand operational carbon footprint. (176billion params)\r\n9\r\n\r\nRed AI\r\nAccuracy: 0.999999999\r\nGreen AI\r\n‚Ä¢ Energy \r\n‚Ä¢ Time \r\n‚Ä¢ Reproducibility \r\n‚Ä¢ Reusage\r\n\r\nHow can we adopt Green AI\r\n‚Ä¢ Check whether AI is needed. \r\n‚Ä¢ Select green datacenters. \r\n‚Ä¢ Run on low carbon intensity hours. \r\n‚Ä¢ Opt for GPU-optimised solutions (?) \r\n‚Ä¢ Opt for low-power hardware (e.g., Nvidia Jetson boards) \r\n‚Ä¢ Or GPUs that provide energy metrics (e.g., NVIDIA GPUs via the nvidia-smi tool) \r\n‚Ä¢ Report energy/carbon metrics (e.g., embed in MLFlow?) \r\n‚Ä¢ Use pre-trained models (Transfer Learning) \r\n‚Ä¢ Preprocess dataset to reduce size. \r\n‚Ä¢ Improve parameter-tuning strategy.\r\n11\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ We need benchmarks. \r\n‚Ä¢ AllenAI leaderboard\u2028\r\nhttps://leaderboard.allenai.org \r\n‚Ä¢ No carbon metrics, yet \r\n‚Ä¢ Report comparable proxies for energy \r\nconsumption. \r\n‚Ä¢ ‚ö† Learning algorithms behave in a non-\r\ndeterministic \r\n‚Ä¢ ‚ö† Different data-points lead to different \r\nenergy consumption\r\n12\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ Reporting measured energy consumption \r\n‚Ä¢ + Accurate \r\n‚Ä¢ + Easy to map to carbon emissions \r\n‚Ä¢ - Hard to measure \r\n‚Ä¢ - Low replicability \r\n‚Ä¢ Reporting time / estimation based on time & hardware \r\n‚Ä¢ + Easy to measure \r\n‚Ä¢ + Correlates with energy consumption in most cases. \r\n‚Ä¢ -  Difficult to compare with measurements from other setups \r\n‚Ä¢ E.g., floating point operations (FPOs) (?) \r\n‚Ä¢ + comparable across different setups \r\n‚Ä¢ + cheap \r\n‚Ä¢ - does not factor in memory energy consumption \r\n‚Ä¢ - does not reflect carbon emissions\r\n13\r\n\r\nData-centric AI\r\n\r\nData-centric AI\r\n‚Ä¢ Emerging discipline that deals with systematically engineering data to build AI \r\nsystems. \r\n‚Ä¢ Shift from improving the training strategy to improving the data. \r\n‚Ä¢ It is better to have small but reliable datasets than large but noisy \r\ndatasets. \r\n‚Ä¢ => Improve data collection, data labelling, and data preprocessing. \r\n‚Ä¢ More about data-centric AI by Andrew Ng:\u2028\r\nhttps://www.youtube.com/watch?v=06-AZXmwHjo\r\n15\r\n\r\n\r\nGreen Data-centric AI\r\n‚Ä¢ How do different ML algorithms compare \r\nin terms of energy consumption? \r\n‚Ä¢ How does number of rows relate to the \r\nenergy consumption of ML models? \r\n‚Ä¢ How does number of features relate to \r\nthe energy consumption of ML models? \r\n‚Ä¢ What is the impact of reducing data in the \r\nperformance of the model?', '‚Ä¢ Deadline April 4.\r\n6\r\n\r\nStrategy\r\n‚Ä¢ Week 0 \r\n‚Ä¢ Decide project idea (today) \r\n‚Ä¢ Define steering meeting schedule \r\n‚Ä¢ Create working document of the \r\narticle: Problem statement and solution \r\nproposal! \r\n‚Ä¢ Define and assign tasks for each week. \r\n‚Ä¢ Week 1 \r\n‚Ä¢ Implementation \r\n‚Ä¢ Agreements with supervisor. \r\n‚Ä¢ Week 2 \r\n‚Ä¢ Implementation \r\n‚Ä¢ Week 3 \r\n‚Ä¢ Implementation, Full draft of article, \r\ndissemination. \r\n‚Ä¢ Week 4 \r\n‚Ä¢ Final refinements \r\n‚Ä¢ Prepare presentation\r\n7\r\n\r\nProject ideas\r\n‚Ä¢ A1. Prototype cross-machine comparable benchmarks \r\n‚Ä¢ A2. Add energy metrics to LMstudio/Ollama \r\n‚Ä¢ A3. Visualizations built-in with EnergiBridge \r\n‚Ä¢ A4. Service-based version of EnergiBridge\r\n\r\nProject ideas\r\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \r\n‚Ä¢ B2. Study test generation energy consumption \r\n‚Ä¢ B3. Energy profiling of static analysis tools \r\n‚Ä¢ B4. Detailed energy profiling of build pipelines \r\n‚Ä¢ B5. Tool supporting SusAF workshop / process \r\n‚Ä¢ B6. Dataset of government-developed OS software \r\n‚Ä¢ B7. Queue - but better for the student / TA society\r\nQuality Assurance & Testing\r\nSocial & Individual \u2028\r\nSustainability\r\n\r\nProject ideas\r\n‚Ä¢ C1. Compare energy consumption of docker images for ML workloads. \r\n‚Ä¢ C2. Create a plugin to visualize Hugging Face carbon emissions in detail. \r\n‚Ä¢ C3. Plugin for ChatGPT (footprint per chat window) \r\n‚Ä¢ C4. NutriScore for software libraries. \r\n‚Ä¢ C5. Add energy-awareness to existing software \r\n‚Ä¢ C6. Green Shift Left \r\n‚Ä¢ C7. Education for Sustainable SE\r\n\r\nA1. Prototype cross-machine comparable benchmarks\r\n‚Ä¢ Energy-usage comparisons require running both baseline + software on the \r\nsame machine ‚Üí limits how extensive our experiments can be \r\n‚Ä¢ Research community is in need of benchmarks that make energy \r\nmeasurements comparable even if executed on different machines \r\n‚Ä¢ Focus on a single task or model (i.e. computing vision, classification)\r\n\r\nA2. Adding energy metrics to LMstudio/Ollama\r\n‚Ä¢ Make energy consumption visible to users \r\nwithin local chat-interface for LLMs \r\n‚Ä¢ LMstudio/Ollama are tools for easy \r\ndeployment of LLMs \r\n‚Ä¢ Do not show energy metrics \r\n‚Ä¢ Add energy metrics to LMstudio-python \r\nor Ollama\r\nhttps://lmstudio.ai/\r\n\r\nA3. Visualizations built-in with EnergiBridge\r\n‚Ä¢ EnergiBridge simplifies energy measurement, but analysis & visualization is \r\nstill left to the user \r\n‚Ä¢ Extend the tool with well-chosen visualizations and analyses directly from the \r\nprovided data\r\n\r\nA4. Service-based version of EnergiBridge\r\n‚Ä¢ Simplify interaction & setup with EnergiBridge \r\n‚Ä¢ Service that runs independently, start/stop signals over RPC to manage \r\nexperiments \r\n‚Ä¢ Potential: create EnergiBridge interface for other prog. lang\r\n\r\nB1. Measure energy consumption of single JUnit tests\r\n‚Ä¢ We‚Äôd like to identify energy anti patterns in unit tests \r\n‚Ä¢ As a first step, we need tooling to measure and compare the energy \r\nconsumption of single unit tests \r\n‚Ä¢ Ideally including preliminary analysis looking at potential reasons for high-\r\nenergy-consuming tests\r\n\r\nB2. Study test generation energy consumption\r\n‚Ä¢ Automatic test generation mainly focuses on making strong test suites \r\n‚Ä¢ Do different techniques and configurations impact the energy consumption \r\nduring generation? \r\n‚Ä¢ Preferably focus on non-LLM test generation methods (EvoSuite, Pyguin, \r\nDSpot)\r\n\r\nB3. Detailed energy profiling of build pipelines\r\n‚Ä¢ Automatic builds have become a cornerstone of quality assurance.', 'google.com/view/energy-efficiency-languages\r\n21\r\nAna Radovanovic ÃÅ, Ross Koningstein, Ian Schneider, Bokan \r\nChen, Alexandre Duarte, Binz Roy, Diyue Xiao, Maya \r\nHaridasan, Patrick Hung, Nick Care, Saurav Talukdar, Eric \r\nMullen, Kendal Smith, MariEllen Cottman, and Walfredo Cirne \r\n\r\n\r\n‚Ä¢ Google‚Äôs Carbon-Intelligent Computing System (CICS) \r\n‚Ä¢ Main idea: use carbon-intensity data to shift datacenter jobs in time \r\n‚Ä¢ Typically, job schedulers use a metric of cluster capacity to schedule a job in \r\na particular cluster. \r\n‚Ä¢ CICS overrides this metric with the virtual capacity curve (VCC) that \r\nfactors in Carbon intensity \r\n‚Ä¢ When a new job comes in, the scheduler estimates its CPU load and power \r\nusage and assigns it to a cluster if the VCC is not exceeded.\r\n23\r\n\r\n‚Ä¢ Jobs are divided between flexible and inflexible. \r\n‚Ä¢ Flexible load is considered shapeable/shiftable as long as its total daily \r\ncompute (CPU) demand is preserved \r\n‚Ä¢ The system needs to consider that, while running a job, the virtual capacity \r\ncurve (VCC) might drop. Hence, this job should not start in the first place. \r\n‚Ä¢ They forecast VCC for the next day\r\n24\r\n\r\n\r\nVirtual Cluster Capacity (VCC)\r\n‚Ä¢ Aims at reducing the peak load at carbon intensive hours but in total it should allow for the \r\nsome amount of daily computation! \r\n‚Ä¢ Considers Carbon intensity \r\n‚Ä¢ Using data from electricityMap.org \r\n‚Ä¢ It does not use carbon intensity directly.\u2028\r\nCarbon intensity is converted to a cost (kgCO2 -> $$) \r\n‚Ä¢ This way, they can factor in other metrics that can also be converted to money. E.g., the \r\ncost saved by preventing peak load \r\n‚Ä¢ Peak workload entails extra cost at the infrastructure level (e.g., control faclities‚Äô \r\ntemperature). \r\n‚Ä¢ By using money cost instead of carbon cost, they have more data available.\r\n26\r\n\r\nVirtual Cluster Capacity (VCC)\r\n‚Ä¢ If the forecast of VCC fails it shift flexible workload more than expected.  \r\n‚Ä¢ This happens because the amount of workload forecasted was below the \r\nworkload needed, and VCC was ‚Äúaggressively‚Äù low. \r\n‚Ä¢ The systems fall back to the real cluster capacity for 1 week until results \r\nstart being realistic again.\r\n27\r\n\r\nNext steps\r\n‚Ä¢ They will consider spatial flexibility. \r\n‚Ä¢ I.e., tasks that can be shifted over time and over space. \r\n‚Ä¢ It needs to factor in relocation overheads, though.\r\n28\r\n\r\nCritical questions\r\n‚Ä¢ Who defines what is flexible and inflexible? \r\n‚Ä¢ How do you estimate the CPU load of a given task?\r\n29\r\n\r\nEnergy Regression Testing\r\n‚ÜíEnergy?\r\nGreener? Greener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\n\r\nE-compare\r\nGithub Actions\r\n‚ûú https://koenhagen.github.io/E-Compare/\r\n\r\nEnergy Regression Testing \r\n\r\n4. Debugging Energy with \r\nDocker Images\r\n\r\nUnveiling the Energy Vampires \r\nA methodology for debugging Software \r\nEnergy Consumption\r\n ‚úÖ ICSE 2025\r\n\r\nData Centers and Docker\r\n‚Ä¢ Containers are the most popular way to deploy apps into the cloud \r\n‚Ä¢ Base image is an important choice when building an image \r\n‚Ä¢ Criteria \r\n‚Ä¢ Linux distribution and binaries \r\n‚Ä¢ Image size \r\n‚Ä¢ Energy?\r\n35\r\n\r\nRedis energy consumption\r\n‚Ä¢ Ubuntu/Alpine base images have different energy consumption for Redis\r\n36\r\n\r\nRedis Energy Consumption\r\n‚Ä¢RQ1: What is the difference \r\nin energy consumption \r\nbetween glibc and musl? \r\n‚Ä¢RQ2: Can we use tracing \r\nto compare energy \r\nconsumption in shared \r\nlibraries?', '5. Green Software Metrics\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nLu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\nCarolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl\r\nSustainableSE 2025\r\n\r\nBitcoin example\r\n‚Ä¢ 1 bitcoin transaction is equivalent to more than 1.5 million VISA transactions. \r\n \r\n   \r\n \r\n‚Ä¢ Day-to-day metrics are easy to grasp \r\n‚Ä¢ If we say 8 gigajoules, it‚Äôs a bit more difficult to understand. \r\n‚Ä¢ These numbers keep changing (check it here: https://www.statista.com/\r\nstatistics/881541/bitcoin-energy-consumption-transaction-comparison-visa/)\r\n2\r\n\r\n3\r\n\r\n(Electrical) Energy\r\n‚Ä¢ Work required to move charged particles. \r\n‚Ä¢ Same concept but different perspective when talking about thermal, \r\nmechanical, or nuclear energy. \r\n‚Ä¢ Most common units: \r\n‚Ä¢ joule (J) -  recommended; scientific communications; metric from the \r\nInternational System of Units \r\n‚Ä¢ kilowatt-hour (kWh) - more common, e.g., used for household electricity \r\nconsumption\r\n4\r\n+q\r\n-q\r\nF\r\nF\r\n\r\nPower\r\n‚Ä¢ Amount of work being done per unit of time. \r\n‚Ä¢ Commonly measured in watts (W).\r\n5\r\n\r\n‚à´\r\ntf=9\r\nti=1\r\nP(t)dt\r\n\r\n‚à´\r\ntf=9\r\nti=1\r\nP(t)dt\r\n\r\nA = a + b\r\n2\r\nh\r\nMeasured Energy \r\nConsumption\r\n=\r\nPtn + Ptn+1\r\n2\r\n‚ãÖŒît = 3.5W + 2.0W\r\n2\r\n‚ãÖ1s = 2.75J\r\nA = ?\r\na\r\nb\r\nh\r\n\r\n‚à´\r\ntn\r\nt0\r\nP(t)dt ‚âàŒît\r\n2 [P(t0) + 2P(t1) + 2P(t2) + . . . + 2P(tn‚àí1) + P(tn)]\r\nMeasured Energy \r\nConsumption\r\n‚ö† Sometimes you cannot assume that the sampling interval (\r\n) is always the same. ‚ö†\r\nŒît\r\nTrapezoid Rule\r\n\r\nTrapezoid Rule in Python\r\nimport numpy as np \r\nenergy_consumption = np.trapz(power_sample, timestamps) \r\n\r\nAverage power\r\n‚Ä¢ Easy to convert to energy consumption \r\n‚Ä¢ Simply multiply by the elapsed time. \r\n‚Ä¢ (This is another reason to always collect time data along with energy \r\nmetrics.)\r\n11\r\nEnergy = Pavg¬∑Œît\r\n\r\nPower or Energy?\r\n‚Ä¢ Average power consumption makes sense when we report the \r\nconsumption of a continuous use case. E.g., reading an ebook in your \r\ncomputer. \r\n‚Ä¢ Energy consumption makes sense in one-off use cases. E.g., energy \r\nconsumption of a bitcoin transaction. \r\n‚ö†\r\n\r\nLearning activity\r\n‚Ä¢ Pair up with one colleague and discuss potential software use cases where \r\none should test energy efficiency. \r\n‚Ä¢ Choose one use case where energy consumption is the best metric to \r\ndiscuss/test energy efficiency. \r\n‚Ä¢ Choose one use case where average power consumption is the best \r\nmetric to discuss/test energy efficiency.\r\n13\r\n\r\nEnergy Delay Product (EDP)\r\n‚Ä¢ In some cases, to achieve less energy consumption, one simply runs the \r\nsoftware on a low power mode of the CPU. \r\n‚Ä¢ E.g., setting the CPU at a low frequency will make execution slow but more \r\nenergy-efficient. \r\n‚Ä¢ Energy consumption metric that penalizes slow runs \r\n \r\n \r\n‚Ä¢ Gives more importance to application runtime, with the goal of making both \r\nlow energy and fast runtime applications.', 'Energy profiling of static analysis tools\r\n‚Ä¢ What is the energy consumption of a ""typical run"" for a few OSS projects? \r\n‚Ä¢ Does the type of analysis matter? Are certain analysis more expensive? Does \r\nthe number of rules that are activated in a static analysis tool important for the \r\nenergy consumption? \r\n‚Ä¢ Differences between static analysis tools [lower priority]\r\n\r\nB5. Tool supporting SusAF workshop / process\r\n‚Ä¢ Lead engineers through process & questions \r\n‚Ä¢ Interface to create & document the two diagrams \r\n‚Ä¢ (!) Should be easy to start using & set up \r\n‚Ä¢ You may also create a simplified version / \u2028\r\nyour favorite sustainability framework\r\nEnvironmental\r\nEconomic\r\nTechnical\r\nIndividual\r\nSocial\r\nImmediate\r\nEnabling\r\nStructural\r\nAirbnb\r\ngreater \r\nearnings\r\nincrease \r\nin rents\r\ngentrification\r\ngreater racial \r\ndisparities\r\nrent \r\nrooms\r\n5\r\n1\r\n3\r\n4\r\n2\r\n \r\n \r\n \r\n \r\n \r\n \r\nVery \r\nunlikely \r\nVery \r\nlikely \r\n\r\nB6. Dataset of government-developed OS software\r\n‚Ä¢ Governments develop & use software for supporting society\u2028\r\nOpen-source development & policies are on the rise \r\n‚Ä¢ But studying government software is difficult b/c we don‚Äôt know what is out \r\nthere\u2028\r\n‚Üí Lack of incentive to make popular \u2028\r\n‚Üí Language barriers \r\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \r\nbuildable?, open dev. history?, requirements documentation? \r\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!\r\n\r\nB7. Queue - but better for the student / TA society\r\n‚Ä¢ Requirements analysis regarding social and individual sustainability effects \r\nof Queue \r\n‚Ä¢ Other EIP / TUD used software also possible: e.g., Answers EWI \r\n‚Ä¢ Non-technical project ‚Üí proper process (workshops? Interviews?) & rich \r\ndescription of outcomes focus of grading\r\nhttps://eip.pages.ewi.tudelft.nl/eip-website/queue.html\r\n\r\nC1. Compare energy consumption of docker images for \r\nML workloads.\r\n‚Ä¢ Similar to what we have seen in the lectures but for ML-specific workloads. \r\n‚Ä¢ We can reuse existing experiment replication packages.\r\n22\r\n\r\nC2. Plugin to visualize Hugging Face carbon emissions.\r\n‚Ä¢ https://huggingface.co/blog/leaderboard-emissions-\r\nanalysis \r\n‚Ä¢\r\nYoo, Taewon, et al. ""Visualizing the Carbon Intensity of Machine Learning Inference for Image Analysis on TensorFlow Hub.""\r\n\r\nC3. Plugin for ChatGPT\r\n‚Ä¢ Users seldom know how much carbon they are emitting when they interact \r\nwith chat GPT. \r\n‚Ä¢ Let‚Äôs make it transparent to the users. Browser plugin?\r\n24\r\nCO2\r\n\r\nC4. NutriScore for software libraries\r\n25\r\n‚Ä¢ NutriScore labels are not perfect but they are a good starting point! \r\n‚Ä¢ What if we could do the same thing for the energy efficiency of software. \r\n‚Ä¢ (Also open to individual or social sustainability) \r\n‚Ä¢ This work can be scoped in particular domains/ecossystems/use cases. \r\n‚Ä¢ Libraries for stats? ML? Web Dev? Cloud?\r\n\r\nC5. Add energy-awareness to existing software\r\n26\r\n‚Ä¢ Streamlit, Notebooks, JSFiddle, \r\nPyScript, zsh, etc. \r\n‚Ä¢\r\n\r\nC6 - Green Shift Left\r\n‚Ä¢ Estimate energy efficiency using static code analysis. \r\n‚Ä¢ We don‚Äôt need an accurate value. \r\n‚Ä¢ It is useful to know which code is more likely to \r\nintroduce energy hotspots and that should be \r\nreviewed with more attention. \r\n‚Ä¢ Can be scoped to a particular domain (react, php, data \r\nscience, web, etc., etc.)']","['<1-hop>\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing', '<2-hop>\n\nReading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.']","Neuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain. Its practical applications include:

1. **Power-Efficient Computing**: Neuromorphic systems are designed to be highly energy-efficient, making them suitable for applications where power consumption is a critical factor, such as in mobile devices and IoT applications.

2. **Real-Time Processing**: Due to their architecture, neuromorphic systems can process information in real-time, which is beneficial for applications like autonomous vehicles, robotics, and real-time data analysis.

3. **Adaptive Systems**: Neuromorphic computing can lead to systems that are adaptive and capable of learning from their environment, similar to how the human brain learns. This is useful in developing intelligent systems that can adjust to new situations without explicit reprogramming.

4. **Sensory Processing**: Inspired by the brain's ability to process sensory information, neuromorphic systems can be used in sensory perception tasks, such as image and sound recognition, with applications in surveillance, healthcare, and more.

The biological inspiration influences its implementation by emphasizing the use of spiking neural networks (SNNs), which mimic the way neurons in the brain communicate through spikes. This leads to systems that use sparse encoding and high temporal resolution, allowing for efficient computation with fewer resources. The focus on mimicking the brain's structure and function also drives the development of specialized hardware that can emulate neural processes more directly than traditional computing architectures.","Neuromorphic computing, inspired by the human brain, offers practical applications through its ability to process information in a manner similar to biological neurons. This biological inspiration influences its implementation by enabling the development of systems that can efficiently handle tasks such as pattern recognition and adaptive learning, as detailed in resources like 'Computing with spiking neuron networks' and discussions on the convergence of deep learning with biological systems.",0.2853535353440235,0.5,1.0,0.71,,0.9584266558837133
What are the practical applications of neuromorphic systems that leverage biological inspiration and advanced training methods for efficient computation?,"[""‚Ä¢ Our question: Can we save energy with alternative approaches? \r\n‚Ä¢ We studied Grid Search, Random Search and Bayesian \r\nOptimisation.\r\n27\r\nTim's MSc Thesis, 2022 \r\nAccepted at CAIN‚Äô23\r\n\r\n\r\nResults\r\n29\r\nConclusions? \r\n‚Ä¢ Bayesian converges faster. \r\n‚Ä¢ No clear winner between Grid and Random\r\n\r\nDeepSeekMoE\r\n30\r\nPreprint at ArXiv, 2024 https://arxiv.org/pdf/\r\n2401.06066\r\n\r\nMixture of Experts\r\n‚Ä¢ Llama3.1 has 405B parameters, DeepSeek V3 671B \r\n‚Ä¢ Yet DeepSeek has quicker inference times and claims less energy \r\nconsumption (?) \r\n‚Ä¢ Divide the model into smaller blocks of experts \r\n‚Ä¢ Tokens get routed to certain experts based on the query \r\n‚Ä¢ Only part of the network is active during inference \r\n‚Ä¢ DeepSeek claims only 37B out of 671B parameters get active\r\n31\r\n\r\nDeepSeekMoE\r\n32\r\n\r\nDeepSeekMoE\r\n33\r\n‚Ä¢ Comparable performance to \r\nLLaMA2 7B effectively using \r\nless half the parameters \r\n‚Ä¢ Less computational power \r\n‚Ä¢ Problems (?) \r\n‚Ä¢ Still need to load all the \r\nparameters \r\n‚Ä¢ High memory -> high \r\nembodied carbon\r\n\r\nGreen AI at FacebookMeta\r\n34\r\nSustainable AI: Environmental Implications, \r\nChallenges and Opportunities (2022)\r\n\r\nCarbon footprint mapped to the AI lifecycle\r\n‚Ä¢ There are 4 main overarching stages where carbon emissions need to be isolated: data \r\ncollection, experimentation, training, inference. \r\n‚Ä¢ At Facebook, recommendation systems split energy consumption evenly between \r\ntraining and inference; text translation models have a 35%/65% split. (Operational cost) \r\n‚Ä¢ Operational/embodied cost split: 30%/70%\r\n35\r\n\r\nOpen issues according to Meta\r\n‚Ä¢ A vast portion of projects only use GPUs at 30%.\u2028\r\nShould be higher to attenuate embodied carbon.\r\n36\r\nBased on 10K AI projects\r\n\r\nData Jan\r\nInformed Adaptation\r\nData Feb\r\nData Mar\r\nData Apr\r\nData May\r\n‚Ä¶\r\n~Data Dec\r\n~Data Dec\r\nData Jan\r\nData Feb\r\nData Mar\r\nData Apr\r\nData May\r\n‚Ä¶\r\nModel update Model update Model update\r\nCheck if \r\ndata change\r\nCheck if \r\ndata change\r\nCheck if \r\ndata change\r\nModel update\r\nBlind Adaptation\r\nThe AI Model will be \r\nupdated fewer times and \r\nonly when necessary.\r\nKnow when to retrain models\r\nNeither too early nor too late\r\n37\r\nAdaptation Techniques\r\n?\r\n\r\nGreen Architectural Tactics for ML-Enabled \r\nSystem\r\n38\r\nICSE-SEIS 2024\r\n\r\nArchitectural tactics\r\n39\r\n\r\nData-centric\r\n40\r\n‚Ä¢ Reduce data size \r\n‚Ä¢ Sampling \r\n‚Ä¢ Dimensionality reduction \r\n‚Ä¢ Quantization\r\n\r\nAlgorithm Design\r\n41\r\n‚Ä¢ Carefully select your algorithm \r\n‚Ä¢ You don‚Äôt need the fanciest \r\ntechniques\r\n\r\nModel Optimization\r\n42\r\n‚Ä¢ Add energy to training parameters \r\n‚Ä¢ Reduce FLOPs \r\n‚Ä¢ Pruning, sparsity \r\n‚Ä¢  Take advantage of existing models\r\n\r\nModel Training\r\n43\r\n‚Ä¢ Quantization\r\n‚Ä¢ SAVE TRAINING PROGRESS\r\n\r\nModel Deployment\r\n44\r\n‚Ä¢ Distributed deployment \r\n‚Ä¢ Energy efficient hardware and \r\nconfigurations\r\n\r\nModel Management\r\n45\r\n‚Ä¢ Reuse the model as much as possible \r\n\r\nRethinking the Architecture: Spiking Neural Networks\r\n46\r\n\r\nRethinking the Architecture: Spiking Neural Networks\r\n47\r\n\r\nSELF Lab\r\n48\r\n\r\nrecap"", 'McCulloch-Pitts neuron [1, 2]\r\n1940s: How do biological neurons compute basic \r\nlogic functions? (e.g. logic gates)\r\nNote: Ref. [3] gives a nice brief history on the ideas which lead to the \r\nMcCulloch-Pitts neuron.\r\n\r\nWhat is a neural network?\r\n1950s: How are neurons organized to perform \r\nsensory perception?\r\n\r\nWhat is a neural network?\r\n1950s: How are neurons organized to perform \r\nsensory perception?\r\nThe first ""neural network"": Perceptron (1958). [4]\r\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\r\nFrank Rosenblatt (Psychologist)\r\nwith a Mark I Perceptron computer in 1960\r\n\r\nWhat is a neural network?\r\n1950s: How are neurons organized to perform \r\nsensory perception?\r\nThe first ""neural network"": Perceptron (1958). [4]\r\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\r\nFrank Rosenblatt (Psychologist)\r\nwith a Mark I Perceptron computer in 1960\r\nPower-efficient\r\n\r\nNeuromorphic computing\r\nWhy neuromorphic computing?\r\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\r\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\r\n\r\nNeuromorphic computing\r\nWhy neuromorphic computing?\r\n‚ÄòBiological inspiration‚Äô for artificial neural networks (ANNs) is not a new idea.\r\nEmulation (as opposed to simulation) of neural networks in hardware is not a new idea.\r\nQuestion: What can we gain from increasing biological realism in existing neural networks?\r\n\r\nPower-efficiency at scale\r\nModern, deep neural networks*\r\nare trained using GPUs.\r\n* It is estimated that ChatGPT was trained on \r\n10,000-20,000 GPUs and that it will require\r\n30,000 GPUs to keep running stably in the future.\r\n* It is estimated that ChatGPT has 10-20 billion \r\nparameters.\r\nhttps://www.anandtech.com/show/4008/nvidias-geforce-gtx-580/17\r\n\r\nPower-efficiency at scale\r\nModern, deep neural networks*\r\nare trained using GPUs.\r\n* It is estimated that ChatGPT was trained on \r\n10,000-20,000 GPUs and that it will require\r\n30,000 GPUs to keep running stably in the future.\r\n* It is estimated that ChatGPT has 10-20 billion \r\nparameters.\r\nSingle model with 20 billion parameters:\r\n200 Watts x 30,000 GPUs = 6M Watts\r\n\r\nPower-efficiency at scale\r\nhttps://hai.stanford.edu/ai-index/2024-ai-index-report\r\nTraining a single large language model can \r\ngenerate greater CO2 emissions than the \r\ntotal lifetime emissions of 8 cars (in 2020)!\r\n\r\nPower-efficiency at scale\r\nhttps://hai.stanford.edu/ai-index/2024-ai-index-report\r\nTraining a single model can consume \r\nmore than 1000 MWh of power!\r\n\r\nPower-efficiency at scale\r\nhttps://hai.stanford.edu/ai-index/2024-ai-index-report\r\nTraining a single model can consume \r\nmore than 1000 MWh of power!\r\n‚Ä¶ with energy costs reaching 200M USD!\r\n\r\nPower-efficiency at scale\r\nYour brain runs on:\r\n\r\nPower-efficiency at scale\r\nYour brain runs on:\r\nHigh estimate ~3000 kcal a day\r\n   ‚âà145 Watts\r\n* Human brain has ~600 trillion synapses \r\n(‚âàparameters).', 'Different encoding strategies with spiking neurons\r\n\r\nDifferent encoding strategies with spiking neurons\r\nUsing latency or spatio-temporal codes\r\nour encoding is faster and more spike-efficient (sparser)!\r\n\r\nDifferent encoding strategies with spiking neurons\r\nUsing latency or spatio-temporal codes\r\nour encoding is faster and more spike-efficient (sparser)!\r\nQuestions?\r\n\r\nNeuromorphic computing\r\nWhat is the advantage for applications?\r\n-\r\nLess spikes = less energy consumption in specialized neuromorphic hardware\r\n(e.g. Intel Loihi [12])\r\nBrains are energy efficient: \r\n2. Sparse encoding\r\n\r\nMultiply-accumulate (MAC) operations:\r\nNormal neuron: Multiplies input with \r\nweights, then adds.\r\nSpiking neuron: Consider binary input (e.g. input currents are piecewise \r\nconstant and assume values {0,1}). There is no multiplication, only addition.\r\n\r\nAssume one multiplier and one adder circuit uses M and A energy respectively with AÔπ§M\r\n(e.g., for a 45nm CMOS process, standard energy usage is A = 0.9 pJ and M = 3.7 pJ).\r\nNormal neuron: nin x nout multiplications,\r\n(nin‚Äì 1) x nout additions\r\nSpiking neuron: 0 multiplications, (nactive‚Äì 1) x nout \r\nadditions, with nactive ‚â§ nin\r\nEnergy consumption:\r\nEnormal = M nin nout + A (nin‚Äì 1) nout = 17.5 pJ\r\nEnergy consumption:\r\nEspiking = A (nactive‚Äì 1) nout = 2.7 pJ\r\nMultiply-accumulate (MAC) operations:\r\n\r\nAssume one multiplier and one adder circuit uses M and A energy respectively with AÔπ§M\r\n(e.g., for a 45nm CMOS process, standard energy usage is A = 0.9 pJ and M = 3.7 pJ).\r\nNormal neuron: nin x nout multiplications,\r\n(nin‚Äì 1) x nout additions\r\nSpiking neuron: 0 multiplications, (nactive‚Äì 1) x nout \r\nadditions, with nactive ‚â§ nin\r\nEnergy consumption:\r\nEnormal = M nin nout + A (nin‚Äì 1) nout = 17.5 pJ\r\nEnergy consumption:\r\nEspiking = A (nactive‚Äì 1) nout = 2.7 pJ\r\nMultiply-accumulate (MAC) operations:\r\nSNN challenge: how to \r\ncompute with the least \r\namount of spikes!\r\n\r\nOften, we observe a \r\nsparsity (energy)-\r\ntask accuracy trade-off\r\n(Left: results for image \r\nclassification)\r\nSNN challenge: how to \r\ncompute with the least \r\namount of spikes!\r\nhttps://arxiv.org/pdf/2409.08290\r\n\r\nIn practice, energy \r\nconsumption computations \r\nare complex. \r\nNeed to take into account\r\n- memory access,\r\n- addressing,\r\n- auxiliary operations,\r\nin addition to MACs.\r\nEstimated energy consumption for 3 different datasets (CIFAR10, GSC, NCARS; image, sound \r\nand video classification respectively). FNN‚Äôs are conventional feed-forward neural networks.\r\nIn this example: SNNs are 6 to 8 times more energy efficient than FNNs.\r\nhttps://arxiv.org/pdf/2210.13107\r\nComputing energy consumption\r\n\r\nIn practice, energy \r\nconsumption computations \r\nare complex. \r\nNeed to take into account\r\n- memory access,\r\n- addressing,\r\n- auxiliary operations,\r\nin addition to MACs.\r\nEstimated energy consumption for 3 different datasets (CIFAR10, GSC, NCARS; image, sound \r\nand video classification respectively). FNN‚Äôs are conventional feed-forward neural networks.\r\nIn this example: SNNs are 6 to 8 times more energy efficient than FNNs.', 'Normal neuron: nin x nout multiplications,\r\n(nin‚Äì 1) x nout additions\r\nSpiking neuron: 0 multiplications, (nactive‚Äì 1) x nout \r\nadditions, with nactive ‚â§ nin\r\nEnergy consumption:\r\nEnormal = M nin nout + A (nin‚Äì 1) nout = 17.5 pJ\r\nEnergy consumption:\r\nEspiking = A (nactive‚Äì 1) nout = 2.7 pJ\r\nMultiply-accumulate (MAC) operations:\r\nSNN challenge: how to \r\ncompute with the least \r\namount of spikes!\r\n\r\nOften, we observe a \r\nsparsity (energy)-\r\ntask accuracy trade-off\r\n(Left: results for image \r\nclassification)\r\nSNN challenge: how to \r\ncompute with the least \r\namount of spikes!\r\nhttps://arxiv.org/pdf/2409.08290\r\n\r\nIn practice, energy \r\nconsumption computations \r\nare complex. \r\nNeed to take into account\r\n- memory access,\r\n- addressing,\r\n- auxiliary operations,\r\nin addition to MACs.\r\nEstimated energy consumption for 3 different datasets (CIFAR10, GSC, NCARS; image, sound \r\nand video classification respectively). FNN‚Äôs are conventional feed-forward neural networks.\r\nIn this example: SNNs are 6 to 8 times more energy efficient than FNNs.\r\nhttps://arxiv.org/pdf/2210.13107\r\nComputing energy consumption\r\n\r\nIn practice, energy \r\nconsumption computations \r\nare complex. \r\nNeed to take into account\r\n- memory access,\r\n- addressing,\r\n- auxiliary operations,\r\nin addition to MACs.\r\nEstimated energy consumption for 3 different datasets (CIFAR10, GSC, NCARS; image, sound \r\nand video classification respectively). FNN‚Äôs are conventional feed-forward neural networks.\r\nIn this example: SNNs are 6 to 8 times more energy efficient than FNNs.\r\nComputing energy consumption\r\nQuestions?\r\n\r\nReading materials\r\nMain reading:\r\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \r\nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\r\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\r\n- Neuromorphic computing:\r\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \r\nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\r\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \r\noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\r\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019.', ""Oversimplification\r\nThere are also multiple other advantages‚Ä¶\r\n\r\nHuman vs. computer computation\r\n- Fast real-time decision making, e.g. sports, e-sports\r\n- Adaptive, e.g. context-aware and employs selective attention\r\n- Energy efficient: Close to 100 billion neurons in the brain\r\n- Robust, for example to changes in illumination or obstructions in object tracking\r\n\r\nHuman vs. computer computation\r\nBrains are energy efficient: Why?\r\n1.\r\nHigh temporal resolution (more computation with less neurons)\r\n2.\r\nSparse encoding\r\n\r\nHuman vs. computer computation\r\nQuestions?\r\nBrains are energy efficient: Why?\r\n1.\r\nHigh temporal resolution (more computation with less neurons)\r\n2.\r\nSparse encoding\r\n\r\nHow do biological neurons communicate?\r\nAnalogy to artificial neural networks\r\nReal neuron\r\nArtificial neuron\r\nCurrent\r\n\r\nHow do biological neurons communicate?\r\nHow does the electrical activity propagate?\r\n?\r\nCurrent\r\n\r\nHow do biological neurons work?\r\ntime\r\nelectrode\r\nhttps://tinmard.github.io/spike-sorting-animation.html\r\nQuick electrical pulses trigger chemical signals for the next neuron ‚Üí Spikes\r\n\r\nHow do biological neurons work?\r\nQuick electrical pulses trigger chemical signals for the next neuron ‚Üí Spikes\r\nhttps://tinmard.github.io/spike-sorting-animation.html\r\ntime\r\nelectrode\r\nFrom CS perspective:\r\nSparse binary \r\nencoding\r\n\r\nBiologically realistic spiking neuron models\r\nBiologically realistic neuron models have \r\na new dimension: Time!\r\nSpiking neural networks (SNNs):\r\nThe input x  (t  ) to each neuron is summed \r\n(integrated) over time.\r\nscalar\r\nfunction of \r\ntime\r\n(t)\r\n(t)\r\nhttps://www.mdpi.com/2076-3425/12/7/863\r\n\r\nHow to model spiking neurons?\r\nANN: Perceptron, threshold activation function:\r\n\r\nHow to model spiking neurons?\r\nANN: Perceptron, threshold activation function:\r\n\r\nHow to model spiking neurons?\r\nSpiking neural network (SNN): The 'input current' Œµ(t) is integrated over time.\r\nspike\r\n\r\nHow to model spiking neurons?\r\nEquivalence to perceptron: Computation at least as complex as a perceptron.\r\n\r\nNon-leaky integrate-and-fire (IF) neuron\r\nThe temporal profile of the input current Œµ(t) can be chosen differently, for different computations.\r\n\r\nQuestions?\r\n\r\nComputation with spiking neurons\r\nCoincidence detection\r\n\r\nComputation with spiking neurons\r\nCoincidence detection\r\nx, y ‚àà {0, 1}n\r\nExample: n = 2\r\ninput = \r\nx1\r\nx2\r\ny1\r\ny2\r\n= \r\n0\r\n1\r\n1\r\n1\r\noutput? \r\n\r\nCoincidence detection\r\nComputation with spiking neurons\r\n\r\nCoincidence detection\r\nCan be trivially computed with a single spiking neuron! Requires at least n/log(n+1) hidden \r\nunits for a perceptron (proof in [7]).\r\nComputation with spiking neurons\r\n\r\nCoincidence detection\r\nCan be trivially computed with a single spiking neuron! Requires at least n/log(n+1) hidden \r\nunits for a perceptron (proof in [7]).\r\nBrains are energy efficient: \r\n1.\r\nHigh temporal resolution (more computation with less neurons)\r\nComputation with spiking neurons\r\n\r\nEncoding strategies\r\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\r\nHow should we encode information about 'features' in a large network with many spikes?\r\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\r\nElephant?\r\nhttps://www.nationalgeographic.com/anim\r\nals/mammals/facts/african-elephant\r\n\r\nFiring rates\r\nClassical view of the brain:\r\n- Each neuron is selective for one specific \r\nfeature in the input."", 'In this example: SNNs are 6 to 8 times more energy efficient than FNNs.\r\nComputing energy consumption\r\nQuestions?\r\n\r\nReading materials\r\nMain reading:\r\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \r\nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\r\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\r\n- Neuromorphic computing:\r\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \r\nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\r\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \r\noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\r\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \r\nhttps://www.nature.com/articles/s41586-019-1677-2\r\nExtra reading:\r\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \r\nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\r\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \r\nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \r\nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\r\nBasics of \'conventional\' neural networks:\r\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\r\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.\r\n\r\nReferences\r\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \r\nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\r\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947.', ""- Higher firing rate (spikes per unit time) for \r\n'selected' feature.\r\nAdapted from Hubel & Wiesel, 1959\r\n\r\nFiring rates\r\nClassical view of the brain:\r\n- Each neuron is selective for one specific \r\nfeature in the input.\r\n- Higher firing rate (spikes per unit time) for \r\n'selected' feature.\r\n- Link to modern ANNs: The scalar output of \r\nan artificial neuron is interpreted as the firing \r\nrate.\r\nAdapted from Hubel & Wiesel, 1959\r\n\r\nFiring rates\r\nClassical view of the brain:\r\n- Each neuron is selective for one specific \r\nfeature in the input.\r\n- Higher firing rate (spikes per unit time) for \r\n'selected' feature.\r\n- Link to modern ANNs: The scalar output of \r\nan artificial neuron is interpreted as the firing \r\nrate.\r\nAdapted from Hubel & Wiesel, 1959\r\nBut rate coding is inefficient and slow‚Ä¶\r\n(i.e. each neuron needs to fire many spikes to get good precision)\r\nboth in vivo and in silico.\r\n\r\nDifferent encoding strategies with spiking neurons [8]\r\n7 neurons\r\n7 time bins\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nn\r\n6\r\n(in the general \r\ncase a \r\nnumber \r\nbetween 0-7)\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nn\r\nTotal spike \r\ncount can \r\nencode 3 bits.\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nIndividual rates \r\ncan encode 7 \r\nbits.\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nLatency can \r\nencode ~3*7 or \r\n~19 bits.\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nRank order can \r\nencode ~12 bits.\r\n\r\nDifferent encoding strategies with spiking neurons\r\n\r\nDifferent encoding strategies with spiking neurons\r\nUsing latency or spatio-temporal codes\r\nour encoding is faster and more spike-efficient (sparser)!\r\n\r\nDifferent encoding strategies with spiking neurons\r\nUsing latency or spatio-temporal codes\r\nour encoding is faster and more spike-efficient (sparser)!\r\nQuestions?\r\n\r\nNeuromorphic computing\r\nWhat is the advantage for applications?\r\n-\r\nLess spikes = less energy consumption in specialized neuromorphic hardware\r\n(e.g. Intel Loihi [12])\r\nBrains are energy efficient: \r\n2. Sparse encoding\r\n\r\nMultiply-accumulate (MAC) operations:\r\nNormal neuron: Multiplies input with \r\nweights, then adds.\r\nSpiking neuron: Consider binary input (e.g. input currents are piecewise \r\nconstant and assume values {0,1}). There is no multiplication, only addition.\r\n\r\nAssume one multiplier and one adder circuit uses M and A energy respectively with AÔπ§M\r\n(e.g., for a 45nm CMOS process, standard energy usage is A = 0.9 pJ and M = 3.7 pJ).\r\nNormal neuron: nin x nout multiplications,\r\n(nin‚Äì 1) x nout additions\r\nSpiking neuron: 0 multiplications, (nactive‚Äì 1) x nout \r\nadditions, with nactive ‚â§ nin\r\nEnergy consumption:\r\nEnormal = M nin nout + A (nin‚Äì 1) nout = 17.5 pJ\r\nEnergy consumption:\r\nEspiking = A (nactive‚Äì 1) nout = 2.7 pJ\r\nMultiply-accumulate (MAC) operations:\r\n\r\nAssume one multiplier and one adder circuit uses M and A energy respectively with AÔπ§M\r\n(e.g., for a 45nm CMOS process, standard energy usage is A = 0.9 pJ and M = 3.7 pJ)."", '9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\r\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \r\nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\r\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \r\n(not publicly available) doi:10.1037/h0042519\r\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \r\nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\r\n6) https://github.com/idsc-frazzoli/retina\r\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \r\nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\r\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \r\nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\r\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \r\nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\r\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \r\nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\r\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \r\nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\r\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\r\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\r\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \r\n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568', 'Power-efficiency at scale\r\nModern, deep neural networks*\r\nare trained using GPUs.\r\n* It is estimated that ChatGPT was trained on \r\n10,000-20,000 GPUs and that it will require\r\n30,000 GPUs to keep running stably in the future.\r\n* It is estimated that ChatGPT has 10-20 billion \r\nparameters.\r\nhttps://www.anandtech.com/show/4008/nvidias-geforce-gtx-580/17\r\n\r\nPower-efficiency at scale\r\nModern, deep neural networks*\r\nare trained using GPUs.\r\n* It is estimated that ChatGPT was trained on \r\n10,000-20,000 GPUs and that it will require\r\n30,000 GPUs to keep running stably in the future.\r\n* It is estimated that ChatGPT has 10-20 billion \r\nparameters.\r\nSingle model with 20 billion parameters:\r\n200 Watts x 30,000 GPUs = 6M Watts\r\n\r\nPower-efficiency at scale\r\nhttps://hai.stanford.edu/ai-index/2024-ai-index-report\r\nTraining a single large language model can \r\ngenerate greater CO2 emissions than the \r\ntotal lifetime emissions of 8 cars (in 2020)!\r\n\r\nPower-efficiency at scale\r\nhttps://hai.stanford.edu/ai-index/2024-ai-index-report\r\nTraining a single model can consume \r\nmore than 1000 MWh of power!\r\n\r\nPower-efficiency at scale\r\nhttps://hai.stanford.edu/ai-index/2024-ai-index-report\r\nTraining a single model can consume \r\nmore than 1000 MWh of power!\r\n‚Ä¶ with energy costs reaching 200M USD!\r\n\r\nPower-efficiency at scale\r\nYour brain runs on:\r\n\r\nPower-efficiency at scale\r\nYour brain runs on:\r\nHigh estimate ~3000 kcal a day\r\n   ‚âà145 Watts\r\n* Human brain has ~600 trillion synapses \r\n(‚âàparameters).\r\n\r\nPower-efficiency at scale\r\nYour brain runs on:\r\nHigh estimate ~3000 kcal a day\r\n   ‚âà145 Watts\r\n* Human brain has ~600 trillion synapses \r\n(‚âàparameters).\r\nOversimplification\r\nThere are also multiple other advantages‚Ä¶\r\n\r\nHuman vs. computer computation\r\n- Fast real-time decision making, e.g. sports, e-sports\r\n- Adaptive, e.g. context-aware and employs selective attention\r\n- Energy efficient: Close to 100 billion neurons in the brain\r\n- Robust, for example to changes in illumination or obstructions in object tracking\r\n\r\nHuman vs. computer computation\r\nBrains are energy efficient: Why?\r\n1.\r\nHigh temporal resolution (more computation with less neurons)\r\n2.\r\nSparse encoding\r\n\r\nHuman vs. computer computation\r\nQuestions?\r\nBrains are energy efficient: Why?\r\n1.\r\nHigh temporal resolution (more computation with less neurons)\r\n2.\r\nSparse encoding\r\n\r\nHow do biological neurons communicate?\r\nAnalogy to artificial neural networks\r\nReal neuron\r\nArtificial neuron\r\nCurrent\r\n\r\nHow do biological neurons communicate?\r\nHow does the electrical activity propagate?\r\n?\r\nCurrent\r\n\r\nHow do biological neurons work?\r\ntime\r\nelectrode\r\nhttps://tinmard.github.io/spike-sorting-animation.html\r\nQuick electrical pulses trigger chemical signals for the next neuron ‚Üí Spikes\r\n\r\nHow do biological neurons work?\r\nQuick electrical pulses trigger chemical signals for the next neuron ‚Üí Spikes\r\nhttps://tinmard.github.io/spike-sorting-animation.html\r\ntime\r\nelectrode\r\nFrom CS perspective:\r\nSparse binary \r\nencoding\r\n\r\nBiologically realistic spiking neuron models\r\nBiologically realistic neuron models have \r\na new dimension: Time!\r\nSpiking neural networks (SNNs):\r\nThe input x  (t  ) to each neuron is summed \r\n(integrated) over time.\r\nscalar\r\nfunction of \r\ntime\r\n(t)\r\n(t)\r\nhttps://www.mdpi.com/2076-3425/12/7/863\r\n\r\nHow to model spiking neurons?', ""Spiking neural network (SNN): The 'input current' Œµ(t) is integrated over time.\r\nspike\r\n\r\nHow to model spiking neurons?\r\nEquivalence to perceptron: Computation at least as complex as a perceptron.\r\n\r\nNon-leaky integrate-and-fire (IF) neuron\r\nThe temporal profile of the input current Œµ(t) can be chosen differently, for different computations.\r\n\r\nQuestions?\r\n\r\nComputation with spiking neurons\r\nCoincidence detection\r\n\r\nComputation with spiking neurons\r\nCoincidence detection\r\nx, y ‚àà {0, 1}n\r\nExample: n = 2\r\ninput = \r\nx1\r\nx2\r\ny1\r\ny2\r\n= \r\n0\r\n1\r\n1\r\n1\r\noutput? \r\n\r\nCoincidence detection\r\nComputation with spiking neurons\r\n\r\nCoincidence detection\r\nCan be trivially computed with a single spiking neuron! Requires at least n/log(n+1) hidden \r\nunits for a perceptron (proof in [7]).\r\nComputation with spiking neurons\r\n\r\nCoincidence detection\r\nCan be trivially computed with a single spiking neuron! Requires at least n/log(n+1) hidden \r\nunits for a perceptron (proof in [7]).\r\nBrains are energy efficient: \r\n1.\r\nHigh temporal resolution (more computation with less neurons)\r\nComputation with spiking neurons\r\n\r\nEncoding strategies\r\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\r\nHow should we encode information about 'features' in a large network with many spikes?\r\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\r\nElephant?\r\nhttps://www.nationalgeographic.com/anim\r\nals/mammals/facts/african-elephant\r\n\r\nFiring rates\r\nClassical view of the brain:\r\n- Each neuron is selective for one specific \r\nfeature in the input.\r\n- Higher firing rate (spikes per unit time) for \r\n'selected' feature.\r\nAdapted from Hubel & Wiesel, 1959\r\n\r\nFiring rates\r\nClassical view of the brain:\r\n- Each neuron is selective for one specific \r\nfeature in the input.\r\n- Higher firing rate (spikes per unit time) for \r\n'selected' feature.\r\n- Link to modern ANNs: The scalar output of \r\nan artificial neuron is interpreted as the firing \r\nrate.\r\nAdapted from Hubel & Wiesel, 1959\r\n\r\nFiring rates\r\nClassical view of the brain:\r\n- Each neuron is selective for one specific \r\nfeature in the input.\r\n- Higher firing rate (spikes per unit time) for \r\n'selected' feature.\r\n- Link to modern ANNs: The scalar output of \r\nan artificial neuron is interpreted as the firing \r\nrate.\r\nAdapted from Hubel & Wiesel, 1959\r\nBut rate coding is inefficient and slow‚Ä¶\r\n(i.e. each neuron needs to fire many spikes to get good precision)\r\nboth in vivo and in silico.\r\n\r\nDifferent encoding strategies with spiking neurons [8]\r\n7 neurons\r\n7 time bins\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nn\r\n6\r\n(in the general \r\ncase a \r\nnumber \r\nbetween 0-7)\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nn\r\nTotal spike \r\ncount can \r\nencode 3 bits.\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nIndividual rates \r\ncan encode 7 \r\nbits.\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nLatency can \r\nencode ~3*7 or \r\n~19 bits.\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nRank order can \r\nencode ~12 bits."", '8. Green AI\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nLu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\nCarolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl\r\n\r\n- Overview of Green AI \r\n- Large language models \r\n- Green data-centric AI \r\n- Model simplification \r\n- Hyper parameter tuning \r\n- Mixture of Experts and DeepSeek \r\n- Green AI at Meta \r\n\r\nAI\r\n‚Ä¢ Artificial Intelligence (AI) is the branch of computer science that deals with \r\nautomating tasks that typically require human intelligence. \r\n‚Ä¢ In the past years AI has been widely applied across different domains.\u2028\r\nE.g., health care, transportation, finance. \r\n‚Ä¢ To deploy AI systems, we test them against benchmarks (or validation sets). \r\n‚Ä¢ The goal is to outperform the previous existing models. \r\n‚Ä¢ E.g., in Machine Learning we usually resort to accuracy metrics. The \r\nhighest the accuracy, the better the model.\r\n3\r\n\r\nSince 2012, the amount of computing used for AI \r\ntraining has been doubling every 6 months\r\n‚Ä¢ https://epoch.ai/blog/compute-trends\r\n4\r\n\r\n‚Ä¢ To create better AI systems we are currently adding \r\n‚Ä¢ More data \r\n‚Ä¢ More experiments \r\n‚Ä¢ Larger models\r\n5\r\n\r\nThe Equation of Red AI\r\nCost(R) ‚àùE¬∑D¬∑H\r\nCost of a single (E)xample\r\nSize of (D)ataset\r\nNumber of (H)yperparameters\r\nBy Schwartz et al. (2020)\r\n\r\nIssues of Red AI\r\n‚Ä¢ High costs (hardware, electricity, data access, etc.) \r\n‚Ä¢ Limited reproducibility.  \r\n‚Ä¢ Energy consumption. \r\n‚Ä¢ Carbon emissions. \r\n‚Ä¢ SMEs can hardly be competitive. \r\n‚Ä¢ Groundbreaking AI research is mostly done by tech giants.\r\n7\r\n\r\nA few examples of Red AI\r\n‚Ä¢ Google‚Äôs BERT-large \r\n‚Ä¢ 350 million features \r\n‚Ä¢ Trained for 2.5 days using 512 TPU chips, costing $60K+ \r\n‚Ä¢ Open-GPT3 (now GPT-4/o1) \r\n‚Ä¢ 550 tonnes CO2-eq (Patterson, 2021) \r\n‚Ä¢ 175 billion features \r\n‚Ä¢ API is open but no-pretrained model is available \r\n‚Ä¢ AlphaGo \r\n‚Ä¢ 1920 CPUs, 280 GPUs, costing $35M\r\n8\r\n\r\nRed AI in Large Language Models (LLMs)\r\n‚Ä¢ OPT by Meta reports 75 tons CO2-eq (1/7 of OpenGPT‚Äôs footprint).\u2028\r\n(Also 175billion params) \r\n‚Ä¢ However, Llama 3 reported 2,290 tons of CO2-eq (7.7M GPU hours \r\ntraining ) \r\n‚Ä¢ Open science: release includes both the pretrained models and the code \r\nneeded to train and use them. \r\n‚Ä¢ DeepSeek-V3 claims ‚Äúonly‚Äù 2.78M GPU hours \r\n‚Ä¢ Bloom by Huggingface reports 25 tons, 51 when considering embodied \r\nand operational carbon footprint. (176billion params)\r\n9\r\n\r\nRed AI\r\nAccuracy: 0.999999999\r\nGreen AI\r\n‚Ä¢ Energy \r\n‚Ä¢ Time \r\n‚Ä¢ Reproducibility \r\n‚Ä¢ Reusage\r\n\r\nHow can we adopt Green AI\r\n‚Ä¢ Check whether AI is needed. \r\n‚Ä¢ Select green datacenters. \r\n‚Ä¢ Run on low carbon intensity hours. \r\n‚Ä¢ Opt for GPU-optimised solutions (?) \r\n‚Ä¢ Opt for low-power hardware (e.g., Nvidia Jetson boards) \r\n‚Ä¢ Or GPUs that provide energy metrics (e.g., NVIDIA GPUs via the nvidia-smi tool) \r\n‚Ä¢ Report energy/carbon metrics (e.g., embed in MLFlow?)', 'Neuromorphic computing\r\nCS4575\r\nSustainable Software Engineering\r\n05.03.2025\r\nNergis T√∂men\r\n\r\nIntroduction\r\nComputer Vision Lab\r\nBiomorphic Intelligence Lab\r\nBiomedical Intervention Optimisation Lab\r\nNergis\r\n\r\nNeuromorphic computing\r\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\r\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\r\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing\r\n\r\nHow many of you are familiar \r\nwith neural networks?\r\n\r\nSimple model of an artificial neuron\r\nhttps://medium.com/@cprasenjit32/perceptron-a-simple-yet-mighty-machine-learning-algorithm-9ff6b7d86a71\r\n\r\nWhat is a neural network?\r\nhttps://www.tibco.com/reference-center/what-is-a-neural-network\r\n\r\nWhy is it called a \'neural network\'?\r\nhttps://www.tibco.com/reference-center/what-is-a-neural-network\r\n\r\nWhat is a neural network?\r\nWhy is it called a \'neural network\'?\r\nMcCulloch-Pitts neuron [1, 2] (1943)\r\nWarren Sturgis McCulloch\r\n(Neurophysiologist)\r\nWalter Pitts\r\n(Logician)\r\n\r\nHow do biological neurons work?\r\nhttps://commons.wikimedia.org/wiki/File:Coincidence_detection_in_dendrites_of_pyramidal_neurons.gif\r\n\'Input current\' travels down the dendrites (top),\r\nget integrated (summed!) in the cell body\r\nwhich generates an \'output current\' (bottom)\r\nwhich is chemically transmitted to the dendrites of \r\nother neurons.\r\n\r\nSimplified picture\r\nReal neuron\r\nArtificial neuron\r\nhttps://vajiramandravi.com/quest-upsc-notes/artificial-neural-network/\r\n\r\nWhat is a neural network?\r\nMcCulloch-Pitts neuron [1, 2]\r\n1940s: How do biological neurons compute basic \r\nlogic functions? (e.g. logic gates)\r\nNote: Ref. [3] gives a nice brief history on the ideas which lead to the \r\nMcCulloch-Pitts neuron.\r\n\r\nWhat is a neural network?\r\n1950s: How are neurons organized to perform \r\nsensory perception?\r\n\r\nWhat is a neural network?\r\n1950s: How are neurons organized to perform \r\nsensory perception?\r\nThe first ""neural network"": Perceptron (1958). [4]\r\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\r\nFrank Rosenblatt (Psychologist)\r\nwith a Mark I Perceptron computer in 1960\r\n\r\nWhat is a neural network?\r\n1950s: How are neurons organized to perform \r\nsensory perception?\r\nThe first ""neural network"": Perceptron (1958). [4]\r\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\r\nFrank Rosenblatt (Psychologist)\r\nwith a Mark I Perceptron computer in 1960\r\nPower-efficient\r\n\r\nNeuromorphic computing\r\nWhy neuromorphic computing?\r\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\r\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\r\n\r\nNeuromorphic computing\r\nWhy neuromorphic computing?\r\n‚ÄòBiological inspiration‚Äô for artificial neural networks (ANNs) is not a new idea.\r\nEmulation (as opposed to simulation) of neural networks in hardware is not a new idea.', ""‚Ä¢ 6 machine learning algorithms: SVM, Decision Tree, KNN, Random Forrest, \r\nAdaBoost, Bagging Classifier. \r\n‚Ä¢ Reduce the number of rows. 10%, 20%, .., 100% \r\n‚Ä¢ Stratified random sampling (?) \r\n‚Ä¢ Reduce the number of features. 10%, 20%, .., 100% \r\n‚Ä¢ Feature importance metric based on the Chi-Square Test (Chi2) \r\n‚Ä¢ Estimate energy consumption using a RAPL-based tool. (?)\r\n18\r\n\r\n‚Ä¢ Repeat 30 times \r\n‚Ä¢ Fix random seeds \r\n‚Ä¢ ‚Ä¶ \r\n‚Ä¢ Data was not Normal => tailed Normal distribution.\r\n19\r\n(?)\r\n\r\nResults: energy consumption of algorithms\r\n\r\nResults: energy vs data shape\r\n\r\nResults: performance vs data shape\r\n\r\nDiscussion\r\n‚Ä¢ Other data properties should be investigated. \r\n‚Ä¢ E.g., data types \r\n‚Ä¢ Reporting energy data is essential. It can lead to different model selection \r\nwithout hindering model performance. \r\n‚Ä¢ There is a big opportunity in Model and Data Simplification.\r\n23\r\n\r\nData/Model Simplification\r\n‚Ä¢ (?) \r\n‚Ä¢ Data selection \r\n‚Ä¢ Data quantisation. Posit? \r\n‚Ä¢ Data distillation \r\n‚Ä¢ Coreset extraction (?) \r\n‚Ä¢ Model distillation \r\n‚Ä¢ Model quantisation \r\n‚Ä¢ Model pruning \r\n‚Ä¢ ‚Ä¶\r\n24\r\n\r\nPosit vs Float\r\nMore about this: https://spectrum.ieee.org/floating-point-numbers-posits-processor\r\nBetter for DL use cases\r\n\r\nHow can we tune \r\nlearning \r\nparameters \r\nefficiently?\r\n\r\nHyper parameter tuning\r\n‚Ä¢ When training an ML model, there are several parameters that need to be \r\ntuned. \r\n‚Ä¢ E.g., in SVM we have the Regularization parameter C, the kernel function, \r\nthe degree of the kernel function, and depending on the case, many other. \r\n‚Ä¢ The common approach revolves around grid search. The user provides a \r\nsequence of possible values for each parameter and the pipeline runs all \r\npossible combinations. \r\n‚Ä¢ Our question: Can we save energy with alternative approaches? \r\n‚Ä¢ We studied Grid Search, Random Search and Bayesian \r\nOptimisation.\r\n27\r\nTim's MSc Thesis, 2022 \r\nAccepted at CAIN‚Äô23\r\n\r\n\r\nResults\r\n29\r\nConclusions? \r\n‚Ä¢ Bayesian converges faster. \r\n‚Ä¢ No clear winner between Grid and Random\r\n\r\nDeepSeekMoE\r\n30\r\nPreprint at ArXiv, 2024 https://arxiv.org/pdf/\r\n2401.06066\r\n\r\nMixture of Experts\r\n‚Ä¢ Llama3.1 has 405B parameters, DeepSeek V3 671B \r\n‚Ä¢ Yet DeepSeek has quicker inference times and claims less energy \r\nconsumption (?) \r\n‚Ä¢ Divide the model into smaller blocks of experts \r\n‚Ä¢ Tokens get routed to certain experts based on the query \r\n‚Ä¢ Only part of the network is active during inference \r\n‚Ä¢ DeepSeek claims only 37B out of 671B parameters get active\r\n31\r\n\r\nDeepSeekMoE\r\n32\r\n\r\nDeepSeekMoE\r\n33\r\n‚Ä¢ Comparable performance to \r\nLLaMA2 7B effectively using \r\nless half the parameters \r\n‚Ä¢ Less computational power \r\n‚Ä¢ Problems (?) \r\n‚Ä¢ Still need to load all the \r\nparameters \r\n‚Ä¢ High memory -> high \r\nembodied carbon\r\n\r\nGreen AI at FacebookMeta\r\n34\r\nSustainable AI: Environmental Implications, \r\nChallenges and Opportunities (2022)\r\n\r\nCarbon footprint mapped to the AI lifecycle\r\n‚Ä¢ There are 4 main overarching stages where carbon emissions need to be isolated: data \r\ncollection, experimentation, training, inference. \r\n‚Ä¢ At Facebook, recommendation systems split energy consumption evenly between \r\ntraining and inference; text translation models have a 35%/65% split. (Operational cost) \r\n‚Ä¢ Operational/embodied cost split: 30%/70%\r\n35\r\n\r\nOpen issues according to Meta\r\n‚Ä¢ A vast portion of projects only use GPUs at 30%.\u2028\r\nShould be higher to attenuate embodied carbon."", '‚Ä¢ Groundbreaking AI research is mostly done by tech giants.\r\n7\r\n\r\nA few examples of Red AI\r\n‚Ä¢ Google‚Äôs BERT-large \r\n‚Ä¢ 350 million features \r\n‚Ä¢ Trained for 2.5 days using 512 TPU chips, costing $60K+ \r\n‚Ä¢ Open-GPT3 (now GPT-4/o1) \r\n‚Ä¢ 550 tonnes CO2-eq (Patterson, 2021) \r\n‚Ä¢ 175 billion features \r\n‚Ä¢ API is open but no-pretrained model is available \r\n‚Ä¢ AlphaGo \r\n‚Ä¢ 1920 CPUs, 280 GPUs, costing $35M\r\n8\r\n\r\nRed AI in Large Language Models (LLMs)\r\n‚Ä¢ OPT by Meta reports 75 tons CO2-eq (1/7 of OpenGPT‚Äôs footprint).\u2028\r\n(Also 175billion params) \r\n‚Ä¢ However, Llama 3 reported 2,290 tons of CO2-eq (7.7M GPU hours \r\ntraining ) \r\n‚Ä¢ Open science: release includes both the pretrained models and the code \r\nneeded to train and use them. \r\n‚Ä¢ DeepSeek-V3 claims ‚Äúonly‚Äù 2.78M GPU hours \r\n‚Ä¢ Bloom by Huggingface reports 25 tons, 51 when considering embodied \r\nand operational carbon footprint. (176billion params)\r\n9\r\n\r\nRed AI\r\nAccuracy: 0.999999999\r\nGreen AI\r\n‚Ä¢ Energy \r\n‚Ä¢ Time \r\n‚Ä¢ Reproducibility \r\n‚Ä¢ Reusage\r\n\r\nHow can we adopt Green AI\r\n‚Ä¢ Check whether AI is needed. \r\n‚Ä¢ Select green datacenters. \r\n‚Ä¢ Run on low carbon intensity hours. \r\n‚Ä¢ Opt for GPU-optimised solutions (?) \r\n‚Ä¢ Opt for low-power hardware (e.g., Nvidia Jetson boards) \r\n‚Ä¢ Or GPUs that provide energy metrics (e.g., NVIDIA GPUs via the nvidia-smi tool) \r\n‚Ä¢ Report energy/carbon metrics (e.g., embed in MLFlow?) \r\n‚Ä¢ Use pre-trained models (Transfer Learning) \r\n‚Ä¢ Preprocess dataset to reduce size. \r\n‚Ä¢ Improve parameter-tuning strategy.\r\n11\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ We need benchmarks. \r\n‚Ä¢ AllenAI leaderboard\u2028\r\nhttps://leaderboard.allenai.org \r\n‚Ä¢ No carbon metrics, yet \r\n‚Ä¢ Report comparable proxies for energy \r\nconsumption. \r\n‚Ä¢ ‚ö† Learning algorithms behave in a non-\r\ndeterministic \r\n‚Ä¢ ‚ö† Different data-points lead to different \r\nenergy consumption\r\n12\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ Reporting measured energy consumption \r\n‚Ä¢ + Accurate \r\n‚Ä¢ + Easy to map to carbon emissions \r\n‚Ä¢ - Hard to measure \r\n‚Ä¢ - Low replicability \r\n‚Ä¢ Reporting time / estimation based on time & hardware \r\n‚Ä¢ + Easy to measure \r\n‚Ä¢ + Correlates with energy consumption in most cases. \r\n‚Ä¢ -  Difficult to compare with measurements from other setups \r\n‚Ä¢ E.g., floating point operations (FPOs) (?) \r\n‚Ä¢ + comparable across different setups \r\n‚Ä¢ + cheap \r\n‚Ä¢ - does not factor in memory energy consumption \r\n‚Ä¢ - does not reflect carbon emissions\r\n13\r\n\r\nData-centric AI\r\n\r\nData-centric AI\r\n‚Ä¢ Emerging discipline that deals with systematically engineering data to build AI \r\nsystems. \r\n‚Ä¢ Shift from improving the training strategy to improving the data. \r\n‚Ä¢ It is better to have small but reliable datasets than large but noisy \r\ndatasets. \r\n‚Ä¢ => Improve data collection, data labelling, and data preprocessing. \r\n‚Ä¢ More about data-centric AI by Andrew Ng:\u2028\r\nhttps://www.youtube.com/watch?v=06-AZXmwHjo\r\n15\r\n\r\n\r\nGreen Data-centric AI\r\n‚Ä¢ How do different ML algorithms compare \r\nin terms of energy consumption? \r\n‚Ä¢ How does number of rows relate to the \r\nenergy consumption of ML models? \r\n‚Ä¢ How does number of features relate to \r\nthe energy consumption of ML models? \r\n‚Ä¢ What is the impact of reducing data in the \r\nperformance of the model?', '575(7784):607-17. \r\nhttps://www.nature.com/articles/s41586-019-1677-2\r\nExtra reading:\r\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \r\nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\r\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \r\nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \r\nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\r\nBasics of \'conventional\' neural networks:\r\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\r\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.\r\n\r\nReferences\r\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \r\nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\r\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \r\n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\r\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \r\nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\r\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \r\n(not publicly available) doi:10.1037/h0042519\r\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \r\nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\r\n6) https://github.com/idsc-frazzoli/retina\r\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \r\nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\r\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \r\nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\r\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \r\nNeural Networks.', 'Interviews?) & rich \r\ndescription of outcomes focus of grading\r\nhttps://eip.pages.ewi.tudelft.nl/eip-website/queue.html\r\n\r\nC1. Compare energy consumption of docker images for \r\nML workloads.\r\n‚Ä¢ Similar to what we have seen in the lectures but for ML-specific workloads. \r\n‚Ä¢ We can reuse existing experiment replication packages.\r\n22\r\n\r\nC2. Plugin to visualize Hugging Face carbon emissions.\r\n‚Ä¢ https://huggingface.co/blog/leaderboard-emissions-\r\nanalysis \r\n‚Ä¢\r\nYoo, Taewon, et al. ""Visualizing the Carbon Intensity of Machine Learning Inference for Image Analysis on TensorFlow Hub.""\r\n\r\nC3. Plugin for ChatGPT\r\n‚Ä¢ Users seldom know how much carbon they are emitting when they interact \r\nwith chat GPT. \r\n‚Ä¢ Let‚Äôs make it transparent to the users. Browser plugin?\r\n24\r\nCO2\r\n\r\nC4. NutriScore for software libraries\r\n25\r\n‚Ä¢ NutriScore labels are not perfect but they are a good starting point! \r\n‚Ä¢ What if we could do the same thing for the energy efficiency of software. \r\n‚Ä¢ (Also open to individual or social sustainability) \r\n‚Ä¢ This work can be scoped in particular domains/ecossystems/use cases. \r\n‚Ä¢ Libraries for stats? ML? Web Dev? Cloud?\r\n\r\nC5. Add energy-awareness to existing software\r\n26\r\n‚Ä¢ Streamlit, Notebooks, JSFiddle, \r\nPyScript, zsh, etc. \r\n‚Ä¢\r\n\r\nC6 - Green Shift Left\r\n‚Ä¢ Estimate energy efficiency using static code analysis. \r\n‚Ä¢ We don‚Äôt need an accurate value. \r\n‚Ä¢ It is useful to know which code is more likely to \r\nintroduce energy hotspots and that should be \r\nreviewed with more attention. \r\n‚Ä¢ Can be scoped to a particular domain (react, php, data \r\nscience, web, etc., etc.)\r\n27\r\n\r\nC7 - Education\r\n‚Ä¢ Educational game for Software \r\nSustainability practices \r\n‚Ä¢ Purpose: use within software teams to \r\ndiscuss or learn about different sustainable \r\nIT practices: at the organisation level, \r\nsoftware, etc.\r\n28\r\nhttps://github.com/OttoKaaij/Ticket-To-Sustainability/?tab=readme-ov-file\r\n\r\nProject ideas (old)\r\n‚Ä¢ Plugin from EnergiBridge (GUI, report generator, python library, etc.) \r\n‚Ä¢ Plugin for ChatGPT (carbon emissions per chat window) \r\n‚Ä¢ Seamless measurements for AI libraries \r\n‚Ä¢ Energy patterns for Green AI \r\n‚Ä¢ Sustainable SW dev gamification \r\n‚Ä¢ Sustainability auditor for AI projects \r\n‚Ä¢ Energy Profiling of screen colour filter tools (or display settings) \r\n‚Ä¢ ‚Ä¶ you can also propose yours!\r\n\r\nhttps://edu.nl/64gpk\r\nedu.nl/64gpk', '‚Ä¢ Improve parameter-tuning strategy.\r\n11\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ We need benchmarks. \r\n‚Ä¢ AllenAI leaderboard\u2028\r\nhttps://leaderboard.allenai.org \r\n‚Ä¢ No carbon metrics, yet \r\n‚Ä¢ Report comparable proxies for energy \r\nconsumption. \r\n‚Ä¢ ‚ö† Learning algorithms behave in a non-\r\ndeterministic \r\n‚Ä¢ ‚ö† Different data-points lead to different \r\nenergy consumption\r\n12\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ Reporting measured energy consumption \r\n‚Ä¢ + Accurate \r\n‚Ä¢ + Easy to map to carbon emissions \r\n‚Ä¢ - Hard to measure \r\n‚Ä¢ - Low replicability \r\n‚Ä¢ Reporting time / estimation based on time & hardware \r\n‚Ä¢ + Easy to measure \r\n‚Ä¢ + Correlates with energy consumption in most cases. \r\n‚Ä¢ -  Difficult to compare with measurements from other setups \r\n‚Ä¢ E.g., floating point operations (FPOs) (?) \r\n‚Ä¢ + comparable across different setups \r\n‚Ä¢ + cheap \r\n‚Ä¢ - does not factor in memory energy consumption \r\n‚Ä¢ - does not reflect carbon emissions\r\n13\r\n\r\nData-centric AI\r\n\r\nData-centric AI\r\n‚Ä¢ Emerging discipline that deals with systematically engineering data to build AI \r\nsystems. \r\n‚Ä¢ Shift from improving the training strategy to improving the data. \r\n‚Ä¢ It is better to have small but reliable datasets than large but noisy \r\ndatasets. \r\n‚Ä¢ => Improve data collection, data labelling, and data preprocessing. \r\n‚Ä¢ More about data-centric AI by Andrew Ng:\u2028\r\nhttps://www.youtube.com/watch?v=06-AZXmwHjo\r\n15\r\n\r\n\r\nGreen Data-centric AI\r\n‚Ä¢ How do different ML algorithms compare \r\nin terms of energy consumption? \r\n‚Ä¢ How does number of rows relate to the \r\nenergy consumption of ML models? \r\n‚Ä¢ How does number of features relate to \r\nthe energy consumption of ML models? \r\n‚Ä¢ What is the impact of reducing data in the \r\nperformance of the model? \r\n‚Ä¢ Method -> results -> discussion\r\n17\r\n\r\nMethod\r\n‚Ä¢ Single object of study: natural language model to detect spam messages. \r\n‚Ä¢ 6 machine learning algorithms: SVM, Decision Tree, KNN, Random Forrest, \r\nAdaBoost, Bagging Classifier. \r\n‚Ä¢ Reduce the number of rows. 10%, 20%, .., 100% \r\n‚Ä¢ Stratified random sampling (?) \r\n‚Ä¢ Reduce the number of features. 10%, 20%, .., 100% \r\n‚Ä¢ Feature importance metric based on the Chi-Square Test (Chi2) \r\n‚Ä¢ Estimate energy consumption using a RAPL-based tool. (?)\r\n18\r\n\r\n‚Ä¢ Repeat 30 times \r\n‚Ä¢ Fix random seeds \r\n‚Ä¢ ‚Ä¶ \r\n‚Ä¢ Data was not Normal => tailed Normal distribution.\r\n19\r\n(?)\r\n\r\nResults: energy consumption of algorithms\r\n\r\nResults: energy vs data shape\r\n\r\nResults: performance vs data shape\r\n\r\nDiscussion\r\n‚Ä¢ Other data properties should be investigated. \r\n‚Ä¢ E.g., data types \r\n‚Ä¢ Reporting energy data is essential. It can lead to different model selection \r\nwithout hindering model performance. \r\n‚Ä¢ There is a big opportunity in Model and Data Simplification.\r\n23\r\n\r\nData/Model Simplification\r\n‚Ä¢ (?) \r\n‚Ä¢ Data selection \r\n‚Ä¢ Data quantisation. Posit? \r\n‚Ä¢ Data distillation \r\n‚Ä¢ Coreset extraction (?) \r\n‚Ä¢ Model distillation \r\n‚Ä¢ Model quantisation \r\n‚Ä¢ Model pruning \r\n‚Ä¢ ‚Ä¶\r\n24\r\n\r\nPosit vs Float\r\nMore about this: https://spectrum.ieee.org/floating-point-numbers-posits-processor\r\nBetter for DL use cases\r\n\r\nHow can we tune \r\nlearning \r\nparameters \r\nefficiently?\r\n\r\nHyper parameter tuning\r\n‚Ä¢ When training an ML model, there are several parameters that need to be \r\ntuned. \r\n‚Ä¢ E.g., in SVM we have the Regularization parameter C, the kernel function, \r\nthe degree of the kernel function, and depending on the case, many other. \r\n‚Ä¢ The common approach revolves around grid search.', '‚Ä¢ Deadline April 4.\r\n6\r\n\r\nStrategy\r\n‚Ä¢ Week 0 \r\n‚Ä¢ Decide project idea (today) \r\n‚Ä¢ Define steering meeting schedule \r\n‚Ä¢ Create working document of the \r\narticle: Problem statement and solution \r\nproposal! \r\n‚Ä¢ Define and assign tasks for each week. \r\n‚Ä¢ Week 1 \r\n‚Ä¢ Implementation \r\n‚Ä¢ Agreements with supervisor. \r\n‚Ä¢ Week 2 \r\n‚Ä¢ Implementation \r\n‚Ä¢ Week 3 \r\n‚Ä¢ Implementation, Full draft of article, \r\ndissemination. \r\n‚Ä¢ Week 4 \r\n‚Ä¢ Final refinements \r\n‚Ä¢ Prepare presentation\r\n7\r\n\r\nProject ideas\r\n‚Ä¢ A1. Prototype cross-machine comparable benchmarks \r\n‚Ä¢ A2. Add energy metrics to LMstudio/Ollama \r\n‚Ä¢ A3. Visualizations built-in with EnergiBridge \r\n‚Ä¢ A4. Service-based version of EnergiBridge\r\n\r\nProject ideas\r\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \r\n‚Ä¢ B2. Study test generation energy consumption \r\n‚Ä¢ B3. Energy profiling of static analysis tools \r\n‚Ä¢ B4. Detailed energy profiling of build pipelines \r\n‚Ä¢ B5. Tool supporting SusAF workshop / process \r\n‚Ä¢ B6. Dataset of government-developed OS software \r\n‚Ä¢ B7. Queue - but better for the student / TA society\r\nQuality Assurance & Testing\r\nSocial & Individual \u2028\r\nSustainability\r\n\r\nProject ideas\r\n‚Ä¢ C1. Compare energy consumption of docker images for ML workloads. \r\n‚Ä¢ C2. Create a plugin to visualize Hugging Face carbon emissions in detail. \r\n‚Ä¢ C3. Plugin for ChatGPT (footprint per chat window) \r\n‚Ä¢ C4. NutriScore for software libraries. \r\n‚Ä¢ C5. Add energy-awareness to existing software \r\n‚Ä¢ C6. Green Shift Left \r\n‚Ä¢ C7. Education for Sustainable SE\r\n\r\nA1. Prototype cross-machine comparable benchmarks\r\n‚Ä¢ Energy-usage comparisons require running both baseline + software on the \r\nsame machine ‚Üí limits how extensive our experiments can be \r\n‚Ä¢ Research community is in need of benchmarks that make energy \r\nmeasurements comparable even if executed on different machines \r\n‚Ä¢ Focus on a single task or model (i.e. computing vision, classification)\r\n\r\nA2. Adding energy metrics to LMstudio/Ollama\r\n‚Ä¢ Make energy consumption visible to users \r\nwithin local chat-interface for LLMs \r\n‚Ä¢ LMstudio/Ollama are tools for easy \r\ndeployment of LLMs \r\n‚Ä¢ Do not show energy metrics \r\n‚Ä¢ Add energy metrics to LMstudio-python \r\nor Ollama\r\nhttps://lmstudio.ai/\r\n\r\nA3. Visualizations built-in with EnergiBridge\r\n‚Ä¢ EnergiBridge simplifies energy measurement, but analysis & visualization is \r\nstill left to the user \r\n‚Ä¢ Extend the tool with well-chosen visualizations and analyses directly from the \r\nprovided data\r\n\r\nA4. Service-based version of EnergiBridge\r\n‚Ä¢ Simplify interaction & setup with EnergiBridge \r\n‚Ä¢ Service that runs independently, start/stop signals over RPC to manage \r\nexperiments \r\n‚Ä¢ Potential: create EnergiBridge interface for other prog. lang\r\n\r\nB1. Measure energy consumption of single JUnit tests\r\n‚Ä¢ We‚Äôd like to identify energy anti patterns in unit tests \r\n‚Ä¢ As a first step, we need tooling to measure and compare the energy \r\nconsumption of single unit tests \r\n‚Ä¢ Ideally including preliminary analysis looking at potential reasons for high-\r\nenergy-consuming tests\r\n\r\nB2. Study test generation energy consumption\r\n‚Ä¢ Automatic test generation mainly focuses on making strong test suites \r\n‚Ä¢ Do different techniques and configurations impact the energy consumption \r\nduring generation? \r\n‚Ä¢ Preferably focus on non-LLM test generation methods (EvoSuite, Pyguin, \r\nDSpot)\r\n\r\nB3. Detailed energy profiling of build pipelines\r\n‚Ä¢ Automatic builds have become a cornerstone of quality assurance.', 'google.com/view/energy-efficiency-languages\r\n21\r\nAna Radovanovic ÃÅ, Ross Koningstein, Ian Schneider, Bokan \r\nChen, Alexandre Duarte, Binz Roy, Diyue Xiao, Maya \r\nHaridasan, Patrick Hung, Nick Care, Saurav Talukdar, Eric \r\nMullen, Kendal Smith, MariEllen Cottman, and Walfredo Cirne \r\n\r\n\r\n‚Ä¢ Google‚Äôs Carbon-Intelligent Computing System (CICS) \r\n‚Ä¢ Main idea: use carbon-intensity data to shift datacenter jobs in time \r\n‚Ä¢ Typically, job schedulers use a metric of cluster capacity to schedule a job in \r\na particular cluster. \r\n‚Ä¢ CICS overrides this metric with the virtual capacity curve (VCC) that \r\nfactors in Carbon intensity \r\n‚Ä¢ When a new job comes in, the scheduler estimates its CPU load and power \r\nusage and assigns it to a cluster if the VCC is not exceeded.\r\n23\r\n\r\n‚Ä¢ Jobs are divided between flexible and inflexible. \r\n‚Ä¢ Flexible load is considered shapeable/shiftable as long as its total daily \r\ncompute (CPU) demand is preserved \r\n‚Ä¢ The system needs to consider that, while running a job, the virtual capacity \r\ncurve (VCC) might drop. Hence, this job should not start in the first place. \r\n‚Ä¢ They forecast VCC for the next day\r\n24\r\n\r\n\r\nVirtual Cluster Capacity (VCC)\r\n‚Ä¢ Aims at reducing the peak load at carbon intensive hours but in total it should allow for the \r\nsome amount of daily computation! \r\n‚Ä¢ Considers Carbon intensity \r\n‚Ä¢ Using data from electricityMap.org \r\n‚Ä¢ It does not use carbon intensity directly.\u2028\r\nCarbon intensity is converted to a cost (kgCO2 -> $$) \r\n‚Ä¢ This way, they can factor in other metrics that can also be converted to money. E.g., the \r\ncost saved by preventing peak load \r\n‚Ä¢ Peak workload entails extra cost at the infrastructure level (e.g., control faclities‚Äô \r\ntemperature). \r\n‚Ä¢ By using money cost instead of carbon cost, they have more data available.\r\n26\r\n\r\nVirtual Cluster Capacity (VCC)\r\n‚Ä¢ If the forecast of VCC fails it shift flexible workload more than expected.  \r\n‚Ä¢ This happens because the amount of workload forecasted was below the \r\nworkload needed, and VCC was ‚Äúaggressively‚Äù low. \r\n‚Ä¢ The systems fall back to the real cluster capacity for 1 week until results \r\nstart being realistic again.\r\n27\r\n\r\nNext steps\r\n‚Ä¢ They will consider spatial flexibility. \r\n‚Ä¢ I.e., tasks that can be shifted over time and over space. \r\n‚Ä¢ It needs to factor in relocation overheads, though.\r\n28\r\n\r\nCritical questions\r\n‚Ä¢ Who defines what is flexible and inflexible? \r\n‚Ä¢ How do you estimate the CPU load of a given task?\r\n29\r\n\r\nEnergy Regression Testing\r\n‚ÜíEnergy?\r\nGreener? Greener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\n\r\nE-compare\r\nGithub Actions\r\n‚ûú https://koenhagen.github.io/E-Compare/\r\n\r\nEnergy Regression Testing \r\n\r\n4. Debugging Energy with \r\nDocker Images\r\n\r\nUnveiling the Energy Vampires \r\nA methodology for debugging Software \r\nEnergy Consumption\r\n ‚úÖ ICSE 2025\r\n\r\nData Centers and Docker\r\n‚Ä¢ Containers are the most popular way to deploy apps into the cloud \r\n‚Ä¢ Base image is an important choice when building an image \r\n‚Ä¢ Criteria \r\n‚Ä¢ Linux distribution and binaries \r\n‚Ä¢ Image size \r\n‚Ä¢ Energy?\r\n35\r\n\r\nRedis energy consumption\r\n‚Ä¢ Ubuntu/Alpine base images have different energy consumption for Redis\r\n36\r\n\r\nRedis Energy Consumption\r\n‚Ä¢RQ1: What is the difference \r\nin energy consumption \r\nbetween glibc and musl? \r\n‚Ä¢RQ2: Can we use tracing \r\nto compare energy \r\nconsumption in shared \r\nlibraries?', 'It‚Äôs more important that we learn how to \r\ndiscuss this topic and come up with new ideas than learning all the theory. \r\nCritical thinking over checkboxes. \r\n‚Ä¢ Mix of content and discussion \r\n‚Ä¢ Ultimately, the lectures aim to give you food for thought and the necessary \r\nknowledge to excel in Project 2. (We will talk about it later)\r\n30\r\n\r\nhttps://luiscruz.github.io/course_sustainableSE/\r\n31\r\nContent of the course üëá\r\n\r\n32\r\nhttps://mattermost.tudelft.nl/signup_user_complete/?id=1nj9tk6usjf8xmsws8wpq3s5uy&md=link&sbr=su\r\n\r\nProject 1\r\n‚Ä¢ Goal: Measure the energy consumption of software applications. \r\n‚Ä¢ Approach: energy measurement tools; use case testing. \r\n‚Ä¢ Deliverable: blog-style report (approx. 2500 words) \r\n‚Ä¢ Deadline: Week 3, Feb 28, 2025 \r\n‚Ä¢ Group size: 4‚Äì5\r\n33\r\n\r\nProject 2\r\n‚Ä¢ Goal: Create a solution/tool/technique that helps building green software. (You \r\ncan come up with your own idea or choose one from a list of suggestions). \r\n‚Ä¢ Approach: open-source software development; literature review. \r\n‚Ä¢ Deliverable: library/tool/app; paper; presentation. \r\n‚Ä¢ Two deadlines:\u2028\r\n1. Paper and software: Week 8, April 4, 2025\u2028\r\n2. Presentation: Week 9, April 11, 2025 \r\n‚Ä¢ Group size: 4‚Äì5\r\n34\r\n\r\nGuest Lectures\r\nNergis T√∂men \r\nComputer Vision lab | TU Delft \r\nWeek 4, Wed, Mar 5, 2025\r\n35\r\n\r\nCommunity \r\nHow to get involved?\r\n36\r\n\r\nGreen TU\r\n‚Ä¢ https://www.tudelft.nl/sustainability/get-\r\ninvolved/greentu \r\n‚Ä¢ Student organisation at the TU Delft devoted \r\nto stimulating sustainability in education, \r\nresearch, university operations and \r\ncommunity engagement.\r\n37\r\n\r\nClimateAction.tech\r\n‚Ä¢ Great community for outreach \r\n‚Ä¢ Based on Slack  \r\n‚Ä¢ Regular meetings, talks, social events \r\n‚Ä¢ You can join as a volunteer or simply to \r\nconnect to other techies \r\n‚Ä¢ Also good to for job hunting on green tech.\r\n38\r\n\r\nClimateAction.tech\r\n39\r\n\r\nBranch magazine\r\n‚Ä¢ Stay up-to-date on sustainable tech \r\n‚Ä¢ Creativity booster \r\n‚Ä¢ Carbon-aware UI \r\n‚Ä¢ https://branch.climateaction.tech üîó\r\n40\r\n\r\nThis is the fourth edition\r\n‚Ä¢ Any feedback is welcome! Email or DM!\r\n41\r\n\r\n42\r\n\r\nCarolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nLu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\n1. Intro Class\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl']","['<1-hop>\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing', '<2-hop>\n\nReading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.', '<1-hop>\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing', '<2-hop>\n\nReading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.', '<1-hop>\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing', '<2-hop>\n\nReading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.']","Neuromorphic systems, which are inspired by the structure and function of the human brain, have several practical applications that leverage biological inspiration and advanced training methods for efficient computation:

1. **Energy Efficiency**: Neuromorphic systems are designed to be highly energy-efficient, mimicking the brain's ability to perform complex tasks with minimal energy consumption. This makes them suitable for applications where power efficiency is critical, such as in portable and wearable devices.

2. **Real-Time Decision Making**: These systems can be used in applications requiring fast real-time decision-making, such as autonomous vehicles, robotics, and e-sports, due to their ability to process information quickly and efficiently.

3. **Adaptive Systems**: Neuromorphic systems can adapt to changing environments and contexts, making them ideal for applications in adaptive control systems and context-aware computing.

4. **Sparse Encoding**: By using sparse encoding strategies, neuromorphic systems can efficiently handle large volumes of data, which is beneficial in fields like image and video processing, where data is abundant but needs to be processed efficiently.

5. **Spiking Neural Networks (SNNs)**: These networks are particularly useful for tasks that require temporal processing, such as speech and sound recognition, due to their ability to integrate information over time.

6. **Event-Based Vision**: Neuromorphic systems are used in event-based vision applications, such as dynamic vision sensors, which capture changes in a scene rather than static frames, leading to more efficient data processing.

Overall, neuromorphic computing offers a promising approach for developing systems that require efficient, adaptive, and real-time processing capabilities.","Neuromorphic systems, inspired by the human brain, have practical applications such as event-based vision, which is detailed in the reading materials. These systems use advanced training methods like surrogate gradient learning to optimize spiking neural networks, enabling efficient computation and real-world applications.",0.1499999999925,1.0,0.75,0.46,,0.9494900119714513
"What is the biological basis of neuromorphic computing, and how does it differ from conventional neural networks?","['Different encoding strategies with spiking neurons\r\n\r\nDifferent encoding strategies with spiking neurons\r\nUsing latency or spatio-temporal codes\r\nour encoding is faster and more spike-efficient (sparser)!\r\n\r\nDifferent encoding strategies with spiking neurons\r\nUsing latency or spatio-temporal codes\r\nour encoding is faster and more spike-efficient (sparser)!\r\nQuestions?\r\n\r\nNeuromorphic computing\r\nWhat is the advantage for applications?\r\n-\r\nLess spikes = less energy consumption in specialized neuromorphic hardware\r\n(e.g. Intel Loihi [12])\r\nBrains are energy efficient: \r\n2. Sparse encoding\r\n\r\nMultiply-accumulate (MAC) operations:\r\nNormal neuron: Multiplies input with \r\nweights, then adds.\r\nSpiking neuron: Consider binary input (e.g. input currents are piecewise \r\nconstant and assume values {0,1}). There is no multiplication, only addition.\r\n\r\nAssume one multiplier and one adder circuit uses M and A energy respectively with AÔπ§M\r\n(e.g., for a 45nm CMOS process, standard energy usage is A = 0.9 pJ and M = 3.7 pJ).\r\nNormal neuron: nin x nout multiplications,\r\n(nin‚Äì 1) x nout additions\r\nSpiking neuron: 0 multiplications, (nactive‚Äì 1) x nout \r\nadditions, with nactive ‚â§ nin\r\nEnergy consumption:\r\nEnormal = M nin nout + A (nin‚Äì 1) nout = 17.5 pJ\r\nEnergy consumption:\r\nEspiking = A (nactive‚Äì 1) nout = 2.7 pJ\r\nMultiply-accumulate (MAC) operations:\r\n\r\nAssume one multiplier and one adder circuit uses M and A energy respectively with AÔπ§M\r\n(e.g., for a 45nm CMOS process, standard energy usage is A = 0.9 pJ and M = 3.7 pJ).\r\nNormal neuron: nin x nout multiplications,\r\n(nin‚Äì 1) x nout additions\r\nSpiking neuron: 0 multiplications, (nactive‚Äì 1) x nout \r\nadditions, with nactive ‚â§ nin\r\nEnergy consumption:\r\nEnormal = M nin nout + A (nin‚Äì 1) nout = 17.5 pJ\r\nEnergy consumption:\r\nEspiking = A (nactive‚Äì 1) nout = 2.7 pJ\r\nMultiply-accumulate (MAC) operations:\r\nSNN challenge: how to \r\ncompute with the least \r\namount of spikes!\r\n\r\nOften, we observe a \r\nsparsity (energy)-\r\ntask accuracy trade-off\r\n(Left: results for image \r\nclassification)\r\nSNN challenge: how to \r\ncompute with the least \r\namount of spikes!\r\nhttps://arxiv.org/pdf/2409.08290\r\n\r\nIn practice, energy \r\nconsumption computations \r\nare complex. \r\nNeed to take into account\r\n- memory access,\r\n- addressing,\r\n- auxiliary operations,\r\nin addition to MACs.\r\nEstimated energy consumption for 3 different datasets (CIFAR10, GSC, NCARS; image, sound \r\nand video classification respectively). FNN‚Äôs are conventional feed-forward neural networks.\r\nIn this example: SNNs are 6 to 8 times more energy efficient than FNNs.\r\nhttps://arxiv.org/pdf/2210.13107\r\nComputing energy consumption\r\n\r\nIn practice, energy \r\nconsumption computations \r\nare complex. \r\nNeed to take into account\r\n- memory access,\r\n- addressing,\r\n- auxiliary operations,\r\nin addition to MACs.\r\nEstimated energy consumption for 3 different datasets (CIFAR10, GSC, NCARS; image, sound \r\nand video classification respectively). FNN‚Äôs are conventional feed-forward neural networks.\r\nIn this example: SNNs are 6 to 8 times more energy efficient than FNNs.', ""- Higher firing rate (spikes per unit time) for \r\n'selected' feature.\r\nAdapted from Hubel & Wiesel, 1959\r\n\r\nFiring rates\r\nClassical view of the brain:\r\n- Each neuron is selective for one specific \r\nfeature in the input.\r\n- Higher firing rate (spikes per unit time) for \r\n'selected' feature.\r\n- Link to modern ANNs: The scalar output of \r\nan artificial neuron is interpreted as the firing \r\nrate.\r\nAdapted from Hubel & Wiesel, 1959\r\n\r\nFiring rates\r\nClassical view of the brain:\r\n- Each neuron is selective for one specific \r\nfeature in the input.\r\n- Higher firing rate (spikes per unit time) for \r\n'selected' feature.\r\n- Link to modern ANNs: The scalar output of \r\nan artificial neuron is interpreted as the firing \r\nrate.\r\nAdapted from Hubel & Wiesel, 1959\r\nBut rate coding is inefficient and slow‚Ä¶\r\n(i.e. each neuron needs to fire many spikes to get good precision)\r\nboth in vivo and in silico.\r\n\r\nDifferent encoding strategies with spiking neurons [8]\r\n7 neurons\r\n7 time bins\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nn\r\n6\r\n(in the general \r\ncase a \r\nnumber \r\nbetween 0-7)\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nn\r\nTotal spike \r\ncount can \r\nencode 3 bits.\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nIndividual rates \r\ncan encode 7 \r\nbits.\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nLatency can \r\nencode ~3*7 or \r\n~19 bits.\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nRank order can \r\nencode ~12 bits.\r\n\r\nDifferent encoding strategies with spiking neurons\r\n\r\nDifferent encoding strategies with spiking neurons\r\nUsing latency or spatio-temporal codes\r\nour encoding is faster and more spike-efficient (sparser)!\r\n\r\nDifferent encoding strategies with spiking neurons\r\nUsing latency or spatio-temporal codes\r\nour encoding is faster and more spike-efficient (sparser)!\r\nQuestions?\r\n\r\nNeuromorphic computing\r\nWhat is the advantage for applications?\r\n-\r\nLess spikes = less energy consumption in specialized neuromorphic hardware\r\n(e.g. Intel Loihi [12])\r\nBrains are energy efficient: \r\n2. Sparse encoding\r\n\r\nMultiply-accumulate (MAC) operations:\r\nNormal neuron: Multiplies input with \r\nweights, then adds.\r\nSpiking neuron: Consider binary input (e.g. input currents are piecewise \r\nconstant and assume values {0,1}). There is no multiplication, only addition.\r\n\r\nAssume one multiplier and one adder circuit uses M and A energy respectively with AÔπ§M\r\n(e.g., for a 45nm CMOS process, standard energy usage is A = 0.9 pJ and M = 3.7 pJ).\r\nNormal neuron: nin x nout multiplications,\r\n(nin‚Äì 1) x nout additions\r\nSpiking neuron: 0 multiplications, (nactive‚Äì 1) x nout \r\nadditions, with nactive ‚â§ nin\r\nEnergy consumption:\r\nEnormal = M nin nout + A (nin‚Äì 1) nout = 17.5 pJ\r\nEnergy consumption:\r\nEspiking = A (nactive‚Äì 1) nout = 2.7 pJ\r\nMultiply-accumulate (MAC) operations:\r\n\r\nAssume one multiplier and one adder circuit uses M and A energy respectively with AÔπ§M\r\n(e.g., for a 45nm CMOS process, standard energy usage is A = 0.9 pJ and M = 3.7 pJ)."", 'McCulloch-Pitts neuron [1, 2]\r\n1940s: How do biological neurons compute basic \r\nlogic functions? (e.g. logic gates)\r\nNote: Ref. [3] gives a nice brief history on the ideas which lead to the \r\nMcCulloch-Pitts neuron.\r\n\r\nWhat is a neural network?\r\n1950s: How are neurons organized to perform \r\nsensory perception?\r\n\r\nWhat is a neural network?\r\n1950s: How are neurons organized to perform \r\nsensory perception?\r\nThe first ""neural network"": Perceptron (1958). [4]\r\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\r\nFrank Rosenblatt (Psychologist)\r\nwith a Mark I Perceptron computer in 1960\r\n\r\nWhat is a neural network?\r\n1950s: How are neurons organized to perform \r\nsensory perception?\r\nThe first ""neural network"": Perceptron (1958). [4]\r\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\r\nFrank Rosenblatt (Psychologist)\r\nwith a Mark I Perceptron computer in 1960\r\nPower-efficient\r\n\r\nNeuromorphic computing\r\nWhy neuromorphic computing?\r\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\r\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\r\n\r\nNeuromorphic computing\r\nWhy neuromorphic computing?\r\n‚ÄòBiological inspiration‚Äô for artificial neural networks (ANNs) is not a new idea.\r\nEmulation (as opposed to simulation) of neural networks in hardware is not a new idea.\r\nQuestion: What can we gain from increasing biological realism in existing neural networks?\r\n\r\nPower-efficiency at scale\r\nModern, deep neural networks*\r\nare trained using GPUs.\r\n* It is estimated that ChatGPT was trained on \r\n10,000-20,000 GPUs and that it will require\r\n30,000 GPUs to keep running stably in the future.\r\n* It is estimated that ChatGPT has 10-20 billion \r\nparameters.\r\nhttps://www.anandtech.com/show/4008/nvidias-geforce-gtx-580/17\r\n\r\nPower-efficiency at scale\r\nModern, deep neural networks*\r\nare trained using GPUs.\r\n* It is estimated that ChatGPT was trained on \r\n10,000-20,000 GPUs and that it will require\r\n30,000 GPUs to keep running stably in the future.\r\n* It is estimated that ChatGPT has 10-20 billion \r\nparameters.\r\nSingle model with 20 billion parameters:\r\n200 Watts x 30,000 GPUs = 6M Watts\r\n\r\nPower-efficiency at scale\r\nhttps://hai.stanford.edu/ai-index/2024-ai-index-report\r\nTraining a single large language model can \r\ngenerate greater CO2 emissions than the \r\ntotal lifetime emissions of 8 cars (in 2020)!\r\n\r\nPower-efficiency at scale\r\nhttps://hai.stanford.edu/ai-index/2024-ai-index-report\r\nTraining a single model can consume \r\nmore than 1000 MWh of power!\r\n\r\nPower-efficiency at scale\r\nhttps://hai.stanford.edu/ai-index/2024-ai-index-report\r\nTraining a single model can consume \r\nmore than 1000 MWh of power!\r\n‚Ä¶ with energy costs reaching 200M USD!\r\n\r\nPower-efficiency at scale\r\nYour brain runs on:\r\n\r\nPower-efficiency at scale\r\nYour brain runs on:\r\nHigh estimate ~3000 kcal a day\r\n   ‚âà145 Watts\r\n* Human brain has ~600 trillion synapses \r\n(‚âàparameters).', 'Neuromorphic computing\r\nCS4575\r\nSustainable Software Engineering\r\n05.03.2025\r\nNergis T√∂men\r\n\r\nIntroduction\r\nComputer Vision Lab\r\nBiomorphic Intelligence Lab\r\nBiomedical Intervention Optimisation Lab\r\nNergis\r\n\r\nNeuromorphic computing\r\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\r\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\r\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing\r\n\r\nHow many of you are familiar \r\nwith neural networks?\r\n\r\nSimple model of an artificial neuron\r\nhttps://medium.com/@cprasenjit32/perceptron-a-simple-yet-mighty-machine-learning-algorithm-9ff6b7d86a71\r\n\r\nWhat is a neural network?\r\nhttps://www.tibco.com/reference-center/what-is-a-neural-network\r\n\r\nWhy is it called a \'neural network\'?\r\nhttps://www.tibco.com/reference-center/what-is-a-neural-network\r\n\r\nWhat is a neural network?\r\nWhy is it called a \'neural network\'?\r\nMcCulloch-Pitts neuron [1, 2] (1943)\r\nWarren Sturgis McCulloch\r\n(Neurophysiologist)\r\nWalter Pitts\r\n(Logician)\r\n\r\nHow do biological neurons work?\r\nhttps://commons.wikimedia.org/wiki/File:Coincidence_detection_in_dendrites_of_pyramidal_neurons.gif\r\n\'Input current\' travels down the dendrites (top),\r\nget integrated (summed!) in the cell body\r\nwhich generates an \'output current\' (bottom)\r\nwhich is chemically transmitted to the dendrites of \r\nother neurons.\r\n\r\nSimplified picture\r\nReal neuron\r\nArtificial neuron\r\nhttps://vajiramandravi.com/quest-upsc-notes/artificial-neural-network/\r\n\r\nWhat is a neural network?\r\nMcCulloch-Pitts neuron [1, 2]\r\n1940s: How do biological neurons compute basic \r\nlogic functions? (e.g. logic gates)\r\nNote: Ref. [3] gives a nice brief history on the ideas which lead to the \r\nMcCulloch-Pitts neuron.\r\n\r\nWhat is a neural network?\r\n1950s: How are neurons organized to perform \r\nsensory perception?\r\n\r\nWhat is a neural network?\r\n1950s: How are neurons organized to perform \r\nsensory perception?\r\nThe first ""neural network"": Perceptron (1958). [4]\r\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\r\nFrank Rosenblatt (Psychologist)\r\nwith a Mark I Perceptron computer in 1960\r\n\r\nWhat is a neural network?\r\n1950s: How are neurons organized to perform \r\nsensory perception?\r\nThe first ""neural network"": Perceptron (1958). [4]\r\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\r\nFrank Rosenblatt (Psychologist)\r\nwith a Mark I Perceptron computer in 1960\r\nPower-efficient\r\n\r\nNeuromorphic computing\r\nWhy neuromorphic computing?\r\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\r\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\r\n\r\nNeuromorphic computing\r\nWhy neuromorphic computing?\r\n‚ÄòBiological inspiration‚Äô for artificial neural networks (ANNs) is not a new idea.\r\nEmulation (as opposed to simulation) of neural networks in hardware is not a new idea.', 'Normal neuron: nin x nout multiplications,\r\n(nin‚Äì 1) x nout additions\r\nSpiking neuron: 0 multiplications, (nactive‚Äì 1) x nout \r\nadditions, with nactive ‚â§ nin\r\nEnergy consumption:\r\nEnormal = M nin nout + A (nin‚Äì 1) nout = 17.5 pJ\r\nEnergy consumption:\r\nEspiking = A (nactive‚Äì 1) nout = 2.7 pJ\r\nMultiply-accumulate (MAC) operations:\r\nSNN challenge: how to \r\ncompute with the least \r\namount of spikes!\r\n\r\nOften, we observe a \r\nsparsity (energy)-\r\ntask accuracy trade-off\r\n(Left: results for image \r\nclassification)\r\nSNN challenge: how to \r\ncompute with the least \r\namount of spikes!\r\nhttps://arxiv.org/pdf/2409.08290\r\n\r\nIn practice, energy \r\nconsumption computations \r\nare complex. \r\nNeed to take into account\r\n- memory access,\r\n- addressing,\r\n- auxiliary operations,\r\nin addition to MACs.\r\nEstimated energy consumption for 3 different datasets (CIFAR10, GSC, NCARS; image, sound \r\nand video classification respectively). FNN‚Äôs are conventional feed-forward neural networks.\r\nIn this example: SNNs are 6 to 8 times more energy efficient than FNNs.\r\nhttps://arxiv.org/pdf/2210.13107\r\nComputing energy consumption\r\n\r\nIn practice, energy \r\nconsumption computations \r\nare complex. \r\nNeed to take into account\r\n- memory access,\r\n- addressing,\r\n- auxiliary operations,\r\nin addition to MACs.\r\nEstimated energy consumption for 3 different datasets (CIFAR10, GSC, NCARS; image, sound \r\nand video classification respectively). FNN‚Äôs are conventional feed-forward neural networks.\r\nIn this example: SNNs are 6 to 8 times more energy efficient than FNNs.\r\nComputing energy consumption\r\nQuestions?\r\n\r\nReading materials\r\nMain reading:\r\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \r\nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\r\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\r\n- Neuromorphic computing:\r\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \r\nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\r\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \r\noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\r\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019.', ""Spiking neural network (SNN): The 'input current' Œµ(t) is integrated over time.\r\nspike\r\n\r\nHow to model spiking neurons?\r\nEquivalence to perceptron: Computation at least as complex as a perceptron.\r\n\r\nNon-leaky integrate-and-fire (IF) neuron\r\nThe temporal profile of the input current Œµ(t) can be chosen differently, for different computations.\r\n\r\nQuestions?\r\n\r\nComputation with spiking neurons\r\nCoincidence detection\r\n\r\nComputation with spiking neurons\r\nCoincidence detection\r\nx, y ‚àà {0, 1}n\r\nExample: n = 2\r\ninput = \r\nx1\r\nx2\r\ny1\r\ny2\r\n= \r\n0\r\n1\r\n1\r\n1\r\noutput? \r\n\r\nCoincidence detection\r\nComputation with spiking neurons\r\n\r\nCoincidence detection\r\nCan be trivially computed with a single spiking neuron! Requires at least n/log(n+1) hidden \r\nunits for a perceptron (proof in [7]).\r\nComputation with spiking neurons\r\n\r\nCoincidence detection\r\nCan be trivially computed with a single spiking neuron! Requires at least n/log(n+1) hidden \r\nunits for a perceptron (proof in [7]).\r\nBrains are energy efficient: \r\n1.\r\nHigh temporal resolution (more computation with less neurons)\r\nComputation with spiking neurons\r\n\r\nEncoding strategies\r\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\r\nHow should we encode information about 'features' in a large network with many spikes?\r\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\r\nElephant?\r\nhttps://www.nationalgeographic.com/anim\r\nals/mammals/facts/african-elephant\r\n\r\nFiring rates\r\nClassical view of the brain:\r\n- Each neuron is selective for one specific \r\nfeature in the input.\r\n- Higher firing rate (spikes per unit time) for \r\n'selected' feature.\r\nAdapted from Hubel & Wiesel, 1959\r\n\r\nFiring rates\r\nClassical view of the brain:\r\n- Each neuron is selective for one specific \r\nfeature in the input.\r\n- Higher firing rate (spikes per unit time) for \r\n'selected' feature.\r\n- Link to modern ANNs: The scalar output of \r\nan artificial neuron is interpreted as the firing \r\nrate.\r\nAdapted from Hubel & Wiesel, 1959\r\n\r\nFiring rates\r\nClassical view of the brain:\r\n- Each neuron is selective for one specific \r\nfeature in the input.\r\n- Higher firing rate (spikes per unit time) for \r\n'selected' feature.\r\n- Link to modern ANNs: The scalar output of \r\nan artificial neuron is interpreted as the firing \r\nrate.\r\nAdapted from Hubel & Wiesel, 1959\r\nBut rate coding is inefficient and slow‚Ä¶\r\n(i.e. each neuron needs to fire many spikes to get good precision)\r\nboth in vivo and in silico.\r\n\r\nDifferent encoding strategies with spiking neurons [8]\r\n7 neurons\r\n7 time bins\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nn\r\n6\r\n(in the general \r\ncase a \r\nnumber \r\nbetween 0-7)\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nn\r\nTotal spike \r\ncount can \r\nencode 3 bits.\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nIndividual rates \r\ncan encode 7 \r\nbits.\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nLatency can \r\nencode ~3*7 or \r\n~19 bits.\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nRank order can \r\nencode ~12 bits."", ""Oversimplification\r\nThere are also multiple other advantages‚Ä¶\r\n\r\nHuman vs. computer computation\r\n- Fast real-time decision making, e.g. sports, e-sports\r\n- Adaptive, e.g. context-aware and employs selective attention\r\n- Energy efficient: Close to 100 billion neurons in the brain\r\n- Robust, for example to changes in illumination or obstructions in object tracking\r\n\r\nHuman vs. computer computation\r\nBrains are energy efficient: Why?\r\n1.\r\nHigh temporal resolution (more computation with less neurons)\r\n2.\r\nSparse encoding\r\n\r\nHuman vs. computer computation\r\nQuestions?\r\nBrains are energy efficient: Why?\r\n1.\r\nHigh temporal resolution (more computation with less neurons)\r\n2.\r\nSparse encoding\r\n\r\nHow do biological neurons communicate?\r\nAnalogy to artificial neural networks\r\nReal neuron\r\nArtificial neuron\r\nCurrent\r\n\r\nHow do biological neurons communicate?\r\nHow does the electrical activity propagate?\r\n?\r\nCurrent\r\n\r\nHow do biological neurons work?\r\ntime\r\nelectrode\r\nhttps://tinmard.github.io/spike-sorting-animation.html\r\nQuick electrical pulses trigger chemical signals for the next neuron ‚Üí Spikes\r\n\r\nHow do biological neurons work?\r\nQuick electrical pulses trigger chemical signals for the next neuron ‚Üí Spikes\r\nhttps://tinmard.github.io/spike-sorting-animation.html\r\ntime\r\nelectrode\r\nFrom CS perspective:\r\nSparse binary \r\nencoding\r\n\r\nBiologically realistic spiking neuron models\r\nBiologically realistic neuron models have \r\na new dimension: Time!\r\nSpiking neural networks (SNNs):\r\nThe input x  (t  ) to each neuron is summed \r\n(integrated) over time.\r\nscalar\r\nfunction of \r\ntime\r\n(t)\r\n(t)\r\nhttps://www.mdpi.com/2076-3425/12/7/863\r\n\r\nHow to model spiking neurons?\r\nANN: Perceptron, threshold activation function:\r\n\r\nHow to model spiking neurons?\r\nANN: Perceptron, threshold activation function:\r\n\r\nHow to model spiking neurons?\r\nSpiking neural network (SNN): The 'input current' Œµ(t) is integrated over time.\r\nspike\r\n\r\nHow to model spiking neurons?\r\nEquivalence to perceptron: Computation at least as complex as a perceptron.\r\n\r\nNon-leaky integrate-and-fire (IF) neuron\r\nThe temporal profile of the input current Œµ(t) can be chosen differently, for different computations.\r\n\r\nQuestions?\r\n\r\nComputation with spiking neurons\r\nCoincidence detection\r\n\r\nComputation with spiking neurons\r\nCoincidence detection\r\nx, y ‚àà {0, 1}n\r\nExample: n = 2\r\ninput = \r\nx1\r\nx2\r\ny1\r\ny2\r\n= \r\n0\r\n1\r\n1\r\n1\r\noutput? \r\n\r\nCoincidence detection\r\nComputation with spiking neurons\r\n\r\nCoincidence detection\r\nCan be trivially computed with a single spiking neuron! Requires at least n/log(n+1) hidden \r\nunits for a perceptron (proof in [7]).\r\nComputation with spiking neurons\r\n\r\nCoincidence detection\r\nCan be trivially computed with a single spiking neuron! Requires at least n/log(n+1) hidden \r\nunits for a perceptron (proof in [7]).\r\nBrains are energy efficient: \r\n1.\r\nHigh temporal resolution (more computation with less neurons)\r\nComputation with spiking neurons\r\n\r\nEncoding strategies\r\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\r\nHow should we encode information about 'features' in a large network with many spikes?\r\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\r\nElephant?\r\nhttps://www.nationalgeographic.com/anim\r\nals/mammals/facts/african-elephant\r\n\r\nFiring rates\r\nClassical view of the brain:\r\n- Each neuron is selective for one specific \r\nfeature in the input."", 'Power-efficiency at scale\r\nModern, deep neural networks*\r\nare trained using GPUs.\r\n* It is estimated that ChatGPT was trained on \r\n10,000-20,000 GPUs and that it will require\r\n30,000 GPUs to keep running stably in the future.\r\n* It is estimated that ChatGPT has 10-20 billion \r\nparameters.\r\nhttps://www.anandtech.com/show/4008/nvidias-geforce-gtx-580/17\r\n\r\nPower-efficiency at scale\r\nModern, deep neural networks*\r\nare trained using GPUs.\r\n* It is estimated that ChatGPT was trained on \r\n10,000-20,000 GPUs and that it will require\r\n30,000 GPUs to keep running stably in the future.\r\n* It is estimated that ChatGPT has 10-20 billion \r\nparameters.\r\nSingle model with 20 billion parameters:\r\n200 Watts x 30,000 GPUs = 6M Watts\r\n\r\nPower-efficiency at scale\r\nhttps://hai.stanford.edu/ai-index/2024-ai-index-report\r\nTraining a single large language model can \r\ngenerate greater CO2 emissions than the \r\ntotal lifetime emissions of 8 cars (in 2020)!\r\n\r\nPower-efficiency at scale\r\nhttps://hai.stanford.edu/ai-index/2024-ai-index-report\r\nTraining a single model can consume \r\nmore than 1000 MWh of power!\r\n\r\nPower-efficiency at scale\r\nhttps://hai.stanford.edu/ai-index/2024-ai-index-report\r\nTraining a single model can consume \r\nmore than 1000 MWh of power!\r\n‚Ä¶ with energy costs reaching 200M USD!\r\n\r\nPower-efficiency at scale\r\nYour brain runs on:\r\n\r\nPower-efficiency at scale\r\nYour brain runs on:\r\nHigh estimate ~3000 kcal a day\r\n   ‚âà145 Watts\r\n* Human brain has ~600 trillion synapses \r\n(‚âàparameters).\r\n\r\nPower-efficiency at scale\r\nYour brain runs on:\r\nHigh estimate ~3000 kcal a day\r\n   ‚âà145 Watts\r\n* Human brain has ~600 trillion synapses \r\n(‚âàparameters).\r\nOversimplification\r\nThere are also multiple other advantages‚Ä¶\r\n\r\nHuman vs. computer computation\r\n- Fast real-time decision making, e.g. sports, e-sports\r\n- Adaptive, e.g. context-aware and employs selective attention\r\n- Energy efficient: Close to 100 billion neurons in the brain\r\n- Robust, for example to changes in illumination or obstructions in object tracking\r\n\r\nHuman vs. computer computation\r\nBrains are energy efficient: Why?\r\n1.\r\nHigh temporal resolution (more computation with less neurons)\r\n2.\r\nSparse encoding\r\n\r\nHuman vs. computer computation\r\nQuestions?\r\nBrains are energy efficient: Why?\r\n1.\r\nHigh temporal resolution (more computation with less neurons)\r\n2.\r\nSparse encoding\r\n\r\nHow do biological neurons communicate?\r\nAnalogy to artificial neural networks\r\nReal neuron\r\nArtificial neuron\r\nCurrent\r\n\r\nHow do biological neurons communicate?\r\nHow does the electrical activity propagate?\r\n?\r\nCurrent\r\n\r\nHow do biological neurons work?\r\ntime\r\nelectrode\r\nhttps://tinmard.github.io/spike-sorting-animation.html\r\nQuick electrical pulses trigger chemical signals for the next neuron ‚Üí Spikes\r\n\r\nHow do biological neurons work?\r\nQuick electrical pulses trigger chemical signals for the next neuron ‚Üí Spikes\r\nhttps://tinmard.github.io/spike-sorting-animation.html\r\ntime\r\nelectrode\r\nFrom CS perspective:\r\nSparse binary \r\nencoding\r\n\r\nBiologically realistic spiking neuron models\r\nBiologically realistic neuron models have \r\na new dimension: Time!\r\nSpiking neural networks (SNNs):\r\nThe input x  (t  ) to each neuron is summed \r\n(integrated) over time.\r\nscalar\r\nfunction of \r\ntime\r\n(t)\r\n(t)\r\nhttps://www.mdpi.com/2076-3425/12/7/863\r\n\r\nHow to model spiking neurons?', 'In this example: SNNs are 6 to 8 times more energy efficient than FNNs.\r\nComputing energy consumption\r\nQuestions?\r\n\r\nReading materials\r\nMain reading:\r\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \r\nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\r\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\r\n- Neuromorphic computing:\r\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \r\nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\r\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \r\noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\r\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \r\nhttps://www.nature.com/articles/s41586-019-1677-2\r\nExtra reading:\r\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \r\nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\r\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \r\nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \r\nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\r\nBasics of \'conventional\' neural networks:\r\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\r\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.\r\n\r\nReferences\r\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \r\nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\r\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947.', '9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\r\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \r\nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\r\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \r\n(not publicly available) doi:10.1037/h0042519\r\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \r\nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\r\n6) https://github.com/idsc-frazzoli/retina\r\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \r\nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\r\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \r\nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\r\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \r\nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\r\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \r\nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\r\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \r\nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\r\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\r\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\r\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \r\n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568', '575(7784):607-17. \r\nhttps://www.nature.com/articles/s41586-019-1677-2\r\nExtra reading:\r\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \r\nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\r\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \r\nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \r\nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\r\nBasics of \'conventional\' neural networks:\r\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\r\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.\r\n\r\nReferences\r\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \r\nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\r\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \r\n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\r\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \r\nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\r\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \r\n(not publicly available) doi:10.1037/h0042519\r\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \r\nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\r\n6) https://github.com/idsc-frazzoli/retina\r\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \r\nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\r\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \r\nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\r\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \r\nNeural Networks.', ""‚Ä¢ Our question: Can we save energy with alternative approaches? \r\n‚Ä¢ We studied Grid Search, Random Search and Bayesian \r\nOptimisation.\r\n27\r\nTim's MSc Thesis, 2022 \r\nAccepted at CAIN‚Äô23\r\n\r\n\r\nResults\r\n29\r\nConclusions? \r\n‚Ä¢ Bayesian converges faster. \r\n‚Ä¢ No clear winner between Grid and Random\r\n\r\nDeepSeekMoE\r\n30\r\nPreprint at ArXiv, 2024 https://arxiv.org/pdf/\r\n2401.06066\r\n\r\nMixture of Experts\r\n‚Ä¢ Llama3.1 has 405B parameters, DeepSeek V3 671B \r\n‚Ä¢ Yet DeepSeek has quicker inference times and claims less energy \r\nconsumption (?) \r\n‚Ä¢ Divide the model into smaller blocks of experts \r\n‚Ä¢ Tokens get routed to certain experts based on the query \r\n‚Ä¢ Only part of the network is active during inference \r\n‚Ä¢ DeepSeek claims only 37B out of 671B parameters get active\r\n31\r\n\r\nDeepSeekMoE\r\n32\r\n\r\nDeepSeekMoE\r\n33\r\n‚Ä¢ Comparable performance to \r\nLLaMA2 7B effectively using \r\nless half the parameters \r\n‚Ä¢ Less computational power \r\n‚Ä¢ Problems (?) \r\n‚Ä¢ Still need to load all the \r\nparameters \r\n‚Ä¢ High memory -> high \r\nembodied carbon\r\n\r\nGreen AI at FacebookMeta\r\n34\r\nSustainable AI: Environmental Implications, \r\nChallenges and Opportunities (2022)\r\n\r\nCarbon footprint mapped to the AI lifecycle\r\n‚Ä¢ There are 4 main overarching stages where carbon emissions need to be isolated: data \r\ncollection, experimentation, training, inference. \r\n‚Ä¢ At Facebook, recommendation systems split energy consumption evenly between \r\ntraining and inference; text translation models have a 35%/65% split. (Operational cost) \r\n‚Ä¢ Operational/embodied cost split: 30%/70%\r\n35\r\n\r\nOpen issues according to Meta\r\n‚Ä¢ A vast portion of projects only use GPUs at 30%.\u2028\r\nShould be higher to attenuate embodied carbon.\r\n36\r\nBased on 10K AI projects\r\n\r\nData Jan\r\nInformed Adaptation\r\nData Feb\r\nData Mar\r\nData Apr\r\nData May\r\n‚Ä¶\r\n~Data Dec\r\n~Data Dec\r\nData Jan\r\nData Feb\r\nData Mar\r\nData Apr\r\nData May\r\n‚Ä¶\r\nModel update Model update Model update\r\nCheck if \r\ndata change\r\nCheck if \r\ndata change\r\nCheck if \r\ndata change\r\nModel update\r\nBlind Adaptation\r\nThe AI Model will be \r\nupdated fewer times and \r\nonly when necessary.\r\nKnow when to retrain models\r\nNeither too early nor too late\r\n37\r\nAdaptation Techniques\r\n?\r\n\r\nGreen Architectural Tactics for ML-Enabled \r\nSystem\r\n38\r\nICSE-SEIS 2024\r\n\r\nArchitectural tactics\r\n39\r\n\r\nData-centric\r\n40\r\n‚Ä¢ Reduce data size \r\n‚Ä¢ Sampling \r\n‚Ä¢ Dimensionality reduction \r\n‚Ä¢ Quantization\r\n\r\nAlgorithm Design\r\n41\r\n‚Ä¢ Carefully select your algorithm \r\n‚Ä¢ You don‚Äôt need the fanciest \r\ntechniques\r\n\r\nModel Optimization\r\n42\r\n‚Ä¢ Add energy to training parameters \r\n‚Ä¢ Reduce FLOPs \r\n‚Ä¢ Pruning, sparsity \r\n‚Ä¢  Take advantage of existing models\r\n\r\nModel Training\r\n43\r\n‚Ä¢ Quantization\r\n‚Ä¢ SAVE TRAINING PROGRESS\r\n\r\nModel Deployment\r\n44\r\n‚Ä¢ Distributed deployment \r\n‚Ä¢ Energy efficient hardware and \r\nconfigurations\r\n\r\nModel Management\r\n45\r\n‚Ä¢ Reuse the model as much as possible \r\n\r\nRethinking the Architecture: Spiking Neural Networks\r\n46\r\n\r\nRethinking the Architecture: Spiking Neural Networks\r\n47\r\n\r\nSELF Lab\r\n48\r\n\r\nrecap"", '‚Ä¢ Improve parameter-tuning strategy.\r\n11\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ We need benchmarks. \r\n‚Ä¢ AllenAI leaderboard\u2028\r\nhttps://leaderboard.allenai.org \r\n‚Ä¢ No carbon metrics, yet \r\n‚Ä¢ Report comparable proxies for energy \r\nconsumption. \r\n‚Ä¢ ‚ö† Learning algorithms behave in a non-\r\ndeterministic \r\n‚Ä¢ ‚ö† Different data-points lead to different \r\nenergy consumption\r\n12\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ Reporting measured energy consumption \r\n‚Ä¢ + Accurate \r\n‚Ä¢ + Easy to map to carbon emissions \r\n‚Ä¢ - Hard to measure \r\n‚Ä¢ - Low replicability \r\n‚Ä¢ Reporting time / estimation based on time & hardware \r\n‚Ä¢ + Easy to measure \r\n‚Ä¢ + Correlates with energy consumption in most cases. \r\n‚Ä¢ -  Difficult to compare with measurements from other setups \r\n‚Ä¢ E.g., floating point operations (FPOs) (?) \r\n‚Ä¢ + comparable across different setups \r\n‚Ä¢ + cheap \r\n‚Ä¢ - does not factor in memory energy consumption \r\n‚Ä¢ - does not reflect carbon emissions\r\n13\r\n\r\nData-centric AI\r\n\r\nData-centric AI\r\n‚Ä¢ Emerging discipline that deals with systematically engineering data to build AI \r\nsystems. \r\n‚Ä¢ Shift from improving the training strategy to improving the data. \r\n‚Ä¢ It is better to have small but reliable datasets than large but noisy \r\ndatasets. \r\n‚Ä¢ => Improve data collection, data labelling, and data preprocessing. \r\n‚Ä¢ More about data-centric AI by Andrew Ng:\u2028\r\nhttps://www.youtube.com/watch?v=06-AZXmwHjo\r\n15\r\n\r\n\r\nGreen Data-centric AI\r\n‚Ä¢ How do different ML algorithms compare \r\nin terms of energy consumption? \r\n‚Ä¢ How does number of rows relate to the \r\nenergy consumption of ML models? \r\n‚Ä¢ How does number of features relate to \r\nthe energy consumption of ML models? \r\n‚Ä¢ What is the impact of reducing data in the \r\nperformance of the model? \r\n‚Ä¢ Method -> results -> discussion\r\n17\r\n\r\nMethod\r\n‚Ä¢ Single object of study: natural language model to detect spam messages. \r\n‚Ä¢ 6 machine learning algorithms: SVM, Decision Tree, KNN, Random Forrest, \r\nAdaBoost, Bagging Classifier. \r\n‚Ä¢ Reduce the number of rows. 10%, 20%, .., 100% \r\n‚Ä¢ Stratified random sampling (?) \r\n‚Ä¢ Reduce the number of features. 10%, 20%, .., 100% \r\n‚Ä¢ Feature importance metric based on the Chi-Square Test (Chi2) \r\n‚Ä¢ Estimate energy consumption using a RAPL-based tool. (?)\r\n18\r\n\r\n‚Ä¢ Repeat 30 times \r\n‚Ä¢ Fix random seeds \r\n‚Ä¢ ‚Ä¶ \r\n‚Ä¢ Data was not Normal => tailed Normal distribution.\r\n19\r\n(?)\r\n\r\nResults: energy consumption of algorithms\r\n\r\nResults: energy vs data shape\r\n\r\nResults: performance vs data shape\r\n\r\nDiscussion\r\n‚Ä¢ Other data properties should be investigated. \r\n‚Ä¢ E.g., data types \r\n‚Ä¢ Reporting energy data is essential. It can lead to different model selection \r\nwithout hindering model performance. \r\n‚Ä¢ There is a big opportunity in Model and Data Simplification.\r\n23\r\n\r\nData/Model Simplification\r\n‚Ä¢ (?) \r\n‚Ä¢ Data selection \r\n‚Ä¢ Data quantisation. Posit? \r\n‚Ä¢ Data distillation \r\n‚Ä¢ Coreset extraction (?) \r\n‚Ä¢ Model distillation \r\n‚Ä¢ Model quantisation \r\n‚Ä¢ Model pruning \r\n‚Ä¢ ‚Ä¶\r\n24\r\n\r\nPosit vs Float\r\nMore about this: https://spectrum.ieee.org/floating-point-numbers-posits-processor\r\nBetter for DL use cases\r\n\r\nHow can we tune \r\nlearning \r\nparameters \r\nefficiently?\r\n\r\nHyper parameter tuning\r\n‚Ä¢ When training an ML model, there are several parameters that need to be \r\ntuned. \r\n‚Ä¢ E.g., in SVM we have the Regularization parameter C, the kernel function, \r\nthe degree of the kernel function, and depending on the case, many other. \r\n‚Ä¢ The common approach revolves around grid search.', '8. Green AI\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nLu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\nCarolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl\r\n\r\n- Overview of Green AI \r\n- Large language models \r\n- Green data-centric AI \r\n- Model simplification \r\n- Hyper parameter tuning \r\n- Mixture of Experts and DeepSeek \r\n- Green AI at Meta \r\n\r\nAI\r\n‚Ä¢ Artificial Intelligence (AI) is the branch of computer science that deals with \r\nautomating tasks that typically require human intelligence. \r\n‚Ä¢ In the past years AI has been widely applied across different domains.\u2028\r\nE.g., health care, transportation, finance. \r\n‚Ä¢ To deploy AI systems, we test them against benchmarks (or validation sets). \r\n‚Ä¢ The goal is to outperform the previous existing models. \r\n‚Ä¢ E.g., in Machine Learning we usually resort to accuracy metrics. The \r\nhighest the accuracy, the better the model.\r\n3\r\n\r\nSince 2012, the amount of computing used for AI \r\ntraining has been doubling every 6 months\r\n‚Ä¢ https://epoch.ai/blog/compute-trends\r\n4\r\n\r\n‚Ä¢ To create better AI systems we are currently adding \r\n‚Ä¢ More data \r\n‚Ä¢ More experiments \r\n‚Ä¢ Larger models\r\n5\r\n\r\nThe Equation of Red AI\r\nCost(R) ‚àùE¬∑D¬∑H\r\nCost of a single (E)xample\r\nSize of (D)ataset\r\nNumber of (H)yperparameters\r\nBy Schwartz et al. (2020)\r\n\r\nIssues of Red AI\r\n‚Ä¢ High costs (hardware, electricity, data access, etc.) \r\n‚Ä¢ Limited reproducibility.  \r\n‚Ä¢ Energy consumption. \r\n‚Ä¢ Carbon emissions. \r\n‚Ä¢ SMEs can hardly be competitive. \r\n‚Ä¢ Groundbreaking AI research is mostly done by tech giants.\r\n7\r\n\r\nA few examples of Red AI\r\n‚Ä¢ Google‚Äôs BERT-large \r\n‚Ä¢ 350 million features \r\n‚Ä¢ Trained for 2.5 days using 512 TPU chips, costing $60K+ \r\n‚Ä¢ Open-GPT3 (now GPT-4/o1) \r\n‚Ä¢ 550 tonnes CO2-eq (Patterson, 2021) \r\n‚Ä¢ 175 billion features \r\n‚Ä¢ API is open but no-pretrained model is available \r\n‚Ä¢ AlphaGo \r\n‚Ä¢ 1920 CPUs, 280 GPUs, costing $35M\r\n8\r\n\r\nRed AI in Large Language Models (LLMs)\r\n‚Ä¢ OPT by Meta reports 75 tons CO2-eq (1/7 of OpenGPT‚Äôs footprint).\u2028\r\n(Also 175billion params) \r\n‚Ä¢ However, Llama 3 reported 2,290 tons of CO2-eq (7.7M GPU hours \r\ntraining ) \r\n‚Ä¢ Open science: release includes both the pretrained models and the code \r\nneeded to train and use them. \r\n‚Ä¢ DeepSeek-V3 claims ‚Äúonly‚Äù 2.78M GPU hours \r\n‚Ä¢ Bloom by Huggingface reports 25 tons, 51 when considering embodied \r\nand operational carbon footprint. (176billion params)\r\n9\r\n\r\nRed AI\r\nAccuracy: 0.999999999\r\nGreen AI\r\n‚Ä¢ Energy \r\n‚Ä¢ Time \r\n‚Ä¢ Reproducibility \r\n‚Ä¢ Reusage\r\n\r\nHow can we adopt Green AI\r\n‚Ä¢ Check whether AI is needed. \r\n‚Ä¢ Select green datacenters. \r\n‚Ä¢ Run on low carbon intensity hours. \r\n‚Ä¢ Opt for GPU-optimised solutions (?) \r\n‚Ä¢ Opt for low-power hardware (e.g., Nvidia Jetson boards) \r\n‚Ä¢ Or GPUs that provide energy metrics (e.g., NVIDIA GPUs via the nvidia-smi tool) \r\n‚Ä¢ Report energy/carbon metrics (e.g., embed in MLFlow?)', ""‚Ä¢ 6 machine learning algorithms: SVM, Decision Tree, KNN, Random Forrest, \r\nAdaBoost, Bagging Classifier. \r\n‚Ä¢ Reduce the number of rows. 10%, 20%, .., 100% \r\n‚Ä¢ Stratified random sampling (?) \r\n‚Ä¢ Reduce the number of features. 10%, 20%, .., 100% \r\n‚Ä¢ Feature importance metric based on the Chi-Square Test (Chi2) \r\n‚Ä¢ Estimate energy consumption using a RAPL-based tool. (?)\r\n18\r\n\r\n‚Ä¢ Repeat 30 times \r\n‚Ä¢ Fix random seeds \r\n‚Ä¢ ‚Ä¶ \r\n‚Ä¢ Data was not Normal => tailed Normal distribution.\r\n19\r\n(?)\r\n\r\nResults: energy consumption of algorithms\r\n\r\nResults: energy vs data shape\r\n\r\nResults: performance vs data shape\r\n\r\nDiscussion\r\n‚Ä¢ Other data properties should be investigated. \r\n‚Ä¢ E.g., data types \r\n‚Ä¢ Reporting energy data is essential. It can lead to different model selection \r\nwithout hindering model performance. \r\n‚Ä¢ There is a big opportunity in Model and Data Simplification.\r\n23\r\n\r\nData/Model Simplification\r\n‚Ä¢ (?) \r\n‚Ä¢ Data selection \r\n‚Ä¢ Data quantisation. Posit? \r\n‚Ä¢ Data distillation \r\n‚Ä¢ Coreset extraction (?) \r\n‚Ä¢ Model distillation \r\n‚Ä¢ Model quantisation \r\n‚Ä¢ Model pruning \r\n‚Ä¢ ‚Ä¶\r\n24\r\n\r\nPosit vs Float\r\nMore about this: https://spectrum.ieee.org/floating-point-numbers-posits-processor\r\nBetter for DL use cases\r\n\r\nHow can we tune \r\nlearning \r\nparameters \r\nefficiently?\r\n\r\nHyper parameter tuning\r\n‚Ä¢ When training an ML model, there are several parameters that need to be \r\ntuned. \r\n‚Ä¢ E.g., in SVM we have the Regularization parameter C, the kernel function, \r\nthe degree of the kernel function, and depending on the case, many other. \r\n‚Ä¢ The common approach revolves around grid search. The user provides a \r\nsequence of possible values for each parameter and the pipeline runs all \r\npossible combinations. \r\n‚Ä¢ Our question: Can we save energy with alternative approaches? \r\n‚Ä¢ We studied Grid Search, Random Search and Bayesian \r\nOptimisation.\r\n27\r\nTim's MSc Thesis, 2022 \r\nAccepted at CAIN‚Äô23\r\n\r\n\r\nResults\r\n29\r\nConclusions? \r\n‚Ä¢ Bayesian converges faster. \r\n‚Ä¢ No clear winner between Grid and Random\r\n\r\nDeepSeekMoE\r\n30\r\nPreprint at ArXiv, 2024 https://arxiv.org/pdf/\r\n2401.06066\r\n\r\nMixture of Experts\r\n‚Ä¢ Llama3.1 has 405B parameters, DeepSeek V3 671B \r\n‚Ä¢ Yet DeepSeek has quicker inference times and claims less energy \r\nconsumption (?) \r\n‚Ä¢ Divide the model into smaller blocks of experts \r\n‚Ä¢ Tokens get routed to certain experts based on the query \r\n‚Ä¢ Only part of the network is active during inference \r\n‚Ä¢ DeepSeek claims only 37B out of 671B parameters get active\r\n31\r\n\r\nDeepSeekMoE\r\n32\r\n\r\nDeepSeekMoE\r\n33\r\n‚Ä¢ Comparable performance to \r\nLLaMA2 7B effectively using \r\nless half the parameters \r\n‚Ä¢ Less computational power \r\n‚Ä¢ Problems (?) \r\n‚Ä¢ Still need to load all the \r\nparameters \r\n‚Ä¢ High memory -> high \r\nembodied carbon\r\n\r\nGreen AI at FacebookMeta\r\n34\r\nSustainable AI: Environmental Implications, \r\nChallenges and Opportunities (2022)\r\n\r\nCarbon footprint mapped to the AI lifecycle\r\n‚Ä¢ There are 4 main overarching stages where carbon emissions need to be isolated: data \r\ncollection, experimentation, training, inference. \r\n‚Ä¢ At Facebook, recommendation systems split energy consumption evenly between \r\ntraining and inference; text translation models have a 35%/65% split. (Operational cost) \r\n‚Ä¢ Operational/embodied cost split: 30%/70%\r\n35\r\n\r\nOpen issues according to Meta\r\n‚Ä¢ A vast portion of projects only use GPUs at 30%.\u2028\r\nShould be higher to attenuate embodied carbon."", '‚Ä¢ Groundbreaking AI research is mostly done by tech giants.\r\n7\r\n\r\nA few examples of Red AI\r\n‚Ä¢ Google‚Äôs BERT-large \r\n‚Ä¢ 350 million features \r\n‚Ä¢ Trained for 2.5 days using 512 TPU chips, costing $60K+ \r\n‚Ä¢ Open-GPT3 (now GPT-4/o1) \r\n‚Ä¢ 550 tonnes CO2-eq (Patterson, 2021) \r\n‚Ä¢ 175 billion features \r\n‚Ä¢ API is open but no-pretrained model is available \r\n‚Ä¢ AlphaGo \r\n‚Ä¢ 1920 CPUs, 280 GPUs, costing $35M\r\n8\r\n\r\nRed AI in Large Language Models (LLMs)\r\n‚Ä¢ OPT by Meta reports 75 tons CO2-eq (1/7 of OpenGPT‚Äôs footprint).\u2028\r\n(Also 175billion params) \r\n‚Ä¢ However, Llama 3 reported 2,290 tons of CO2-eq (7.7M GPU hours \r\ntraining ) \r\n‚Ä¢ Open science: release includes both the pretrained models and the code \r\nneeded to train and use them. \r\n‚Ä¢ DeepSeek-V3 claims ‚Äúonly‚Äù 2.78M GPU hours \r\n‚Ä¢ Bloom by Huggingface reports 25 tons, 51 when considering embodied \r\nand operational carbon footprint. (176billion params)\r\n9\r\n\r\nRed AI\r\nAccuracy: 0.999999999\r\nGreen AI\r\n‚Ä¢ Energy \r\n‚Ä¢ Time \r\n‚Ä¢ Reproducibility \r\n‚Ä¢ Reusage\r\n\r\nHow can we adopt Green AI\r\n‚Ä¢ Check whether AI is needed. \r\n‚Ä¢ Select green datacenters. \r\n‚Ä¢ Run on low carbon intensity hours. \r\n‚Ä¢ Opt for GPU-optimised solutions (?) \r\n‚Ä¢ Opt for low-power hardware (e.g., Nvidia Jetson boards) \r\n‚Ä¢ Or GPUs that provide energy metrics (e.g., NVIDIA GPUs via the nvidia-smi tool) \r\n‚Ä¢ Report energy/carbon metrics (e.g., embed in MLFlow?) \r\n‚Ä¢ Use pre-trained models (Transfer Learning) \r\n‚Ä¢ Preprocess dataset to reduce size. \r\n‚Ä¢ Improve parameter-tuning strategy.\r\n11\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ We need benchmarks. \r\n‚Ä¢ AllenAI leaderboard\u2028\r\nhttps://leaderboard.allenai.org \r\n‚Ä¢ No carbon metrics, yet \r\n‚Ä¢ Report comparable proxies for energy \r\nconsumption. \r\n‚Ä¢ ‚ö† Learning algorithms behave in a non-\r\ndeterministic \r\n‚Ä¢ ‚ö† Different data-points lead to different \r\nenergy consumption\r\n12\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ Reporting measured energy consumption \r\n‚Ä¢ + Accurate \r\n‚Ä¢ + Easy to map to carbon emissions \r\n‚Ä¢ - Hard to measure \r\n‚Ä¢ - Low replicability \r\n‚Ä¢ Reporting time / estimation based on time & hardware \r\n‚Ä¢ + Easy to measure \r\n‚Ä¢ + Correlates with energy consumption in most cases. \r\n‚Ä¢ -  Difficult to compare with measurements from other setups \r\n‚Ä¢ E.g., floating point operations (FPOs) (?) \r\n‚Ä¢ + comparable across different setups \r\n‚Ä¢ + cheap \r\n‚Ä¢ - does not factor in memory energy consumption \r\n‚Ä¢ - does not reflect carbon emissions\r\n13\r\n\r\nData-centric AI\r\n\r\nData-centric AI\r\n‚Ä¢ Emerging discipline that deals with systematically engineering data to build AI \r\nsystems. \r\n‚Ä¢ Shift from improving the training strategy to improving the data. \r\n‚Ä¢ It is better to have small but reliable datasets than large but noisy \r\ndatasets. \r\n‚Ä¢ => Improve data collection, data labelling, and data preprocessing. \r\n‚Ä¢ More about data-centric AI by Andrew Ng:\u2028\r\nhttps://www.youtube.com/watch?v=06-AZXmwHjo\r\n15\r\n\r\n\r\nGreen Data-centric AI\r\n‚Ä¢ How do different ML algorithms compare \r\nin terms of energy consumption? \r\n‚Ä¢ How does number of rows relate to the \r\nenergy consumption of ML models? \r\n‚Ä¢ How does number of features relate to \r\nthe energy consumption of ML models? \r\n‚Ä¢ What is the impact of reducing data in the \r\nperformance of the model?', ""Unless there‚Äôs a \r\ngood reason. \r\n‚Ä¢ E.g., somewhere amongst the 30 executions, \r\nthere might be 1 or 2 that failed to finish due \r\nto some unexpected error. \r\n‚Ä¢ (It happens and that‚Äôs ok!)‚Äì consequently, \r\nthe execution is shorter and spends less \r\nenergy ‚Äì falsely appearing as more \r\nenergy efficient. \r\n‚Ä¢ If data is not Normal there might be some \r\nissues affecting the measurements that \r\nmight be ruining results. It is important to \r\ninvestigate this.\r\n16\r\n\r\nEnergy data is not normal. Why?\r\n‚Ä¢ It might be caused by one of the following reasons: \r\n‚Ä¢ There was an error in some of the executions. If not detected and fixed it \r\nmight ruin results. \r\n‚Ä¢ Your tests are not fully replicable or are not deterministic. Quite frequent \r\nwhen you have internet requests or random-based algorithms. \r\n‚Ä¢ There is an unusual task being run by the system during some experiments. \r\n‚Ä¢ The computer entered a different power mode. \r\n‚Ä¢ External physical conditions have changed. E.g., someone opened a \r\nwindow.\r\n17\r\n\r\nEnergy data is not normal. How to fix?\r\n‚Ä¢ We have 2+1 options: \r\n1. Remove outliers. If there are only a few points that deviate from the normal \r\ndistribution, it is okay to simply remove them. \r\n‚Ä¢ Use the z-score outlier removal. (?) \r\n‚Ä¢ Remove all data points that deviate from the mean more than 3 standard \r\ndeviations: \r\n \r\n2. Fix the issue and rerun experiments. \r\n3. Conclude that nothing can be done about it and data will never be normal. (e.g., \r\nin AI, executions are rarely deterministic). ‚ö† Only after ruling out the previous \r\npoints.\r\n| ¬Øx ‚àíx| > 3s\r\n18\r\n\r\nHow do we know whether data is Normal?\r\n‚Ä¢ Visualise distribution shape: violin plots, histograms, density plot.\u2028\r\n \r\n‚Ä¢ Shapiro-Wilk test.\u2028\r\ndata is not normal;\u2028\r\nwe are not sure but it is okay to assume that data is \r\nnormal.\r\np-value < 0.05 ‚áí\r\np-value ‚â•0.05 ‚áí\r\n19\r\n\r\nAfter having all data ready, which artefact \r\nis more energy efficient(?) \r\nFirst approach: compare sample means. \r\n‚ö† assuming normal distribution\r\n\r\nStatistical significance\r\n‚Ä¢ Even if, on average, one artefact has lower \r\nenergy consumption than other,  it might be just \r\na random difference. \r\n‚Ä¢ When we extract a sample from a normal \r\ndistribution it will never be the exact same \r\n‚Ä¢ Statistical significance tests help you \r\nunderstand the differences in the average are \r\nconclusive/significant or inconclusive/\r\ninsignificant.\r\n21\r\n‚ö† assuming normal distribution\r\n\r\nStatistical significance test\r\n‚Ä¢ Two-sided parametric test Welch‚Äôs t-test. \r\n‚Ä¢ Less known alternative to student‚Äôs t-test.\r\n22\r\nWelch‚Äôs t-test in Python\r\nfrom scipy.stats import ttest_ind \r\n_,pvalue = ttest_ind(sample_a, sample_b, \r\n                     equal_var=False, \r\n                     alternative='two-sided')\r\n(?)\r\n‚ö† assuming normal distribution\r\n\r\nEffect Size analysis\r\n‚Ä¢ Now that we know that results are statistically significant we need to \r\nmeasure the difference between the two samples. \r\n‚Ä¢ Mean difference: \r\n \r\n‚Ä¢ Percent change: \r\n \r\n‚Ä¢ Cohen‚Äôs d (informal definition: mean difference normalized by a combined \r\nstandard deviation): \r\nŒî¬Øx\r\nxB ‚àíxA\r\nxA\r\n√ó 100 % = Œî¬Øx\r\nxA\r\n√ó 100 %\r\nŒî¬Øx\r\n1\r\n2\r\ns21 + s22\r\n23\r\n‚ö† assuming normal distribution\r\n\r\nImagine that version A spends 70J and \r\nversion B spends 69J with a \r\n."", '. . + 2P(tn‚àí1) + P(tn)]\r\nMeasured Energy \r\nConsumption\r\n‚ö† Sometimes you cannot assume that the sampling interval (\r\n) is always the same. ‚ö†\r\nŒît\r\nTrapezoid Rule\r\n\r\nTrapezoid Rule in Python\r\nimport numpy as np \r\nenergy_consumption = np.trapz(power_sample, timestamps) \r\n\r\nAverage power\r\n‚Ä¢ Easy to convert to energy consumption \r\n‚Ä¢ Simply multiply by the elapsed time. \r\n‚Ä¢ (This is another reason to always collect time data along with energy \r\nmetrics.)\r\n11\r\nEnergy = Pavg¬∑Œît\r\n\r\nPower or Energy?\r\n‚Ä¢ Average power consumption makes sense when we report the \r\nconsumption of a continuous use case. E.g., reading an ebook in your \r\ncomputer. \r\n‚Ä¢ Energy consumption makes sense in one-off use cases. E.g., energy \r\nconsumption of a bitcoin transaction. \r\n‚ö†\r\n\r\nLearning activity\r\n‚Ä¢ Pair up with one colleague and discuss potential software use cases where \r\none should test energy efficiency. \r\n‚Ä¢ Choose one use case where energy consumption is the best metric to \r\ndiscuss/test energy efficiency. \r\n‚Ä¢ Choose one use case where average power consumption is the best \r\nmetric to discuss/test energy efficiency.\r\n13\r\n\r\nEnergy Delay Product (EDP)\r\n‚Ä¢ In some cases, to achieve less energy consumption, one simply runs the \r\nsoftware on a low power mode of the CPU. \r\n‚Ä¢ E.g., setting the CPU at a low frequency will make execution slow but more \r\nenergy-efficient. \r\n‚Ä¢ Energy consumption metric that penalizes slow runs \r\n \r\n \r\n‚Ä¢ Gives more importance to application runtime, with the goal of making both \r\nlow energy and fast runtime applications.\r\nEDP = E √ó t = ŒîP √ó t2\r\n14\r\n\r\nmAh\r\njoules\r\nmilliampere hour\r\nmobile industry\r\nThis is not energy or power. \r\nIt is a unit of electric charge.\r\nThe typical notebook battery has between 2,000 \r\nand 6,000 milliamp hours (mAh)\r\n?\r\n\r\nElectric charge\r\n‚Ä¢ International System of Units (SI): Coulomb (C). \r\n‚Ä¢ 1 electron has 1.602176634√ó10-19 coulombs. Moving the electron around the electric \r\nfield requires work (energy consumption).  \r\n‚Ä¢ mAh is the most common metric to specify the capacity of batteries. \r\n‚Ä¢ 1 mAh = 3.6C \r\n‚Ä¢ To compute the actual energy of a battery we need to factor in voltage: \r\n \r\n  \r\n‚Ä¢ E.g., for a battery with a capacity of 1000mAh: \r\n \r\nEnergy = Voltage √ó Charge\r\n1000mAh √ó 3.8V = 3800mWh = 3.8Wh = 3.8 √ó 3600J = 13680J\r\n16\r\n\r\nWhy do we use charge units for batteries?\r\n‚Ä¢ There is a continuous change of voltage throughout a charge/discharge \r\ncycle. \r\n‚Ä¢ E.g., it can start with 4.5 V at a ‚Äú100%‚Äù capacity and from to 3.0V at 5% \r\ncapacity. \r\n‚Ä¢ Most devices use voltage to compute their battery level percentage.\r\n17\r\n\r\nInternational System of Units (SI)\r\n‚Ä¢ Energy: Joule \r\n‚Ä¢ Power: Watt \r\n‚Ä¢ Charge: Coulomb \r\n‚Ä¢ (Time: second)\r\n18\r\n\r\nSI Units are difficult to grasp\r\n‚Ä¢ Whenever talking to a general audience use relative units: \r\n‚Ä¢ Compare to the other well-known things: \r\n‚Ä¢ Yearly household energy consumption \r\n‚Ä¢ Yearly country electrical energy consumption.\u2028\r\n(e.g., https://ccaf.io/cbeci/index/comparisons) \r\n‚Ä¢ Driving kms with a standard car \r\n‚Ä¢ Percentage of a normal battery charge cycle. \r\n‚Ä¢ Compare to other software artefacts/usecases: \r\n‚Ä¢ E.g, percentage of Version A over Version B.', 'google.com/view/energy-efficiency-languages\r\n21\r\nAna Radovanovic ÃÅ, Ross Koningstein, Ian Schneider, Bokan \r\nChen, Alexandre Duarte, Binz Roy, Diyue Xiao, Maya \r\nHaridasan, Patrick Hung, Nick Care, Saurav Talukdar, Eric \r\nMullen, Kendal Smith, MariEllen Cottman, and Walfredo Cirne \r\n\r\n\r\n‚Ä¢ Google‚Äôs Carbon-Intelligent Computing System (CICS) \r\n‚Ä¢ Main idea: use carbon-intensity data to shift datacenter jobs in time \r\n‚Ä¢ Typically, job schedulers use a metric of cluster capacity to schedule a job in \r\na particular cluster. \r\n‚Ä¢ CICS overrides this metric with the virtual capacity curve (VCC) that \r\nfactors in Carbon intensity \r\n‚Ä¢ When a new job comes in, the scheduler estimates its CPU load and power \r\nusage and assigns it to a cluster if the VCC is not exceeded.\r\n23\r\n\r\n‚Ä¢ Jobs are divided between flexible and inflexible. \r\n‚Ä¢ Flexible load is considered shapeable/shiftable as long as its total daily \r\ncompute (CPU) demand is preserved \r\n‚Ä¢ The system needs to consider that, while running a job, the virtual capacity \r\ncurve (VCC) might drop. Hence, this job should not start in the first place. \r\n‚Ä¢ They forecast VCC for the next day\r\n24\r\n\r\n\r\nVirtual Cluster Capacity (VCC)\r\n‚Ä¢ Aims at reducing the peak load at carbon intensive hours but in total it should allow for the \r\nsome amount of daily computation! \r\n‚Ä¢ Considers Carbon intensity \r\n‚Ä¢ Using data from electricityMap.org \r\n‚Ä¢ It does not use carbon intensity directly.\u2028\r\nCarbon intensity is converted to a cost (kgCO2 -> $$) \r\n‚Ä¢ This way, they can factor in other metrics that can also be converted to money. E.g., the \r\ncost saved by preventing peak load \r\n‚Ä¢ Peak workload entails extra cost at the infrastructure level (e.g., control faclities‚Äô \r\ntemperature). \r\n‚Ä¢ By using money cost instead of carbon cost, they have more data available.\r\n26\r\n\r\nVirtual Cluster Capacity (VCC)\r\n‚Ä¢ If the forecast of VCC fails it shift flexible workload more than expected.  \r\n‚Ä¢ This happens because the amount of workload forecasted was below the \r\nworkload needed, and VCC was ‚Äúaggressively‚Äù low. \r\n‚Ä¢ The systems fall back to the real cluster capacity for 1 week until results \r\nstart being realistic again.\r\n27\r\n\r\nNext steps\r\n‚Ä¢ They will consider spatial flexibility. \r\n‚Ä¢ I.e., tasks that can be shifted over time and over space. \r\n‚Ä¢ It needs to factor in relocation overheads, though.\r\n28\r\n\r\nCritical questions\r\n‚Ä¢ Who defines what is flexible and inflexible? \r\n‚Ä¢ How do you estimate the CPU load of a given task?\r\n29\r\n\r\nEnergy Regression Testing\r\n‚ÜíEnergy?\r\nGreener? Greener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\n\r\nE-compare\r\nGithub Actions\r\n‚ûú https://koenhagen.github.io/E-Compare/\r\n\r\nEnergy Regression Testing \r\n\r\n4. Debugging Energy with \r\nDocker Images\r\n\r\nUnveiling the Energy Vampires \r\nA methodology for debugging Software \r\nEnergy Consumption\r\n ‚úÖ ICSE 2025\r\n\r\nData Centers and Docker\r\n‚Ä¢ Containers are the most popular way to deploy apps into the cloud \r\n‚Ä¢ Base image is an important choice when building an image \r\n‚Ä¢ Criteria \r\n‚Ä¢ Linux distribution and binaries \r\n‚Ä¢ Image size \r\n‚Ä¢ Energy?\r\n35\r\n\r\nRedis energy consumption\r\n‚Ä¢ Ubuntu/Alpine base images have different energy consumption for Redis\r\n36\r\n\r\nRedis Energy Consumption\r\n‚Ä¢RQ1: What is the difference \r\nin energy consumption \r\nbetween glibc and musl? \r\n‚Ä¢RQ2: Can we use tracing \r\nto compare energy \r\nconsumption in shared \r\nlibraries?', '[‚Ä¶]\r\n13\r\n\r\nAvoid Extraneous Graphics and \r\nAnimations  \r\n‚Ä¢ Context: Mobile apps that feature impressive graphics \r\nand animations. [‚Ä¶] \r\n‚Ä¢ Solution: Study the importance of graphics and \r\nanimations to the user experience and reduce them when \r\napplicable. [‚Ä¶]\r\n‚Ä¢ Example: Resort to low frame rates for animations when \r\npossible. \r\nDespite being important to improve user experience, graphics \r\nand animations are battery intensive and should be used with \r\nmoderation.  \r\n14\r\n\r\nEnergy Patterns are \r\nmore Frequent\r\nin Android Apps\r\n\r\nExample case: Nextcloud\r\nFOSS\r\n\r\nExample case: Nextcloud\r\n‚Ä¢ Users complain that sometimes they go on a trip and  Nextcloud drains their \r\nbattery. Users consider uninstalling the app when battery life is essential. \r\n‚Ä¢ File sync can be energy-greedy. Send large files to the server, long 3G/4G data connections. \r\n‚Ä¢ It is mostly used for backup. No real-time collaboration is needed. \r\n‚Ä¢ Energy requirements vary depending on context and user. Some days you really \r\nneed all the battery you can get. \r\n‚Ä¢ https://github.com/nextcloud/android/commit/\r\n8bc432027e0d33e8043cf40192203203a40ca29c\r\nSolutions?\r\n17\r\n\r\nExample case: K-9 mail\r\n18\r\n\r\nExample case: K-9 mail\r\n19\r\nSolutions?\r\n‚Ä¢ Some users noticed that K-9 mail was spending more energy than usual. üôâ \r\n‚Ä¢ A user that was having issues with a personal mail server  noticed that K-9 \r\nmail was the one of the most energy-greedy apps. IMAP IDLE protocol for real-time \r\nnotifications. \r\n‚Ä¢ When a connection is not possible, the app automatically retries later. \r\n‚Ä¢ https://github.com/k9mail/k-9/commit/\r\n86f3b28f79509d1a4d613eb39f60603e08579ea3\r\n\r\nEcoAndroid\r\n‚Ä¢ Plugin for IntelliJ (Android Studio) \r\n‚Ä¢ Dynamic Retry Delay \r\n‚Ä¢ Push Over Poll \r\n‚Ä¢ Reduce Size \r\n‚Ä¢ Cache \r\n‚Ä¢ Avoid Graphics and Animations\r\n20\r\n\r\nCarbon-Aware Computing for \r\nDatacenters \r\nhttps://sites.google.com/view/energy-efficiency-languages\r\n21\r\nAna Radovanovic ÃÅ, Ross Koningstein, Ian Schneider, Bokan \r\nChen, Alexandre Duarte, Binz Roy, Diyue Xiao, Maya \r\nHaridasan, Patrick Hung, Nick Care, Saurav Talukdar, Eric \r\nMullen, Kendal Smith, MariEllen Cottman, and Walfredo Cirne \r\n\r\n\r\n‚Ä¢ Google‚Äôs Carbon-Intelligent Computing System (CICS) \r\n‚Ä¢ Main idea: use carbon-intensity data to shift datacenter jobs in time \r\n‚Ä¢ Typically, job schedulers use a metric of cluster capacity to schedule a job in \r\na particular cluster. \r\n‚Ä¢ CICS overrides this metric with the virtual capacity curve (VCC) that \r\nfactors in Carbon intensity \r\n‚Ä¢ When a new job comes in, the scheduler estimates its CPU load and power \r\nusage and assigns it to a cluster if the VCC is not exceeded.\r\n23\r\n\r\n‚Ä¢ Jobs are divided between flexible and inflexible. \r\n‚Ä¢ Flexible load is considered shapeable/shiftable as long as its total daily \r\ncompute (CPU) demand is preserved \r\n‚Ä¢ The system needs to consider that, while running a job, the virtual capacity \r\ncurve (VCC) might drop. Hence, this job should not start in the first place. \r\n‚Ä¢ They forecast VCC for the next day\r\n24\r\n\r\n\r\nVirtual Cluster Capacity (VCC)\r\n‚Ä¢ Aims at reducing the peak load at carbon intensive hours but in total it should allow for the \r\nsome amount of daily computation!']","['<1-hop>\n\nNeuromorphic computing\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing', '<2-hop>\n\nReading materials\nMain reading:\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n- Neuromorphic computing:\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \nhttps://www.nature.com/articles/s41586-019-1677-2\nExtra reading:\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\nBasics of \'conventional\' neural networks:\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.']","Neuromorphic computing is inspired by the structure and function of the human brain. It uses physical artificial neurons to perform computations, emulating the way biological neurons work. The biological basis lies in mimicking the brain's energy efficiency, sparse encoding, and high temporal resolution, allowing for more computation with fewer neurons.

In contrast, conventional neural networks, such as those used in deep learning, are typically implemented in software and run on general-purpose hardware like GPUs. These networks are inspired by the brain but do not emulate its physical processes. They rely on dense connections and require significant computational resources, often leading to high energy consumption.

Neuromorphic computing aims to achieve power efficiency by reducing the number of spikes (or activations) and using specialized hardware that mimics the brain's architecture, such as spiking neural networks (SNNs). These networks use binary inputs and focus on addition rather than multiplication, leading to lower energy consumption compared to conventional neural networks.","Neuromorphic computing is based on the biological principles of the human brain, utilizing physical artificial neurons to perform computations. Unlike conventional neural networks, which rely on traditional computing architectures, neuromorphic systems are designed to mimic the brain's structure and function, enabling more efficient and biologically inspired processing.",0.6829365079251257,1.0,0.8947368421052632,0.57,0.0,0.9341463807721383
What is the difference between spiking neural networks and spiking neuron networks?,"['Normal neuron: nin x nout multiplications,\r\n(nin‚Äì 1) x nout additions\r\nSpiking neuron: 0 multiplications, (nactive‚Äì 1) x nout \r\nadditions, with nactive ‚â§ nin\r\nEnergy consumption:\r\nEnormal = M nin nout + A (nin‚Äì 1) nout = 17.5 pJ\r\nEnergy consumption:\r\nEspiking = A (nactive‚Äì 1) nout = 2.7 pJ\r\nMultiply-accumulate (MAC) operations:\r\nSNN challenge: how to \r\ncompute with the least \r\namount of spikes!\r\n\r\nOften, we observe a \r\nsparsity (energy)-\r\ntask accuracy trade-off\r\n(Left: results for image \r\nclassification)\r\nSNN challenge: how to \r\ncompute with the least \r\namount of spikes!\r\nhttps://arxiv.org/pdf/2409.08290\r\n\r\nIn practice, energy \r\nconsumption computations \r\nare complex. \r\nNeed to take into account\r\n- memory access,\r\n- addressing,\r\n- auxiliary operations,\r\nin addition to MACs.\r\nEstimated energy consumption for 3 different datasets (CIFAR10, GSC, NCARS; image, sound \r\nand video classification respectively). FNN‚Äôs are conventional feed-forward neural networks.\r\nIn this example: SNNs are 6 to 8 times more energy efficient than FNNs.\r\nhttps://arxiv.org/pdf/2210.13107\r\nComputing energy consumption\r\n\r\nIn practice, energy \r\nconsumption computations \r\nare complex. \r\nNeed to take into account\r\n- memory access,\r\n- addressing,\r\n- auxiliary operations,\r\nin addition to MACs.\r\nEstimated energy consumption for 3 different datasets (CIFAR10, GSC, NCARS; image, sound \r\nand video classification respectively). FNN‚Äôs are conventional feed-forward neural networks.\r\nIn this example: SNNs are 6 to 8 times more energy efficient than FNNs.\r\nComputing energy consumption\r\nQuestions?\r\n\r\nReading materials\r\nMain reading:\r\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \r\nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\r\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\r\n- Neuromorphic computing:\r\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \r\nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\r\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \r\noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\r\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019.', 'Different encoding strategies with spiking neurons\r\n\r\nDifferent encoding strategies with spiking neurons\r\nUsing latency or spatio-temporal codes\r\nour encoding is faster and more spike-efficient (sparser)!\r\n\r\nDifferent encoding strategies with spiking neurons\r\nUsing latency or spatio-temporal codes\r\nour encoding is faster and more spike-efficient (sparser)!\r\nQuestions?\r\n\r\nNeuromorphic computing\r\nWhat is the advantage for applications?\r\n-\r\nLess spikes = less energy consumption in specialized neuromorphic hardware\r\n(e.g. Intel Loihi [12])\r\nBrains are energy efficient: \r\n2. Sparse encoding\r\n\r\nMultiply-accumulate (MAC) operations:\r\nNormal neuron: Multiplies input with \r\nweights, then adds.\r\nSpiking neuron: Consider binary input (e.g. input currents are piecewise \r\nconstant and assume values {0,1}). There is no multiplication, only addition.\r\n\r\nAssume one multiplier and one adder circuit uses M and A energy respectively with AÔπ§M\r\n(e.g., for a 45nm CMOS process, standard energy usage is A = 0.9 pJ and M = 3.7 pJ).\r\nNormal neuron: nin x nout multiplications,\r\n(nin‚Äì 1) x nout additions\r\nSpiking neuron: 0 multiplications, (nactive‚Äì 1) x nout \r\nadditions, with nactive ‚â§ nin\r\nEnergy consumption:\r\nEnormal = M nin nout + A (nin‚Äì 1) nout = 17.5 pJ\r\nEnergy consumption:\r\nEspiking = A (nactive‚Äì 1) nout = 2.7 pJ\r\nMultiply-accumulate (MAC) operations:\r\n\r\nAssume one multiplier and one adder circuit uses M and A energy respectively with AÔπ§M\r\n(e.g., for a 45nm CMOS process, standard energy usage is A = 0.9 pJ and M = 3.7 pJ).\r\nNormal neuron: nin x nout multiplications,\r\n(nin‚Äì 1) x nout additions\r\nSpiking neuron: 0 multiplications, (nactive‚Äì 1) x nout \r\nadditions, with nactive ‚â§ nin\r\nEnergy consumption:\r\nEnormal = M nin nout + A (nin‚Äì 1) nout = 17.5 pJ\r\nEnergy consumption:\r\nEspiking = A (nactive‚Äì 1) nout = 2.7 pJ\r\nMultiply-accumulate (MAC) operations:\r\nSNN challenge: how to \r\ncompute with the least \r\namount of spikes!\r\n\r\nOften, we observe a \r\nsparsity (energy)-\r\ntask accuracy trade-off\r\n(Left: results for image \r\nclassification)\r\nSNN challenge: how to \r\ncompute with the least \r\namount of spikes!\r\nhttps://arxiv.org/pdf/2409.08290\r\n\r\nIn practice, energy \r\nconsumption computations \r\nare complex. \r\nNeed to take into account\r\n- memory access,\r\n- addressing,\r\n- auxiliary operations,\r\nin addition to MACs.\r\nEstimated energy consumption for 3 different datasets (CIFAR10, GSC, NCARS; image, sound \r\nand video classification respectively). FNN‚Äôs are conventional feed-forward neural networks.\r\nIn this example: SNNs are 6 to 8 times more energy efficient than FNNs.\r\nhttps://arxiv.org/pdf/2210.13107\r\nComputing energy consumption\r\n\r\nIn practice, energy \r\nconsumption computations \r\nare complex. \r\nNeed to take into account\r\n- memory access,\r\n- addressing,\r\n- auxiliary operations,\r\nin addition to MACs.\r\nEstimated energy consumption for 3 different datasets (CIFAR10, GSC, NCARS; image, sound \r\nand video classification respectively). FNN‚Äôs are conventional feed-forward neural networks.\r\nIn this example: SNNs are 6 to 8 times more energy efficient than FNNs.', ""- Higher firing rate (spikes per unit time) for \r\n'selected' feature.\r\nAdapted from Hubel & Wiesel, 1959\r\n\r\nFiring rates\r\nClassical view of the brain:\r\n- Each neuron is selective for one specific \r\nfeature in the input.\r\n- Higher firing rate (spikes per unit time) for \r\n'selected' feature.\r\n- Link to modern ANNs: The scalar output of \r\nan artificial neuron is interpreted as the firing \r\nrate.\r\nAdapted from Hubel & Wiesel, 1959\r\n\r\nFiring rates\r\nClassical view of the brain:\r\n- Each neuron is selective for one specific \r\nfeature in the input.\r\n- Higher firing rate (spikes per unit time) for \r\n'selected' feature.\r\n- Link to modern ANNs: The scalar output of \r\nan artificial neuron is interpreted as the firing \r\nrate.\r\nAdapted from Hubel & Wiesel, 1959\r\nBut rate coding is inefficient and slow‚Ä¶\r\n(i.e. each neuron needs to fire many spikes to get good precision)\r\nboth in vivo and in silico.\r\n\r\nDifferent encoding strategies with spiking neurons [8]\r\n7 neurons\r\n7 time bins\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nn\r\n6\r\n(in the general \r\ncase a \r\nnumber \r\nbetween 0-7)\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nn\r\nTotal spike \r\ncount can \r\nencode 3 bits.\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nIndividual rates \r\ncan encode 7 \r\nbits.\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nLatency can \r\nencode ~3*7 or \r\n~19 bits.\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nRank order can \r\nencode ~12 bits.\r\n\r\nDifferent encoding strategies with spiking neurons\r\n\r\nDifferent encoding strategies with spiking neurons\r\nUsing latency or spatio-temporal codes\r\nour encoding is faster and more spike-efficient (sparser)!\r\n\r\nDifferent encoding strategies with spiking neurons\r\nUsing latency or spatio-temporal codes\r\nour encoding is faster and more spike-efficient (sparser)!\r\nQuestions?\r\n\r\nNeuromorphic computing\r\nWhat is the advantage for applications?\r\n-\r\nLess spikes = less energy consumption in specialized neuromorphic hardware\r\n(e.g. Intel Loihi [12])\r\nBrains are energy efficient: \r\n2. Sparse encoding\r\n\r\nMultiply-accumulate (MAC) operations:\r\nNormal neuron: Multiplies input with \r\nweights, then adds.\r\nSpiking neuron: Consider binary input (e.g. input currents are piecewise \r\nconstant and assume values {0,1}). There is no multiplication, only addition.\r\n\r\nAssume one multiplier and one adder circuit uses M and A energy respectively with AÔπ§M\r\n(e.g., for a 45nm CMOS process, standard energy usage is A = 0.9 pJ and M = 3.7 pJ).\r\nNormal neuron: nin x nout multiplications,\r\n(nin‚Äì 1) x nout additions\r\nSpiking neuron: 0 multiplications, (nactive‚Äì 1) x nout \r\nadditions, with nactive ‚â§ nin\r\nEnergy consumption:\r\nEnormal = M nin nout + A (nin‚Äì 1) nout = 17.5 pJ\r\nEnergy consumption:\r\nEspiking = A (nactive‚Äì 1) nout = 2.7 pJ\r\nMultiply-accumulate (MAC) operations:\r\n\r\nAssume one multiplier and one adder circuit uses M and A energy respectively with AÔπ§M\r\n(e.g., for a 45nm CMOS process, standard energy usage is A = 0.9 pJ and M = 3.7 pJ)."", ""Oversimplification\r\nThere are also multiple other advantages‚Ä¶\r\n\r\nHuman vs. computer computation\r\n- Fast real-time decision making, e.g. sports, e-sports\r\n- Adaptive, e.g. context-aware and employs selective attention\r\n- Energy efficient: Close to 100 billion neurons in the brain\r\n- Robust, for example to changes in illumination or obstructions in object tracking\r\n\r\nHuman vs. computer computation\r\nBrains are energy efficient: Why?\r\n1.\r\nHigh temporal resolution (more computation with less neurons)\r\n2.\r\nSparse encoding\r\n\r\nHuman vs. computer computation\r\nQuestions?\r\nBrains are energy efficient: Why?\r\n1.\r\nHigh temporal resolution (more computation with less neurons)\r\n2.\r\nSparse encoding\r\n\r\nHow do biological neurons communicate?\r\nAnalogy to artificial neural networks\r\nReal neuron\r\nArtificial neuron\r\nCurrent\r\n\r\nHow do biological neurons communicate?\r\nHow does the electrical activity propagate?\r\n?\r\nCurrent\r\n\r\nHow do biological neurons work?\r\ntime\r\nelectrode\r\nhttps://tinmard.github.io/spike-sorting-animation.html\r\nQuick electrical pulses trigger chemical signals for the next neuron ‚Üí Spikes\r\n\r\nHow do biological neurons work?\r\nQuick electrical pulses trigger chemical signals for the next neuron ‚Üí Spikes\r\nhttps://tinmard.github.io/spike-sorting-animation.html\r\ntime\r\nelectrode\r\nFrom CS perspective:\r\nSparse binary \r\nencoding\r\n\r\nBiologically realistic spiking neuron models\r\nBiologically realistic neuron models have \r\na new dimension: Time!\r\nSpiking neural networks (SNNs):\r\nThe input x  (t  ) to each neuron is summed \r\n(integrated) over time.\r\nscalar\r\nfunction of \r\ntime\r\n(t)\r\n(t)\r\nhttps://www.mdpi.com/2076-3425/12/7/863\r\n\r\nHow to model spiking neurons?\r\nANN: Perceptron, threshold activation function:\r\n\r\nHow to model spiking neurons?\r\nANN: Perceptron, threshold activation function:\r\n\r\nHow to model spiking neurons?\r\nSpiking neural network (SNN): The 'input current' Œµ(t) is integrated over time.\r\nspike\r\n\r\nHow to model spiking neurons?\r\nEquivalence to perceptron: Computation at least as complex as a perceptron.\r\n\r\nNon-leaky integrate-and-fire (IF) neuron\r\nThe temporal profile of the input current Œµ(t) can be chosen differently, for different computations.\r\n\r\nQuestions?\r\n\r\nComputation with spiking neurons\r\nCoincidence detection\r\n\r\nComputation with spiking neurons\r\nCoincidence detection\r\nx, y ‚àà {0, 1}n\r\nExample: n = 2\r\ninput = \r\nx1\r\nx2\r\ny1\r\ny2\r\n= \r\n0\r\n1\r\n1\r\n1\r\noutput? \r\n\r\nCoincidence detection\r\nComputation with spiking neurons\r\n\r\nCoincidence detection\r\nCan be trivially computed with a single spiking neuron! Requires at least n/log(n+1) hidden \r\nunits for a perceptron (proof in [7]).\r\nComputation with spiking neurons\r\n\r\nCoincidence detection\r\nCan be trivially computed with a single spiking neuron! Requires at least n/log(n+1) hidden \r\nunits for a perceptron (proof in [7]).\r\nBrains are energy efficient: \r\n1.\r\nHigh temporal resolution (more computation with less neurons)\r\nComputation with spiking neurons\r\n\r\nEncoding strategies\r\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\r\nHow should we encode information about 'features' in a large network with many spikes?\r\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\r\nElephant?\r\nhttps://www.nationalgeographic.com/anim\r\nals/mammals/facts/african-elephant\r\n\r\nFiring rates\r\nClassical view of the brain:\r\n- Each neuron is selective for one specific \r\nfeature in the input."", ""Spiking neural network (SNN): The 'input current' Œµ(t) is integrated over time.\r\nspike\r\n\r\nHow to model spiking neurons?\r\nEquivalence to perceptron: Computation at least as complex as a perceptron.\r\n\r\nNon-leaky integrate-and-fire (IF) neuron\r\nThe temporal profile of the input current Œµ(t) can be chosen differently, for different computations.\r\n\r\nQuestions?\r\n\r\nComputation with spiking neurons\r\nCoincidence detection\r\n\r\nComputation with spiking neurons\r\nCoincidence detection\r\nx, y ‚àà {0, 1}n\r\nExample: n = 2\r\ninput = \r\nx1\r\nx2\r\ny1\r\ny2\r\n= \r\n0\r\n1\r\n1\r\n1\r\noutput? \r\n\r\nCoincidence detection\r\nComputation with spiking neurons\r\n\r\nCoincidence detection\r\nCan be trivially computed with a single spiking neuron! Requires at least n/log(n+1) hidden \r\nunits for a perceptron (proof in [7]).\r\nComputation with spiking neurons\r\n\r\nCoincidence detection\r\nCan be trivially computed with a single spiking neuron! Requires at least n/log(n+1) hidden \r\nunits for a perceptron (proof in [7]).\r\nBrains are energy efficient: \r\n1.\r\nHigh temporal resolution (more computation with less neurons)\r\nComputation with spiking neurons\r\n\r\nEncoding strategies\r\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\r\nHow should we encode information about 'features' in a large network with many spikes?\r\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\r\nElephant?\r\nhttps://www.nationalgeographic.com/anim\r\nals/mammals/facts/african-elephant\r\n\r\nFiring rates\r\nClassical view of the brain:\r\n- Each neuron is selective for one specific \r\nfeature in the input.\r\n- Higher firing rate (spikes per unit time) for \r\n'selected' feature.\r\nAdapted from Hubel & Wiesel, 1959\r\n\r\nFiring rates\r\nClassical view of the brain:\r\n- Each neuron is selective for one specific \r\nfeature in the input.\r\n- Higher firing rate (spikes per unit time) for \r\n'selected' feature.\r\n- Link to modern ANNs: The scalar output of \r\nan artificial neuron is interpreted as the firing \r\nrate.\r\nAdapted from Hubel & Wiesel, 1959\r\n\r\nFiring rates\r\nClassical view of the brain:\r\n- Each neuron is selective for one specific \r\nfeature in the input.\r\n- Higher firing rate (spikes per unit time) for \r\n'selected' feature.\r\n- Link to modern ANNs: The scalar output of \r\nan artificial neuron is interpreted as the firing \r\nrate.\r\nAdapted from Hubel & Wiesel, 1959\r\nBut rate coding is inefficient and slow‚Ä¶\r\n(i.e. each neuron needs to fire many spikes to get good precision)\r\nboth in vivo and in silico.\r\n\r\nDifferent encoding strategies with spiking neurons [8]\r\n7 neurons\r\n7 time bins\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nn\r\n6\r\n(in the general \r\ncase a \r\nnumber \r\nbetween 0-7)\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nn\r\nTotal spike \r\ncount can \r\nencode 3 bits.\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nIndividual rates \r\ncan encode 7 \r\nbits.\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nLatency can \r\nencode ~3*7 or \r\n~19 bits.\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nRank order can \r\nencode ~12 bits."", 'Power-efficiency at scale\r\nModern, deep neural networks*\r\nare trained using GPUs.\r\n* It is estimated that ChatGPT was trained on \r\n10,000-20,000 GPUs and that it will require\r\n30,000 GPUs to keep running stably in the future.\r\n* It is estimated that ChatGPT has 10-20 billion \r\nparameters.\r\nhttps://www.anandtech.com/show/4008/nvidias-geforce-gtx-580/17\r\n\r\nPower-efficiency at scale\r\nModern, deep neural networks*\r\nare trained using GPUs.\r\n* It is estimated that ChatGPT was trained on \r\n10,000-20,000 GPUs and that it will require\r\n30,000 GPUs to keep running stably in the future.\r\n* It is estimated that ChatGPT has 10-20 billion \r\nparameters.\r\nSingle model with 20 billion parameters:\r\n200 Watts x 30,000 GPUs = 6M Watts\r\n\r\nPower-efficiency at scale\r\nhttps://hai.stanford.edu/ai-index/2024-ai-index-report\r\nTraining a single large language model can \r\ngenerate greater CO2 emissions than the \r\ntotal lifetime emissions of 8 cars (in 2020)!\r\n\r\nPower-efficiency at scale\r\nhttps://hai.stanford.edu/ai-index/2024-ai-index-report\r\nTraining a single model can consume \r\nmore than 1000 MWh of power!\r\n\r\nPower-efficiency at scale\r\nhttps://hai.stanford.edu/ai-index/2024-ai-index-report\r\nTraining a single model can consume \r\nmore than 1000 MWh of power!\r\n‚Ä¶ with energy costs reaching 200M USD!\r\n\r\nPower-efficiency at scale\r\nYour brain runs on:\r\n\r\nPower-efficiency at scale\r\nYour brain runs on:\r\nHigh estimate ~3000 kcal a day\r\n   ‚âà145 Watts\r\n* Human brain has ~600 trillion synapses \r\n(‚âàparameters).\r\n\r\nPower-efficiency at scale\r\nYour brain runs on:\r\nHigh estimate ~3000 kcal a day\r\n   ‚âà145 Watts\r\n* Human brain has ~600 trillion synapses \r\n(‚âàparameters).\r\nOversimplification\r\nThere are also multiple other advantages‚Ä¶\r\n\r\nHuman vs. computer computation\r\n- Fast real-time decision making, e.g. sports, e-sports\r\n- Adaptive, e.g. context-aware and employs selective attention\r\n- Energy efficient: Close to 100 billion neurons in the brain\r\n- Robust, for example to changes in illumination or obstructions in object tracking\r\n\r\nHuman vs. computer computation\r\nBrains are energy efficient: Why?\r\n1.\r\nHigh temporal resolution (more computation with less neurons)\r\n2.\r\nSparse encoding\r\n\r\nHuman vs. computer computation\r\nQuestions?\r\nBrains are energy efficient: Why?\r\n1.\r\nHigh temporal resolution (more computation with less neurons)\r\n2.\r\nSparse encoding\r\n\r\nHow do biological neurons communicate?\r\nAnalogy to artificial neural networks\r\nReal neuron\r\nArtificial neuron\r\nCurrent\r\n\r\nHow do biological neurons communicate?\r\nHow does the electrical activity propagate?\r\n?\r\nCurrent\r\n\r\nHow do biological neurons work?\r\ntime\r\nelectrode\r\nhttps://tinmard.github.io/spike-sorting-animation.html\r\nQuick electrical pulses trigger chemical signals for the next neuron ‚Üí Spikes\r\n\r\nHow do biological neurons work?\r\nQuick electrical pulses trigger chemical signals for the next neuron ‚Üí Spikes\r\nhttps://tinmard.github.io/spike-sorting-animation.html\r\ntime\r\nelectrode\r\nFrom CS perspective:\r\nSparse binary \r\nencoding\r\n\r\nBiologically realistic spiking neuron models\r\nBiologically realistic neuron models have \r\na new dimension: Time!\r\nSpiking neural networks (SNNs):\r\nThe input x  (t  ) to each neuron is summed \r\n(integrated) over time.\r\nscalar\r\nfunction of \r\ntime\r\n(t)\r\n(t)\r\nhttps://www.mdpi.com/2076-3425/12/7/863\r\n\r\nHow to model spiking neurons?', '9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\r\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \r\nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\r\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \r\n(not publicly available) doi:10.1037/h0042519\r\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \r\nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\r\n6) https://github.com/idsc-frazzoli/retina\r\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \r\nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\r\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \r\nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\r\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \r\nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\r\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \r\nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\r\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \r\nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\r\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\r\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\r\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \r\n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568', 'In this example: SNNs are 6 to 8 times more energy efficient than FNNs.\r\nComputing energy consumption\r\nQuestions?\r\n\r\nReading materials\r\nMain reading:\r\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \r\nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\r\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\r\n- Neuromorphic computing:\r\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \r\nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\r\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \r\noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\r\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \r\nhttps://www.nature.com/articles/s41586-019-1677-2\r\nExtra reading:\r\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \r\nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\r\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \r\nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \r\nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\r\nBasics of \'conventional\' neural networks:\r\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\r\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.\r\n\r\nReferences\r\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \r\nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\r\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947.', '575(7784):607-17. \r\nhttps://www.nature.com/articles/s41586-019-1677-2\r\nExtra reading:\r\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \r\nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\r\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \r\nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \r\nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\r\nBasics of \'conventional\' neural networks:\r\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\r\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.\r\n\r\nReferences\r\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \r\nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\r\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \r\n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\r\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \r\nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\r\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \r\n(not publicly available) doi:10.1037/h0042519\r\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \r\nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\r\n6) https://github.com/idsc-frazzoli/retina\r\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \r\nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\r\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \r\nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\r\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \r\nNeural Networks.', 'Neuromorphic computing\r\nCS4575\r\nSustainable Software Engineering\r\n05.03.2025\r\nNergis T√∂men\r\n\r\nIntroduction\r\nComputer Vision Lab\r\nBiomorphic Intelligence Lab\r\nBiomedical Intervention Optimisation Lab\r\nNergis\r\n\r\nNeuromorphic computing\r\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\r\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\r\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing\r\n\r\nHow many of you are familiar \r\nwith neural networks?\r\n\r\nSimple model of an artificial neuron\r\nhttps://medium.com/@cprasenjit32/perceptron-a-simple-yet-mighty-machine-learning-algorithm-9ff6b7d86a71\r\n\r\nWhat is a neural network?\r\nhttps://www.tibco.com/reference-center/what-is-a-neural-network\r\n\r\nWhy is it called a \'neural network\'?\r\nhttps://www.tibco.com/reference-center/what-is-a-neural-network\r\n\r\nWhat is a neural network?\r\nWhy is it called a \'neural network\'?\r\nMcCulloch-Pitts neuron [1, 2] (1943)\r\nWarren Sturgis McCulloch\r\n(Neurophysiologist)\r\nWalter Pitts\r\n(Logician)\r\n\r\nHow do biological neurons work?\r\nhttps://commons.wikimedia.org/wiki/File:Coincidence_detection_in_dendrites_of_pyramidal_neurons.gif\r\n\'Input current\' travels down the dendrites (top),\r\nget integrated (summed!) in the cell body\r\nwhich generates an \'output current\' (bottom)\r\nwhich is chemically transmitted to the dendrites of \r\nother neurons.\r\n\r\nSimplified picture\r\nReal neuron\r\nArtificial neuron\r\nhttps://vajiramandravi.com/quest-upsc-notes/artificial-neural-network/\r\n\r\nWhat is a neural network?\r\nMcCulloch-Pitts neuron [1, 2]\r\n1940s: How do biological neurons compute basic \r\nlogic functions? (e.g. logic gates)\r\nNote: Ref. [3] gives a nice brief history on the ideas which lead to the \r\nMcCulloch-Pitts neuron.\r\n\r\nWhat is a neural network?\r\n1950s: How are neurons organized to perform \r\nsensory perception?\r\n\r\nWhat is a neural network?\r\n1950s: How are neurons organized to perform \r\nsensory perception?\r\nThe first ""neural network"": Perceptron (1958). [4]\r\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\r\nFrank Rosenblatt (Psychologist)\r\nwith a Mark I Perceptron computer in 1960\r\n\r\nWhat is a neural network?\r\n1950s: How are neurons organized to perform \r\nsensory perception?\r\nThe first ""neural network"": Perceptron (1958). [4]\r\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\r\nFrank Rosenblatt (Psychologist)\r\nwith a Mark I Perceptron computer in 1960\r\nPower-efficient\r\n\r\nNeuromorphic computing\r\nWhy neuromorphic computing?\r\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\r\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\r\n\r\nNeuromorphic computing\r\nWhy neuromorphic computing?\r\n‚ÄòBiological inspiration‚Äô for artificial neural networks (ANNs) is not a new idea.\r\nEmulation (as opposed to simulation) of neural networks in hardware is not a new idea.', ""‚Ä¢ Our question: Can we save energy with alternative approaches? \r\n‚Ä¢ We studied Grid Search, Random Search and Bayesian \r\nOptimisation.\r\n27\r\nTim's MSc Thesis, 2022 \r\nAccepted at CAIN‚Äô23\r\n\r\n\r\nResults\r\n29\r\nConclusions? \r\n‚Ä¢ Bayesian converges faster. \r\n‚Ä¢ No clear winner between Grid and Random\r\n\r\nDeepSeekMoE\r\n30\r\nPreprint at ArXiv, 2024 https://arxiv.org/pdf/\r\n2401.06066\r\n\r\nMixture of Experts\r\n‚Ä¢ Llama3.1 has 405B parameters, DeepSeek V3 671B \r\n‚Ä¢ Yet DeepSeek has quicker inference times and claims less energy \r\nconsumption (?) \r\n‚Ä¢ Divide the model into smaller blocks of experts \r\n‚Ä¢ Tokens get routed to certain experts based on the query \r\n‚Ä¢ Only part of the network is active during inference \r\n‚Ä¢ DeepSeek claims only 37B out of 671B parameters get active\r\n31\r\n\r\nDeepSeekMoE\r\n32\r\n\r\nDeepSeekMoE\r\n33\r\n‚Ä¢ Comparable performance to \r\nLLaMA2 7B effectively using \r\nless half the parameters \r\n‚Ä¢ Less computational power \r\n‚Ä¢ Problems (?) \r\n‚Ä¢ Still need to load all the \r\nparameters \r\n‚Ä¢ High memory -> high \r\nembodied carbon\r\n\r\nGreen AI at FacebookMeta\r\n34\r\nSustainable AI: Environmental Implications, \r\nChallenges and Opportunities (2022)\r\n\r\nCarbon footprint mapped to the AI lifecycle\r\n‚Ä¢ There are 4 main overarching stages where carbon emissions need to be isolated: data \r\ncollection, experimentation, training, inference. \r\n‚Ä¢ At Facebook, recommendation systems split energy consumption evenly between \r\ntraining and inference; text translation models have a 35%/65% split. (Operational cost) \r\n‚Ä¢ Operational/embodied cost split: 30%/70%\r\n35\r\n\r\nOpen issues according to Meta\r\n‚Ä¢ A vast portion of projects only use GPUs at 30%.\u2028\r\nShould be higher to attenuate embodied carbon.\r\n36\r\nBased on 10K AI projects\r\n\r\nData Jan\r\nInformed Adaptation\r\nData Feb\r\nData Mar\r\nData Apr\r\nData May\r\n‚Ä¶\r\n~Data Dec\r\n~Data Dec\r\nData Jan\r\nData Feb\r\nData Mar\r\nData Apr\r\nData May\r\n‚Ä¶\r\nModel update Model update Model update\r\nCheck if \r\ndata change\r\nCheck if \r\ndata change\r\nCheck if \r\ndata change\r\nModel update\r\nBlind Adaptation\r\nThe AI Model will be \r\nupdated fewer times and \r\nonly when necessary.\r\nKnow when to retrain models\r\nNeither too early nor too late\r\n37\r\nAdaptation Techniques\r\n?\r\n\r\nGreen Architectural Tactics for ML-Enabled \r\nSystem\r\n38\r\nICSE-SEIS 2024\r\n\r\nArchitectural tactics\r\n39\r\n\r\nData-centric\r\n40\r\n‚Ä¢ Reduce data size \r\n‚Ä¢ Sampling \r\n‚Ä¢ Dimensionality reduction \r\n‚Ä¢ Quantization\r\n\r\nAlgorithm Design\r\n41\r\n‚Ä¢ Carefully select your algorithm \r\n‚Ä¢ You don‚Äôt need the fanciest \r\ntechniques\r\n\r\nModel Optimization\r\n42\r\n‚Ä¢ Add energy to training parameters \r\n‚Ä¢ Reduce FLOPs \r\n‚Ä¢ Pruning, sparsity \r\n‚Ä¢  Take advantage of existing models\r\n\r\nModel Training\r\n43\r\n‚Ä¢ Quantization\r\n‚Ä¢ SAVE TRAINING PROGRESS\r\n\r\nModel Deployment\r\n44\r\n‚Ä¢ Distributed deployment \r\n‚Ä¢ Energy efficient hardware and \r\nconfigurations\r\n\r\nModel Management\r\n45\r\n‚Ä¢ Reuse the model as much as possible \r\n\r\nRethinking the Architecture: Spiking Neural Networks\r\n46\r\n\r\nRethinking the Architecture: Spiking Neural Networks\r\n47\r\n\r\nSELF Lab\r\n48\r\n\r\nrecap"", 'McCulloch-Pitts neuron [1, 2]\r\n1940s: How do biological neurons compute basic \r\nlogic functions? (e.g. logic gates)\r\nNote: Ref. [3] gives a nice brief history on the ideas which lead to the \r\nMcCulloch-Pitts neuron.\r\n\r\nWhat is a neural network?\r\n1950s: How are neurons organized to perform \r\nsensory perception?\r\n\r\nWhat is a neural network?\r\n1950s: How are neurons organized to perform \r\nsensory perception?\r\nThe first ""neural network"": Perceptron (1958). [4]\r\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\r\nFrank Rosenblatt (Psychologist)\r\nwith a Mark I Perceptron computer in 1960\r\n\r\nWhat is a neural network?\r\n1950s: How are neurons organized to perform \r\nsensory perception?\r\nThe first ""neural network"": Perceptron (1958). [4]\r\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\r\nFrank Rosenblatt (Psychologist)\r\nwith a Mark I Perceptron computer in 1960\r\nPower-efficient\r\n\r\nNeuromorphic computing\r\nWhy neuromorphic computing?\r\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\r\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\r\n\r\nNeuromorphic computing\r\nWhy neuromorphic computing?\r\n‚ÄòBiological inspiration‚Äô for artificial neural networks (ANNs) is not a new idea.\r\nEmulation (as opposed to simulation) of neural networks in hardware is not a new idea.\r\nQuestion: What can we gain from increasing biological realism in existing neural networks?\r\n\r\nPower-efficiency at scale\r\nModern, deep neural networks*\r\nare trained using GPUs.\r\n* It is estimated that ChatGPT was trained on \r\n10,000-20,000 GPUs and that it will require\r\n30,000 GPUs to keep running stably in the future.\r\n* It is estimated that ChatGPT has 10-20 billion \r\nparameters.\r\nhttps://www.anandtech.com/show/4008/nvidias-geforce-gtx-580/17\r\n\r\nPower-efficiency at scale\r\nModern, deep neural networks*\r\nare trained using GPUs.\r\n* It is estimated that ChatGPT was trained on \r\n10,000-20,000 GPUs and that it will require\r\n30,000 GPUs to keep running stably in the future.\r\n* It is estimated that ChatGPT has 10-20 billion \r\nparameters.\r\nSingle model with 20 billion parameters:\r\n200 Watts x 30,000 GPUs = 6M Watts\r\n\r\nPower-efficiency at scale\r\nhttps://hai.stanford.edu/ai-index/2024-ai-index-report\r\nTraining a single large language model can \r\ngenerate greater CO2 emissions than the \r\ntotal lifetime emissions of 8 cars (in 2020)!\r\n\r\nPower-efficiency at scale\r\nhttps://hai.stanford.edu/ai-index/2024-ai-index-report\r\nTraining a single model can consume \r\nmore than 1000 MWh of power!\r\n\r\nPower-efficiency at scale\r\nhttps://hai.stanford.edu/ai-index/2024-ai-index-report\r\nTraining a single model can consume \r\nmore than 1000 MWh of power!\r\n‚Ä¶ with energy costs reaching 200M USD!\r\n\r\nPower-efficiency at scale\r\nYour brain runs on:\r\n\r\nPower-efficiency at scale\r\nYour brain runs on:\r\nHigh estimate ~3000 kcal a day\r\n   ‚âà145 Watts\r\n* Human brain has ~600 trillion synapses \r\n(‚âàparameters).', '‚Ä¢ Improve parameter-tuning strategy.\r\n11\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ We need benchmarks. \r\n‚Ä¢ AllenAI leaderboard\u2028\r\nhttps://leaderboard.allenai.org \r\n‚Ä¢ No carbon metrics, yet \r\n‚Ä¢ Report comparable proxies for energy \r\nconsumption. \r\n‚Ä¢ ‚ö† Learning algorithms behave in a non-\r\ndeterministic \r\n‚Ä¢ ‚ö† Different data-points lead to different \r\nenergy consumption\r\n12\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ Reporting measured energy consumption \r\n‚Ä¢ + Accurate \r\n‚Ä¢ + Easy to map to carbon emissions \r\n‚Ä¢ - Hard to measure \r\n‚Ä¢ - Low replicability \r\n‚Ä¢ Reporting time / estimation based on time & hardware \r\n‚Ä¢ + Easy to measure \r\n‚Ä¢ + Correlates with energy consumption in most cases. \r\n‚Ä¢ -  Difficult to compare with measurements from other setups \r\n‚Ä¢ E.g., floating point operations (FPOs) (?) \r\n‚Ä¢ + comparable across different setups \r\n‚Ä¢ + cheap \r\n‚Ä¢ - does not factor in memory energy consumption \r\n‚Ä¢ - does not reflect carbon emissions\r\n13\r\n\r\nData-centric AI\r\n\r\nData-centric AI\r\n‚Ä¢ Emerging discipline that deals with systematically engineering data to build AI \r\nsystems. \r\n‚Ä¢ Shift from improving the training strategy to improving the data. \r\n‚Ä¢ It is better to have small but reliable datasets than large but noisy \r\ndatasets. \r\n‚Ä¢ => Improve data collection, data labelling, and data preprocessing. \r\n‚Ä¢ More about data-centric AI by Andrew Ng:\u2028\r\nhttps://www.youtube.com/watch?v=06-AZXmwHjo\r\n15\r\n\r\n\r\nGreen Data-centric AI\r\n‚Ä¢ How do different ML algorithms compare \r\nin terms of energy consumption? \r\n‚Ä¢ How does number of rows relate to the \r\nenergy consumption of ML models? \r\n‚Ä¢ How does number of features relate to \r\nthe energy consumption of ML models? \r\n‚Ä¢ What is the impact of reducing data in the \r\nperformance of the model? \r\n‚Ä¢ Method -> results -> discussion\r\n17\r\n\r\nMethod\r\n‚Ä¢ Single object of study: natural language model to detect spam messages. \r\n‚Ä¢ 6 machine learning algorithms: SVM, Decision Tree, KNN, Random Forrest, \r\nAdaBoost, Bagging Classifier. \r\n‚Ä¢ Reduce the number of rows. 10%, 20%, .., 100% \r\n‚Ä¢ Stratified random sampling (?) \r\n‚Ä¢ Reduce the number of features. 10%, 20%, .., 100% \r\n‚Ä¢ Feature importance metric based on the Chi-Square Test (Chi2) \r\n‚Ä¢ Estimate energy consumption using a RAPL-based tool. (?)\r\n18\r\n\r\n‚Ä¢ Repeat 30 times \r\n‚Ä¢ Fix random seeds \r\n‚Ä¢ ‚Ä¶ \r\n‚Ä¢ Data was not Normal => tailed Normal distribution.\r\n19\r\n(?)\r\n\r\nResults: energy consumption of algorithms\r\n\r\nResults: energy vs data shape\r\n\r\nResults: performance vs data shape\r\n\r\nDiscussion\r\n‚Ä¢ Other data properties should be investigated. \r\n‚Ä¢ E.g., data types \r\n‚Ä¢ Reporting energy data is essential. It can lead to different model selection \r\nwithout hindering model performance. \r\n‚Ä¢ There is a big opportunity in Model and Data Simplification.\r\n23\r\n\r\nData/Model Simplification\r\n‚Ä¢ (?) \r\n‚Ä¢ Data selection \r\n‚Ä¢ Data quantisation. Posit? \r\n‚Ä¢ Data distillation \r\n‚Ä¢ Coreset extraction (?) \r\n‚Ä¢ Model distillation \r\n‚Ä¢ Model quantisation \r\n‚Ä¢ Model pruning \r\n‚Ä¢ ‚Ä¶\r\n24\r\n\r\nPosit vs Float\r\nMore about this: https://spectrum.ieee.org/floating-point-numbers-posits-processor\r\nBetter for DL use cases\r\n\r\nHow can we tune \r\nlearning \r\nparameters \r\nefficiently?\r\n\r\nHyper parameter tuning\r\n‚Ä¢ When training an ML model, there are several parameters that need to be \r\ntuned. \r\n‚Ä¢ E.g., in SVM we have the Regularization parameter C, the kernel function, \r\nthe degree of the kernel function, and depending on the case, many other. \r\n‚Ä¢ The common approach revolves around grid search.', '‚Ä¢ Groundbreaking AI research is mostly done by tech giants.\r\n7\r\n\r\nA few examples of Red AI\r\n‚Ä¢ Google‚Äôs BERT-large \r\n‚Ä¢ 350 million features \r\n‚Ä¢ Trained for 2.5 days using 512 TPU chips, costing $60K+ \r\n‚Ä¢ Open-GPT3 (now GPT-4/o1) \r\n‚Ä¢ 550 tonnes CO2-eq (Patterson, 2021) \r\n‚Ä¢ 175 billion features \r\n‚Ä¢ API is open but no-pretrained model is available \r\n‚Ä¢ AlphaGo \r\n‚Ä¢ 1920 CPUs, 280 GPUs, costing $35M\r\n8\r\n\r\nRed AI in Large Language Models (LLMs)\r\n‚Ä¢ OPT by Meta reports 75 tons CO2-eq (1/7 of OpenGPT‚Äôs footprint).\u2028\r\n(Also 175billion params) \r\n‚Ä¢ However, Llama 3 reported 2,290 tons of CO2-eq (7.7M GPU hours \r\ntraining ) \r\n‚Ä¢ Open science: release includes both the pretrained models and the code \r\nneeded to train and use them. \r\n‚Ä¢ DeepSeek-V3 claims ‚Äúonly‚Äù 2.78M GPU hours \r\n‚Ä¢ Bloom by Huggingface reports 25 tons, 51 when considering embodied \r\nand operational carbon footprint. (176billion params)\r\n9\r\n\r\nRed AI\r\nAccuracy: 0.999999999\r\nGreen AI\r\n‚Ä¢ Energy \r\n‚Ä¢ Time \r\n‚Ä¢ Reproducibility \r\n‚Ä¢ Reusage\r\n\r\nHow can we adopt Green AI\r\n‚Ä¢ Check whether AI is needed. \r\n‚Ä¢ Select green datacenters. \r\n‚Ä¢ Run on low carbon intensity hours. \r\n‚Ä¢ Opt for GPU-optimised solutions (?) \r\n‚Ä¢ Opt for low-power hardware (e.g., Nvidia Jetson boards) \r\n‚Ä¢ Or GPUs that provide energy metrics (e.g., NVIDIA GPUs via the nvidia-smi tool) \r\n‚Ä¢ Report energy/carbon metrics (e.g., embed in MLFlow?) \r\n‚Ä¢ Use pre-trained models (Transfer Learning) \r\n‚Ä¢ Preprocess dataset to reduce size. \r\n‚Ä¢ Improve parameter-tuning strategy.\r\n11\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ We need benchmarks. \r\n‚Ä¢ AllenAI leaderboard\u2028\r\nhttps://leaderboard.allenai.org \r\n‚Ä¢ No carbon metrics, yet \r\n‚Ä¢ Report comparable proxies for energy \r\nconsumption. \r\n‚Ä¢ ‚ö† Learning algorithms behave in a non-\r\ndeterministic \r\n‚Ä¢ ‚ö† Different data-points lead to different \r\nenergy consumption\r\n12\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ Reporting measured energy consumption \r\n‚Ä¢ + Accurate \r\n‚Ä¢ + Easy to map to carbon emissions \r\n‚Ä¢ - Hard to measure \r\n‚Ä¢ - Low replicability \r\n‚Ä¢ Reporting time / estimation based on time & hardware \r\n‚Ä¢ + Easy to measure \r\n‚Ä¢ + Correlates with energy consumption in most cases. \r\n‚Ä¢ -  Difficult to compare with measurements from other setups \r\n‚Ä¢ E.g., floating point operations (FPOs) (?) \r\n‚Ä¢ + comparable across different setups \r\n‚Ä¢ + cheap \r\n‚Ä¢ - does not factor in memory energy consumption \r\n‚Ä¢ - does not reflect carbon emissions\r\n13\r\n\r\nData-centric AI\r\n\r\nData-centric AI\r\n‚Ä¢ Emerging discipline that deals with systematically engineering data to build AI \r\nsystems. \r\n‚Ä¢ Shift from improving the training strategy to improving the data. \r\n‚Ä¢ It is better to have small but reliable datasets than large but noisy \r\ndatasets. \r\n‚Ä¢ => Improve data collection, data labelling, and data preprocessing. \r\n‚Ä¢ More about data-centric AI by Andrew Ng:\u2028\r\nhttps://www.youtube.com/watch?v=06-AZXmwHjo\r\n15\r\n\r\n\r\nGreen Data-centric AI\r\n‚Ä¢ How do different ML algorithms compare \r\nin terms of energy consumption? \r\n‚Ä¢ How does number of rows relate to the \r\nenergy consumption of ML models? \r\n‚Ä¢ How does number of features relate to \r\nthe energy consumption of ML models? \r\n‚Ä¢ What is the impact of reducing data in the \r\nperformance of the model?', ""‚Ä¢ 6 machine learning algorithms: SVM, Decision Tree, KNN, Random Forrest, \r\nAdaBoost, Bagging Classifier. \r\n‚Ä¢ Reduce the number of rows. 10%, 20%, .., 100% \r\n‚Ä¢ Stratified random sampling (?) \r\n‚Ä¢ Reduce the number of features. 10%, 20%, .., 100% \r\n‚Ä¢ Feature importance metric based on the Chi-Square Test (Chi2) \r\n‚Ä¢ Estimate energy consumption using a RAPL-based tool. (?)\r\n18\r\n\r\n‚Ä¢ Repeat 30 times \r\n‚Ä¢ Fix random seeds \r\n‚Ä¢ ‚Ä¶ \r\n‚Ä¢ Data was not Normal => tailed Normal distribution.\r\n19\r\n(?)\r\n\r\nResults: energy consumption of algorithms\r\n\r\nResults: energy vs data shape\r\n\r\nResults: performance vs data shape\r\n\r\nDiscussion\r\n‚Ä¢ Other data properties should be investigated. \r\n‚Ä¢ E.g., data types \r\n‚Ä¢ Reporting energy data is essential. It can lead to different model selection \r\nwithout hindering model performance. \r\n‚Ä¢ There is a big opportunity in Model and Data Simplification.\r\n23\r\n\r\nData/Model Simplification\r\n‚Ä¢ (?) \r\n‚Ä¢ Data selection \r\n‚Ä¢ Data quantisation. Posit? \r\n‚Ä¢ Data distillation \r\n‚Ä¢ Coreset extraction (?) \r\n‚Ä¢ Model distillation \r\n‚Ä¢ Model quantisation \r\n‚Ä¢ Model pruning \r\n‚Ä¢ ‚Ä¶\r\n24\r\n\r\nPosit vs Float\r\nMore about this: https://spectrum.ieee.org/floating-point-numbers-posits-processor\r\nBetter for DL use cases\r\n\r\nHow can we tune \r\nlearning \r\nparameters \r\nefficiently?\r\n\r\nHyper parameter tuning\r\n‚Ä¢ When training an ML model, there are several parameters that need to be \r\ntuned. \r\n‚Ä¢ E.g., in SVM we have the Regularization parameter C, the kernel function, \r\nthe degree of the kernel function, and depending on the case, many other. \r\n‚Ä¢ The common approach revolves around grid search. The user provides a \r\nsequence of possible values for each parameter and the pipeline runs all \r\npossible combinations. \r\n‚Ä¢ Our question: Can we save energy with alternative approaches? \r\n‚Ä¢ We studied Grid Search, Random Search and Bayesian \r\nOptimisation.\r\n27\r\nTim's MSc Thesis, 2022 \r\nAccepted at CAIN‚Äô23\r\n\r\n\r\nResults\r\n29\r\nConclusions? \r\n‚Ä¢ Bayesian converges faster. \r\n‚Ä¢ No clear winner between Grid and Random\r\n\r\nDeepSeekMoE\r\n30\r\nPreprint at ArXiv, 2024 https://arxiv.org/pdf/\r\n2401.06066\r\n\r\nMixture of Experts\r\n‚Ä¢ Llama3.1 has 405B parameters, DeepSeek V3 671B \r\n‚Ä¢ Yet DeepSeek has quicker inference times and claims less energy \r\nconsumption (?) \r\n‚Ä¢ Divide the model into smaller blocks of experts \r\n‚Ä¢ Tokens get routed to certain experts based on the query \r\n‚Ä¢ Only part of the network is active during inference \r\n‚Ä¢ DeepSeek claims only 37B out of 671B parameters get active\r\n31\r\n\r\nDeepSeekMoE\r\n32\r\n\r\nDeepSeekMoE\r\n33\r\n‚Ä¢ Comparable performance to \r\nLLaMA2 7B effectively using \r\nless half the parameters \r\n‚Ä¢ Less computational power \r\n‚Ä¢ Problems (?) \r\n‚Ä¢ Still need to load all the \r\nparameters \r\n‚Ä¢ High memory -> high \r\nembodied carbon\r\n\r\nGreen AI at FacebookMeta\r\n34\r\nSustainable AI: Environmental Implications, \r\nChallenges and Opportunities (2022)\r\n\r\nCarbon footprint mapped to the AI lifecycle\r\n‚Ä¢ There are 4 main overarching stages where carbon emissions need to be isolated: data \r\ncollection, experimentation, training, inference. \r\n‚Ä¢ At Facebook, recommendation systems split energy consumption evenly between \r\ntraining and inference; text translation models have a 35%/65% split. (Operational cost) \r\n‚Ä¢ Operational/embodied cost split: 30%/70%\r\n35\r\n\r\nOpen issues according to Meta\r\n‚Ä¢ A vast portion of projects only use GPUs at 30%.\u2028\r\nShould be higher to attenuate embodied carbon."", ""Unless there‚Äôs a \r\ngood reason. \r\n‚Ä¢ E.g., somewhere amongst the 30 executions, \r\nthere might be 1 or 2 that failed to finish due \r\nto some unexpected error. \r\n‚Ä¢ (It happens and that‚Äôs ok!)‚Äì consequently, \r\nthe execution is shorter and spends less \r\nenergy ‚Äì falsely appearing as more \r\nenergy efficient. \r\n‚Ä¢ If data is not Normal there might be some \r\nissues affecting the measurements that \r\nmight be ruining results. It is important to \r\ninvestigate this.\r\n16\r\n\r\nEnergy data is not normal. Why?\r\n‚Ä¢ It might be caused by one of the following reasons: \r\n‚Ä¢ There was an error in some of the executions. If not detected and fixed it \r\nmight ruin results. \r\n‚Ä¢ Your tests are not fully replicable or are not deterministic. Quite frequent \r\nwhen you have internet requests or random-based algorithms. \r\n‚Ä¢ There is an unusual task being run by the system during some experiments. \r\n‚Ä¢ The computer entered a different power mode. \r\n‚Ä¢ External physical conditions have changed. E.g., someone opened a \r\nwindow.\r\n17\r\n\r\nEnergy data is not normal. How to fix?\r\n‚Ä¢ We have 2+1 options: \r\n1. Remove outliers. If there are only a few points that deviate from the normal \r\ndistribution, it is okay to simply remove them. \r\n‚Ä¢ Use the z-score outlier removal. (?) \r\n‚Ä¢ Remove all data points that deviate from the mean more than 3 standard \r\ndeviations: \r\n \r\n2. Fix the issue and rerun experiments. \r\n3. Conclude that nothing can be done about it and data will never be normal. (e.g., \r\nin AI, executions are rarely deterministic). ‚ö† Only after ruling out the previous \r\npoints.\r\n| ¬Øx ‚àíx| > 3s\r\n18\r\n\r\nHow do we know whether data is Normal?\r\n‚Ä¢ Visualise distribution shape: violin plots, histograms, density plot.\u2028\r\n \r\n‚Ä¢ Shapiro-Wilk test.\u2028\r\ndata is not normal;\u2028\r\nwe are not sure but it is okay to assume that data is \r\nnormal.\r\np-value < 0.05 ‚áí\r\np-value ‚â•0.05 ‚áí\r\n19\r\n\r\nAfter having all data ready, which artefact \r\nis more energy efficient(?) \r\nFirst approach: compare sample means. \r\n‚ö† assuming normal distribution\r\n\r\nStatistical significance\r\n‚Ä¢ Even if, on average, one artefact has lower \r\nenergy consumption than other,  it might be just \r\na random difference. \r\n‚Ä¢ When we extract a sample from a normal \r\ndistribution it will never be the exact same \r\n‚Ä¢ Statistical significance tests help you \r\nunderstand the differences in the average are \r\nconclusive/significant or inconclusive/\r\ninsignificant.\r\n21\r\n‚ö† assuming normal distribution\r\n\r\nStatistical significance test\r\n‚Ä¢ Two-sided parametric test Welch‚Äôs t-test. \r\n‚Ä¢ Less known alternative to student‚Äôs t-test.\r\n22\r\nWelch‚Äôs t-test in Python\r\nfrom scipy.stats import ttest_ind \r\n_,pvalue = ttest_ind(sample_a, sample_b, \r\n                     equal_var=False, \r\n                     alternative='two-sided')\r\n(?)\r\n‚ö† assuming normal distribution\r\n\r\nEffect Size analysis\r\n‚Ä¢ Now that we know that results are statistically significant we need to \r\nmeasure the difference between the two samples. \r\n‚Ä¢ Mean difference: \r\n \r\n‚Ä¢ Percent change: \r\n \r\n‚Ä¢ Cohen‚Äôs d (informal definition: mean difference normalized by a combined \r\nstandard deviation): \r\nŒî¬Øx\r\nxB ‚àíxA\r\nxA\r\n√ó 100 % = Œî¬Øx\r\nxA\r\n√ó 100 %\r\nŒî¬Øx\r\n1\r\n2\r\ns21 + s22\r\n23\r\n‚ö† assuming normal distribution\r\n\r\nImagine that version A spends 70J and \r\nversion B spends 69J with a \r\n."", '. . + 2P(tn‚àí1) + P(tn)]\r\nMeasured Energy \r\nConsumption\r\n‚ö† Sometimes you cannot assume that the sampling interval (\r\n) is always the same. ‚ö†\r\nŒît\r\nTrapezoid Rule\r\n\r\nTrapezoid Rule in Python\r\nimport numpy as np \r\nenergy_consumption = np.trapz(power_sample, timestamps) \r\n\r\nAverage power\r\n‚Ä¢ Easy to convert to energy consumption \r\n‚Ä¢ Simply multiply by the elapsed time. \r\n‚Ä¢ (This is another reason to always collect time data along with energy \r\nmetrics.)\r\n11\r\nEnergy = Pavg¬∑Œît\r\n\r\nPower or Energy?\r\n‚Ä¢ Average power consumption makes sense when we report the \r\nconsumption of a continuous use case. E.g., reading an ebook in your \r\ncomputer. \r\n‚Ä¢ Energy consumption makes sense in one-off use cases. E.g., energy \r\nconsumption of a bitcoin transaction. \r\n‚ö†\r\n\r\nLearning activity\r\n‚Ä¢ Pair up with one colleague and discuss potential software use cases where \r\none should test energy efficiency. \r\n‚Ä¢ Choose one use case where energy consumption is the best metric to \r\ndiscuss/test energy efficiency. \r\n‚Ä¢ Choose one use case where average power consumption is the best \r\nmetric to discuss/test energy efficiency.\r\n13\r\n\r\nEnergy Delay Product (EDP)\r\n‚Ä¢ In some cases, to achieve less energy consumption, one simply runs the \r\nsoftware on a low power mode of the CPU. \r\n‚Ä¢ E.g., setting the CPU at a low frequency will make execution slow but more \r\nenergy-efficient. \r\n‚Ä¢ Energy consumption metric that penalizes slow runs \r\n \r\n \r\n‚Ä¢ Gives more importance to application runtime, with the goal of making both \r\nlow energy and fast runtime applications.\r\nEDP = E √ó t = ŒîP √ó t2\r\n14\r\n\r\nmAh\r\njoules\r\nmilliampere hour\r\nmobile industry\r\nThis is not energy or power. \r\nIt is a unit of electric charge.\r\nThe typical notebook battery has between 2,000 \r\nand 6,000 milliamp hours (mAh)\r\n?\r\n\r\nElectric charge\r\n‚Ä¢ International System of Units (SI): Coulomb (C). \r\n‚Ä¢ 1 electron has 1.602176634√ó10-19 coulombs. Moving the electron around the electric \r\nfield requires work (energy consumption).  \r\n‚Ä¢ mAh is the most common metric to specify the capacity of batteries. \r\n‚Ä¢ 1 mAh = 3.6C \r\n‚Ä¢ To compute the actual energy of a battery we need to factor in voltage: \r\n \r\n  \r\n‚Ä¢ E.g., for a battery with a capacity of 1000mAh: \r\n \r\nEnergy = Voltage √ó Charge\r\n1000mAh √ó 3.8V = 3800mWh = 3.8Wh = 3.8 √ó 3600J = 13680J\r\n16\r\n\r\nWhy do we use charge units for batteries?\r\n‚Ä¢ There is a continuous change of voltage throughout a charge/discharge \r\ncycle. \r\n‚Ä¢ E.g., it can start with 4.5 V at a ‚Äú100%‚Äù capacity and from to 3.0V at 5% \r\ncapacity. \r\n‚Ä¢ Most devices use voltage to compute their battery level percentage.\r\n17\r\n\r\nInternational System of Units (SI)\r\n‚Ä¢ Energy: Joule \r\n‚Ä¢ Power: Watt \r\n‚Ä¢ Charge: Coulomb \r\n‚Ä¢ (Time: second)\r\n18\r\n\r\nSI Units are difficult to grasp\r\n‚Ä¢ Whenever talking to a general audience use relative units: \r\n‚Ä¢ Compare to the other well-known things: \r\n‚Ä¢ Yearly household energy consumption \r\n‚Ä¢ Yearly country electrical energy consumption.\u2028\r\n(e.g., https://ccaf.io/cbeci/index/comparisons) \r\n‚Ä¢ Driving kms with a standard car \r\n‚Ä¢ Percentage of a normal battery charge cycle. \r\n‚Ä¢ Compare to other software artefacts/usecases: \r\n‚Ä¢ E.g, percentage of Version A over Version B.', ""‚Ä¢ Visualise distribution shape: violin plots, histograms, density plot.\u2028\r\n \r\n‚Ä¢ Shapiro-Wilk test.\u2028\r\ndata is not normal;\u2028\r\nwe are not sure but it is okay to assume that data is \r\nnormal.\r\np-value < 0.05 ‚áí\r\np-value ‚â•0.05 ‚áí\r\n19\r\n\r\nAfter having all data ready, which artefact \r\nis more energy efficient(?) \r\nFirst approach: compare sample means. \r\n‚ö† assuming normal distribution\r\n\r\nStatistical significance\r\n‚Ä¢ Even if, on average, one artefact has lower \r\nenergy consumption than other,  it might be just \r\na random difference. \r\n‚Ä¢ When we extract a sample from a normal \r\ndistribution it will never be the exact same \r\n‚Ä¢ Statistical significance tests help you \r\nunderstand the differences in the average are \r\nconclusive/significant or inconclusive/\r\ninsignificant.\r\n21\r\n‚ö† assuming normal distribution\r\n\r\nStatistical significance test\r\n‚Ä¢ Two-sided parametric test Welch‚Äôs t-test. \r\n‚Ä¢ Less known alternative to student‚Äôs t-test.\r\n22\r\nWelch‚Äôs t-test in Python\r\nfrom scipy.stats import ttest_ind \r\n_,pvalue = ttest_ind(sample_a, sample_b, \r\n                     equal_var=False, \r\n                     alternative='two-sided')\r\n(?)\r\n‚ö† assuming normal distribution\r\n\r\nEffect Size analysis\r\n‚Ä¢ Now that we know that results are statistically significant we need to \r\nmeasure the difference between the two samples. \r\n‚Ä¢ Mean difference: \r\n \r\n‚Ä¢ Percent change: \r\n \r\n‚Ä¢ Cohen‚Äôs d (informal definition: mean difference normalized by a combined \r\nstandard deviation): \r\nŒî¬Øx\r\nxB ‚àíxA\r\nxA\r\n√ó 100 % = Œî¬Øx\r\nxA\r\n√ó 100 %\r\nŒî¬Øx\r\n1\r\n2\r\ns21 + s22\r\n23\r\n‚ö† assuming normal distribution\r\n\r\nImagine that version A spends 70J and \r\nversion B spends 69J with a \r\n.\r\np-value = 0.04\r\nOn average, version B spent less energy than version A  ‚Äî  ‚úÖ \r\nThere is statistical significance ‚Äî  ‚úÖ \r\nEffect size, percent-change is ‚âà1% ‚Äî ü§î \r\n‚ö† Do we care?\r\n(?)\r\n\r\nPractical Significance\r\n‚Ä¢ Depending on the case, a 2% improvement might be either wonderful or completely \r\nuseless. \r\n‚Ä¢ Effect size analyses help assess practical significance but might not be enough. \r\n‚Ä¢ A critical discussion always needs to be performed. Consider context and explain in what \r\nsense the effect size might be relevant. \r\n‚Ä¢ E.g.: \r\n‚Ä¢  to improve 2% in energy efficiency the code will be less readable or the user \r\nexperience is not so appealing. \r\n‚Ä¢ A particular method improves 2% but it will only be used 1% of the time. \r\n‚Ä¢ There is no particular metric or structure, but this kind of critical analysis is very important.\r\n25\r\n\r\nWhat if data is not Normal?\r\nSame approach but different tests/metrics!\r\n\r\nNon-normal data\r\n‚Ä¢ Statistical significance: non-parametric test (?) \r\n‚Ä¢ Mann-Whitney U test. Instead of looking at standard deviation or mean, it orders \r\nsamples and compares with each other. \r\n‚Ä¢ Less power than parametric-tests (?) \r\n‚Ä¢ Effect size \r\n‚Ä¢ Median difference: \r\n \r\n‚Ä¢ Percentage of pairs supporting a conclusion\u2028\r\n(i.e., # pairs where version A > version B/ total pairs) \r\n‚Ä¢ Common language effect size: \r\nŒîM\r\nU1\r\nN1N2\r\n27\r\n\r\nRecap\r\nImpossible to \r\nfix but \r\nexplainable."", 'p-value = 0.04\r\nOn average, version B spent less energy than version A  ‚Äî  ‚úÖ \r\nThere is statistical significance ‚Äî  ‚úÖ \r\nEffect size, percent-change is ‚âà1% ‚Äî ü§î \r\n‚ö† Do we care?\r\n(?)\r\n\r\nPractical Significance\r\n‚Ä¢ Depending on the case, a 2% improvement might be either wonderful or completely \r\nuseless. \r\n‚Ä¢ Effect size analyses help assess practical significance but might not be enough. \r\n‚Ä¢ A critical discussion always needs to be performed. Consider context and explain in what \r\nsense the effect size might be relevant. \r\n‚Ä¢ E.g.: \r\n‚Ä¢  to improve 2% in energy efficiency the code will be less readable or the user \r\nexperience is not so appealing. \r\n‚Ä¢ A particular method improves 2% but it will only be used 1% of the time. \r\n‚Ä¢ There is no particular metric or structure, but this kind of critical analysis is very important.\r\n25\r\n\r\nWhat if data is not Normal?\r\nSame approach but different tests/metrics!\r\n\r\nNon-normal data\r\n‚Ä¢ Statistical significance: non-parametric test (?) \r\n‚Ä¢ Mann-Whitney U test. Instead of looking at standard deviation or mean, it orders \r\nsamples and compares with each other. \r\n‚Ä¢ Less power than parametric-tests (?) \r\n‚Ä¢ Effect size \r\n‚Ä¢ Median difference: \r\n \r\n‚Ä¢ Percentage of pairs supporting a conclusion\u2028\r\n(i.e., # pairs where version A > version B/ total pairs) \r\n‚Ä¢ Common language effect size: \r\nŒîM\r\nU1\r\nN1N2\r\n27\r\n\r\nRecap\r\nImpossible to \r\nfix but \r\nexplainable.\r\n\r\nEnergy Efficiency Across \r\nProgramming Languages\r\nhttps://sites.google.com/view/energy-efficiency-languages\r\n29\r\nRui Pereira, Marco Couto, Francisco Ribeiro, Rui Rua, J√°come \r\nCunha, Jo√£o Paulo Fernandes, and Jo√£o Saraiva\r\n\r\n‚Ä¢ Is a faster programming language also more energy efficient? \r\n‚Ä¢ Comparing different programming languages is not an easy task. \r\n‚Ä¢ They differ in many mechanisms: \r\n‚Ä¢ Interpreted vs Compiled \r\n‚Ä¢ Optimisations at the compiler level \r\n‚Ä¢ Virtual machine \r\n‚Ä¢ Garbage collector \r\n‚Ä¢ Available libraries\r\n30\r\n\r\nResearch Questions\r\n‚Ä¢ Can we compare the energy efficiency of software languages?  \r\n‚Ä¢ Is the faster language always the most energy efficient? \r\n‚Ä¢ How does memory usage relate to energy consumption? (We don‚Äôt cover this one) \r\n‚Ä¢ Can we automatically decide what is the best programming language \r\nconsidering energy, time, and memory usage?  \r\n‚Ä¢ How do the results of our energy consumption analysis of programming \r\nlanguages gathered from rigorous performance benchmarking solutions \r\ncompare to results of average day-to-day solutions? \u2028\r\n31\r\n\r\nMethodology\r\n\r\nThe Computer Language Benchmarks Game \r\n‚Ä¢ https://benchmarksgame-team.pages.debian.net/benchmarksgame/\r\n33\r\n\r\nProblems in the Computer Language Benchmarks Game\r\n34\r\n\r\n‚Ä¢ 27 Programming languages across different paradigms  \r\n‚Ä¢ Functional (e.g., Ocaml, F#, Haskell) \r\n‚Ä¢ Imperative (e.g., C, Go, Python) \r\n‚Ä¢ Object-oriented (e.g., C++, C#, Java) \r\n‚Ä¢ Scripting (or interpretative) (e.g., JavaScript, Python, Ruby) \r\n‚Ä¢ (These are not mutual exclusive) \r\n‚Ä¢ Intel RAPL‚Äôs C library to measure energy consumption\r\n35\r\n\r\n‚Ä¢ Execute each benchmark solution 10 times. \r\n‚Ä¢ Collect energy data and timestamps. \r\n‚Ä¢ Two-minute interval between executions\r\n36\r\n\r\n\r\n\r\n\r\nCritical thinking\r\n‚Ä¢ There is no doubt this is an excellent study. Yet, as any excellent study, there‚Äôs \r\na lot we can discuss and criticise constructively. \r\n‚Ä¢ What kind of issues you see in drawing conclusions from such a table of \r\nresults?', '27\r\n\r\nCarbon intensity\r\n‚Ä¢ How much carbon is emitted per kWh of electricity consumed. \r\n‚Ä¢ The common unit: \r\n ü§∑ \r\n‚Ä¢ E.g.,  gas-based power plants emit less carbon than coal-based plants. \r\n‚Ä¢ The power grid is a mix between different sources of electricity ‚Äì different \r\nlocations have different carbon intensity.\r\ngCO2eq/kWh\r\n28\r\n\r\nhttps://app.electricitymaps.com/map\r\n\r\nBy Asim Hussain: https://principles.green/principles/carbon-intensity/\r\nüìù Reducing software energy consumption can help reduce the carbon intensity. Why?\r\n\r\nOne would expect zero carbon intensity from solar-\r\npanels or wind farms, but that‚Äôs not the case.\r\n‚ö†\r\n?\r\n\r\nMarginal Power Plant\r\n‚Ä¢ Renewable-based power plants cannot adapt to demand. \r\n‚Ä¢ When demand is higher than the existing power in the electricity grid, we \r\nneed a power plant that is able to scale up to that demand. \r\n‚Ä¢ This is usually done by fossil-based power plants. They are called the \r\nmarginal power plants. \r\n‚Ä¢ The problem is that marginal power plants do not scale down to zero. \r\n‚Ä¢ There is always a minimum carbon that needs to be emitted, even if there is \r\na lot of renewable energy in the grid.\r\n32\r\n\r\nBy Asim Hussain: https://principles.green/principles/carbon-intensity/\r\nHow could we fix this?\r\nWhat‚Äôs the problem here?\r\n\r\nMarginal Carbon Intensity\r\n‚Ä¢ Increase or decrease in carbon emissions in the electrical grid, in response \r\nto an infinitesimal increase/decrease in power demand/supply.\r\n\r\nFrom: ‚ÄúLiterature Review: On the effectiveness of a Marginal Carbon Intensity Signal ‚Äú\r\n\r\nWhy is marginal carbon intensity \r\nrelevant for software?\r\n‚Ä¢ Tip: consider a task scheduler in a datacenter.\r\n\r\nRecap\r\n‚Ä¢ Power \r\n‚Ä¢ Energy \r\n‚Ä¢ Average Power \r\n‚Ä¢ Energy Delay Product \r\n‚Ä¢ Electric charge (battery capacity) \r\n‚Ä¢ Carbon dioxide equivalent (carbon emissions) \r\n‚Ä¢ 100-global-warming potential \r\n‚Ä¢ Carbon Intensity \r\n‚Ä¢ Marginal Carbon Intensity\r\n37\r\n?\r\n\r\nFurther Reading\r\n‚Ä¢ Blog post on energy units:\u2028\r\nhttps://luiscruz.github.io/2023/05/13/energy-units.html \r\n38\r\n?']","[""<1-hop>\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant"", '<2-hop>\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \n(not publicly available) doi:10.1037/h0042519\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568', ""<1-hop>\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant"", '<2-hop>\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \n(not publicly available) doi:10.1037/h0042519\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568']","The terms ""spiking neural networks"" (SNNs) and ""spiking neuron networks"" are often used interchangeably in the context of neuromorphic computing and computational neuroscience. Both refer to networks of spiking neurons that mimic the way biological neurons communicate through discrete spikes or action potentials.

Spiking Neural Networks (SNNs):
- SNNs are a type of artificial neural network that uses spikes to transmit information between neurons, similar to how the brain operates.
- They incorporate the concept of time into their operations, as the timing of spikes can carry information.
- SNNs are considered the third generation of neural network models, following perceptrons and traditional artificial neural networks (ANNs).

Spiking Neuron Networks:
- This term is essentially synonymous with spiking neural networks.
- It emphasizes the network aspect of interconnected spiking neurons.

In summary, there is no significant difference between the two terms; they both describe networks that use spiking neurons to process information in a manner inspired by biological neural systems.","Spiking neural networks (SNNs) are a type of neural network model that processes information using spikes, similar to biological neurons. Spiking neuron networks refer to the individual components within these networks, focusing on how each neuron processes and communicates information through spikes.",0.0,,,0.4,,0.9926658901363807
What is the foundational concepts of spiking neural networks and how they are used in encoding strategies?,"[""Spiking neural network (SNN): The 'input current' Œµ(t) is integrated over time.\r\nspike\r\n\r\nHow to model spiking neurons?\r\nEquivalence to perceptron: Computation at least as complex as a perceptron.\r\n\r\nNon-leaky integrate-and-fire (IF) neuron\r\nThe temporal profile of the input current Œµ(t) can be chosen differently, for different computations.\r\n\r\nQuestions?\r\n\r\nComputation with spiking neurons\r\nCoincidence detection\r\n\r\nComputation with spiking neurons\r\nCoincidence detection\r\nx, y ‚àà {0, 1}n\r\nExample: n = 2\r\ninput = \r\nx1\r\nx2\r\ny1\r\ny2\r\n= \r\n0\r\n1\r\n1\r\n1\r\noutput? \r\n\r\nCoincidence detection\r\nComputation with spiking neurons\r\n\r\nCoincidence detection\r\nCan be trivially computed with a single spiking neuron! Requires at least n/log(n+1) hidden \r\nunits for a perceptron (proof in [7]).\r\nComputation with spiking neurons\r\n\r\nCoincidence detection\r\nCan be trivially computed with a single spiking neuron! Requires at least n/log(n+1) hidden \r\nunits for a perceptron (proof in [7]).\r\nBrains are energy efficient: \r\n1.\r\nHigh temporal resolution (more computation with less neurons)\r\nComputation with spiking neurons\r\n\r\nEncoding strategies\r\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\r\nHow should we encode information about 'features' in a large network with many spikes?\r\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\r\nElephant?\r\nhttps://www.nationalgeographic.com/anim\r\nals/mammals/facts/african-elephant\r\n\r\nFiring rates\r\nClassical view of the brain:\r\n- Each neuron is selective for one specific \r\nfeature in the input.\r\n- Higher firing rate (spikes per unit time) for \r\n'selected' feature.\r\nAdapted from Hubel & Wiesel, 1959\r\n\r\nFiring rates\r\nClassical view of the brain:\r\n- Each neuron is selective for one specific \r\nfeature in the input.\r\n- Higher firing rate (spikes per unit time) for \r\n'selected' feature.\r\n- Link to modern ANNs: The scalar output of \r\nan artificial neuron is interpreted as the firing \r\nrate.\r\nAdapted from Hubel & Wiesel, 1959\r\n\r\nFiring rates\r\nClassical view of the brain:\r\n- Each neuron is selective for one specific \r\nfeature in the input.\r\n- Higher firing rate (spikes per unit time) for \r\n'selected' feature.\r\n- Link to modern ANNs: The scalar output of \r\nan artificial neuron is interpreted as the firing \r\nrate.\r\nAdapted from Hubel & Wiesel, 1959\r\nBut rate coding is inefficient and slow‚Ä¶\r\n(i.e. each neuron needs to fire many spikes to get good precision)\r\nboth in vivo and in silico.\r\n\r\nDifferent encoding strategies with spiking neurons [8]\r\n7 neurons\r\n7 time bins\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nn\r\n6\r\n(in the general \r\ncase a \r\nnumber \r\nbetween 0-7)\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nn\r\nTotal spike \r\ncount can \r\nencode 3 bits.\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nIndividual rates \r\ncan encode 7 \r\nbits.\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nLatency can \r\nencode ~3*7 or \r\n~19 bits.\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nRank order can \r\nencode ~12 bits."", ""- Higher firing rate (spikes per unit time) for \r\n'selected' feature.\r\nAdapted from Hubel & Wiesel, 1959\r\n\r\nFiring rates\r\nClassical view of the brain:\r\n- Each neuron is selective for one specific \r\nfeature in the input.\r\n- Higher firing rate (spikes per unit time) for \r\n'selected' feature.\r\n- Link to modern ANNs: The scalar output of \r\nan artificial neuron is interpreted as the firing \r\nrate.\r\nAdapted from Hubel & Wiesel, 1959\r\n\r\nFiring rates\r\nClassical view of the brain:\r\n- Each neuron is selective for one specific \r\nfeature in the input.\r\n- Higher firing rate (spikes per unit time) for \r\n'selected' feature.\r\n- Link to modern ANNs: The scalar output of \r\nan artificial neuron is interpreted as the firing \r\nrate.\r\nAdapted from Hubel & Wiesel, 1959\r\nBut rate coding is inefficient and slow‚Ä¶\r\n(i.e. each neuron needs to fire many spikes to get good precision)\r\nboth in vivo and in silico.\r\n\r\nDifferent encoding strategies with spiking neurons [8]\r\n7 neurons\r\n7 time bins\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nn\r\n6\r\n(in the general \r\ncase a \r\nnumber \r\nbetween 0-7)\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nn\r\nTotal spike \r\ncount can \r\nencode 3 bits.\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nIndividual rates \r\ncan encode 7 \r\nbits.\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nLatency can \r\nencode ~3*7 or \r\n~19 bits.\r\n\r\nDifferent encoding strategies with spiking neurons\r\n7 neurons\r\n7 time bins\r\nRank order can \r\nencode ~12 bits.\r\n\r\nDifferent encoding strategies with spiking neurons\r\n\r\nDifferent encoding strategies with spiking neurons\r\nUsing latency or spatio-temporal codes\r\nour encoding is faster and more spike-efficient (sparser)!\r\n\r\nDifferent encoding strategies with spiking neurons\r\nUsing latency or spatio-temporal codes\r\nour encoding is faster and more spike-efficient (sparser)!\r\nQuestions?\r\n\r\nNeuromorphic computing\r\nWhat is the advantage for applications?\r\n-\r\nLess spikes = less energy consumption in specialized neuromorphic hardware\r\n(e.g. Intel Loihi [12])\r\nBrains are energy efficient: \r\n2. Sparse encoding\r\n\r\nMultiply-accumulate (MAC) operations:\r\nNormal neuron: Multiplies input with \r\nweights, then adds.\r\nSpiking neuron: Consider binary input (e.g. input currents are piecewise \r\nconstant and assume values {0,1}). There is no multiplication, only addition.\r\n\r\nAssume one multiplier and one adder circuit uses M and A energy respectively with AÔπ§M\r\n(e.g., for a 45nm CMOS process, standard energy usage is A = 0.9 pJ and M = 3.7 pJ).\r\nNormal neuron: nin x nout multiplications,\r\n(nin‚Äì 1) x nout additions\r\nSpiking neuron: 0 multiplications, (nactive‚Äì 1) x nout \r\nadditions, with nactive ‚â§ nin\r\nEnergy consumption:\r\nEnormal = M nin nout + A (nin‚Äì 1) nout = 17.5 pJ\r\nEnergy consumption:\r\nEspiking = A (nactive‚Äì 1) nout = 2.7 pJ\r\nMultiply-accumulate (MAC) operations:\r\n\r\nAssume one multiplier and one adder circuit uses M and A energy respectively with AÔπ§M\r\n(e.g., for a 45nm CMOS process, standard energy usage is A = 0.9 pJ and M = 3.7 pJ)."", 'Different encoding strategies with spiking neurons\r\n\r\nDifferent encoding strategies with spiking neurons\r\nUsing latency or spatio-temporal codes\r\nour encoding is faster and more spike-efficient (sparser)!\r\n\r\nDifferent encoding strategies with spiking neurons\r\nUsing latency or spatio-temporal codes\r\nour encoding is faster and more spike-efficient (sparser)!\r\nQuestions?\r\n\r\nNeuromorphic computing\r\nWhat is the advantage for applications?\r\n-\r\nLess spikes = less energy consumption in specialized neuromorphic hardware\r\n(e.g. Intel Loihi [12])\r\nBrains are energy efficient: \r\n2. Sparse encoding\r\n\r\nMultiply-accumulate (MAC) operations:\r\nNormal neuron: Multiplies input with \r\nweights, then adds.\r\nSpiking neuron: Consider binary input (e.g. input currents are piecewise \r\nconstant and assume values {0,1}). There is no multiplication, only addition.\r\n\r\nAssume one multiplier and one adder circuit uses M and A energy respectively with AÔπ§M\r\n(e.g., for a 45nm CMOS process, standard energy usage is A = 0.9 pJ and M = 3.7 pJ).\r\nNormal neuron: nin x nout multiplications,\r\n(nin‚Äì 1) x nout additions\r\nSpiking neuron: 0 multiplications, (nactive‚Äì 1) x nout \r\nadditions, with nactive ‚â§ nin\r\nEnergy consumption:\r\nEnormal = M nin nout + A (nin‚Äì 1) nout = 17.5 pJ\r\nEnergy consumption:\r\nEspiking = A (nactive‚Äì 1) nout = 2.7 pJ\r\nMultiply-accumulate (MAC) operations:\r\n\r\nAssume one multiplier and one adder circuit uses M and A energy respectively with AÔπ§M\r\n(e.g., for a 45nm CMOS process, standard energy usage is A = 0.9 pJ and M = 3.7 pJ).\r\nNormal neuron: nin x nout multiplications,\r\n(nin‚Äì 1) x nout additions\r\nSpiking neuron: 0 multiplications, (nactive‚Äì 1) x nout \r\nadditions, with nactive ‚â§ nin\r\nEnergy consumption:\r\nEnormal = M nin nout + A (nin‚Äì 1) nout = 17.5 pJ\r\nEnergy consumption:\r\nEspiking = A (nactive‚Äì 1) nout = 2.7 pJ\r\nMultiply-accumulate (MAC) operations:\r\nSNN challenge: how to \r\ncompute with the least \r\namount of spikes!\r\n\r\nOften, we observe a \r\nsparsity (energy)-\r\ntask accuracy trade-off\r\n(Left: results for image \r\nclassification)\r\nSNN challenge: how to \r\ncompute with the least \r\namount of spikes!\r\nhttps://arxiv.org/pdf/2409.08290\r\n\r\nIn practice, energy \r\nconsumption computations \r\nare complex. \r\nNeed to take into account\r\n- memory access,\r\n- addressing,\r\n- auxiliary operations,\r\nin addition to MACs.\r\nEstimated energy consumption for 3 different datasets (CIFAR10, GSC, NCARS; image, sound \r\nand video classification respectively). FNN‚Äôs are conventional feed-forward neural networks.\r\nIn this example: SNNs are 6 to 8 times more energy efficient than FNNs.\r\nhttps://arxiv.org/pdf/2210.13107\r\nComputing energy consumption\r\n\r\nIn practice, energy \r\nconsumption computations \r\nare complex. \r\nNeed to take into account\r\n- memory access,\r\n- addressing,\r\n- auxiliary operations,\r\nin addition to MACs.\r\nEstimated energy consumption for 3 different datasets (CIFAR10, GSC, NCARS; image, sound \r\nand video classification respectively). FNN‚Äôs are conventional feed-forward neural networks.\r\nIn this example: SNNs are 6 to 8 times more energy efficient than FNNs.', ""Oversimplification\r\nThere are also multiple other advantages‚Ä¶\r\n\r\nHuman vs. computer computation\r\n- Fast real-time decision making, e.g. sports, e-sports\r\n- Adaptive, e.g. context-aware and employs selective attention\r\n- Energy efficient: Close to 100 billion neurons in the brain\r\n- Robust, for example to changes in illumination or obstructions in object tracking\r\n\r\nHuman vs. computer computation\r\nBrains are energy efficient: Why?\r\n1.\r\nHigh temporal resolution (more computation with less neurons)\r\n2.\r\nSparse encoding\r\n\r\nHuman vs. computer computation\r\nQuestions?\r\nBrains are energy efficient: Why?\r\n1.\r\nHigh temporal resolution (more computation with less neurons)\r\n2.\r\nSparse encoding\r\n\r\nHow do biological neurons communicate?\r\nAnalogy to artificial neural networks\r\nReal neuron\r\nArtificial neuron\r\nCurrent\r\n\r\nHow do biological neurons communicate?\r\nHow does the electrical activity propagate?\r\n?\r\nCurrent\r\n\r\nHow do biological neurons work?\r\ntime\r\nelectrode\r\nhttps://tinmard.github.io/spike-sorting-animation.html\r\nQuick electrical pulses trigger chemical signals for the next neuron ‚Üí Spikes\r\n\r\nHow do biological neurons work?\r\nQuick electrical pulses trigger chemical signals for the next neuron ‚Üí Spikes\r\nhttps://tinmard.github.io/spike-sorting-animation.html\r\ntime\r\nelectrode\r\nFrom CS perspective:\r\nSparse binary \r\nencoding\r\n\r\nBiologically realistic spiking neuron models\r\nBiologically realistic neuron models have \r\na new dimension: Time!\r\nSpiking neural networks (SNNs):\r\nThe input x  (t  ) to each neuron is summed \r\n(integrated) over time.\r\nscalar\r\nfunction of \r\ntime\r\n(t)\r\n(t)\r\nhttps://www.mdpi.com/2076-3425/12/7/863\r\n\r\nHow to model spiking neurons?\r\nANN: Perceptron, threshold activation function:\r\n\r\nHow to model spiking neurons?\r\nANN: Perceptron, threshold activation function:\r\n\r\nHow to model spiking neurons?\r\nSpiking neural network (SNN): The 'input current' Œµ(t) is integrated over time.\r\nspike\r\n\r\nHow to model spiking neurons?\r\nEquivalence to perceptron: Computation at least as complex as a perceptron.\r\n\r\nNon-leaky integrate-and-fire (IF) neuron\r\nThe temporal profile of the input current Œµ(t) can be chosen differently, for different computations.\r\n\r\nQuestions?\r\n\r\nComputation with spiking neurons\r\nCoincidence detection\r\n\r\nComputation with spiking neurons\r\nCoincidence detection\r\nx, y ‚àà {0, 1}n\r\nExample: n = 2\r\ninput = \r\nx1\r\nx2\r\ny1\r\ny2\r\n= \r\n0\r\n1\r\n1\r\n1\r\noutput? \r\n\r\nCoincidence detection\r\nComputation with spiking neurons\r\n\r\nCoincidence detection\r\nCan be trivially computed with a single spiking neuron! Requires at least n/log(n+1) hidden \r\nunits for a perceptron (proof in [7]).\r\nComputation with spiking neurons\r\n\r\nCoincidence detection\r\nCan be trivially computed with a single spiking neuron! Requires at least n/log(n+1) hidden \r\nunits for a perceptron (proof in [7]).\r\nBrains are energy efficient: \r\n1.\r\nHigh temporal resolution (more computation with less neurons)\r\nComputation with spiking neurons\r\n\r\nEncoding strategies\r\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\r\nHow should we encode information about 'features' in a large network with many spikes?\r\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\r\nElephant?\r\nhttps://www.nationalgeographic.com/anim\r\nals/mammals/facts/african-elephant\r\n\r\nFiring rates\r\nClassical view of the brain:\r\n- Each neuron is selective for one specific \r\nfeature in the input."", 'Normal neuron: nin x nout multiplications,\r\n(nin‚Äì 1) x nout additions\r\nSpiking neuron: 0 multiplications, (nactive‚Äì 1) x nout \r\nadditions, with nactive ‚â§ nin\r\nEnergy consumption:\r\nEnormal = M nin nout + A (nin‚Äì 1) nout = 17.5 pJ\r\nEnergy consumption:\r\nEspiking = A (nactive‚Äì 1) nout = 2.7 pJ\r\nMultiply-accumulate (MAC) operations:\r\nSNN challenge: how to \r\ncompute with the least \r\namount of spikes!\r\n\r\nOften, we observe a \r\nsparsity (energy)-\r\ntask accuracy trade-off\r\n(Left: results for image \r\nclassification)\r\nSNN challenge: how to \r\ncompute with the least \r\namount of spikes!\r\nhttps://arxiv.org/pdf/2409.08290\r\n\r\nIn practice, energy \r\nconsumption computations \r\nare complex. \r\nNeed to take into account\r\n- memory access,\r\n- addressing,\r\n- auxiliary operations,\r\nin addition to MACs.\r\nEstimated energy consumption for 3 different datasets (CIFAR10, GSC, NCARS; image, sound \r\nand video classification respectively). FNN‚Äôs are conventional feed-forward neural networks.\r\nIn this example: SNNs are 6 to 8 times more energy efficient than FNNs.\r\nhttps://arxiv.org/pdf/2210.13107\r\nComputing energy consumption\r\n\r\nIn practice, energy \r\nconsumption computations \r\nare complex. \r\nNeed to take into account\r\n- memory access,\r\n- addressing,\r\n- auxiliary operations,\r\nin addition to MACs.\r\nEstimated energy consumption for 3 different datasets (CIFAR10, GSC, NCARS; image, sound \r\nand video classification respectively). FNN‚Äôs are conventional feed-forward neural networks.\r\nIn this example: SNNs are 6 to 8 times more energy efficient than FNNs.\r\nComputing energy consumption\r\nQuestions?\r\n\r\nReading materials\r\nMain reading:\r\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \r\nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\r\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\r\n- Neuromorphic computing:\r\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \r\nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\r\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \r\noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\r\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019.', 'Power-efficiency at scale\r\nModern, deep neural networks*\r\nare trained using GPUs.\r\n* It is estimated that ChatGPT was trained on \r\n10,000-20,000 GPUs and that it will require\r\n30,000 GPUs to keep running stably in the future.\r\n* It is estimated that ChatGPT has 10-20 billion \r\nparameters.\r\nhttps://www.anandtech.com/show/4008/nvidias-geforce-gtx-580/17\r\n\r\nPower-efficiency at scale\r\nModern, deep neural networks*\r\nare trained using GPUs.\r\n* It is estimated that ChatGPT was trained on \r\n10,000-20,000 GPUs and that it will require\r\n30,000 GPUs to keep running stably in the future.\r\n* It is estimated that ChatGPT has 10-20 billion \r\nparameters.\r\nSingle model with 20 billion parameters:\r\n200 Watts x 30,000 GPUs = 6M Watts\r\n\r\nPower-efficiency at scale\r\nhttps://hai.stanford.edu/ai-index/2024-ai-index-report\r\nTraining a single large language model can \r\ngenerate greater CO2 emissions than the \r\ntotal lifetime emissions of 8 cars (in 2020)!\r\n\r\nPower-efficiency at scale\r\nhttps://hai.stanford.edu/ai-index/2024-ai-index-report\r\nTraining a single model can consume \r\nmore than 1000 MWh of power!\r\n\r\nPower-efficiency at scale\r\nhttps://hai.stanford.edu/ai-index/2024-ai-index-report\r\nTraining a single model can consume \r\nmore than 1000 MWh of power!\r\n‚Ä¶ with energy costs reaching 200M USD!\r\n\r\nPower-efficiency at scale\r\nYour brain runs on:\r\n\r\nPower-efficiency at scale\r\nYour brain runs on:\r\nHigh estimate ~3000 kcal a day\r\n   ‚âà145 Watts\r\n* Human brain has ~600 trillion synapses \r\n(‚âàparameters).\r\n\r\nPower-efficiency at scale\r\nYour brain runs on:\r\nHigh estimate ~3000 kcal a day\r\n   ‚âà145 Watts\r\n* Human brain has ~600 trillion synapses \r\n(‚âàparameters).\r\nOversimplification\r\nThere are also multiple other advantages‚Ä¶\r\n\r\nHuman vs. computer computation\r\n- Fast real-time decision making, e.g. sports, e-sports\r\n- Adaptive, e.g. context-aware and employs selective attention\r\n- Energy efficient: Close to 100 billion neurons in the brain\r\n- Robust, for example to changes in illumination or obstructions in object tracking\r\n\r\nHuman vs. computer computation\r\nBrains are energy efficient: Why?\r\n1.\r\nHigh temporal resolution (more computation with less neurons)\r\n2.\r\nSparse encoding\r\n\r\nHuman vs. computer computation\r\nQuestions?\r\nBrains are energy efficient: Why?\r\n1.\r\nHigh temporal resolution (more computation with less neurons)\r\n2.\r\nSparse encoding\r\n\r\nHow do biological neurons communicate?\r\nAnalogy to artificial neural networks\r\nReal neuron\r\nArtificial neuron\r\nCurrent\r\n\r\nHow do biological neurons communicate?\r\nHow does the electrical activity propagate?\r\n?\r\nCurrent\r\n\r\nHow do biological neurons work?\r\ntime\r\nelectrode\r\nhttps://tinmard.github.io/spike-sorting-animation.html\r\nQuick electrical pulses trigger chemical signals for the next neuron ‚Üí Spikes\r\n\r\nHow do biological neurons work?\r\nQuick electrical pulses trigger chemical signals for the next neuron ‚Üí Spikes\r\nhttps://tinmard.github.io/spike-sorting-animation.html\r\ntime\r\nelectrode\r\nFrom CS perspective:\r\nSparse binary \r\nencoding\r\n\r\nBiologically realistic spiking neuron models\r\nBiologically realistic neuron models have \r\na new dimension: Time!\r\nSpiking neural networks (SNNs):\r\nThe input x  (t  ) to each neuron is summed \r\n(integrated) over time.\r\nscalar\r\nfunction of \r\ntime\r\n(t)\r\n(t)\r\nhttps://www.mdpi.com/2076-3425/12/7/863\r\n\r\nHow to model spiking neurons?', '9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\r\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \r\nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\r\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \r\n(not publicly available) doi:10.1037/h0042519\r\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \r\nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\r\n6) https://github.com/idsc-frazzoli/retina\r\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \r\nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\r\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \r\nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\r\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \r\nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\r\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \r\nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\r\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \r\nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\r\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\r\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\r\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \r\n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568', '575(7784):607-17. \r\nhttps://www.nature.com/articles/s41586-019-1677-2\r\nExtra reading:\r\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \r\nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\r\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \r\nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \r\nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\r\nBasics of \'conventional\' neural networks:\r\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\r\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.\r\n\r\nReferences\r\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \r\nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\r\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \r\n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\r\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \r\nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\r\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \r\n(not publicly available) doi:10.1037/h0042519\r\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \r\nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\r\n6) https://github.com/idsc-frazzoli/retina\r\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \r\nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\r\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \r\nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\r\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \r\nNeural Networks.', 'Neuromorphic computing\r\nCS4575\r\nSustainable Software Engineering\r\n05.03.2025\r\nNergis T√∂men\r\n\r\nIntroduction\r\nComputer Vision Lab\r\nBiomorphic Intelligence Lab\r\nBiomedical Intervention Optimisation Lab\r\nNergis\r\n\r\nNeuromorphic computing\r\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\r\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\r\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing\r\n\r\nHow many of you are familiar \r\nwith neural networks?\r\n\r\nSimple model of an artificial neuron\r\nhttps://medium.com/@cprasenjit32/perceptron-a-simple-yet-mighty-machine-learning-algorithm-9ff6b7d86a71\r\n\r\nWhat is a neural network?\r\nhttps://www.tibco.com/reference-center/what-is-a-neural-network\r\n\r\nWhy is it called a \'neural network\'?\r\nhttps://www.tibco.com/reference-center/what-is-a-neural-network\r\n\r\nWhat is a neural network?\r\nWhy is it called a \'neural network\'?\r\nMcCulloch-Pitts neuron [1, 2] (1943)\r\nWarren Sturgis McCulloch\r\n(Neurophysiologist)\r\nWalter Pitts\r\n(Logician)\r\n\r\nHow do biological neurons work?\r\nhttps://commons.wikimedia.org/wiki/File:Coincidence_detection_in_dendrites_of_pyramidal_neurons.gif\r\n\'Input current\' travels down the dendrites (top),\r\nget integrated (summed!) in the cell body\r\nwhich generates an \'output current\' (bottom)\r\nwhich is chemically transmitted to the dendrites of \r\nother neurons.\r\n\r\nSimplified picture\r\nReal neuron\r\nArtificial neuron\r\nhttps://vajiramandravi.com/quest-upsc-notes/artificial-neural-network/\r\n\r\nWhat is a neural network?\r\nMcCulloch-Pitts neuron [1, 2]\r\n1940s: How do biological neurons compute basic \r\nlogic functions? (e.g. logic gates)\r\nNote: Ref. [3] gives a nice brief history on the ideas which lead to the \r\nMcCulloch-Pitts neuron.\r\n\r\nWhat is a neural network?\r\n1950s: How are neurons organized to perform \r\nsensory perception?\r\n\r\nWhat is a neural network?\r\n1950s: How are neurons organized to perform \r\nsensory perception?\r\nThe first ""neural network"": Perceptron (1958). [4]\r\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\r\nFrank Rosenblatt (Psychologist)\r\nwith a Mark I Perceptron computer in 1960\r\n\r\nWhat is a neural network?\r\n1950s: How are neurons organized to perform \r\nsensory perception?\r\nThe first ""neural network"": Perceptron (1958). [4]\r\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\r\nFrank Rosenblatt (Psychologist)\r\nwith a Mark I Perceptron computer in 1960\r\nPower-efficient\r\n\r\nNeuromorphic computing\r\nWhy neuromorphic computing?\r\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\r\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\r\n\r\nNeuromorphic computing\r\nWhy neuromorphic computing?\r\n‚ÄòBiological inspiration‚Äô for artificial neural networks (ANNs) is not a new idea.\r\nEmulation (as opposed to simulation) of neural networks in hardware is not a new idea.', 'In this example: SNNs are 6 to 8 times more energy efficient than FNNs.\r\nComputing energy consumption\r\nQuestions?\r\n\r\nReading materials\r\nMain reading:\r\n- Section 1 and Section 3.1 of ""Computing with spiking neuron networks."" by Paugam-Moisy H, Bohte SM, in Handbook of natural computing (2012). \r\nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\r\n- Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. https://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\r\n- Neuromorphic computing:\r\n- Based on biology: Zenke F, Boht√© SM, Clopath C, Com≈üa IM, G√∂ltz J, Maass W, Masquelier T, Naud R, Neftci EO, Petrovici MA, Scherr F. Visualizing a joint future of \r\nneuroscience and neuromorphic engineering. Neuron. 2021. 109(4):571-5. https://www.sciencedirect.com/science/article/pii/S089662732100009X\r\n- How to train modern spiking networks: Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based \r\noptimization to spiking neural networks. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\r\n- Rate-based SNNs: Roy K, Jaiswal A, Panda P. Towards spike-based machine intelligence with neuromorphic computing. Nature. 2019. 575(7784):607-17. \r\nhttps://www.nature.com/articles/s41586-019-1677-2\r\nExtra reading:\r\n- Converging history of deep networks and biological systems: Sejnowski TJ. The unreasonable effectiveness of deep learning in artificial intelligence. Proceedings of the National \r\nAcademy of Sciences. 2020. 117(48):30033-8. https://www.pnas.org/doi/full/10.1073/pnas.1907373117\r\n- Also an important part of neuromorphic systems and vision ‚Üí Event Cameras: Gallego G, Delbr√ºck T, Orchard G, Bartolozzi C, Taba B, Censi A, Leutenegger S, Davison AJ, Conradt J, \r\nDaniilidis K, Scaramuzza D. Event-based vision: A survey. IEEE transactions on pattern analysis and machine intelligence. 2020. 44(1):154-80. \r\nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9138762\r\nBasics of \'conventional\' neural networks:\r\n- Sections 4.1 to 4.4 from the book ""Pattern Recognition"" by Theodoridis and Koutroumbas.\r\n- Subsection 4.1.7 from the book ""Pattern Recognition and Machine Learning"" by Bishop.\r\n\r\nReferences\r\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \r\nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\r\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947.', 'McCulloch-Pitts neuron [1, 2]\r\n1940s: How do biological neurons compute basic \r\nlogic functions? (e.g. logic gates)\r\nNote: Ref. [3] gives a nice brief history on the ideas which lead to the \r\nMcCulloch-Pitts neuron.\r\n\r\nWhat is a neural network?\r\n1950s: How are neurons organized to perform \r\nsensory perception?\r\n\r\nWhat is a neural network?\r\n1950s: How are neurons organized to perform \r\nsensory perception?\r\nThe first ""neural network"": Perceptron (1958). [4]\r\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\r\nFrank Rosenblatt (Psychologist)\r\nwith a Mark I Perceptron computer in 1960\r\n\r\nWhat is a neural network?\r\n1950s: How are neurons organized to perform \r\nsensory perception?\r\nThe first ""neural network"": Perceptron (1958). [4]\r\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\r\nFrank Rosenblatt (Psychologist)\r\nwith a Mark I Perceptron computer in 1960\r\nPower-efficient\r\n\r\nNeuromorphic computing\r\nWhy neuromorphic computing?\r\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\r\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\r\n\r\nNeuromorphic computing\r\nWhy neuromorphic computing?\r\n‚ÄòBiological inspiration‚Äô for artificial neural networks (ANNs) is not a new idea.\r\nEmulation (as opposed to simulation) of neural networks in hardware is not a new idea.\r\nQuestion: What can we gain from increasing biological realism in existing neural networks?\r\n\r\nPower-efficiency at scale\r\nModern, deep neural networks*\r\nare trained using GPUs.\r\n* It is estimated that ChatGPT was trained on \r\n10,000-20,000 GPUs and that it will require\r\n30,000 GPUs to keep running stably in the future.\r\n* It is estimated that ChatGPT has 10-20 billion \r\nparameters.\r\nhttps://www.anandtech.com/show/4008/nvidias-geforce-gtx-580/17\r\n\r\nPower-efficiency at scale\r\nModern, deep neural networks*\r\nare trained using GPUs.\r\n* It is estimated that ChatGPT was trained on \r\n10,000-20,000 GPUs and that it will require\r\n30,000 GPUs to keep running stably in the future.\r\n* It is estimated that ChatGPT has 10-20 billion \r\nparameters.\r\nSingle model with 20 billion parameters:\r\n200 Watts x 30,000 GPUs = 6M Watts\r\n\r\nPower-efficiency at scale\r\nhttps://hai.stanford.edu/ai-index/2024-ai-index-report\r\nTraining a single large language model can \r\ngenerate greater CO2 emissions than the \r\ntotal lifetime emissions of 8 cars (in 2020)!\r\n\r\nPower-efficiency at scale\r\nhttps://hai.stanford.edu/ai-index/2024-ai-index-report\r\nTraining a single model can consume \r\nmore than 1000 MWh of power!\r\n\r\nPower-efficiency at scale\r\nhttps://hai.stanford.edu/ai-index/2024-ai-index-report\r\nTraining a single model can consume \r\nmore than 1000 MWh of power!\r\n‚Ä¶ with energy costs reaching 200M USD!\r\n\r\nPower-efficiency at scale\r\nYour brain runs on:\r\n\r\nPower-efficiency at scale\r\nYour brain runs on:\r\nHigh estimate ~3000 kcal a day\r\n   ‚âà145 Watts\r\n* Human brain has ~600 trillion synapses \r\n(‚âàparameters).', ""‚Ä¢ Our question: Can we save energy with alternative approaches? \r\n‚Ä¢ We studied Grid Search, Random Search and Bayesian \r\nOptimisation.\r\n27\r\nTim's MSc Thesis, 2022 \r\nAccepted at CAIN‚Äô23\r\n\r\n\r\nResults\r\n29\r\nConclusions? \r\n‚Ä¢ Bayesian converges faster. \r\n‚Ä¢ No clear winner between Grid and Random\r\n\r\nDeepSeekMoE\r\n30\r\nPreprint at ArXiv, 2024 https://arxiv.org/pdf/\r\n2401.06066\r\n\r\nMixture of Experts\r\n‚Ä¢ Llama3.1 has 405B parameters, DeepSeek V3 671B \r\n‚Ä¢ Yet DeepSeek has quicker inference times and claims less energy \r\nconsumption (?) \r\n‚Ä¢ Divide the model into smaller blocks of experts \r\n‚Ä¢ Tokens get routed to certain experts based on the query \r\n‚Ä¢ Only part of the network is active during inference \r\n‚Ä¢ DeepSeek claims only 37B out of 671B parameters get active\r\n31\r\n\r\nDeepSeekMoE\r\n32\r\n\r\nDeepSeekMoE\r\n33\r\n‚Ä¢ Comparable performance to \r\nLLaMA2 7B effectively using \r\nless half the parameters \r\n‚Ä¢ Less computational power \r\n‚Ä¢ Problems (?) \r\n‚Ä¢ Still need to load all the \r\nparameters \r\n‚Ä¢ High memory -> high \r\nembodied carbon\r\n\r\nGreen AI at FacebookMeta\r\n34\r\nSustainable AI: Environmental Implications, \r\nChallenges and Opportunities (2022)\r\n\r\nCarbon footprint mapped to the AI lifecycle\r\n‚Ä¢ There are 4 main overarching stages where carbon emissions need to be isolated: data \r\ncollection, experimentation, training, inference. \r\n‚Ä¢ At Facebook, recommendation systems split energy consumption evenly between \r\ntraining and inference; text translation models have a 35%/65% split. (Operational cost) \r\n‚Ä¢ Operational/embodied cost split: 30%/70%\r\n35\r\n\r\nOpen issues according to Meta\r\n‚Ä¢ A vast portion of projects only use GPUs at 30%.\u2028\r\nShould be higher to attenuate embodied carbon.\r\n36\r\nBased on 10K AI projects\r\n\r\nData Jan\r\nInformed Adaptation\r\nData Feb\r\nData Mar\r\nData Apr\r\nData May\r\n‚Ä¶\r\n~Data Dec\r\n~Data Dec\r\nData Jan\r\nData Feb\r\nData Mar\r\nData Apr\r\nData May\r\n‚Ä¶\r\nModel update Model update Model update\r\nCheck if \r\ndata change\r\nCheck if \r\ndata change\r\nCheck if \r\ndata change\r\nModel update\r\nBlind Adaptation\r\nThe AI Model will be \r\nupdated fewer times and \r\nonly when necessary.\r\nKnow when to retrain models\r\nNeither too early nor too late\r\n37\r\nAdaptation Techniques\r\n?\r\n\r\nGreen Architectural Tactics for ML-Enabled \r\nSystem\r\n38\r\nICSE-SEIS 2024\r\n\r\nArchitectural tactics\r\n39\r\n\r\nData-centric\r\n40\r\n‚Ä¢ Reduce data size \r\n‚Ä¢ Sampling \r\n‚Ä¢ Dimensionality reduction \r\n‚Ä¢ Quantization\r\n\r\nAlgorithm Design\r\n41\r\n‚Ä¢ Carefully select your algorithm \r\n‚Ä¢ You don‚Äôt need the fanciest \r\ntechniques\r\n\r\nModel Optimization\r\n42\r\n‚Ä¢ Add energy to training parameters \r\n‚Ä¢ Reduce FLOPs \r\n‚Ä¢ Pruning, sparsity \r\n‚Ä¢  Take advantage of existing models\r\n\r\nModel Training\r\n43\r\n‚Ä¢ Quantization\r\n‚Ä¢ SAVE TRAINING PROGRESS\r\n\r\nModel Deployment\r\n44\r\n‚Ä¢ Distributed deployment \r\n‚Ä¢ Energy efficient hardware and \r\nconfigurations\r\n\r\nModel Management\r\n45\r\n‚Ä¢ Reuse the model as much as possible \r\n\r\nRethinking the Architecture: Spiking Neural Networks\r\n46\r\n\r\nRethinking the Architecture: Spiking Neural Networks\r\n47\r\n\r\nSELF Lab\r\n48\r\n\r\nrecap"", '‚Ä¢ Improve parameter-tuning strategy.\r\n11\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ We need benchmarks. \r\n‚Ä¢ AllenAI leaderboard\u2028\r\nhttps://leaderboard.allenai.org \r\n‚Ä¢ No carbon metrics, yet \r\n‚Ä¢ Report comparable proxies for energy \r\nconsumption. \r\n‚Ä¢ ‚ö† Learning algorithms behave in a non-\r\ndeterministic \r\n‚Ä¢ ‚ö† Different data-points lead to different \r\nenergy consumption\r\n12\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ Reporting measured energy consumption \r\n‚Ä¢ + Accurate \r\n‚Ä¢ + Easy to map to carbon emissions \r\n‚Ä¢ - Hard to measure \r\n‚Ä¢ - Low replicability \r\n‚Ä¢ Reporting time / estimation based on time & hardware \r\n‚Ä¢ + Easy to measure \r\n‚Ä¢ + Correlates with energy consumption in most cases. \r\n‚Ä¢ -  Difficult to compare with measurements from other setups \r\n‚Ä¢ E.g., floating point operations (FPOs) (?) \r\n‚Ä¢ + comparable across different setups \r\n‚Ä¢ + cheap \r\n‚Ä¢ - does not factor in memory energy consumption \r\n‚Ä¢ - does not reflect carbon emissions\r\n13\r\n\r\nData-centric AI\r\n\r\nData-centric AI\r\n‚Ä¢ Emerging discipline that deals with systematically engineering data to build AI \r\nsystems. \r\n‚Ä¢ Shift from improving the training strategy to improving the data. \r\n‚Ä¢ It is better to have small but reliable datasets than large but noisy \r\ndatasets. \r\n‚Ä¢ => Improve data collection, data labelling, and data preprocessing. \r\n‚Ä¢ More about data-centric AI by Andrew Ng:\u2028\r\nhttps://www.youtube.com/watch?v=06-AZXmwHjo\r\n15\r\n\r\n\r\nGreen Data-centric AI\r\n‚Ä¢ How do different ML algorithms compare \r\nin terms of energy consumption? \r\n‚Ä¢ How does number of rows relate to the \r\nenergy consumption of ML models? \r\n‚Ä¢ How does number of features relate to \r\nthe energy consumption of ML models? \r\n‚Ä¢ What is the impact of reducing data in the \r\nperformance of the model? \r\n‚Ä¢ Method -> results -> discussion\r\n17\r\n\r\nMethod\r\n‚Ä¢ Single object of study: natural language model to detect spam messages. \r\n‚Ä¢ 6 machine learning algorithms: SVM, Decision Tree, KNN, Random Forrest, \r\nAdaBoost, Bagging Classifier. \r\n‚Ä¢ Reduce the number of rows. 10%, 20%, .., 100% \r\n‚Ä¢ Stratified random sampling (?) \r\n‚Ä¢ Reduce the number of features. 10%, 20%, .., 100% \r\n‚Ä¢ Feature importance metric based on the Chi-Square Test (Chi2) \r\n‚Ä¢ Estimate energy consumption using a RAPL-based tool. (?)\r\n18\r\n\r\n‚Ä¢ Repeat 30 times \r\n‚Ä¢ Fix random seeds \r\n‚Ä¢ ‚Ä¶ \r\n‚Ä¢ Data was not Normal => tailed Normal distribution.\r\n19\r\n(?)\r\n\r\nResults: energy consumption of algorithms\r\n\r\nResults: energy vs data shape\r\n\r\nResults: performance vs data shape\r\n\r\nDiscussion\r\n‚Ä¢ Other data properties should be investigated. \r\n‚Ä¢ E.g., data types \r\n‚Ä¢ Reporting energy data is essential. It can lead to different model selection \r\nwithout hindering model performance. \r\n‚Ä¢ There is a big opportunity in Model and Data Simplification.\r\n23\r\n\r\nData/Model Simplification\r\n‚Ä¢ (?) \r\n‚Ä¢ Data selection \r\n‚Ä¢ Data quantisation. Posit? \r\n‚Ä¢ Data distillation \r\n‚Ä¢ Coreset extraction (?) \r\n‚Ä¢ Model distillation \r\n‚Ä¢ Model quantisation \r\n‚Ä¢ Model pruning \r\n‚Ä¢ ‚Ä¶\r\n24\r\n\r\nPosit vs Float\r\nMore about this: https://spectrum.ieee.org/floating-point-numbers-posits-processor\r\nBetter for DL use cases\r\n\r\nHow can we tune \r\nlearning \r\nparameters \r\nefficiently?\r\n\r\nHyper parameter tuning\r\n‚Ä¢ When training an ML model, there are several parameters that need to be \r\ntuned. \r\n‚Ä¢ E.g., in SVM we have the Regularization parameter C, the kernel function, \r\nthe degree of the kernel function, and depending on the case, many other. \r\n‚Ä¢ The common approach revolves around grid search.', ""‚Ä¢ 6 machine learning algorithms: SVM, Decision Tree, KNN, Random Forrest, \r\nAdaBoost, Bagging Classifier. \r\n‚Ä¢ Reduce the number of rows. 10%, 20%, .., 100% \r\n‚Ä¢ Stratified random sampling (?) \r\n‚Ä¢ Reduce the number of features. 10%, 20%, .., 100% \r\n‚Ä¢ Feature importance metric based on the Chi-Square Test (Chi2) \r\n‚Ä¢ Estimate energy consumption using a RAPL-based tool. (?)\r\n18\r\n\r\n‚Ä¢ Repeat 30 times \r\n‚Ä¢ Fix random seeds \r\n‚Ä¢ ‚Ä¶ \r\n‚Ä¢ Data was not Normal => tailed Normal distribution.\r\n19\r\n(?)\r\n\r\nResults: energy consumption of algorithms\r\n\r\nResults: energy vs data shape\r\n\r\nResults: performance vs data shape\r\n\r\nDiscussion\r\n‚Ä¢ Other data properties should be investigated. \r\n‚Ä¢ E.g., data types \r\n‚Ä¢ Reporting energy data is essential. It can lead to different model selection \r\nwithout hindering model performance. \r\n‚Ä¢ There is a big opportunity in Model and Data Simplification.\r\n23\r\n\r\nData/Model Simplification\r\n‚Ä¢ (?) \r\n‚Ä¢ Data selection \r\n‚Ä¢ Data quantisation. Posit? \r\n‚Ä¢ Data distillation \r\n‚Ä¢ Coreset extraction (?) \r\n‚Ä¢ Model distillation \r\n‚Ä¢ Model quantisation \r\n‚Ä¢ Model pruning \r\n‚Ä¢ ‚Ä¶\r\n24\r\n\r\nPosit vs Float\r\nMore about this: https://spectrum.ieee.org/floating-point-numbers-posits-processor\r\nBetter for DL use cases\r\n\r\nHow can we tune \r\nlearning \r\nparameters \r\nefficiently?\r\n\r\nHyper parameter tuning\r\n‚Ä¢ When training an ML model, there are several parameters that need to be \r\ntuned. \r\n‚Ä¢ E.g., in SVM we have the Regularization parameter C, the kernel function, \r\nthe degree of the kernel function, and depending on the case, many other. \r\n‚Ä¢ The common approach revolves around grid search. The user provides a \r\nsequence of possible values for each parameter and the pipeline runs all \r\npossible combinations. \r\n‚Ä¢ Our question: Can we save energy with alternative approaches? \r\n‚Ä¢ We studied Grid Search, Random Search and Bayesian \r\nOptimisation.\r\n27\r\nTim's MSc Thesis, 2022 \r\nAccepted at CAIN‚Äô23\r\n\r\n\r\nResults\r\n29\r\nConclusions? \r\n‚Ä¢ Bayesian converges faster. \r\n‚Ä¢ No clear winner between Grid and Random\r\n\r\nDeepSeekMoE\r\n30\r\nPreprint at ArXiv, 2024 https://arxiv.org/pdf/\r\n2401.06066\r\n\r\nMixture of Experts\r\n‚Ä¢ Llama3.1 has 405B parameters, DeepSeek V3 671B \r\n‚Ä¢ Yet DeepSeek has quicker inference times and claims less energy \r\nconsumption (?) \r\n‚Ä¢ Divide the model into smaller blocks of experts \r\n‚Ä¢ Tokens get routed to certain experts based on the query \r\n‚Ä¢ Only part of the network is active during inference \r\n‚Ä¢ DeepSeek claims only 37B out of 671B parameters get active\r\n31\r\n\r\nDeepSeekMoE\r\n32\r\n\r\nDeepSeekMoE\r\n33\r\n‚Ä¢ Comparable performance to \r\nLLaMA2 7B effectively using \r\nless half the parameters \r\n‚Ä¢ Less computational power \r\n‚Ä¢ Problems (?) \r\n‚Ä¢ Still need to load all the \r\nparameters \r\n‚Ä¢ High memory -> high \r\nembodied carbon\r\n\r\nGreen AI at FacebookMeta\r\n34\r\nSustainable AI: Environmental Implications, \r\nChallenges and Opportunities (2022)\r\n\r\nCarbon footprint mapped to the AI lifecycle\r\n‚Ä¢ There are 4 main overarching stages where carbon emissions need to be isolated: data \r\ncollection, experimentation, training, inference. \r\n‚Ä¢ At Facebook, recommendation systems split energy consumption evenly between \r\ntraining and inference; text translation models have a 35%/65% split. (Operational cost) \r\n‚Ä¢ Operational/embodied cost split: 30%/70%\r\n35\r\n\r\nOpen issues according to Meta\r\n‚Ä¢ A vast portion of projects only use GPUs at 30%.\u2028\r\nShould be higher to attenuate embodied carbon."", '8. Green AI\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nLu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\nCarolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl\r\n\r\n- Overview of Green AI \r\n- Large language models \r\n- Green data-centric AI \r\n- Model simplification \r\n- Hyper parameter tuning \r\n- Mixture of Experts and DeepSeek \r\n- Green AI at Meta \r\n\r\nAI\r\n‚Ä¢ Artificial Intelligence (AI) is the branch of computer science that deals with \r\nautomating tasks that typically require human intelligence. \r\n‚Ä¢ In the past years AI has been widely applied across different domains.\u2028\r\nE.g., health care, transportation, finance. \r\n‚Ä¢ To deploy AI systems, we test them against benchmarks (or validation sets). \r\n‚Ä¢ The goal is to outperform the previous existing models. \r\n‚Ä¢ E.g., in Machine Learning we usually resort to accuracy metrics. The \r\nhighest the accuracy, the better the model.\r\n3\r\n\r\nSince 2012, the amount of computing used for AI \r\ntraining has been doubling every 6 months\r\n‚Ä¢ https://epoch.ai/blog/compute-trends\r\n4\r\n\r\n‚Ä¢ To create better AI systems we are currently adding \r\n‚Ä¢ More data \r\n‚Ä¢ More experiments \r\n‚Ä¢ Larger models\r\n5\r\n\r\nThe Equation of Red AI\r\nCost(R) ‚àùE¬∑D¬∑H\r\nCost of a single (E)xample\r\nSize of (D)ataset\r\nNumber of (H)yperparameters\r\nBy Schwartz et al. (2020)\r\n\r\nIssues of Red AI\r\n‚Ä¢ High costs (hardware, electricity, data access, etc.) \r\n‚Ä¢ Limited reproducibility.  \r\n‚Ä¢ Energy consumption. \r\n‚Ä¢ Carbon emissions. \r\n‚Ä¢ SMEs can hardly be competitive. \r\n‚Ä¢ Groundbreaking AI research is mostly done by tech giants.\r\n7\r\n\r\nA few examples of Red AI\r\n‚Ä¢ Google‚Äôs BERT-large \r\n‚Ä¢ 350 million features \r\n‚Ä¢ Trained for 2.5 days using 512 TPU chips, costing $60K+ \r\n‚Ä¢ Open-GPT3 (now GPT-4/o1) \r\n‚Ä¢ 550 tonnes CO2-eq (Patterson, 2021) \r\n‚Ä¢ 175 billion features \r\n‚Ä¢ API is open but no-pretrained model is available \r\n‚Ä¢ AlphaGo \r\n‚Ä¢ 1920 CPUs, 280 GPUs, costing $35M\r\n8\r\n\r\nRed AI in Large Language Models (LLMs)\r\n‚Ä¢ OPT by Meta reports 75 tons CO2-eq (1/7 of OpenGPT‚Äôs footprint).\u2028\r\n(Also 175billion params) \r\n‚Ä¢ However, Llama 3 reported 2,290 tons of CO2-eq (7.7M GPU hours \r\ntraining ) \r\n‚Ä¢ Open science: release includes both the pretrained models and the code \r\nneeded to train and use them. \r\n‚Ä¢ DeepSeek-V3 claims ‚Äúonly‚Äù 2.78M GPU hours \r\n‚Ä¢ Bloom by Huggingface reports 25 tons, 51 when considering embodied \r\nand operational carbon footprint. (176billion params)\r\n9\r\n\r\nRed AI\r\nAccuracy: 0.999999999\r\nGreen AI\r\n‚Ä¢ Energy \r\n‚Ä¢ Time \r\n‚Ä¢ Reproducibility \r\n‚Ä¢ Reusage\r\n\r\nHow can we adopt Green AI\r\n‚Ä¢ Check whether AI is needed. \r\n‚Ä¢ Select green datacenters. \r\n‚Ä¢ Run on low carbon intensity hours. \r\n‚Ä¢ Opt for GPU-optimised solutions (?) \r\n‚Ä¢ Opt for low-power hardware (e.g., Nvidia Jetson boards) \r\n‚Ä¢ Or GPUs that provide energy metrics (e.g., NVIDIA GPUs via the nvidia-smi tool) \r\n‚Ä¢ Report energy/carbon metrics (e.g., embed in MLFlow?)', '‚Ä¢ Groundbreaking AI research is mostly done by tech giants.\r\n7\r\n\r\nA few examples of Red AI\r\n‚Ä¢ Google‚Äôs BERT-large \r\n‚Ä¢ 350 million features \r\n‚Ä¢ Trained for 2.5 days using 512 TPU chips, costing $60K+ \r\n‚Ä¢ Open-GPT3 (now GPT-4/o1) \r\n‚Ä¢ 550 tonnes CO2-eq (Patterson, 2021) \r\n‚Ä¢ 175 billion features \r\n‚Ä¢ API is open but no-pretrained model is available \r\n‚Ä¢ AlphaGo \r\n‚Ä¢ 1920 CPUs, 280 GPUs, costing $35M\r\n8\r\n\r\nRed AI in Large Language Models (LLMs)\r\n‚Ä¢ OPT by Meta reports 75 tons CO2-eq (1/7 of OpenGPT‚Äôs footprint).\u2028\r\n(Also 175billion params) \r\n‚Ä¢ However, Llama 3 reported 2,290 tons of CO2-eq (7.7M GPU hours \r\ntraining ) \r\n‚Ä¢ Open science: release includes both the pretrained models and the code \r\nneeded to train and use them. \r\n‚Ä¢ DeepSeek-V3 claims ‚Äúonly‚Äù 2.78M GPU hours \r\n‚Ä¢ Bloom by Huggingface reports 25 tons, 51 when considering embodied \r\nand operational carbon footprint. (176billion params)\r\n9\r\n\r\nRed AI\r\nAccuracy: 0.999999999\r\nGreen AI\r\n‚Ä¢ Energy \r\n‚Ä¢ Time \r\n‚Ä¢ Reproducibility \r\n‚Ä¢ Reusage\r\n\r\nHow can we adopt Green AI\r\n‚Ä¢ Check whether AI is needed. \r\n‚Ä¢ Select green datacenters. \r\n‚Ä¢ Run on low carbon intensity hours. \r\n‚Ä¢ Opt for GPU-optimised solutions (?) \r\n‚Ä¢ Opt for low-power hardware (e.g., Nvidia Jetson boards) \r\n‚Ä¢ Or GPUs that provide energy metrics (e.g., NVIDIA GPUs via the nvidia-smi tool) \r\n‚Ä¢ Report energy/carbon metrics (e.g., embed in MLFlow?) \r\n‚Ä¢ Use pre-trained models (Transfer Learning) \r\n‚Ä¢ Preprocess dataset to reduce size. \r\n‚Ä¢ Improve parameter-tuning strategy.\r\n11\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ We need benchmarks. \r\n‚Ä¢ AllenAI leaderboard\u2028\r\nhttps://leaderboard.allenai.org \r\n‚Ä¢ No carbon metrics, yet \r\n‚Ä¢ Report comparable proxies for energy \r\nconsumption. \r\n‚Ä¢ ‚ö† Learning algorithms behave in a non-\r\ndeterministic \r\n‚Ä¢ ‚ö† Different data-points lead to different \r\nenergy consumption\r\n12\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ Reporting measured energy consumption \r\n‚Ä¢ + Accurate \r\n‚Ä¢ + Easy to map to carbon emissions \r\n‚Ä¢ - Hard to measure \r\n‚Ä¢ - Low replicability \r\n‚Ä¢ Reporting time / estimation based on time & hardware \r\n‚Ä¢ + Easy to measure \r\n‚Ä¢ + Correlates with energy consumption in most cases. \r\n‚Ä¢ -  Difficult to compare with measurements from other setups \r\n‚Ä¢ E.g., floating point operations (FPOs) (?) \r\n‚Ä¢ + comparable across different setups \r\n‚Ä¢ + cheap \r\n‚Ä¢ - does not factor in memory energy consumption \r\n‚Ä¢ - does not reflect carbon emissions\r\n13\r\n\r\nData-centric AI\r\n\r\nData-centric AI\r\n‚Ä¢ Emerging discipline that deals with systematically engineering data to build AI \r\nsystems. \r\n‚Ä¢ Shift from improving the training strategy to improving the data. \r\n‚Ä¢ It is better to have small but reliable datasets than large but noisy \r\ndatasets. \r\n‚Ä¢ => Improve data collection, data labelling, and data preprocessing. \r\n‚Ä¢ More about data-centric AI by Andrew Ng:\u2028\r\nhttps://www.youtube.com/watch?v=06-AZXmwHjo\r\n15\r\n\r\n\r\nGreen Data-centric AI\r\n‚Ä¢ How do different ML algorithms compare \r\nin terms of energy consumption? \r\n‚Ä¢ How does number of rows relate to the \r\nenergy consumption of ML models? \r\n‚Ä¢ How does number of features relate to \r\nthe energy consumption of ML models? \r\n‚Ä¢ What is the impact of reducing data in the \r\nperformance of the model?', ""‚Ä¢ Visualise distribution shape: violin plots, histograms, density plot.\u2028\r\n \r\n‚Ä¢ Shapiro-Wilk test.\u2028\r\ndata is not normal;\u2028\r\nwe are not sure but it is okay to assume that data is \r\nnormal.\r\np-value < 0.05 ‚áí\r\np-value ‚â•0.05 ‚áí\r\n19\r\n\r\nAfter having all data ready, which artefact \r\nis more energy efficient(?) \r\nFirst approach: compare sample means. \r\n‚ö† assuming normal distribution\r\n\r\nStatistical significance\r\n‚Ä¢ Even if, on average, one artefact has lower \r\nenergy consumption than other,  it might be just \r\na random difference. \r\n‚Ä¢ When we extract a sample from a normal \r\ndistribution it will never be the exact same \r\n‚Ä¢ Statistical significance tests help you \r\nunderstand the differences in the average are \r\nconclusive/significant or inconclusive/\r\ninsignificant.\r\n21\r\n‚ö† assuming normal distribution\r\n\r\nStatistical significance test\r\n‚Ä¢ Two-sided parametric test Welch‚Äôs t-test. \r\n‚Ä¢ Less known alternative to student‚Äôs t-test.\r\n22\r\nWelch‚Äôs t-test in Python\r\nfrom scipy.stats import ttest_ind \r\n_,pvalue = ttest_ind(sample_a, sample_b, \r\n                     equal_var=False, \r\n                     alternative='two-sided')\r\n(?)\r\n‚ö† assuming normal distribution\r\n\r\nEffect Size analysis\r\n‚Ä¢ Now that we know that results are statistically significant we need to \r\nmeasure the difference between the two samples. \r\n‚Ä¢ Mean difference: \r\n \r\n‚Ä¢ Percent change: \r\n \r\n‚Ä¢ Cohen‚Äôs d (informal definition: mean difference normalized by a combined \r\nstandard deviation): \r\nŒî¬Øx\r\nxB ‚àíxA\r\nxA\r\n√ó 100 % = Œî¬Øx\r\nxA\r\n√ó 100 %\r\nŒî¬Øx\r\n1\r\n2\r\ns21 + s22\r\n23\r\n‚ö† assuming normal distribution\r\n\r\nImagine that version A spends 70J and \r\nversion B spends 69J with a \r\n.\r\np-value = 0.04\r\nOn average, version B spent less energy than version A  ‚Äî  ‚úÖ \r\nThere is statistical significance ‚Äî  ‚úÖ \r\nEffect size, percent-change is ‚âà1% ‚Äî ü§î \r\n‚ö† Do we care?\r\n(?)\r\n\r\nPractical Significance\r\n‚Ä¢ Depending on the case, a 2% improvement might be either wonderful or completely \r\nuseless. \r\n‚Ä¢ Effect size analyses help assess practical significance but might not be enough. \r\n‚Ä¢ A critical discussion always needs to be performed. Consider context and explain in what \r\nsense the effect size might be relevant. \r\n‚Ä¢ E.g.: \r\n‚Ä¢  to improve 2% in energy efficiency the code will be less readable or the user \r\nexperience is not so appealing. \r\n‚Ä¢ A particular method improves 2% but it will only be used 1% of the time. \r\n‚Ä¢ There is no particular metric or structure, but this kind of critical analysis is very important.\r\n25\r\n\r\nWhat if data is not Normal?\r\nSame approach but different tests/metrics!\r\n\r\nNon-normal data\r\n‚Ä¢ Statistical significance: non-parametric test (?) \r\n‚Ä¢ Mann-Whitney U test. Instead of looking at standard deviation or mean, it orders \r\nsamples and compares with each other. \r\n‚Ä¢ Less power than parametric-tests (?) \r\n‚Ä¢ Effect size \r\n‚Ä¢ Median difference: \r\n \r\n‚Ä¢ Percentage of pairs supporting a conclusion\u2028\r\n(i.e., # pairs where version A > version B/ total pairs) \r\n‚Ä¢ Common language effect size: \r\nŒîM\r\nU1\r\nN1N2\r\n27\r\n\r\nRecap\r\nImpossible to \r\nfix but \r\nexplainable."", '. . + 2P(tn‚àí1) + P(tn)]\r\nMeasured Energy \r\nConsumption\r\n‚ö† Sometimes you cannot assume that the sampling interval (\r\n) is always the same. ‚ö†\r\nŒît\r\nTrapezoid Rule\r\n\r\nTrapezoid Rule in Python\r\nimport numpy as np \r\nenergy_consumption = np.trapz(power_sample, timestamps) \r\n\r\nAverage power\r\n‚Ä¢ Easy to convert to energy consumption \r\n‚Ä¢ Simply multiply by the elapsed time. \r\n‚Ä¢ (This is another reason to always collect time data along with energy \r\nmetrics.)\r\n11\r\nEnergy = Pavg¬∑Œît\r\n\r\nPower or Energy?\r\n‚Ä¢ Average power consumption makes sense when we report the \r\nconsumption of a continuous use case. E.g., reading an ebook in your \r\ncomputer. \r\n‚Ä¢ Energy consumption makes sense in one-off use cases. E.g., energy \r\nconsumption of a bitcoin transaction. \r\n‚ö†\r\n\r\nLearning activity\r\n‚Ä¢ Pair up with one colleague and discuss potential software use cases where \r\none should test energy efficiency. \r\n‚Ä¢ Choose one use case where energy consumption is the best metric to \r\ndiscuss/test energy efficiency. \r\n‚Ä¢ Choose one use case where average power consumption is the best \r\nmetric to discuss/test energy efficiency.\r\n13\r\n\r\nEnergy Delay Product (EDP)\r\n‚Ä¢ In some cases, to achieve less energy consumption, one simply runs the \r\nsoftware on a low power mode of the CPU. \r\n‚Ä¢ E.g., setting the CPU at a low frequency will make execution slow but more \r\nenergy-efficient. \r\n‚Ä¢ Energy consumption metric that penalizes slow runs \r\n \r\n \r\n‚Ä¢ Gives more importance to application runtime, with the goal of making both \r\nlow energy and fast runtime applications.\r\nEDP = E √ó t = ŒîP √ó t2\r\n14\r\n\r\nmAh\r\njoules\r\nmilliampere hour\r\nmobile industry\r\nThis is not energy or power. \r\nIt is a unit of electric charge.\r\nThe typical notebook battery has between 2,000 \r\nand 6,000 milliamp hours (mAh)\r\n?\r\n\r\nElectric charge\r\n‚Ä¢ International System of Units (SI): Coulomb (C). \r\n‚Ä¢ 1 electron has 1.602176634√ó10-19 coulombs. Moving the electron around the electric \r\nfield requires work (energy consumption).  \r\n‚Ä¢ mAh is the most common metric to specify the capacity of batteries. \r\n‚Ä¢ 1 mAh = 3.6C \r\n‚Ä¢ To compute the actual energy of a battery we need to factor in voltage: \r\n \r\n  \r\n‚Ä¢ E.g., for a battery with a capacity of 1000mAh: \r\n \r\nEnergy = Voltage √ó Charge\r\n1000mAh √ó 3.8V = 3800mWh = 3.8Wh = 3.8 √ó 3600J = 13680J\r\n16\r\n\r\nWhy do we use charge units for batteries?\r\n‚Ä¢ There is a continuous change of voltage throughout a charge/discharge \r\ncycle. \r\n‚Ä¢ E.g., it can start with 4.5 V at a ‚Äú100%‚Äù capacity and from to 3.0V at 5% \r\ncapacity. \r\n‚Ä¢ Most devices use voltage to compute their battery level percentage.\r\n17\r\n\r\nInternational System of Units (SI)\r\n‚Ä¢ Energy: Joule \r\n‚Ä¢ Power: Watt \r\n‚Ä¢ Charge: Coulomb \r\n‚Ä¢ (Time: second)\r\n18\r\n\r\nSI Units are difficult to grasp\r\n‚Ä¢ Whenever talking to a general audience use relative units: \r\n‚Ä¢ Compare to the other well-known things: \r\n‚Ä¢ Yearly household energy consumption \r\n‚Ä¢ Yearly country electrical energy consumption.\u2028\r\n(e.g., https://ccaf.io/cbeci/index/comparisons) \r\n‚Ä¢ Driving kms with a standard car \r\n‚Ä¢ Percentage of a normal battery charge cycle. \r\n‚Ä¢ Compare to other software artefacts/usecases: \r\n‚Ä¢ E.g, percentage of Version A over Version B.', ""Unless there‚Äôs a \r\ngood reason. \r\n‚Ä¢ E.g., somewhere amongst the 30 executions, \r\nthere might be 1 or 2 that failed to finish due \r\nto some unexpected error. \r\n‚Ä¢ (It happens and that‚Äôs ok!)‚Äì consequently, \r\nthe execution is shorter and spends less \r\nenergy ‚Äì falsely appearing as more \r\nenergy efficient. \r\n‚Ä¢ If data is not Normal there might be some \r\nissues affecting the measurements that \r\nmight be ruining results. It is important to \r\ninvestigate this.\r\n16\r\n\r\nEnergy data is not normal. Why?\r\n‚Ä¢ It might be caused by one of the following reasons: \r\n‚Ä¢ There was an error in some of the executions. If not detected and fixed it \r\nmight ruin results. \r\n‚Ä¢ Your tests are not fully replicable or are not deterministic. Quite frequent \r\nwhen you have internet requests or random-based algorithms. \r\n‚Ä¢ There is an unusual task being run by the system during some experiments. \r\n‚Ä¢ The computer entered a different power mode. \r\n‚Ä¢ External physical conditions have changed. E.g., someone opened a \r\nwindow.\r\n17\r\n\r\nEnergy data is not normal. How to fix?\r\n‚Ä¢ We have 2+1 options: \r\n1. Remove outliers. If there are only a few points that deviate from the normal \r\ndistribution, it is okay to simply remove them. \r\n‚Ä¢ Use the z-score outlier removal. (?) \r\n‚Ä¢ Remove all data points that deviate from the mean more than 3 standard \r\ndeviations: \r\n \r\n2. Fix the issue and rerun experiments. \r\n3. Conclude that nothing can be done about it and data will never be normal. (e.g., \r\nin AI, executions are rarely deterministic). ‚ö† Only after ruling out the previous \r\npoints.\r\n| ¬Øx ‚àíx| > 3s\r\n18\r\n\r\nHow do we know whether data is Normal?\r\n‚Ä¢ Visualise distribution shape: violin plots, histograms, density plot.\u2028\r\n \r\n‚Ä¢ Shapiro-Wilk test.\u2028\r\ndata is not normal;\u2028\r\nwe are not sure but it is okay to assume that data is \r\nnormal.\r\np-value < 0.05 ‚áí\r\np-value ‚â•0.05 ‚áí\r\n19\r\n\r\nAfter having all data ready, which artefact \r\nis more energy efficient(?) \r\nFirst approach: compare sample means. \r\n‚ö† assuming normal distribution\r\n\r\nStatistical significance\r\n‚Ä¢ Even if, on average, one artefact has lower \r\nenergy consumption than other,  it might be just \r\na random difference. \r\n‚Ä¢ When we extract a sample from a normal \r\ndistribution it will never be the exact same \r\n‚Ä¢ Statistical significance tests help you \r\nunderstand the differences in the average are \r\nconclusive/significant or inconclusive/\r\ninsignificant.\r\n21\r\n‚ö† assuming normal distribution\r\n\r\nStatistical significance test\r\n‚Ä¢ Two-sided parametric test Welch‚Äôs t-test. \r\n‚Ä¢ Less known alternative to student‚Äôs t-test.\r\n22\r\nWelch‚Äôs t-test in Python\r\nfrom scipy.stats import ttest_ind \r\n_,pvalue = ttest_ind(sample_a, sample_b, \r\n                     equal_var=False, \r\n                     alternative='two-sided')\r\n(?)\r\n‚ö† assuming normal distribution\r\n\r\nEffect Size analysis\r\n‚Ä¢ Now that we know that results are statistically significant we need to \r\nmeasure the difference between the two samples. \r\n‚Ä¢ Mean difference: \r\n \r\n‚Ä¢ Percent change: \r\n \r\n‚Ä¢ Cohen‚Äôs d (informal definition: mean difference normalized by a combined \r\nstandard deviation): \r\nŒî¬Øx\r\nxB ‚àíxA\r\nxA\r\n√ó 100 % = Œî¬Øx\r\nxA\r\n√ó 100 %\r\nŒî¬Øx\r\n1\r\n2\r\ns21 + s22\r\n23\r\n‚ö† assuming normal distribution\r\n\r\nImagine that version A spends 70J and \r\nversion B spends 69J with a \r\n."", 'Interviews?) & rich \r\ndescription of outcomes focus of grading\r\nhttps://eip.pages.ewi.tudelft.nl/eip-website/queue.html\r\n\r\nC1. Compare energy consumption of docker images for \r\nML workloads.\r\n‚Ä¢ Similar to what we have seen in the lectures but for ML-specific workloads. \r\n‚Ä¢ We can reuse existing experiment replication packages.\r\n22\r\n\r\nC2. Plugin to visualize Hugging Face carbon emissions.\r\n‚Ä¢ https://huggingface.co/blog/leaderboard-emissions-\r\nanalysis \r\n‚Ä¢\r\nYoo, Taewon, et al. ""Visualizing the Carbon Intensity of Machine Learning Inference for Image Analysis on TensorFlow Hub.""\r\n\r\nC3. Plugin for ChatGPT\r\n‚Ä¢ Users seldom know how much carbon they are emitting when they interact \r\nwith chat GPT. \r\n‚Ä¢ Let‚Äôs make it transparent to the users. Browser plugin?\r\n24\r\nCO2\r\n\r\nC4. NutriScore for software libraries\r\n25\r\n‚Ä¢ NutriScore labels are not perfect but they are a good starting point! \r\n‚Ä¢ What if we could do the same thing for the energy efficiency of software. \r\n‚Ä¢ (Also open to individual or social sustainability) \r\n‚Ä¢ This work can be scoped in particular domains/ecossystems/use cases. \r\n‚Ä¢ Libraries for stats? ML? Web Dev? Cloud?\r\n\r\nC5. Add energy-awareness to existing software\r\n26\r\n‚Ä¢ Streamlit, Notebooks, JSFiddle, \r\nPyScript, zsh, etc. \r\n‚Ä¢\r\n\r\nC6 - Green Shift Left\r\n‚Ä¢ Estimate energy efficiency using static code analysis. \r\n‚Ä¢ We don‚Äôt need an accurate value. \r\n‚Ä¢ It is useful to know which code is more likely to \r\nintroduce energy hotspots and that should be \r\nreviewed with more attention. \r\n‚Ä¢ Can be scoped to a particular domain (react, php, data \r\nscience, web, etc., etc.)\r\n27\r\n\r\nC7 - Education\r\n‚Ä¢ Educational game for Software \r\nSustainability practices \r\n‚Ä¢ Purpose: use within software teams to \r\ndiscuss or learn about different sustainable \r\nIT practices: at the organisation level, \r\nsoftware, etc.\r\n28\r\nhttps://github.com/OttoKaaij/Ticket-To-Sustainability/?tab=readme-ov-file\r\n\r\nProject ideas (old)\r\n‚Ä¢ Plugin from EnergiBridge (GUI, report generator, python library, etc.) \r\n‚Ä¢ Plugin for ChatGPT (carbon emissions per chat window) \r\n‚Ä¢ Seamless measurements for AI libraries \r\n‚Ä¢ Energy patterns for Green AI \r\n‚Ä¢ Sustainable SW dev gamification \r\n‚Ä¢ Sustainability auditor for AI projects \r\n‚Ä¢ Energy Profiling of screen colour filter tools (or display settings) \r\n‚Ä¢ ‚Ä¶ you can also propose yours!\r\n\r\nhttps://edu.nl/64gpk\r\nedu.nl/64gpk']","[""<1-hop>\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant"", '<2-hop>\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \n(not publicly available) doi:10.1037/h0042519\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568', ""<1-hop>\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant"", '<2-hop>\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \n(not publicly available) doi:10.1037/h0042519\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568', ""<1-hop>\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant"", '<2-hop>\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \n(not publicly available) doi:10.1037/h0042519\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568', ""<1-hop>\n\nEncoding strategies\nWe considered single neurons with Boolean output (‚Äòspike‚Äô=1 or ‚Äòno spike‚Äô=0).\nHow should we encode information about 'features' in a large network with many spikes?\nhttps://analyticsindiamag.com/a-tutorial-on-spiking-neural-networks-for-beginners/\nElephant?\nhttps://www.nationalgeographic.com/anim\nals/mammals/facts/african-elephant"", '<2-hop>\n\nReferences\n1) McCulloch WS, Pitts W. A logical calculus of the ideas immanent in nervous activity. The Bulletin of Mathematical Biophysics. 1943. 5(4):115-33. \nhttps://link.springer.com/content/pdf/10.1007/BF02478259.pdf\n2) Pitts W, McCulloch WS. How we know universals the perception of auditory and visual forms. The Bulletin of Mathematical Biophysics. 1947. \n9(3):127-47. https://link.springer.com/content/pdf/10.1007/BF02478291.pdf\n3) Abraham TH. (Physio) logical circuits: The intellectual origins of the McCulloch‚ÄìPitts neural networks. Journal of the History of the Behavioral \nSciences. 2002. 38(1):3-25. https://onlinelibrary.wiley.com/doi/pdf/10.1002/jhbs.1094\n4) Rosenblatt F. The perceptron: a probabilistic model for information storage and organization in the brain. Psychological review. 1958. 65(6):386. \n(not publicly available) doi:10.1037/h0042519\n5) Tappert CC. Who is the father of deep learning? International Conference on Computational Science and Computational Intelligence (CSCI) 2019. \nhttps://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9070967\n6) https://github.com/idsc-frazzoli/retina\n7) Maass W. Networks of spiking neurons: the third generation of neural network models. Neural networks. 1997. 10(9):1659-71. \nhttps://igi-web.tugraz.at/people/maass/psfiles/85a.pdf\n8) Paugam-Moisy H, Bohte SM, ""Computing with spiking neuron networks."" in Handbook of Natural Computing (2012). \nhttps://homepages.cwi.nl/~sbohte/publication/paugam_moisy_bohte_SNNChapter.pdf\n9) Kheradpisheh SR, Ganjtabesh M, Thorpe SJ, Masquelier T. STDP-based spiking deep convolutional neural networks for object recognition. \nNeural Networks. 2018 Mar 1;99:56-67. https://www-sciencedirect-com.tudelft.idm.oclc.org/science/article/pii/S0893608017302903\n10) G√ºtig R, Sompolinsky H. The tempotron: a neuron that learns spike timing‚Äìbased decisions. Nature neuroscience. 2006 Mar;9(3):420-8. \nhttp://mcn2016public.pbworks.com/w/file/fetch/137818197/Gutig_R_The%20tempotron_Nature%20Neuroscience.pdf\n11) Neftci EO, Mostafa H, Zenke F. Surrogate gradient learning in spiking neural networks: Bringing the power of gradient-based optimization to \nSNNs. IEEE Signal Processing Magazine. 2019. 36(6):51-63. https://ieeexplore.ieee.org/abstract/document/8891809\n12) https://www.intel.com/content/www/us/en/research/neuromorphic-computing.html\n13) https://neuronaldynamics.epfl.ch/online/Ch1.S3.html\n14) Kron G. Numerical solution of ordinary and partial differential equations by means of equivalent circuits. Journal of Applied Physics. 1945. \n16(3):172-86. https://aip.scitation.org/doi/abs/10.1063/1.1707568']","The foundational concept of spiking neural networks (SNNs) is that they mimic the way biological neurons communicate through spikes or quick electrical pulses. In SNNs, the 'input current' is integrated over time, and neurons emit spikes when a certain threshold is reached. This temporal aspect adds a new dimension to the computation, making it at least as complex as a perceptron.

In terms of encoding strategies, SNNs use various methods to encode information efficiently:

1. **Firing Rates**: Traditionally, each neuron is selective for a specific feature, and the firing rate (spikes per unit time) represents the strength of that feature. However, this method is considered inefficient and slow because it requires many spikes for good precision.

2. **Latency Coding**: This strategy encodes information based on the timing of spikes, which can be more efficient and faster than rate coding.

3. **Rank Order Coding**: This involves encoding information based on the order in which neurons fire, which can encode a significant amount of information with fewer spikes.

4. **Spatio-Temporal Codes**: These codes use both spatial and temporal dimensions to encode information, making the encoding faster and more spike-efficient.

Overall, SNNs aim to perform computations with fewer spikes, leading to more energy-efficient processing, which is particularly advantageous in neuromorphic computing.","Spiking neural networks use spikes to encode information, with foundational concepts including the work of McCulloch and Pitts on logical calculus of nervous activity, and later developments in spiking neuron models.",0.19642857141875,,0.9444444444444444,0.2,,0.9625211374740806
What is the project idea about government-developed OS software?,"['Carbon-free giants\r\n‚Ä¢ Google, Microsoft, Meta/Facebook want to be carbon free by 2030 \r\n‚Ä¢ Carbon free is different from carbon neutral \r\n‚Ä¢ Green IT experts are needed to meet these goals\r\n23\r\n\r\n\r\nRebound effect*\r\n‚Ä¢ Energy consumption decreases ‚Üì‚Üì but demand also increases ‚Üë‚Üë. \r\n‚Ä¢ *a.k.a. Jevons Paradox in economics; Downs‚ÄìThomson paradox in\xa0mobility.\r\nEnergy per prompt\r\nPrompts\r\n100\r\n80\r\n30\r\n38\r\nChat \r\nGPT\r\n‚ÄúEnergy-efficient‚Äù \r\nChat GPT\r\n0\r\n\r\nIs sustainability an\u2028\r\nethical issue?\r\n‚Ä¢ Climate change is more likely to affect the \r\npoorest countries. \r\n‚Ä¢ Less financial resources to adapt \r\n‚Ä¢ Climate-impact does not necessarily affect \r\npolluting countries. \r\n‚Ä¢ Poorest countries have contributed less to the \r\nclimate change. \r\n‚Ä¢ We need to figure out how to do more using \r\nless resources.\r\n26\r\n\r\nMorality ‚â† Moralising\r\n‚Ä¢ We should not use climate action as a \r\nshaming weapon \r\n‚Ä¢ Climate action should be agnostic of political \r\nviews, ideology, social status, etc. \r\n‚Ä¢ We need everyone to take action!\r\n27\r\n\r\nWhy?\r\n‚Ä¢ Throughout your career you might: \r\n‚Ä¢ Design/maintain/contract data centers \r\n‚Ä¢ Set up operations/devops \r\n‚Ä¢ Develop AI for IoT devices \r\n‚Ä¢ Be the next CEO/CTO of a software company \r\n‚Ä¢ Sustainability can be your main role: \r\n‚Ä¢ Green Software Developer \r\n‚Ä¢ Sustainability Consultant \r\n‚Ä¢ Green Advocate  \r\n‚Ä¢ Founder of a Green Tech startup (B2B?)\r\n28\r\n\r\nFormat of classes\r\n‚Ä¢ In-person. \r\n‚Ä¢ Collegerama recordings. \r\n‚Ä¢ Lectures and Labs. \r\n‚Ä¢ Guest lectures. \r\n‚Ä¢ Steering meetings (after week 5, new schedule)\r\n29\r\n\r\nFormat of classes\r\n‚Ä¢ There‚Äôs no exam in this course. It‚Äôs more important that we learn how to \r\ndiscuss this topic and come up with new ideas than learning all the theory. \r\nCritical thinking over checkboxes. \r\n‚Ä¢ Mix of content and discussion \r\n‚Ä¢ Ultimately, the lectures aim to give you food for thought and the necessary \r\nknowledge to excel in Project 2. (We will talk about it later)\r\n30\r\n\r\nhttps://luiscruz.github.io/course_sustainableSE/\r\n31\r\nContent of the course üëá\r\n\r\n32\r\nhttps://mattermost.tudelft.nl/signup_user_complete/?id=1nj9tk6usjf8xmsws8wpq3s5uy&md=link&sbr=su\r\n\r\nProject 1\r\n‚Ä¢ Goal: Measure the energy consumption of software applications. \r\n‚Ä¢ Approach: energy measurement tools; use case testing. \r\n‚Ä¢ Deliverable: blog-style report (approx. 2500 words) \r\n‚Ä¢ Deadline: Week 3, Feb 28, 2025 \r\n‚Ä¢ Group size: 4‚Äì5\r\n33\r\n\r\nProject 2\r\n‚Ä¢ Goal: Create a solution/tool/technique that helps building green software. (You \r\ncan come up with your own idea or choose one from a list of suggestions). \r\n‚Ä¢ Approach: open-source software development; literature review. \r\n‚Ä¢ Deliverable: library/tool/app; paper; presentation. \r\n‚Ä¢ Two deadlines:\u2028\r\n1. Paper and software: Week 8, April 4, 2025\u2028\r\n2. Presentation: Week 9, April 11, 2025 \r\n‚Ä¢ Group size: 4‚Äì5\r\n34\r\n\r\nGuest Lectures\r\nNergis T√∂men \r\nComputer Vision lab | TU Delft \r\nWeek 4, Wed, Mar 5, 2025\r\n35\r\n\r\nCommunity \r\nHow to get involved?', 'It‚Äôs more important that we learn how to \r\ndiscuss this topic and come up with new ideas than learning all the theory. \r\nCritical thinking over checkboxes. \r\n‚Ä¢ Mix of content and discussion \r\n‚Ä¢ Ultimately, the lectures aim to give you food for thought and the necessary \r\nknowledge to excel in Project 2. (We will talk about it later)\r\n30\r\n\r\nhttps://luiscruz.github.io/course_sustainableSE/\r\n31\r\nContent of the course üëá\r\n\r\n32\r\nhttps://mattermost.tudelft.nl/signup_user_complete/?id=1nj9tk6usjf8xmsws8wpq3s5uy&md=link&sbr=su\r\n\r\nProject 1\r\n‚Ä¢ Goal: Measure the energy consumption of software applications. \r\n‚Ä¢ Approach: energy measurement tools; use case testing. \r\n‚Ä¢ Deliverable: blog-style report (approx. 2500 words) \r\n‚Ä¢ Deadline: Week 3, Feb 28, 2025 \r\n‚Ä¢ Group size: 4‚Äì5\r\n33\r\n\r\nProject 2\r\n‚Ä¢ Goal: Create a solution/tool/technique that helps building green software. (You \r\ncan come up with your own idea or choose one from a list of suggestions). \r\n‚Ä¢ Approach: open-source software development; literature review. \r\n‚Ä¢ Deliverable: library/tool/app; paper; presentation. \r\n‚Ä¢ Two deadlines:\u2028\r\n1. Paper and software: Week 8, April 4, 2025\u2028\r\n2. Presentation: Week 9, April 11, 2025 \r\n‚Ä¢ Group size: 4‚Äì5\r\n34\r\n\r\nGuest Lectures\r\nNergis T√∂men \r\nComputer Vision lab | TU Delft \r\nWeek 4, Wed, Mar 5, 2025\r\n35\r\n\r\nCommunity \r\nHow to get involved?\r\n36\r\n\r\nGreen TU\r\n‚Ä¢ https://www.tudelft.nl/sustainability/get-\r\ninvolved/greentu \r\n‚Ä¢ Student organisation at the TU Delft devoted \r\nto stimulating sustainability in education, \r\nresearch, university operations and \r\ncommunity engagement.\r\n37\r\n\r\nClimateAction.tech\r\n‚Ä¢ Great community for outreach \r\n‚Ä¢ Based on Slack  \r\n‚Ä¢ Regular meetings, talks, social events \r\n‚Ä¢ You can join as a volunteer or simply to \r\nconnect to other techies \r\n‚Ä¢ Also good to for job hunting on green tech.\r\n38\r\n\r\nClimateAction.tech\r\n39\r\n\r\nBranch magazine\r\n‚Ä¢ Stay up-to-date on sustainable tech \r\n‚Ä¢ Creativity booster \r\n‚Ä¢ Carbon-aware UI \r\n‚Ä¢ https://branch.climateaction.tech üîó\r\n40\r\n\r\nThis is the fourth edition\r\n‚Ä¢ Any feedback is welcome! Email or DM!\r\n41\r\n\r\n42\r\n\r\nCarolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nLu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\n1. Intro Class\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl', 'Lu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\n10. Project 2\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nCarolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl\r\n\r\n1. Goal/assignment \r\n2. Deliverables \r\n3. Strategy \r\n4. Ideas\r\n\r\nAssignment\r\n‚Ä¢ Goal: Solve a Sustainable Software Engineering problem. \r\n‚Ä¢ Identify 1 problem that should be fixed to help enabling sustainability in \r\nthe software engineering industry/community. \r\n‚Ä¢ Propose a solution. A tool, framework, guidelines, etc. \r\n‚Ä¢ Implementation. \r\n‚Ä¢ Validation. (Depending on the idea) \r\n‚Ä¢ Dissemination/social impact. (Solution should be open source, welcome \r\ncontributors, post on social media? Tool website? Available in a package \r\nmanager?)\r\n3\r\n\r\nDeliverables\r\n‚Ä¢ Paper-like article. (Min 4 pages, max 10) \r\n‚Ä¢ Online git repo with open source codebase and/or replication package. \r\n‚Ä¢ Presentation: 5 min + 5min Q&A\r\n4\r\n\r\nArticle\r\n‚Ä¢ Different projects will have different expectations -> Make agreements with \r\nyour coach. \r\n‚Ä¢ Some projects are more technical and some projects more theoretical. \r\n‚Ä¢ Common requirements: \r\n‚Ä¢ Motivation, formulation of the problem being addressed, etc. \r\n‚Ä¢ Description of the solution. \r\n‚Ä¢ Validation of the solution (if applicable -> discuss with coach) \r\n‚Ä¢ Discussion of the solution. (Including limitations)\r\n5\r\n\r\nStrategy\r\n‚Ä¢ Starting next week, there are no lectures  \r\n‚Ä¢ Steering meetings from week 5 till week 9 (either online or in person).  \r\n‚Ä¢ 1 steering meeting per week. (4+1 sprints) \r\n‚Ä¢ Every week, you need to plan different tasks and assignments. \r\n‚Ä¢ Deadline April 4.\r\n6\r\n\r\nStrategy\r\n‚Ä¢ Week 0 \r\n‚Ä¢ Decide project idea (today) \r\n‚Ä¢ Define steering meeting schedule \r\n‚Ä¢ Create working document of the \r\narticle: Problem statement and solution \r\nproposal! \r\n‚Ä¢ Define and assign tasks for each week. \r\n‚Ä¢ Week 1 \r\n‚Ä¢ Implementation \r\n‚Ä¢ Agreements with supervisor. \r\n‚Ä¢ Week 2 \r\n‚Ä¢ Implementation \r\n‚Ä¢ Week 3 \r\n‚Ä¢ Implementation, Full draft of article, \r\ndissemination. \r\n‚Ä¢ Week 4 \r\n‚Ä¢ Final refinements \r\n‚Ä¢ Prepare presentation\r\n7\r\n\r\nProject ideas\r\n‚Ä¢ A1. Prototype cross-machine comparable benchmarks \r\n‚Ä¢ A2. Add energy metrics to LMstudio/Ollama \r\n‚Ä¢ A3. Visualizations built-in with EnergiBridge \r\n‚Ä¢ A4. Service-based version of EnergiBridge\r\n\r\nProject ideas\r\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \r\n‚Ä¢ B2. Study test generation energy consumption \r\n‚Ä¢ B3. Energy profiling of static analysis tools \r\n‚Ä¢ B4. Detailed energy profiling of build pipelines \r\n‚Ä¢ B5. Tool supporting SusAF workshop / process \r\n‚Ä¢ B6. Dataset of government-developed OS software \r\n‚Ä¢ B7. Queue - but better for the student / TA society\r\nQuality Assurance & Testing\r\nSocial & Individual \u2028\r\nSustainability\r\n\r\nProject ideas\r\n‚Ä¢ C1. Compare energy consumption of docker images for ML workloads. \r\n‚Ä¢ C2. Create a plugin to visualize Hugging Face carbon emissions in detail. \r\n‚Ä¢ C3. Plugin for ChatGPT (footprint per chat window) \r\n‚Ä¢ C4. NutriScore for software libraries. \r\n‚Ä¢ C5. Add energy-awareness to existing software \r\n‚Ä¢ C6. Green Shift Left \r\n‚Ä¢ C7. Education for Sustainable SE\r\n\r\nA1.', '‚Ä¢ Deadline April 4.\r\n6\r\n\r\nStrategy\r\n‚Ä¢ Week 0 \r\n‚Ä¢ Decide project idea (today) \r\n‚Ä¢ Define steering meeting schedule \r\n‚Ä¢ Create working document of the \r\narticle: Problem statement and solution \r\nproposal! \r\n‚Ä¢ Define and assign tasks for each week. \r\n‚Ä¢ Week 1 \r\n‚Ä¢ Implementation \r\n‚Ä¢ Agreements with supervisor. \r\n‚Ä¢ Week 2 \r\n‚Ä¢ Implementation \r\n‚Ä¢ Week 3 \r\n‚Ä¢ Implementation, Full draft of article, \r\ndissemination. \r\n‚Ä¢ Week 4 \r\n‚Ä¢ Final refinements \r\n‚Ä¢ Prepare presentation\r\n7\r\n\r\nProject ideas\r\n‚Ä¢ A1. Prototype cross-machine comparable benchmarks \r\n‚Ä¢ A2. Add energy metrics to LMstudio/Ollama \r\n‚Ä¢ A3. Visualizations built-in with EnergiBridge \r\n‚Ä¢ A4. Service-based version of EnergiBridge\r\n\r\nProject ideas\r\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \r\n‚Ä¢ B2. Study test generation energy consumption \r\n‚Ä¢ B3. Energy profiling of static analysis tools \r\n‚Ä¢ B4. Detailed energy profiling of build pipelines \r\n‚Ä¢ B5. Tool supporting SusAF workshop / process \r\n‚Ä¢ B6. Dataset of government-developed OS software \r\n‚Ä¢ B7. Queue - but better for the student / TA society\r\nQuality Assurance & Testing\r\nSocial & Individual \u2028\r\nSustainability\r\n\r\nProject ideas\r\n‚Ä¢ C1. Compare energy consumption of docker images for ML workloads. \r\n‚Ä¢ C2. Create a plugin to visualize Hugging Face carbon emissions in detail. \r\n‚Ä¢ C3. Plugin for ChatGPT (footprint per chat window) \r\n‚Ä¢ C4. NutriScore for software libraries. \r\n‚Ä¢ C5. Add energy-awareness to existing software \r\n‚Ä¢ C6. Green Shift Left \r\n‚Ä¢ C7. Education for Sustainable SE\r\n\r\nA1. Prototype cross-machine comparable benchmarks\r\n‚Ä¢ Energy-usage comparisons require running both baseline + software on the \r\nsame machine ‚Üí limits how extensive our experiments can be \r\n‚Ä¢ Research community is in need of benchmarks that make energy \r\nmeasurements comparable even if executed on different machines \r\n‚Ä¢ Focus on a single task or model (i.e. computing vision, classification)\r\n\r\nA2. Adding energy metrics to LMstudio/Ollama\r\n‚Ä¢ Make energy consumption visible to users \r\nwithin local chat-interface for LLMs \r\n‚Ä¢ LMstudio/Ollama are tools for easy \r\ndeployment of LLMs \r\n‚Ä¢ Do not show energy metrics \r\n‚Ä¢ Add energy metrics to LMstudio-python \r\nor Ollama\r\nhttps://lmstudio.ai/\r\n\r\nA3. Visualizations built-in with EnergiBridge\r\n‚Ä¢ EnergiBridge simplifies energy measurement, but analysis & visualization is \r\nstill left to the user \r\n‚Ä¢ Extend the tool with well-chosen visualizations and analyses directly from the \r\nprovided data\r\n\r\nA4. Service-based version of EnergiBridge\r\n‚Ä¢ Simplify interaction & setup with EnergiBridge \r\n‚Ä¢ Service that runs independently, start/stop signals over RPC to manage \r\nexperiments \r\n‚Ä¢ Potential: create EnergiBridge interface for other prog. lang\r\n\r\nB1. Measure energy consumption of single JUnit tests\r\n‚Ä¢ We‚Äôd like to identify energy anti patterns in unit tests \r\n‚Ä¢ As a first step, we need tooling to measure and compare the energy \r\nconsumption of single unit tests \r\n‚Ä¢ Ideally including preliminary analysis looking at potential reasons for high-\r\nenergy-consuming tests\r\n\r\nB2. Study test generation energy consumption\r\n‚Ä¢ Automatic test generation mainly focuses on making strong test suites \r\n‚Ä¢ Do different techniques and configurations impact the energy consumption \r\nduring generation? \r\n‚Ä¢ Preferably focus on non-LLM test generation methods (EvoSuite, Pyguin, \r\nDSpot)\r\n\r\nB3. Detailed energy profiling of build pipelines\r\n‚Ä¢ Automatic builds have become a cornerstone of quality assurance.', 'computing vision, classification)\r\n\r\nA2. Adding energy metrics to LMstudio/Ollama\r\n‚Ä¢ Make energy consumption visible to users \r\nwithin local chat-interface for LLMs \r\n‚Ä¢ LMstudio/Ollama are tools for easy \r\ndeployment of LLMs \r\n‚Ä¢ Do not show energy metrics \r\n‚Ä¢ Add energy metrics to LMstudio-python \r\nor Ollama\r\nhttps://lmstudio.ai/\r\n\r\nA3. Visualizations built-in with EnergiBridge\r\n‚Ä¢ EnergiBridge simplifies energy measurement, but analysis & visualization is \r\nstill left to the user \r\n‚Ä¢ Extend the tool with well-chosen visualizations and analyses directly from the \r\nprovided data\r\n\r\nA4. Service-based version of EnergiBridge\r\n‚Ä¢ Simplify interaction & setup with EnergiBridge \r\n‚Ä¢ Service that runs independently, start/stop signals over RPC to manage \r\nexperiments \r\n‚Ä¢ Potential: create EnergiBridge interface for other prog. lang\r\n\r\nB1. Measure energy consumption of single JUnit tests\r\n‚Ä¢ We‚Äôd like to identify energy anti patterns in unit tests \r\n‚Ä¢ As a first step, we need tooling to measure and compare the energy \r\nconsumption of single unit tests \r\n‚Ä¢ Ideally including preliminary analysis looking at potential reasons for high-\r\nenergy-consuming tests\r\n\r\nB2. Study test generation energy consumption\r\n‚Ä¢ Automatic test generation mainly focuses on making strong test suites \r\n‚Ä¢ Do different techniques and configurations impact the energy consumption \r\nduring generation? \r\n‚Ä¢ Preferably focus on non-LLM test generation methods (EvoSuite, Pyguin, \r\nDSpot)\r\n\r\nB3. Detailed energy profiling of build pipelines\r\n‚Ä¢ Automatic builds have become a cornerstone of quality assurance. But how \r\nmuch energy do they even consume? \r\n‚Ä¢ Create a tool that reports on the energy consumed during the (different stages \r\nof the) whole build (compile, build, test, package, ‚Ä¶) \r\n‚Ä¢ Should be integrated with build system(s), making setup for developers easy \r\n‚Ä¢ For local setup (to enable true energy measurements)\r\n\r\nB4. Energy profiling of static analysis tools\r\n‚Ä¢ What is the energy consumption of a ""typical run"" for a few OSS projects? \r\n‚Ä¢ Does the type of analysis matter? Are certain analysis more expensive? Does \r\nthe number of rules that are activated in a static analysis tool important for the \r\nenergy consumption? \r\n‚Ä¢ Differences between static analysis tools [lower priority]\r\n\r\nB5. Tool supporting SusAF workshop / process\r\n‚Ä¢ Lead engineers through process & questions \r\n‚Ä¢ Interface to create & document the two diagrams \r\n‚Ä¢ (!) Should be easy to start using & set up \r\n‚Ä¢ You may also create a simplified version / \u2028\r\nyour favorite sustainability framework\r\nEnvironmental\r\nEconomic\r\nTechnical\r\nIndividual\r\nSocial\r\nImmediate\r\nEnabling\r\nStructural\r\nAirbnb\r\ngreater \r\nearnings\r\nincrease \r\nin rents\r\ngentrification\r\ngreater racial \r\ndisparities\r\nrent \r\nrooms\r\n5\r\n1\r\n3\r\n4\r\n2\r\n \r\n \r\n \r\n \r\n \r\n \r\nVery \r\nunlikely \r\nVery \r\nlikely \r\n\r\nB6. Dataset of government-developed OS software\r\n‚Ä¢ Governments develop & use software for supporting society\u2028\r\nOpen-source development & policies are on the rise \r\n‚Ä¢ But studying government software is difficult b/c we don‚Äôt know what is out \r\nthere\u2028\r\n‚Üí Lack of incentive to make popular \u2028\r\n‚Üí Language barriers \r\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \r\nbuildable?, open dev. history?, requirements documentation? \r\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!\r\n\r\nB7. Queue - but better for the student / TA society\r\n‚Ä¢ Requirements analysis regarding social and individual sustainability effects \r\nof Queue \r\n‚Ä¢ Other EIP / TUD used software also possible: e.g., Answers EWI \r\n‚Ä¢ Non-technical project ‚Üí proper process (workshops?', 'Energy profiling of static analysis tools\r\n‚Ä¢ What is the energy consumption of a ""typical run"" for a few OSS projects? \r\n‚Ä¢ Does the type of analysis matter? Are certain analysis more expensive? Does \r\nthe number of rules that are activated in a static analysis tool important for the \r\nenergy consumption? \r\n‚Ä¢ Differences between static analysis tools [lower priority]\r\n\r\nB5. Tool supporting SusAF workshop / process\r\n‚Ä¢ Lead engineers through process & questions \r\n‚Ä¢ Interface to create & document the two diagrams \r\n‚Ä¢ (!) Should be easy to start using & set up \r\n‚Ä¢ You may also create a simplified version / \u2028\r\nyour favorite sustainability framework\r\nEnvironmental\r\nEconomic\r\nTechnical\r\nIndividual\r\nSocial\r\nImmediate\r\nEnabling\r\nStructural\r\nAirbnb\r\ngreater \r\nearnings\r\nincrease \r\nin rents\r\ngentrification\r\ngreater racial \r\ndisparities\r\nrent \r\nrooms\r\n5\r\n1\r\n3\r\n4\r\n2\r\n \r\n \r\n \r\n \r\n \r\n \r\nVery \r\nunlikely \r\nVery \r\nlikely \r\n\r\nB6. Dataset of government-developed OS software\r\n‚Ä¢ Governments develop & use software for supporting society\u2028\r\nOpen-source development & policies are on the rise \r\n‚Ä¢ But studying government software is difficult b/c we don‚Äôt know what is out \r\nthere\u2028\r\n‚Üí Lack of incentive to make popular \u2028\r\n‚Üí Language barriers \r\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \r\nbuildable?, open dev. history?, requirements documentation? \r\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!\r\n\r\nB7. Queue - but better for the student / TA society\r\n‚Ä¢ Requirements analysis regarding social and individual sustainability effects \r\nof Queue \r\n‚Ä¢ Other EIP / TUD used software also possible: e.g., Answers EWI \r\n‚Ä¢ Non-technical project ‚Üí proper process (workshops? Interviews?) & rich \r\ndescription of outcomes focus of grading\r\nhttps://eip.pages.ewi.tudelft.nl/eip-website/queue.html\r\n\r\nC1. Compare energy consumption of docker images for \r\nML workloads.\r\n‚Ä¢ Similar to what we have seen in the lectures but for ML-specific workloads. \r\n‚Ä¢ We can reuse existing experiment replication packages.\r\n22\r\n\r\nC2. Plugin to visualize Hugging Face carbon emissions.\r\n‚Ä¢ https://huggingface.co/blog/leaderboard-emissions-\r\nanalysis \r\n‚Ä¢\r\nYoo, Taewon, et al. ""Visualizing the Carbon Intensity of Machine Learning Inference for Image Analysis on TensorFlow Hub.""\r\n\r\nC3. Plugin for ChatGPT\r\n‚Ä¢ Users seldom know how much carbon they are emitting when they interact \r\nwith chat GPT. \r\n‚Ä¢ Let‚Äôs make it transparent to the users. Browser plugin?\r\n24\r\nCO2\r\n\r\nC4. NutriScore for software libraries\r\n25\r\n‚Ä¢ NutriScore labels are not perfect but they are a good starting point! \r\n‚Ä¢ What if we could do the same thing for the energy efficiency of software. \r\n‚Ä¢ (Also open to individual or social sustainability) \r\n‚Ä¢ This work can be scoped in particular domains/ecossystems/use cases. \r\n‚Ä¢ Libraries for stats? ML? Web Dev? Cloud?\r\n\r\nC5. Add energy-awareness to existing software\r\n26\r\n‚Ä¢ Streamlit, Notebooks, JSFiddle, \r\nPyScript, zsh, etc. \r\n‚Ä¢\r\n\r\nC6 - Green Shift Left\r\n‚Ä¢ Estimate energy efficiency using static code analysis. \r\n‚Ä¢ We don‚Äôt need an accurate value. \r\n‚Ä¢ It is useful to know which code is more likely to \r\nintroduce energy hotspots and that should be \r\nreviewed with more attention. \r\n‚Ä¢ Can be scoped to a particular domain (react, php, data \r\nscience, web, etc., etc.)', 'Interviews?) & rich \r\ndescription of outcomes focus of grading\r\nhttps://eip.pages.ewi.tudelft.nl/eip-website/queue.html\r\n\r\nC1. Compare energy consumption of docker images for \r\nML workloads.\r\n‚Ä¢ Similar to what we have seen in the lectures but for ML-specific workloads. \r\n‚Ä¢ We can reuse existing experiment replication packages.\r\n22\r\n\r\nC2. Plugin to visualize Hugging Face carbon emissions.\r\n‚Ä¢ https://huggingface.co/blog/leaderboard-emissions-\r\nanalysis \r\n‚Ä¢\r\nYoo, Taewon, et al. ""Visualizing the Carbon Intensity of Machine Learning Inference for Image Analysis on TensorFlow Hub.""\r\n\r\nC3. Plugin for ChatGPT\r\n‚Ä¢ Users seldom know how much carbon they are emitting when they interact \r\nwith chat GPT. \r\n‚Ä¢ Let‚Äôs make it transparent to the users. Browser plugin?\r\n24\r\nCO2\r\n\r\nC4. NutriScore for software libraries\r\n25\r\n‚Ä¢ NutriScore labels are not perfect but they are a good starting point! \r\n‚Ä¢ What if we could do the same thing for the energy efficiency of software. \r\n‚Ä¢ (Also open to individual or social sustainability) \r\n‚Ä¢ This work can be scoped in particular domains/ecossystems/use cases. \r\n‚Ä¢ Libraries for stats? ML? Web Dev? Cloud?\r\n\r\nC5. Add energy-awareness to existing software\r\n26\r\n‚Ä¢ Streamlit, Notebooks, JSFiddle, \r\nPyScript, zsh, etc. \r\n‚Ä¢\r\n\r\nC6 - Green Shift Left\r\n‚Ä¢ Estimate energy efficiency using static code analysis. \r\n‚Ä¢ We don‚Äôt need an accurate value. \r\n‚Ä¢ It is useful to know which code is more likely to \r\nintroduce energy hotspots and that should be \r\nreviewed with more attention. \r\n‚Ä¢ Can be scoped to a particular domain (react, php, data \r\nscience, web, etc., etc.)\r\n27\r\n\r\nC7 - Education\r\n‚Ä¢ Educational game for Software \r\nSustainability practices \r\n‚Ä¢ Purpose: use within software teams to \r\ndiscuss or learn about different sustainable \r\nIT practices: at the organisation level, \r\nsoftware, etc.\r\n28\r\nhttps://github.com/OttoKaaij/Ticket-To-Sustainability/?tab=readme-ov-file\r\n\r\nProject ideas (old)\r\n‚Ä¢ Plugin from EnergiBridge (GUI, report generator, python library, etc.) \r\n‚Ä¢ Plugin for ChatGPT (carbon emissions per chat window) \r\n‚Ä¢ Seamless measurements for AI libraries \r\n‚Ä¢ Energy patterns for Green AI \r\n‚Ä¢ Sustainable SW dev gamification \r\n‚Ä¢ Sustainability auditor for AI projects \r\n‚Ä¢ Energy Profiling of screen colour filter tools (or display settings) \r\n‚Ä¢ ‚Ä¶ you can also propose yours!\r\n\r\nhttps://edu.nl/64gpk\r\nedu.nl/64gpk', 'google.com/view/energy-efficiency-languages\r\n21\r\nAna Radovanovic ÃÅ, Ross Koningstein, Ian Schneider, Bokan \r\nChen, Alexandre Duarte, Binz Roy, Diyue Xiao, Maya \r\nHaridasan, Patrick Hung, Nick Care, Saurav Talukdar, Eric \r\nMullen, Kendal Smith, MariEllen Cottman, and Walfredo Cirne \r\n\r\n\r\n‚Ä¢ Google‚Äôs Carbon-Intelligent Computing System (CICS) \r\n‚Ä¢ Main idea: use carbon-intensity data to shift datacenter jobs in time \r\n‚Ä¢ Typically, job schedulers use a metric of cluster capacity to schedule a job in \r\na particular cluster. \r\n‚Ä¢ CICS overrides this metric with the virtual capacity curve (VCC) that \r\nfactors in Carbon intensity \r\n‚Ä¢ When a new job comes in, the scheduler estimates its CPU load and power \r\nusage and assigns it to a cluster if the VCC is not exceeded.\r\n23\r\n\r\n‚Ä¢ Jobs are divided between flexible and inflexible. \r\n‚Ä¢ Flexible load is considered shapeable/shiftable as long as its total daily \r\ncompute (CPU) demand is preserved \r\n‚Ä¢ The system needs to consider that, while running a job, the virtual capacity \r\ncurve (VCC) might drop. Hence, this job should not start in the first place. \r\n‚Ä¢ They forecast VCC for the next day\r\n24\r\n\r\n\r\nVirtual Cluster Capacity (VCC)\r\n‚Ä¢ Aims at reducing the peak load at carbon intensive hours but in total it should allow for the \r\nsome amount of daily computation! \r\n‚Ä¢ Considers Carbon intensity \r\n‚Ä¢ Using data from electricityMap.org \r\n‚Ä¢ It does not use carbon intensity directly.\u2028\r\nCarbon intensity is converted to a cost (kgCO2 -> $$) \r\n‚Ä¢ This way, they can factor in other metrics that can also be converted to money. E.g., the \r\ncost saved by preventing peak load \r\n‚Ä¢ Peak workload entails extra cost at the infrastructure level (e.g., control faclities‚Äô \r\ntemperature). \r\n‚Ä¢ By using money cost instead of carbon cost, they have more data available.\r\n26\r\n\r\nVirtual Cluster Capacity (VCC)\r\n‚Ä¢ If the forecast of VCC fails it shift flexible workload more than expected.  \r\n‚Ä¢ This happens because the amount of workload forecasted was below the \r\nworkload needed, and VCC was ‚Äúaggressively‚Äù low. \r\n‚Ä¢ The systems fall back to the real cluster capacity for 1 week until results \r\nstart being realistic again.\r\n27\r\n\r\nNext steps\r\n‚Ä¢ They will consider spatial flexibility. \r\n‚Ä¢ I.e., tasks that can be shifted over time and over space. \r\n‚Ä¢ It needs to factor in relocation overheads, though.\r\n28\r\n\r\nCritical questions\r\n‚Ä¢ Who defines what is flexible and inflexible? \r\n‚Ä¢ How do you estimate the CPU load of a given task?\r\n29\r\n\r\nEnergy Regression Testing\r\n‚ÜíEnergy?\r\nGreener? Greener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\n\r\nE-compare\r\nGithub Actions\r\n‚ûú https://koenhagen.github.io/E-Compare/\r\n\r\nEnergy Regression Testing \r\n\r\n4. Debugging Energy with \r\nDocker Images\r\n\r\nUnveiling the Energy Vampires \r\nA methodology for debugging Software \r\nEnergy Consumption\r\n ‚úÖ ICSE 2025\r\n\r\nData Centers and Docker\r\n‚Ä¢ Containers are the most popular way to deploy apps into the cloud \r\n‚Ä¢ Base image is an important choice when building an image \r\n‚Ä¢ Criteria \r\n‚Ä¢ Linux distribution and binaries \r\n‚Ä¢ Image size \r\n‚Ä¢ Energy?\r\n35\r\n\r\nRedis energy consumption\r\n‚Ä¢ Ubuntu/Alpine base images have different energy consumption for Redis\r\n36\r\n\r\nRedis Energy Consumption\r\n‚Ä¢RQ1: What is the difference \r\nin energy consumption \r\nbetween glibc and musl? \r\n‚Ä¢RQ2: Can we use tracing \r\nto compare energy \r\nconsumption in shared \r\nlibraries?', '‚Ä¢ Collect the energy data of using Coral BodyPix for 30 seconds.\u2028\r\nhttps://storage.googleapis.com/tfjs-models/demos/body-pix/index.html \r\n‚Ä¢ Report the total energy consumption. \r\n‚Ä¢ Extra-mile: \r\n‚Ä¢ Compare the energy consumption in different browsers. \r\n‚Ä¢ Check the spikes and drops in Power and Temperature.\r\n20\r\n\r\nRetrospection\r\nHands-on 1\r\n‚Ä¢ Are the measurements repeatable? \r\n‚Ä¢ What were the confounding factors? \r\n‚Ä¢ How can we automate this process?\r\n21\r\n\r\nEnergy testing\r\n(Different from energy monitoring)\r\n1. Create a reproducible scenario of the execution of your software. Preferably \r\nthis should be an automated script ‚Äì e.g., using a bash or python script. \r\n2. Execute the scenario in a version of your software. Use the energy profiler to \r\nmeasure the energy consumption. \r\n3. Improve your software in parts of the code that you suspect have low \r\nperformance. \r\n4. Execute the same scenario with the new version. Compare the energy data \r\nin this version with the previous one.\u2028\r\nEnergy is lower, test passes; energy is higher test fails.\r\n22\r\n\r\nHands-on 2\r\n‚Ä¢ Create a reproducible scenario. (Usually easier with command-line interfaces) \r\n‚Ä¢ Automatically start/stop energy profiling.\r\n23\r\n\r\nProject 1\r\n‚Ä¢ Deadline: March 1 \r\n‚Ä¢  Compare energy consumption in common software use cases. \r\n‚Ä¢ Examples: \r\n‚Ä¢ Different versions of the same app; \r\n‚Ä¢ Same use case but different apps \r\n‚Ä¢ Same version, same app, but different user settings (e.g., enable/disable GPU optimisation) \r\n‚Ä¢ Same version, same app, but different running environment \r\n‚Ä¢ Submission via PR (markdown). \r\n‚Ä¢ Blog-style report (markdown, approx 2500 words). \r\n‚Ä¢ Replication package. \r\n‚Ä¢ Points if the experiment is automated.\r\n24\r\n\r\nGroup registration\r\n‚Ä¢ Brightspace > Collaboration > Groups and sign up for one of the groups \r\nunder ""Project Groups (P1 and P2)""  \r\n‚Ä¢ If you are looking for a group or teamembers, use the mattermost channel \r\n‚Äú~Searching-group-members‚Äù. \r\n‚Ä¢ The deadline for self-registering as a group is end of this week, so by Sunday, \r\n16th of February, 23:59. \r\n‚Ä¢ We might do final adjustments afterwards.\r\n25\r\n\r\n26\r\nKay Singh. Apple Silicon M1 Power Consumption Deep Dive Part 1: Safari vs Chrome\u2028\r\nhttps://singhkays.com/blog/apple-silicon-m1-video-power-consumption-pt-1/\r\n(For project 1, you don‚Äôt need to dive deep into hardware details)\r\n\r\n27', '‚Ä¢ Improve parameter-tuning strategy.\r\n11\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ We need benchmarks. \r\n‚Ä¢ AllenAI leaderboard\u2028\r\nhttps://leaderboard.allenai.org \r\n‚Ä¢ No carbon metrics, yet \r\n‚Ä¢ Report comparable proxies for energy \r\nconsumption. \r\n‚Ä¢ ‚ö† Learning algorithms behave in a non-\r\ndeterministic \r\n‚Ä¢ ‚ö† Different data-points lead to different \r\nenergy consumption\r\n12\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ Reporting measured energy consumption \r\n‚Ä¢ + Accurate \r\n‚Ä¢ + Easy to map to carbon emissions \r\n‚Ä¢ - Hard to measure \r\n‚Ä¢ - Low replicability \r\n‚Ä¢ Reporting time / estimation based on time & hardware \r\n‚Ä¢ + Easy to measure \r\n‚Ä¢ + Correlates with energy consumption in most cases. \r\n‚Ä¢ -  Difficult to compare with measurements from other setups \r\n‚Ä¢ E.g., floating point operations (FPOs) (?) \r\n‚Ä¢ + comparable across different setups \r\n‚Ä¢ + cheap \r\n‚Ä¢ - does not factor in memory energy consumption \r\n‚Ä¢ - does not reflect carbon emissions\r\n13\r\n\r\nData-centric AI\r\n\r\nData-centric AI\r\n‚Ä¢ Emerging discipline that deals with systematically engineering data to build AI \r\nsystems. \r\n‚Ä¢ Shift from improving the training strategy to improving the data. \r\n‚Ä¢ It is better to have small but reliable datasets than large but noisy \r\ndatasets. \r\n‚Ä¢ => Improve data collection, data labelling, and data preprocessing. \r\n‚Ä¢ More about data-centric AI by Andrew Ng:\u2028\r\nhttps://www.youtube.com/watch?v=06-AZXmwHjo\r\n15\r\n\r\n\r\nGreen Data-centric AI\r\n‚Ä¢ How do different ML algorithms compare \r\nin terms of energy consumption? \r\n‚Ä¢ How does number of rows relate to the \r\nenergy consumption of ML models? \r\n‚Ä¢ How does number of features relate to \r\nthe energy consumption of ML models? \r\n‚Ä¢ What is the impact of reducing data in the \r\nperformance of the model? \r\n‚Ä¢ Method -> results -> discussion\r\n17\r\n\r\nMethod\r\n‚Ä¢ Single object of study: natural language model to detect spam messages. \r\n‚Ä¢ 6 machine learning algorithms: SVM, Decision Tree, KNN, Random Forrest, \r\nAdaBoost, Bagging Classifier. \r\n‚Ä¢ Reduce the number of rows. 10%, 20%, .., 100% \r\n‚Ä¢ Stratified random sampling (?) \r\n‚Ä¢ Reduce the number of features. 10%, 20%, .., 100% \r\n‚Ä¢ Feature importance metric based on the Chi-Square Test (Chi2) \r\n‚Ä¢ Estimate energy consumption using a RAPL-based tool. (?)\r\n18\r\n\r\n‚Ä¢ Repeat 30 times \r\n‚Ä¢ Fix random seeds \r\n‚Ä¢ ‚Ä¶ \r\n‚Ä¢ Data was not Normal => tailed Normal distribution.\r\n19\r\n(?)\r\n\r\nResults: energy consumption of algorithms\r\n\r\nResults: energy vs data shape\r\n\r\nResults: performance vs data shape\r\n\r\nDiscussion\r\n‚Ä¢ Other data properties should be investigated. \r\n‚Ä¢ E.g., data types \r\n‚Ä¢ Reporting energy data is essential. It can lead to different model selection \r\nwithout hindering model performance. \r\n‚Ä¢ There is a big opportunity in Model and Data Simplification.\r\n23\r\n\r\nData/Model Simplification\r\n‚Ä¢ (?) \r\n‚Ä¢ Data selection \r\n‚Ä¢ Data quantisation. Posit? \r\n‚Ä¢ Data distillation \r\n‚Ä¢ Coreset extraction (?) \r\n‚Ä¢ Model distillation \r\n‚Ä¢ Model quantisation \r\n‚Ä¢ Model pruning \r\n‚Ä¢ ‚Ä¶\r\n24\r\n\r\nPosit vs Float\r\nMore about this: https://spectrum.ieee.org/floating-point-numbers-posits-processor\r\nBetter for DL use cases\r\n\r\nHow can we tune \r\nlearning \r\nparameters \r\nefficiently?\r\n\r\nHyper parameter tuning\r\n‚Ä¢ When training an ML model, there are several parameters that need to be \r\ntuned. \r\n‚Ä¢ E.g., in SVM we have the Regularization parameter C, the kernel function, \r\nthe degree of the kernel function, and depending on the case, many other. \r\n‚Ä¢ The common approach revolves around grid search.', 'Lu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\n7. Green SE ‚Äì Research\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nCarolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl\r\n\r\n1. Energy patterns for mobile apps \r\n2. Carbon-aware datacenters \r\n3. Energy Regression Testing \r\n4. Debugging Energy with Docker images \r\n5. Energy Efficiency vs Code Quality \r\n\r\n‚Ä¢ While learning about these works, try to be critical about them and find their \r\npitfalls.\r\n3\r\n\r\n‚Ä¢ We have seen that measuring energy consumption is not trivial \r\n‚Ä¢ It is not practical considering that developers have other priorities above \r\nenergy efficiency \r\n‚Ä¢ At the same time, every now and then there are some efforts to improve \r\nenergy efficiency in some cases. This is time consuming and requires \r\nexpertise. \r\n‚Ä¢ How can we reuse these efforts?\r\n4\r\n\r\nEnergy Patterns for Mobile \r\nApps\r\nhttps://tqrg.github.io/energy-patterns/\r\n\r\nMethodology\r\n5. Catalog of Energy Patterns\r\n22 \r\npatterns\r\nF-droid\r\nCurated Lists\r\n1. App Collection\r\n1783 \r\napps\r\n3. Manual Refinement of Subjects of \r\nInterest\r\n1563 \r\nchanges\r\n4. Thematic Analysis\r\n431 \r\nreusable \r\nchanges\r\n2. Collect Changes With Potential Interest\r\n/.*(energy|power|battery).*/\r\n6028 \r\nchanges\r\n\r\nThematic Analysis\r\n1. Familiarization with data \r\n2. Generating initial labels \r\n3. Reviewing themes\r\n4. Defining and naming themes\r\n\r\n‚Ä¢ Energy Pattern: design pattern to improve energy efficiency.. \r\n‚Ä¢ 22 energy patterns. \r\n‚Ä¢ Each pattern is described by Context, Solution, Example, References from \r\nliterature, and Occurences (links to code changes from git repositories).\r\n8\r\n\r\nhttps://tqrg.github.io/energy-patterns\r\n\r\nDark UI Colors \r\nProvide a dark UI color theme to \r\nsave battery on devices with \r\nAMOLED screens.\r\n‚Ä¢ Context: [‚Ä¶] Apps that require heavy usage of screen can \r\nhave a substantial negative impact on battery life. \r\n‚Ä¢ Solution: Provide a UI theme with dark background colors. [‚Ä¶]\r\n‚Ä¢ Example: In a reading app, provide a theme with a dark \r\nbackground using light colors to display text. [‚Ä¶] \r\n10\r\n\r\nDark UI Colors \r\nProvide a dark UI color theme to \r\nsave battery on devices with \r\nAMOLED screens.\r\n‚Ä¢ Context: [‚Ä¶] Apps that require heavy usage of screen can \r\nhave a substantial negative impact on battery life. \r\n‚Ä¢ Solution: Provide a UI theme with dark background colors. [‚Ä¶]\r\n‚Ä¢ Example: In a reading app, provide a theme with a dark \r\nbackground using light colors to display text. [‚Ä¶] \r\n11\r\n\r\nDynamic Retry Delay\r\n‚Ä¢ Context: [‚Ä¶] In a mobile app, when a given resource is \r\nunavailable, the app will unnecessarily try to connect the resource \r\nfor a number of times, leading to unnecessary power consumption. \r\n‚Ä¢ Solution: Increase retry interval after each failed connection. [‚Ä¶]\r\n‚Ä¢ Example: Consider a mobile app that provides a news feed and \r\nthe app is not able to reach the server to collect updates. [‚Ä¶] use \r\nthe Fibonacci series to increase the time between attempts.\r\nWhenever an attempt to access a \r\nresource fails, increase the time \r\ninterval before retrying.\r\n12\r\n\r\nBatch Operations \r\n‚Ä¢ Context: Executing operations separately leads to extraneous \r\ntail energy consumptions  \r\n‚Ä¢ Solution: Bundle multiple operations in a single one. [‚Ä¶]\r\n‚Ä¢ Example: Use system provided APIs to schedule background \r\ntasks. These APIs, guarantee that device will exit sleep mode \r\nonly when there is a reasonable amount of work to do or when a \r\ngiven task is urgent.', 'Different \r\nscreen brightness, different results. \r\n‚Ä¢ You need to reduce tasks to the bare minimum: \r\n‚Ä¢ Set brightness to a fixed value; turn off notifications, kill all user-owned \r\nprocesses, turn off cellular data, bluetooth, location services, account \r\nsyncs; uninstall all unnecessary apps, etc.\r\n11\r\n\r\nWhen it comes to desktop/cloud software, the sources \r\nof noise are different but the same concerns apply. \r\n \r\nEach case is different ‚Äì think it through!\r\n‚ö†\r\n\r\nEnergy Profilers\r\n‚Ä¢ Simple setup! Quite reliable (if you choose the profiler wisely). \r\n‚Ä¢ Recently, they are starting to rely on internal power sensors. \r\n‚Ä¢ Still sensitive to noise from concurrent processes/tasks! ‚ö†\r\n13\r\n\r\nExamples of Energy Profilers\r\n\r\n15\r\nhttps://www.websitecarbon.com\r\n\r\n16\r\nhttps://mlco2.github.io/impact/\r\n\r\nIntel Power Monitor\r\n‚Ä¢ Install: https://software.intel.com/content/www/us/en/\r\ndevelop/articles/intel-power-gadget.html \r\n‚Ä¢ To collect: Logging > Log to File \r\n \r\n‚Ä¢ It will store a CSV file with all the collected power data. \r\n(File location is specified in the settings) \r\n‚Ä¢ Based on Intel RAPL. Works with Intel-based Windows \r\nand Macs. \r\n‚Ä¢ Alternative-twin for M1-based Macs: Mx Power Gadget.\u2028\r\nhttps://www.seense.com/menubarstats/mxpg/\r\n17\r\n‚ö† No longer supported by Intel ‚ö†  \r\n\r\n18\r\nüîó https://luiscruz.github.io/\r\n2021/07/20/measuring-energy.html\r\n(Missing Apple m1 tools: mxpg, powermetrics)\r\n\r\n19\r\nEnergiBridge\r\nhttps://github.com/tdurieux/energibridge\r\n> target/release/energibridge -o results.csv --summary sleep 10\r\n\r\nHands-on 1\r\n‚Ä¢ Install your energy profiler (EnergiBridge). \r\n‚Ä¢ Collect the energy data of using Coral BodyPix for 30 seconds.\u2028\r\nhttps://storage.googleapis.com/tfjs-models/demos/body-pix/index.html \r\n‚Ä¢ Report the total energy consumption. \r\n‚Ä¢ Extra-mile: \r\n‚Ä¢ Compare the energy consumption in different browsers. \r\n‚Ä¢ Check the spikes and drops in Power and Temperature.\r\n20\r\n\r\nRetrospection\r\nHands-on 1\r\n‚Ä¢ Are the measurements repeatable? \r\n‚Ä¢ What were the confounding factors? \r\n‚Ä¢ How can we automate this process?\r\n21\r\n\r\nEnergy testing\r\n(Different from energy monitoring)\r\n1. Create a reproducible scenario of the execution of your software. Preferably \r\nthis should be an automated script ‚Äì e.g., using a bash or python script. \r\n2. Execute the scenario in a version of your software. Use the energy profiler to \r\nmeasure the energy consumption. \r\n3. Improve your software in parts of the code that you suspect have low \r\nperformance. \r\n4. Execute the same scenario with the new version. Compare the energy data \r\nin this version with the previous one.\u2028\r\nEnergy is lower, test passes; energy is higher test fails.\r\n22\r\n\r\nHands-on 2\r\n‚Ä¢ Create a reproducible scenario. (Usually easier with command-line interfaces) \r\n‚Ä¢ Automatically start/stop energy profiling.\r\n23\r\n\r\nProject 1\r\n‚Ä¢ Deadline: March 1 \r\n‚Ä¢  Compare energy consumption in common software use cases. \r\n‚Ä¢ Examples: \r\n‚Ä¢ Different versions of the same app; \r\n‚Ä¢ Same use case but different apps \r\n‚Ä¢ Same version, same app, but different user settings (e.g., enable/disable GPU optimisation) \r\n‚Ä¢ Same version, same app, but different running environment \r\n‚Ä¢ Submission via PR (markdown). \r\n‚Ä¢ Blog-style report (markdown, approx 2500 words). \r\n‚Ä¢ Replication package. \r\n‚Ä¢ Points if the experiment is automated.', '‚Ä¢ Examples: \r\n‚Ä¢ Technical Debt \r\n‚Ä¢ Does it scale? \r\n‚Ä¢ Software testing \r\n‚Ä¢ Bus-factor \r\n‚Ä¢ Data integrity \r\n‚Ä¢ Innovation \r\n‚Ä¢ ‚Ä¶\r\n10\r\n\r\nIndividual\r\n‚Ä¢ Well-being of the individuals in an organisation.\u2028\r\nNote that it also includes how well individuals interact \r\nwith each other within the org. \r\n‚Ä¢ Examples: \r\n‚Ä¢ mental and physical well-being \r\n‚Ä¢ self-respect \r\n‚Ä¢ education/skills \r\n‚Ä¢ career development \r\n‚Ä¢ ‚Ä¶\r\n11\r\n\r\nSocial\r\n‚Ä¢ concerned with societal communities (groups of people, \r\norganisations) and the factors that erode trust in society. \r\n‚Ä¢ Examples: \r\n‚Ä¢ Social equity \r\n‚Ä¢ Justice \r\n‚Ä¢ Employment \r\n‚Ä¢ Democracy \r\n‚Ä¢ ‚Ä¶ \r\n‚Ä¢ Also includes compliance with policies and regulations \r\n12\r\n\r\nEnvironmental Sustainability\r\n‚Ä¢ the branch of Software Engineering that studies \r\nthe development of software that has minimal \r\nimpact in our planet throughout its whole \r\nlifecycle. \r\n‚Ä¢ Looking at software at different levels: \r\n‚Ä¢ Developing, Using, Serving, ‚Ä¶ \r\n‚Ä¢ Also includes e-waste. \r\n‚Ä¢ Almost identical to Green Software. (?)\r\n13\r\nBordallo II\r\n\r\nGreen Software\r\n‚Ä¢ Sustainability and energy efficiency. \r\n‚Ä¢ Building energy-efficient software is important also from a \r\ntechnical sustainability POV. \r\n‚Ä¢ Smartphones, smart wearables, IoT devices, etc. run on limited \r\npower resources. \r\n‚Ä¢ Developing software to these devices require energy-efficiency \r\ntesting and improvement. \r\n‚Ä¢ It also leads to environmental sustainability (e.g., less battery \r\ncycles) \r\n‚Ä¢ Important for UX (e.g., no need to walk around with power banks)\r\n14\r\n\r\nhttps://www.menti.com/uns9d89kzn\r\nWhat is the sustainability \r\ndimension you are most \r\ninterested in?\r\n?\r\n15\r\n\r\nEconomical sustainability tops the environment\r\n‚Ä¢ In general, a software project will not survive if it‚Äôs not economical \r\nsustainable \r\n‚Ä¢ Yet, a project can survive even if it is not environmental sustainable \r\n‚Ä¢ The mindset is changing! \r\n‚Ä¢ Software consumers have started to worry about the climate impact \r\nof their behaviour as users. \r\n‚Ä¢ Being environmentally sustainable is now an important competitive \r\nfactor \r\n‚Ä¢ Marketing teams are already using all eco-friendly labels. Technical \r\nteams are not there yet, though. \r\n‚Ä¢ It‚Äôs easier said than done!\r\n$\r\n16\r\n\r\nGreen Washing\r\n‚Ä¢ Deceptively use marketing techniques to \r\nclaim being eco-friendly. \r\n‚Ä¢ Opting for green-coloured designs. \r\n‚Ä¢ Red/orange is usually perceived as \r\ntasty. \r\n‚Ä¢ Green is perceived as eco-friendly. \r\n‚Ä¢ The VW case. (?)\r\n17\r\n\r\nThe VW scandal\r\nGreenwashing\r\n‚Ä¢ Used software to cheat on vehicle emissions \r\ntests. \r\n‚Ä¢ The vehicle‚Äôs software could detect whether they \r\nwere being tested, changing the performance \r\naccordingly to improve results. \r\n‚Ä¢ Affected 11M cars worldwide, 8M in Europe.\r\n18\r\n\r\nHow can we drive sustainability \r\nin the SE industry?\r\n\r\nGreen Procurement\r\n‚Ä¢ Customers decide on providers that share their values \r\n‚Ä¢ This is currently the main trigger reason why organisations \r\nworry about Sustainability and Green Software. \r\n‚Ä¢ Examples of green procurement: \r\n‚Ä¢ Customers that only buy green services/products \r\n‚Ä¢ Companies that only use green providers \r\n‚Ä¢ Developers that only work for green companies \r\n‚Ä¢ Green procurement makes environmental sustainability \r\nessential for economical sustainability.\r\n20\r\n\r\nSustainability via compliance\r\n‚Ä¢ EU wants to be carbon neutral by 2030 \r\n‚Ä¢ This also affects the ICT sector. Estimated to impact \r\n14% of the global carbon footprint by 2040. \r\n‚Ä¢ Some initiatives are already being negotiated. \r\n‚Ä¢ Extending the smartphone lifetime to 7 years. \r\n‚Ä¢ Right-to-repair movement. https://repair.eu \r\n‚Ä¢ Making IT services relying on clean energy more \r\naccessible (e.g., less taxes).\r\n21\r\n\r\nSoftware for Sustainability \r\n‚Ä¢ We are not covering it in this course.', 'Carolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nLu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\n1. Intro Class\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl\r\n\r\n1. Intro to Sustainable SE \r\n2. Intro to the course\r\n2\r\n\r\nof the electricity consumed worldwide \r\nby 2040 will stem from ICT\r\n14%\r\n\r\n4\r\nhttps://xkcd.com/1007/\r\n\r\nBuzz words\r\n‚Ä¢ Eco-friendly \r\n‚Ä¢ Climate change, action, adaption \r\n‚Ä¢ Energy efficiency \r\n‚Ä¢ Environmental-responsible \r\n‚Ä¢ Carbon-neutral; Climate-neutral; Net zero \r\n‚Ä¢ Carbon-offsetting \r\n‚Ä¢ Carbon-free \r\n‚Ä¢ Clean technology \r\n‚Ä¢ E-waste\r\n5\r\n\r\nhttps://www.menti.com/uns9d89kzn\r\nWhat is Sustainable \r\nSoftware Engineering?\r\n?\r\n6\r\n\r\nSustainable Software \r\nEngineering is‚Ä¶\r\n7\r\n‚Ä¶the discipline that studies the process of creating software systems that are able \r\nto create value in the long term without hindering its surrounding environment.\r\n\r\n8\r\nEconomical\r\nSocial\r\nTechnical\r\nIndividual\r\nEnvironmental\r\nSustainable\r\nSoftware\r\nEngineering\r\n‚≠ê\r\nTechnical\u2028\r\n‚öô\r\nEconomical\u2028\r\nüí∞\r\nSocial\u2028\r\nüë©üíºüë®üíºüë©üíºüë©üíº\r\nIndividual\u2028\r\nüë©üíª\r\nEnvironmental\u2028\r\nüå±\r\nSustainable\u2028\r\nSoftware \r\nEngineering\r\n\r\nEconomical\r\n‚Ä¢ Focused on assets, capital and added value\u2028\r\n(wealth creation, prosperity, profitability, capital \r\ninvestment, income, etc.) \r\n‚Ä¢ Nr of customers  \r\n‚Ä¢ Man-day-rate estimate \r\n‚Ä¢ Next round of funding \r\n‚Ä¢ Meet requirements in the contract\r\n9\r\n\r\nTechnical\r\n‚Ä¢ Longevity of information, systems, and infrastructure and their \r\nadequate evolution with changing surrounding conditions. \r\n‚Ä¢ Examples: \r\n‚Ä¢ Technical Debt \r\n‚Ä¢ Does it scale? \r\n‚Ä¢ Software testing \r\n‚Ä¢ Bus-factor \r\n‚Ä¢ Data integrity \r\n‚Ä¢ Innovation \r\n‚Ä¢ ‚Ä¶\r\n10\r\n\r\nIndividual\r\n‚Ä¢ Well-being of the individuals in an organisation.\u2028\r\nNote that it also includes how well individuals interact \r\nwith each other within the org. \r\n‚Ä¢ Examples: \r\n‚Ä¢ mental and physical well-being \r\n‚Ä¢ self-respect \r\n‚Ä¢ education/skills \r\n‚Ä¢ career development \r\n‚Ä¢ ‚Ä¶\r\n11\r\n\r\nSocial\r\n‚Ä¢ concerned with societal communities (groups of people, \r\norganisations) and the factors that erode trust in society. \r\n‚Ä¢ Examples: \r\n‚Ä¢ Social equity \r\n‚Ä¢ Justice \r\n‚Ä¢ Employment \r\n‚Ä¢ Democracy \r\n‚Ä¢ ‚Ä¶ \r\n‚Ä¢ Also includes compliance with policies and regulations \r\n12\r\n\r\nEnvironmental Sustainability\r\n‚Ä¢ the branch of Software Engineering that studies \r\nthe development of software that has minimal \r\nimpact in our planet throughout its whole \r\nlifecycle. \r\n‚Ä¢ Looking at software at different levels: \r\n‚Ä¢ Developing, Using, Serving, ‚Ä¶ \r\n‚Ä¢ Also includes e-waste. \r\n‚Ä¢ Almost identical to Green Software. (?)\r\n13\r\nBordallo II\r\n\r\nGreen Software\r\n‚Ä¢ Sustainability and energy efficiency. \r\n‚Ä¢ Building energy-efficient software is important also from a \r\ntechnical sustainability POV. \r\n‚Ä¢ Smartphones, smart wearables, IoT devices, etc. run on limited \r\npower resources. \r\n‚Ä¢ Developing software to these devices require energy-efficiency \r\ntesting and improvement. \r\n‚Ä¢ It also leads to environmental sustainability (e.g., less battery \r\ncycles) \r\n‚Ä¢ Important for UX (e.g., no need to walk around with power banks)\r\n14\r\n\r\nhttps://www.menti.com/uns9d89kzn\r\nWhat is the sustainability \r\ndimension you are most \r\ninterested in?\r\n?', '‚Ä¢ By using money cost instead of carbon cost, they have more data available.\r\n26\r\n\r\nVirtual Cluster Capacity (VCC)\r\n‚Ä¢ If the forecast of VCC fails it shift flexible workload more than expected.  \r\n‚Ä¢ This happens because the amount of workload forecasted was below the \r\nworkload needed, and VCC was ‚Äúaggressively‚Äù low. \r\n‚Ä¢ The systems fall back to the real cluster capacity for 1 week until results \r\nstart being realistic again.\r\n27\r\n\r\nNext steps\r\n‚Ä¢ They will consider spatial flexibility. \r\n‚Ä¢ I.e., tasks that can be shifted over time and over space. \r\n‚Ä¢ It needs to factor in relocation overheads, though.\r\n28\r\n\r\nCritical questions\r\n‚Ä¢ Who defines what is flexible and inflexible? \r\n‚Ä¢ How do you estimate the CPU load of a given task?\r\n29\r\n\r\nEnergy Regression Testing\r\n‚ÜíEnergy?\r\nGreener? Greener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\n\r\nE-compare\r\nGithub Actions\r\n‚ûú https://koenhagen.github.io/E-Compare/\r\n\r\nEnergy Regression Testing \r\n\r\n4. Debugging Energy with \r\nDocker Images\r\n\r\nUnveiling the Energy Vampires \r\nA methodology for debugging Software \r\nEnergy Consumption\r\n ‚úÖ ICSE 2025\r\n\r\nData Centers and Docker\r\n‚Ä¢ Containers are the most popular way to deploy apps into the cloud \r\n‚Ä¢ Base image is an important choice when building an image \r\n‚Ä¢ Criteria \r\n‚Ä¢ Linux distribution and binaries \r\n‚Ä¢ Image size \r\n‚Ä¢ Energy?\r\n35\r\n\r\nRedis energy consumption\r\n‚Ä¢ Ubuntu/Alpine base images have different energy consumption for Redis\r\n36\r\n\r\nRedis Energy Consumption\r\n‚Ä¢RQ1: What is the difference \r\nin energy consumption \r\nbetween glibc and musl? \r\n‚Ä¢RQ2: Can we use tracing \r\nto compare energy \r\nconsumption in shared \r\nlibraries? \r\n‚Ä¢RQ3: Can we verify the \r\norigin of energy \r\nconsumption differences by \r\nrecreating the workload \r\nbehavior closely?\r\n37\r\n\r\nTracing\r\n‚Ä¢ Find libc function running at the end of the benchmark \r\n‚Ä¢ Tracing: Capture calls made to libc \r\n‚Ä¢ Introduces non-linear overhead\r\n38\r\n\r\nSynchronization\r\n‚Ä¢ Tracing slows down execution and increase energy consumption \r\n‚Ä¢ Run separately and synchronize with logs\r\n39\r\n\r\nTracing Analysis\r\n40\r\n\r\nTracing Analysis\r\n41\r\n\r\nBenchmarking memcpy\r\n‚Ä¢ Copy bytes from one part of memory to \r\nanother \r\n‚Ä¢ Depending on function parameters, different \r\nassembly-level optimizations \r\n‚Ä¢ Some not included in musl\r\n42\r\n\r\nBenchmarking memcpy\r\n‚Ä¢ Copy 4 bytes from fixed \r\npointer to moving pointer \r\n‚Ä¢ (100,300,500,600) x 1M \r\nrequests \r\n‚Ä¢  15% more power and 3X time\r\n43\r\n\r\nConclusions\r\n‚Ä¢ Significant difference in energy consumption for memcpy \r\n‚Ä¢ 8.6% difference for Redis workload and 13% in our benchmark \r\n‚Ä¢ musl trades performance for a smaller codebase \r\n‚Ä¢ No official documentation \r\n‚Ä¢ No awareness about energy performance\r\n44\r\n\r\n5. Energy Efficiency vs Code \r\nQuality\r\n\r\nMeasuring Maintainability\r\n‚Ä¢ According to ISO/IEC 25010, Maintainability is ‚Äúthe degree of \r\neffectiveness and efficiency with which a software product or \r\nsystem can be modified to improve it, correct it or adapt it to \r\nchanges in environment, and in requirements‚Äù \r\n‚Ä¢ We use the code analysis tool Better Code Hub to assess \r\nmaintainability \r\n‚Ä¢ Better Code Hub maps the ISO/IEC 25010 standard on \r\nmaintainability into a set of guidelines derived from static analysis\r\n46\r\n\r\nMaintainability of Energy Changes\r\n‚Ä¢ What is the impact of making energy-oriented code changes on \r\nthe maintainability of mobile apps?', 'Neuromorphic computing\r\nCS4575\r\nSustainable Software Engineering\r\n05.03.2025\r\nNergis T√∂men\r\n\r\nIntroduction\r\nComputer Vision Lab\r\nBiomorphic Intelligence Lab\r\nBiomedical Intervention Optimisation Lab\r\nNergis\r\n\r\nNeuromorphic computing\r\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\r\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\r\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing\r\n\r\nHow many of you are familiar \r\nwith neural networks?\r\n\r\nSimple model of an artificial neuron\r\nhttps://medium.com/@cprasenjit32/perceptron-a-simple-yet-mighty-machine-learning-algorithm-9ff6b7d86a71\r\n\r\nWhat is a neural network?\r\nhttps://www.tibco.com/reference-center/what-is-a-neural-network\r\n\r\nWhy is it called a \'neural network\'?\r\nhttps://www.tibco.com/reference-center/what-is-a-neural-network\r\n\r\nWhat is a neural network?\r\nWhy is it called a \'neural network\'?\r\nMcCulloch-Pitts neuron [1, 2] (1943)\r\nWarren Sturgis McCulloch\r\n(Neurophysiologist)\r\nWalter Pitts\r\n(Logician)\r\n\r\nHow do biological neurons work?\r\nhttps://commons.wikimedia.org/wiki/File:Coincidence_detection_in_dendrites_of_pyramidal_neurons.gif\r\n\'Input current\' travels down the dendrites (top),\r\nget integrated (summed!) in the cell body\r\nwhich generates an \'output current\' (bottom)\r\nwhich is chemically transmitted to the dendrites of \r\nother neurons.\r\n\r\nSimplified picture\r\nReal neuron\r\nArtificial neuron\r\nhttps://vajiramandravi.com/quest-upsc-notes/artificial-neural-network/\r\n\r\nWhat is a neural network?\r\nMcCulloch-Pitts neuron [1, 2]\r\n1940s: How do biological neurons compute basic \r\nlogic functions? (e.g. logic gates)\r\nNote: Ref. [3] gives a nice brief history on the ideas which lead to the \r\nMcCulloch-Pitts neuron.\r\n\r\nWhat is a neural network?\r\n1950s: How are neurons organized to perform \r\nsensory perception?\r\n\r\nWhat is a neural network?\r\n1950s: How are neurons organized to perform \r\nsensory perception?\r\nThe first ""neural network"": Perceptron (1958). [4]\r\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\r\nFrank Rosenblatt (Psychologist)\r\nwith a Mark I Perceptron computer in 1960\r\n\r\nWhat is a neural network?\r\n1950s: How are neurons organized to perform \r\nsensory perception?\r\nThe first ""neural network"": Perceptron (1958). [4]\r\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\r\nFrank Rosenblatt (Psychologist)\r\nwith a Mark I Perceptron computer in 1960\r\nPower-efficient\r\n\r\nNeuromorphic computing\r\nWhy neuromorphic computing?\r\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\r\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\r\n\r\nNeuromorphic computing\r\nWhy neuromorphic computing?\r\n‚ÄòBiological inspiration‚Äô for artificial neural networks (ANNs) is not a new idea.\r\nEmulation (as opposed to simulation) of neural networks in hardware is not a new idea.', '‚Ä¢ Groundbreaking AI research is mostly done by tech giants.\r\n7\r\n\r\nA few examples of Red AI\r\n‚Ä¢ Google‚Äôs BERT-large \r\n‚Ä¢ 350 million features \r\n‚Ä¢ Trained for 2.5 days using 512 TPU chips, costing $60K+ \r\n‚Ä¢ Open-GPT3 (now GPT-4/o1) \r\n‚Ä¢ 550 tonnes CO2-eq (Patterson, 2021) \r\n‚Ä¢ 175 billion features \r\n‚Ä¢ API is open but no-pretrained model is available \r\n‚Ä¢ AlphaGo \r\n‚Ä¢ 1920 CPUs, 280 GPUs, costing $35M\r\n8\r\n\r\nRed AI in Large Language Models (LLMs)\r\n‚Ä¢ OPT by Meta reports 75 tons CO2-eq (1/7 of OpenGPT‚Äôs footprint).\u2028\r\n(Also 175billion params) \r\n‚Ä¢ However, Llama 3 reported 2,290 tons of CO2-eq (7.7M GPU hours \r\ntraining ) \r\n‚Ä¢ Open science: release includes both the pretrained models and the code \r\nneeded to train and use them. \r\n‚Ä¢ DeepSeek-V3 claims ‚Äúonly‚Äù 2.78M GPU hours \r\n‚Ä¢ Bloom by Huggingface reports 25 tons, 51 when considering embodied \r\nand operational carbon footprint. (176billion params)\r\n9\r\n\r\nRed AI\r\nAccuracy: 0.999999999\r\nGreen AI\r\n‚Ä¢ Energy \r\n‚Ä¢ Time \r\n‚Ä¢ Reproducibility \r\n‚Ä¢ Reusage\r\n\r\nHow can we adopt Green AI\r\n‚Ä¢ Check whether AI is needed. \r\n‚Ä¢ Select green datacenters. \r\n‚Ä¢ Run on low carbon intensity hours. \r\n‚Ä¢ Opt for GPU-optimised solutions (?) \r\n‚Ä¢ Opt for low-power hardware (e.g., Nvidia Jetson boards) \r\n‚Ä¢ Or GPUs that provide energy metrics (e.g., NVIDIA GPUs via the nvidia-smi tool) \r\n‚Ä¢ Report energy/carbon metrics (e.g., embed in MLFlow?) \r\n‚Ä¢ Use pre-trained models (Transfer Learning) \r\n‚Ä¢ Preprocess dataset to reduce size. \r\n‚Ä¢ Improve parameter-tuning strategy.\r\n11\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ We need benchmarks. \r\n‚Ä¢ AllenAI leaderboard\u2028\r\nhttps://leaderboard.allenai.org \r\n‚Ä¢ No carbon metrics, yet \r\n‚Ä¢ Report comparable proxies for energy \r\nconsumption. \r\n‚Ä¢ ‚ö† Learning algorithms behave in a non-\r\ndeterministic \r\n‚Ä¢ ‚ö† Different data-points lead to different \r\nenergy consumption\r\n12\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ Reporting measured energy consumption \r\n‚Ä¢ + Accurate \r\n‚Ä¢ + Easy to map to carbon emissions \r\n‚Ä¢ - Hard to measure \r\n‚Ä¢ - Low replicability \r\n‚Ä¢ Reporting time / estimation based on time & hardware \r\n‚Ä¢ + Easy to measure \r\n‚Ä¢ + Correlates with energy consumption in most cases. \r\n‚Ä¢ -  Difficult to compare with measurements from other setups \r\n‚Ä¢ E.g., floating point operations (FPOs) (?) \r\n‚Ä¢ + comparable across different setups \r\n‚Ä¢ + cheap \r\n‚Ä¢ - does not factor in memory energy consumption \r\n‚Ä¢ - does not reflect carbon emissions\r\n13\r\n\r\nData-centric AI\r\n\r\nData-centric AI\r\n‚Ä¢ Emerging discipline that deals with systematically engineering data to build AI \r\nsystems. \r\n‚Ä¢ Shift from improving the training strategy to improving the data. \r\n‚Ä¢ It is better to have small but reliable datasets than large but noisy \r\ndatasets. \r\n‚Ä¢ => Improve data collection, data labelling, and data preprocessing. \r\n‚Ä¢ More about data-centric AI by Andrew Ng:\u2028\r\nhttps://www.youtube.com/watch?v=06-AZXmwHjo\r\n15\r\n\r\n\r\nGreen Data-centric AI\r\n‚Ä¢ How do different ML algorithms compare \r\nin terms of energy consumption? \r\n‚Ä¢ How does number of rows relate to the \r\nenergy consumption of ML models? \r\n‚Ä¢ How does number of features relate to \r\nthe energy consumption of ML models? \r\n‚Ä¢ What is the impact of reducing data in the \r\nperformance of the model?', '‚Ä¢ Software consumers have started to worry about the climate impact \r\nof their behaviour as users. \r\n‚Ä¢ Being environmentally sustainable is now an important competitive \r\nfactor \r\n‚Ä¢ Marketing teams are already using all eco-friendly labels. Technical \r\nteams are not there yet, though. \r\n‚Ä¢ It‚Äôs easier said than done!\r\n$\r\n16\r\n\r\nGreen Washing\r\n‚Ä¢ Deceptively use marketing techniques to \r\nclaim being eco-friendly. \r\n‚Ä¢ Opting for green-coloured designs. \r\n‚Ä¢ Red/orange is usually perceived as \r\ntasty. \r\n‚Ä¢ Green is perceived as eco-friendly. \r\n‚Ä¢ The VW case. (?)\r\n17\r\n\r\nThe VW scandal\r\nGreenwashing\r\n‚Ä¢ Used software to cheat on vehicle emissions \r\ntests. \r\n‚Ä¢ The vehicle‚Äôs software could detect whether they \r\nwere being tested, changing the performance \r\naccordingly to improve results. \r\n‚Ä¢ Affected 11M cars worldwide, 8M in Europe.\r\n18\r\n\r\nHow can we drive sustainability \r\nin the SE industry?\r\n\r\nGreen Procurement\r\n‚Ä¢ Customers decide on providers that share their values \r\n‚Ä¢ This is currently the main trigger reason why organisations \r\nworry about Sustainability and Green Software. \r\n‚Ä¢ Examples of green procurement: \r\n‚Ä¢ Customers that only buy green services/products \r\n‚Ä¢ Companies that only use green providers \r\n‚Ä¢ Developers that only work for green companies \r\n‚Ä¢ Green procurement makes environmental sustainability \r\nessential for economical sustainability.\r\n20\r\n\r\nSustainability via compliance\r\n‚Ä¢ EU wants to be carbon neutral by 2030 \r\n‚Ä¢ This also affects the ICT sector. Estimated to impact \r\n14% of the global carbon footprint by 2040. \r\n‚Ä¢ Some initiatives are already being negotiated. \r\n‚Ä¢ Extending the smartphone lifetime to 7 years. \r\n‚Ä¢ Right-to-repair movement. https://repair.eu \r\n‚Ä¢ Making IT services relying on clean energy more \r\naccessible (e.g., less taxes).\r\n21\r\n\r\nSoftware for Sustainability \r\n‚Ä¢ We are not covering it in this course.\r\n\r\nCarbon-free giants\r\n‚Ä¢ Google, Microsoft, Meta/Facebook want to be carbon free by 2030 \r\n‚Ä¢ Carbon free is different from carbon neutral \r\n‚Ä¢ Green IT experts are needed to meet these goals\r\n23\r\n\r\n\r\nRebound effect*\r\n‚Ä¢ Energy consumption decreases ‚Üì‚Üì but demand also increases ‚Üë‚Üë. \r\n‚Ä¢ *a.k.a. Jevons Paradox in economics; Downs‚ÄìThomson paradox in\xa0mobility.\r\nEnergy per prompt\r\nPrompts\r\n100\r\n80\r\n30\r\n38\r\nChat \r\nGPT\r\n‚ÄúEnergy-efficient‚Äù \r\nChat GPT\r\n0\r\n\r\nIs sustainability an\u2028\r\nethical issue?\r\n‚Ä¢ Climate change is more likely to affect the \r\npoorest countries. \r\n‚Ä¢ Less financial resources to adapt \r\n‚Ä¢ Climate-impact does not necessarily affect \r\npolluting countries. \r\n‚Ä¢ Poorest countries have contributed less to the \r\nclimate change. \r\n‚Ä¢ We need to figure out how to do more using \r\nless resources.\r\n26\r\n\r\nMorality ‚â† Moralising\r\n‚Ä¢ We should not use climate action as a \r\nshaming weapon \r\n‚Ä¢ Climate action should be agnostic of political \r\nviews, ideology, social status, etc. \r\n‚Ä¢ We need everyone to take action!\r\n27\r\n\r\nWhy?\r\n‚Ä¢ Throughout your career you might: \r\n‚Ä¢ Design/maintain/contract data centers \r\n‚Ä¢ Set up operations/devops \r\n‚Ä¢ Develop AI for IoT devices \r\n‚Ä¢ Be the next CEO/CTO of a software company \r\n‚Ä¢ Sustainability can be your main role: \r\n‚Ä¢ Green Software Developer \r\n‚Ä¢ Sustainability Consultant \r\n‚Ä¢ Green Advocate  \r\n‚Ä¢ Founder of a Green Tech startup (B2B?)\r\n28\r\n\r\nFormat of classes\r\n‚Ä¢ In-person. \r\n‚Ä¢ Collegerama recordings. \r\n‚Ä¢ Lectures and Labs. \r\n‚Ä¢ Guest lectures. \r\n‚Ä¢ Steering meetings (after week 5, new schedule)\r\n29\r\n\r\nFormat of classes\r\n‚Ä¢ There‚Äôs no exam in this course.', 'Lu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\n2. Tools to Measure Software Energy \r\n(lab)\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nCarolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl\r\n\r\n1. Tools \r\n2. Hands-on \r\n3. Project 1\r\n\r\n3\r\nHardware Power \r\nMonitors\r\nEnergy Profilers\r\n\r\nHardware Power Monitors\r\n‚Ä¢ Connects directly to the power source of the device/\r\ncomponent. \r\n‚Ä¢ Some power monitors also replace the power source. \r\n‚Ä¢ Example: \r\n‚Ä¢ Monsoon Power Monitor (for IoT and smartphones).  \r\n‚Ä¢ Can be fully automated using a Python API. \r\n‚Ä¢ It measures and powers small electronic devices. \r\n‚Ä¢ There are many power/energy meters out there but for \r\nsoftware use cases we need to be able to control them \r\nusing an API.\r\n4\r\n\r\nConnecting Monsoon to a Smartphone\r\n‚Ä¢ 1. Disassemble the smartphone and find the \r\nconnectors of the battery.  \r\n‚Ä¢ iFixit usually has nice tutorials and blueprints. \r\nhttps://www.ifixit.com\r\n5\r\n\r\nConnecting Monsoon to a Smartphone\r\n‚Ä¢ 2. Extract the electronic component of the battery \r\n‚Ä¢ Modern batteries are connected through 4 terminals: \r\n‚Ä¢ Positive \r\n‚Ä¢ Negative \r\n‚Ä¢ BTEMP, battery temperature (used for safety) \r\n‚Ä¢ BST, battery system indicator (provides info about \r\nthe battery) \r\n‚Ä¢ Hence, one cannot simply connect + and - pins\r\n6\r\n\r\n‚Ä¢ 3. Connect the electronic component \r\ndirectly to the monitor.\r\nConnecting Monsoon to a Smartphone\r\n7\r\n\r\nConnecting Monsoon to a Smartphone\r\n‚Ä¢ 4. Use the library PyMonsoon to control the power \r\nmonitor. \r\n‚Ä¢ https://github.com/msoon/PyMonsoon \r\n‚Ä¢ 4.1. Set the monsoon to desired Voltage. Choose \r\nthe typical voltage of the original battery. For the \r\nNexus 5X, 3.8V was equivalent to its battery at \r\naround 60% capacity. \r\n‚Ä¢ 4.2. Start measuring\r\n8\r\n\r\nConnecting Monsoon to a Smartphone\r\n‚Ä¢ 5. Automate User Interface interaction \r\n‚Ä¢ The last thing you want to do is to manually interact with the smartphone \r\nwhile you measure energy consumption. Tests are less accurate, less \r\nreproducible, and, in this case, the screen cannot not be easily accessed. \r\n‚Ä¢ Tools to automate interaction with Android phones: \r\n‚Ä¢ To open, install, close apps: adb \r\n‚Ä¢ To interact with the app: Appium, Robotium, UIAutomator, espresso, \r\netc. \r\n‚Ä¢ Alternative: physalia is a library that automates all adb interactions and \r\nPyMonsoon calls.\r\n9\r\n\r\nIssue 1: USB cable!\r\n‚Ä¢ You need the USB cable to automate the interaction with the phone. \r\n‚Ä¢ When you connect the USB cable, measurements become\u2028\r\nunreliable. \r\n‚Ä¢ Solution: \r\n‚Ä¢ Monsoon has a feature to control the USB connection (switch on/off) \r\n‚Ä¢ Option 1: Right before starting measurements, the USB connection is stopped. \r\n‚Ä¢ Works fine when when all the interaction instructions can be sent in advance and the time for the \r\nexecution is already known. \r\n‚Ä¢ Option 2: using USB, set up a wireless ADB connection. Stop USB connections afterwards. \r\n‚Ä¢ How to: https://stackoverflow.com/a/3623727\r\n10\r\n\r\nIssue 2: your app is not exclusive\r\n‚Ä¢ Many activities run in a smartphone device. E.g., getting push notifications, \r\nchecking nearby bluetooth devices, etc. \r\n‚Ä¢ Moreover, brightness may change according to environment. Different \r\nscreen brightness, different results.', '5. Green Software Metrics\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nLu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\nCarolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl\r\nSustainableSE 2025\r\n\r\nBitcoin example\r\n‚Ä¢ 1 bitcoin transaction is equivalent to more than 1.5 million VISA transactions. \r\n \r\n   \r\n \r\n‚Ä¢ Day-to-day metrics are easy to grasp \r\n‚Ä¢ If we say 8 gigajoules, it‚Äôs a bit more difficult to understand. \r\n‚Ä¢ These numbers keep changing (check it here: https://www.statista.com/\r\nstatistics/881541/bitcoin-energy-consumption-transaction-comparison-visa/)\r\n2\r\n\r\n3\r\n\r\n(Electrical) Energy\r\n‚Ä¢ Work required to move charged particles. \r\n‚Ä¢ Same concept but different perspective when talking about thermal, \r\nmechanical, or nuclear energy. \r\n‚Ä¢ Most common units: \r\n‚Ä¢ joule (J) -  recommended; scientific communications; metric from the \r\nInternational System of Units \r\n‚Ä¢ kilowatt-hour (kWh) - more common, e.g., used for household electricity \r\nconsumption\r\n4\r\n+q\r\n-q\r\nF\r\nF\r\n\r\nPower\r\n‚Ä¢ Amount of work being done per unit of time. \r\n‚Ä¢ Commonly measured in watts (W).\r\n5\r\n\r\n‚à´\r\ntf=9\r\nti=1\r\nP(t)dt\r\n\r\n‚à´\r\ntf=9\r\nti=1\r\nP(t)dt\r\n\r\nA = a + b\r\n2\r\nh\r\nMeasured Energy \r\nConsumption\r\n=\r\nPtn + Ptn+1\r\n2\r\n‚ãÖŒît = 3.5W + 2.0W\r\n2\r\n‚ãÖ1s = 2.75J\r\nA = ?\r\na\r\nb\r\nh\r\n\r\n‚à´\r\ntn\r\nt0\r\nP(t)dt ‚âàŒît\r\n2 [P(t0) + 2P(t1) + 2P(t2) + . . . + 2P(tn‚àí1) + P(tn)]\r\nMeasured Energy \r\nConsumption\r\n‚ö† Sometimes you cannot assume that the sampling interval (\r\n) is always the same. ‚ö†\r\nŒît\r\nTrapezoid Rule\r\n\r\nTrapezoid Rule in Python\r\nimport numpy as np \r\nenergy_consumption = np.trapz(power_sample, timestamps) \r\n\r\nAverage power\r\n‚Ä¢ Easy to convert to energy consumption \r\n‚Ä¢ Simply multiply by the elapsed time. \r\n‚Ä¢ (This is another reason to always collect time data along with energy \r\nmetrics.)\r\n11\r\nEnergy = Pavg¬∑Œît\r\n\r\nPower or Energy?\r\n‚Ä¢ Average power consumption makes sense when we report the \r\nconsumption of a continuous use case. E.g., reading an ebook in your \r\ncomputer. \r\n‚Ä¢ Energy consumption makes sense in one-off use cases. E.g., energy \r\nconsumption of a bitcoin transaction. \r\n‚ö†\r\n\r\nLearning activity\r\n‚Ä¢ Pair up with one colleague and discuss potential software use cases where \r\none should test energy efficiency. \r\n‚Ä¢ Choose one use case where energy consumption is the best metric to \r\ndiscuss/test energy efficiency. \r\n‚Ä¢ Choose one use case where average power consumption is the best \r\nmetric to discuss/test energy efficiency.\r\n13\r\n\r\nEnergy Delay Product (EDP)\r\n‚Ä¢ In some cases, to achieve less energy consumption, one simply runs the \r\nsoftware on a low power mode of the CPU. \r\n‚Ä¢ E.g., setting the CPU at a low frequency will make execution slow but more \r\nenergy-efficient. \r\n‚Ä¢ Energy consumption metric that penalizes slow runs \r\n \r\n \r\n‚Ä¢ Gives more importance to application runtime, with the goal of making both \r\nlow energy and fast runtime applications.']","['<1-hop>\n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise\n‚Ä¢ But studying government software is diÔ¨Écult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation?\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!', '<2-hop>\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption\n‚Ä¢ B3. Energy proÔ¨Åling of static analysis tools\n‚Ä¢ B4. Detailed energy proÔ¨Åling of build pipelines\n‚Ä¢ B5. Tool supporting SusAF workshop / process\n‚Ä¢ B6. Dataset of government-developed OS software\n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability']","The project idea about government-developed OS software involves creating a comprehensive dataset of software developed and used by governments to support society. This is in response to the rise of open-source development and policies. The challenge is that studying government software is difficult due to a lack of awareness about what is available, lack of incentive to make it popular, and language barriers. The dataset should include information to understand the state of the software, such as whether it is buildable, has an open development history, and includes requirements documentation. The project could start with the Netherlands but would benefit from including other countries as well.","The project idea involves creating a comprehensive dataset of government-developed OS software to understand its state, including buildability, open development history, and requirements documentation. This addresses challenges like lack of incentives and language barriers.",0.524999999986875,1.0,1.0,0.67,0.0,0.9999999999999997
What is the project idea related to creating a dataset of goverment-developed OS software?,"['Lu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\n10. Project 2\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nCarolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl\r\n\r\n1. Goal/assignment \r\n2. Deliverables \r\n3. Strategy \r\n4. Ideas\r\n\r\nAssignment\r\n‚Ä¢ Goal: Solve a Sustainable Software Engineering problem. \r\n‚Ä¢ Identify 1 problem that should be fixed to help enabling sustainability in \r\nthe software engineering industry/community. \r\n‚Ä¢ Propose a solution. A tool, framework, guidelines, etc. \r\n‚Ä¢ Implementation. \r\n‚Ä¢ Validation. (Depending on the idea) \r\n‚Ä¢ Dissemination/social impact. (Solution should be open source, welcome \r\ncontributors, post on social media? Tool website? Available in a package \r\nmanager?)\r\n3\r\n\r\nDeliverables\r\n‚Ä¢ Paper-like article. (Min 4 pages, max 10) \r\n‚Ä¢ Online git repo with open source codebase and/or replication package. \r\n‚Ä¢ Presentation: 5 min + 5min Q&A\r\n4\r\n\r\nArticle\r\n‚Ä¢ Different projects will have different expectations -> Make agreements with \r\nyour coach. \r\n‚Ä¢ Some projects are more technical and some projects more theoretical. \r\n‚Ä¢ Common requirements: \r\n‚Ä¢ Motivation, formulation of the problem being addressed, etc. \r\n‚Ä¢ Description of the solution. \r\n‚Ä¢ Validation of the solution (if applicable -> discuss with coach) \r\n‚Ä¢ Discussion of the solution. (Including limitations)\r\n5\r\n\r\nStrategy\r\n‚Ä¢ Starting next week, there are no lectures  \r\n‚Ä¢ Steering meetings from week 5 till week 9 (either online or in person).  \r\n‚Ä¢ 1 steering meeting per week. (4+1 sprints) \r\n‚Ä¢ Every week, you need to plan different tasks and assignments. \r\n‚Ä¢ Deadline April 4.\r\n6\r\n\r\nStrategy\r\n‚Ä¢ Week 0 \r\n‚Ä¢ Decide project idea (today) \r\n‚Ä¢ Define steering meeting schedule \r\n‚Ä¢ Create working document of the \r\narticle: Problem statement and solution \r\nproposal! \r\n‚Ä¢ Define and assign tasks for each week. \r\n‚Ä¢ Week 1 \r\n‚Ä¢ Implementation \r\n‚Ä¢ Agreements with supervisor. \r\n‚Ä¢ Week 2 \r\n‚Ä¢ Implementation \r\n‚Ä¢ Week 3 \r\n‚Ä¢ Implementation, Full draft of article, \r\ndissemination. \r\n‚Ä¢ Week 4 \r\n‚Ä¢ Final refinements \r\n‚Ä¢ Prepare presentation\r\n7\r\n\r\nProject ideas\r\n‚Ä¢ A1. Prototype cross-machine comparable benchmarks \r\n‚Ä¢ A2. Add energy metrics to LMstudio/Ollama \r\n‚Ä¢ A3. Visualizations built-in with EnergiBridge \r\n‚Ä¢ A4. Service-based version of EnergiBridge\r\n\r\nProject ideas\r\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \r\n‚Ä¢ B2. Study test generation energy consumption \r\n‚Ä¢ B3. Energy profiling of static analysis tools \r\n‚Ä¢ B4. Detailed energy profiling of build pipelines \r\n‚Ä¢ B5. Tool supporting SusAF workshop / process \r\n‚Ä¢ B6. Dataset of government-developed OS software \r\n‚Ä¢ B7. Queue - but better for the student / TA society\r\nQuality Assurance & Testing\r\nSocial & Individual \u2028\r\nSustainability\r\n\r\nProject ideas\r\n‚Ä¢ C1. Compare energy consumption of docker images for ML workloads. \r\n‚Ä¢ C2. Create a plugin to visualize Hugging Face carbon emissions in detail. \r\n‚Ä¢ C3. Plugin for ChatGPT (footprint per chat window) \r\n‚Ä¢ C4. NutriScore for software libraries. \r\n‚Ä¢ C5. Add energy-awareness to existing software \r\n‚Ä¢ C6. Green Shift Left \r\n‚Ä¢ C7. Education for Sustainable SE\r\n\r\nA1.', '‚Ä¢ Deadline April 4.\r\n6\r\n\r\nStrategy\r\n‚Ä¢ Week 0 \r\n‚Ä¢ Decide project idea (today) \r\n‚Ä¢ Define steering meeting schedule \r\n‚Ä¢ Create working document of the \r\narticle: Problem statement and solution \r\nproposal! \r\n‚Ä¢ Define and assign tasks for each week. \r\n‚Ä¢ Week 1 \r\n‚Ä¢ Implementation \r\n‚Ä¢ Agreements with supervisor. \r\n‚Ä¢ Week 2 \r\n‚Ä¢ Implementation \r\n‚Ä¢ Week 3 \r\n‚Ä¢ Implementation, Full draft of article, \r\ndissemination. \r\n‚Ä¢ Week 4 \r\n‚Ä¢ Final refinements \r\n‚Ä¢ Prepare presentation\r\n7\r\n\r\nProject ideas\r\n‚Ä¢ A1. Prototype cross-machine comparable benchmarks \r\n‚Ä¢ A2. Add energy metrics to LMstudio/Ollama \r\n‚Ä¢ A3. Visualizations built-in with EnergiBridge \r\n‚Ä¢ A4. Service-based version of EnergiBridge\r\n\r\nProject ideas\r\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \r\n‚Ä¢ B2. Study test generation energy consumption \r\n‚Ä¢ B3. Energy profiling of static analysis tools \r\n‚Ä¢ B4. Detailed energy profiling of build pipelines \r\n‚Ä¢ B5. Tool supporting SusAF workshop / process \r\n‚Ä¢ B6. Dataset of government-developed OS software \r\n‚Ä¢ B7. Queue - but better for the student / TA society\r\nQuality Assurance & Testing\r\nSocial & Individual \u2028\r\nSustainability\r\n\r\nProject ideas\r\n‚Ä¢ C1. Compare energy consumption of docker images for ML workloads. \r\n‚Ä¢ C2. Create a plugin to visualize Hugging Face carbon emissions in detail. \r\n‚Ä¢ C3. Plugin for ChatGPT (footprint per chat window) \r\n‚Ä¢ C4. NutriScore for software libraries. \r\n‚Ä¢ C5. Add energy-awareness to existing software \r\n‚Ä¢ C6. Green Shift Left \r\n‚Ä¢ C7. Education for Sustainable SE\r\n\r\nA1. Prototype cross-machine comparable benchmarks\r\n‚Ä¢ Energy-usage comparisons require running both baseline + software on the \r\nsame machine ‚Üí limits how extensive our experiments can be \r\n‚Ä¢ Research community is in need of benchmarks that make energy \r\nmeasurements comparable even if executed on different machines \r\n‚Ä¢ Focus on a single task or model (i.e. computing vision, classification)\r\n\r\nA2. Adding energy metrics to LMstudio/Ollama\r\n‚Ä¢ Make energy consumption visible to users \r\nwithin local chat-interface for LLMs \r\n‚Ä¢ LMstudio/Ollama are tools for easy \r\ndeployment of LLMs \r\n‚Ä¢ Do not show energy metrics \r\n‚Ä¢ Add energy metrics to LMstudio-python \r\nor Ollama\r\nhttps://lmstudio.ai/\r\n\r\nA3. Visualizations built-in with EnergiBridge\r\n‚Ä¢ EnergiBridge simplifies energy measurement, but analysis & visualization is \r\nstill left to the user \r\n‚Ä¢ Extend the tool with well-chosen visualizations and analyses directly from the \r\nprovided data\r\n\r\nA4. Service-based version of EnergiBridge\r\n‚Ä¢ Simplify interaction & setup with EnergiBridge \r\n‚Ä¢ Service that runs independently, start/stop signals over RPC to manage \r\nexperiments \r\n‚Ä¢ Potential: create EnergiBridge interface for other prog. lang\r\n\r\nB1. Measure energy consumption of single JUnit tests\r\n‚Ä¢ We‚Äôd like to identify energy anti patterns in unit tests \r\n‚Ä¢ As a first step, we need tooling to measure and compare the energy \r\nconsumption of single unit tests \r\n‚Ä¢ Ideally including preliminary analysis looking at potential reasons for high-\r\nenergy-consuming tests\r\n\r\nB2. Study test generation energy consumption\r\n‚Ä¢ Automatic test generation mainly focuses on making strong test suites \r\n‚Ä¢ Do different techniques and configurations impact the energy consumption \r\nduring generation? \r\n‚Ä¢ Preferably focus on non-LLM test generation methods (EvoSuite, Pyguin, \r\nDSpot)\r\n\r\nB3. Detailed energy profiling of build pipelines\r\n‚Ä¢ Automatic builds have become a cornerstone of quality assurance.', 'computing vision, classification)\r\n\r\nA2. Adding energy metrics to LMstudio/Ollama\r\n‚Ä¢ Make energy consumption visible to users \r\nwithin local chat-interface for LLMs \r\n‚Ä¢ LMstudio/Ollama are tools for easy \r\ndeployment of LLMs \r\n‚Ä¢ Do not show energy metrics \r\n‚Ä¢ Add energy metrics to LMstudio-python \r\nor Ollama\r\nhttps://lmstudio.ai/\r\n\r\nA3. Visualizations built-in with EnergiBridge\r\n‚Ä¢ EnergiBridge simplifies energy measurement, but analysis & visualization is \r\nstill left to the user \r\n‚Ä¢ Extend the tool with well-chosen visualizations and analyses directly from the \r\nprovided data\r\n\r\nA4. Service-based version of EnergiBridge\r\n‚Ä¢ Simplify interaction & setup with EnergiBridge \r\n‚Ä¢ Service that runs independently, start/stop signals over RPC to manage \r\nexperiments \r\n‚Ä¢ Potential: create EnergiBridge interface for other prog. lang\r\n\r\nB1. Measure energy consumption of single JUnit tests\r\n‚Ä¢ We‚Äôd like to identify energy anti patterns in unit tests \r\n‚Ä¢ As a first step, we need tooling to measure and compare the energy \r\nconsumption of single unit tests \r\n‚Ä¢ Ideally including preliminary analysis looking at potential reasons for high-\r\nenergy-consuming tests\r\n\r\nB2. Study test generation energy consumption\r\n‚Ä¢ Automatic test generation mainly focuses on making strong test suites \r\n‚Ä¢ Do different techniques and configurations impact the energy consumption \r\nduring generation? \r\n‚Ä¢ Preferably focus on non-LLM test generation methods (EvoSuite, Pyguin, \r\nDSpot)\r\n\r\nB3. Detailed energy profiling of build pipelines\r\n‚Ä¢ Automatic builds have become a cornerstone of quality assurance. But how \r\nmuch energy do they even consume? \r\n‚Ä¢ Create a tool that reports on the energy consumed during the (different stages \r\nof the) whole build (compile, build, test, package, ‚Ä¶) \r\n‚Ä¢ Should be integrated with build system(s), making setup for developers easy \r\n‚Ä¢ For local setup (to enable true energy measurements)\r\n\r\nB4. Energy profiling of static analysis tools\r\n‚Ä¢ What is the energy consumption of a ""typical run"" for a few OSS projects? \r\n‚Ä¢ Does the type of analysis matter? Are certain analysis more expensive? Does \r\nthe number of rules that are activated in a static analysis tool important for the \r\nenergy consumption? \r\n‚Ä¢ Differences between static analysis tools [lower priority]\r\n\r\nB5. Tool supporting SusAF workshop / process\r\n‚Ä¢ Lead engineers through process & questions \r\n‚Ä¢ Interface to create & document the two diagrams \r\n‚Ä¢ (!) Should be easy to start using & set up \r\n‚Ä¢ You may also create a simplified version / \u2028\r\nyour favorite sustainability framework\r\nEnvironmental\r\nEconomic\r\nTechnical\r\nIndividual\r\nSocial\r\nImmediate\r\nEnabling\r\nStructural\r\nAirbnb\r\ngreater \r\nearnings\r\nincrease \r\nin rents\r\ngentrification\r\ngreater racial \r\ndisparities\r\nrent \r\nrooms\r\n5\r\n1\r\n3\r\n4\r\n2\r\n \r\n \r\n \r\n \r\n \r\n \r\nVery \r\nunlikely \r\nVery \r\nlikely \r\n\r\nB6. Dataset of government-developed OS software\r\n‚Ä¢ Governments develop & use software for supporting society\u2028\r\nOpen-source development & policies are on the rise \r\n‚Ä¢ But studying government software is difficult b/c we don‚Äôt know what is out \r\nthere\u2028\r\n‚Üí Lack of incentive to make popular \u2028\r\n‚Üí Language barriers \r\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \r\nbuildable?, open dev. history?, requirements documentation? \r\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!\r\n\r\nB7. Queue - but better for the student / TA society\r\n‚Ä¢ Requirements analysis regarding social and individual sustainability effects \r\nof Queue \r\n‚Ä¢ Other EIP / TUD used software also possible: e.g., Answers EWI \r\n‚Ä¢ Non-technical project ‚Üí proper process (workshops?', 'Energy profiling of static analysis tools\r\n‚Ä¢ What is the energy consumption of a ""typical run"" for a few OSS projects? \r\n‚Ä¢ Does the type of analysis matter? Are certain analysis more expensive? Does \r\nthe number of rules that are activated in a static analysis tool important for the \r\nenergy consumption? \r\n‚Ä¢ Differences between static analysis tools [lower priority]\r\n\r\nB5. Tool supporting SusAF workshop / process\r\n‚Ä¢ Lead engineers through process & questions \r\n‚Ä¢ Interface to create & document the two diagrams \r\n‚Ä¢ (!) Should be easy to start using & set up \r\n‚Ä¢ You may also create a simplified version / \u2028\r\nyour favorite sustainability framework\r\nEnvironmental\r\nEconomic\r\nTechnical\r\nIndividual\r\nSocial\r\nImmediate\r\nEnabling\r\nStructural\r\nAirbnb\r\ngreater \r\nearnings\r\nincrease \r\nin rents\r\ngentrification\r\ngreater racial \r\ndisparities\r\nrent \r\nrooms\r\n5\r\n1\r\n3\r\n4\r\n2\r\n \r\n \r\n \r\n \r\n \r\n \r\nVery \r\nunlikely \r\nVery \r\nlikely \r\n\r\nB6. Dataset of government-developed OS software\r\n‚Ä¢ Governments develop & use software for supporting society\u2028\r\nOpen-source development & policies are on the rise \r\n‚Ä¢ But studying government software is difficult b/c we don‚Äôt know what is out \r\nthere\u2028\r\n‚Üí Lack of incentive to make popular \u2028\r\n‚Üí Language barriers \r\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \r\nbuildable?, open dev. history?, requirements documentation? \r\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!\r\n\r\nB7. Queue - but better for the student / TA society\r\n‚Ä¢ Requirements analysis regarding social and individual sustainability effects \r\nof Queue \r\n‚Ä¢ Other EIP / TUD used software also possible: e.g., Answers EWI \r\n‚Ä¢ Non-technical project ‚Üí proper process (workshops? Interviews?) & rich \r\ndescription of outcomes focus of grading\r\nhttps://eip.pages.ewi.tudelft.nl/eip-website/queue.html\r\n\r\nC1. Compare energy consumption of docker images for \r\nML workloads.\r\n‚Ä¢ Similar to what we have seen in the lectures but for ML-specific workloads. \r\n‚Ä¢ We can reuse existing experiment replication packages.\r\n22\r\n\r\nC2. Plugin to visualize Hugging Face carbon emissions.\r\n‚Ä¢ https://huggingface.co/blog/leaderboard-emissions-\r\nanalysis \r\n‚Ä¢\r\nYoo, Taewon, et al. ""Visualizing the Carbon Intensity of Machine Learning Inference for Image Analysis on TensorFlow Hub.""\r\n\r\nC3. Plugin for ChatGPT\r\n‚Ä¢ Users seldom know how much carbon they are emitting when they interact \r\nwith chat GPT. \r\n‚Ä¢ Let‚Äôs make it transparent to the users. Browser plugin?\r\n24\r\nCO2\r\n\r\nC4. NutriScore for software libraries\r\n25\r\n‚Ä¢ NutriScore labels are not perfect but they are a good starting point! \r\n‚Ä¢ What if we could do the same thing for the energy efficiency of software. \r\n‚Ä¢ (Also open to individual or social sustainability) \r\n‚Ä¢ This work can be scoped in particular domains/ecossystems/use cases. \r\n‚Ä¢ Libraries for stats? ML? Web Dev? Cloud?\r\n\r\nC5. Add energy-awareness to existing software\r\n26\r\n‚Ä¢ Streamlit, Notebooks, JSFiddle, \r\nPyScript, zsh, etc. \r\n‚Ä¢\r\n\r\nC6 - Green Shift Left\r\n‚Ä¢ Estimate energy efficiency using static code analysis. \r\n‚Ä¢ We don‚Äôt need an accurate value. \r\n‚Ä¢ It is useful to know which code is more likely to \r\nintroduce energy hotspots and that should be \r\nreviewed with more attention. \r\n‚Ä¢ Can be scoped to a particular domain (react, php, data \r\nscience, web, etc., etc.)', 'Carbon-free giants\r\n‚Ä¢ Google, Microsoft, Meta/Facebook want to be carbon free by 2030 \r\n‚Ä¢ Carbon free is different from carbon neutral \r\n‚Ä¢ Green IT experts are needed to meet these goals\r\n23\r\n\r\n\r\nRebound effect*\r\n‚Ä¢ Energy consumption decreases ‚Üì‚Üì but demand also increases ‚Üë‚Üë. \r\n‚Ä¢ *a.k.a. Jevons Paradox in economics; Downs‚ÄìThomson paradox in\xa0mobility.\r\nEnergy per prompt\r\nPrompts\r\n100\r\n80\r\n30\r\n38\r\nChat \r\nGPT\r\n‚ÄúEnergy-efficient‚Äù \r\nChat GPT\r\n0\r\n\r\nIs sustainability an\u2028\r\nethical issue?\r\n‚Ä¢ Climate change is more likely to affect the \r\npoorest countries. \r\n‚Ä¢ Less financial resources to adapt \r\n‚Ä¢ Climate-impact does not necessarily affect \r\npolluting countries. \r\n‚Ä¢ Poorest countries have contributed less to the \r\nclimate change. \r\n‚Ä¢ We need to figure out how to do more using \r\nless resources.\r\n26\r\n\r\nMorality ‚â† Moralising\r\n‚Ä¢ We should not use climate action as a \r\nshaming weapon \r\n‚Ä¢ Climate action should be agnostic of political \r\nviews, ideology, social status, etc. \r\n‚Ä¢ We need everyone to take action!\r\n27\r\n\r\nWhy?\r\n‚Ä¢ Throughout your career you might: \r\n‚Ä¢ Design/maintain/contract data centers \r\n‚Ä¢ Set up operations/devops \r\n‚Ä¢ Develop AI for IoT devices \r\n‚Ä¢ Be the next CEO/CTO of a software company \r\n‚Ä¢ Sustainability can be your main role: \r\n‚Ä¢ Green Software Developer \r\n‚Ä¢ Sustainability Consultant \r\n‚Ä¢ Green Advocate  \r\n‚Ä¢ Founder of a Green Tech startup (B2B?)\r\n28\r\n\r\nFormat of classes\r\n‚Ä¢ In-person. \r\n‚Ä¢ Collegerama recordings. \r\n‚Ä¢ Lectures and Labs. \r\n‚Ä¢ Guest lectures. \r\n‚Ä¢ Steering meetings (after week 5, new schedule)\r\n29\r\n\r\nFormat of classes\r\n‚Ä¢ There‚Äôs no exam in this course. It‚Äôs more important that we learn how to \r\ndiscuss this topic and come up with new ideas than learning all the theory. \r\nCritical thinking over checkboxes. \r\n‚Ä¢ Mix of content and discussion \r\n‚Ä¢ Ultimately, the lectures aim to give you food for thought and the necessary \r\nknowledge to excel in Project 2. (We will talk about it later)\r\n30\r\n\r\nhttps://luiscruz.github.io/course_sustainableSE/\r\n31\r\nContent of the course üëá\r\n\r\n32\r\nhttps://mattermost.tudelft.nl/signup_user_complete/?id=1nj9tk6usjf8xmsws8wpq3s5uy&md=link&sbr=su\r\n\r\nProject 1\r\n‚Ä¢ Goal: Measure the energy consumption of software applications. \r\n‚Ä¢ Approach: energy measurement tools; use case testing. \r\n‚Ä¢ Deliverable: blog-style report (approx. 2500 words) \r\n‚Ä¢ Deadline: Week 3, Feb 28, 2025 \r\n‚Ä¢ Group size: 4‚Äì5\r\n33\r\n\r\nProject 2\r\n‚Ä¢ Goal: Create a solution/tool/technique that helps building green software. (You \r\ncan come up with your own idea or choose one from a list of suggestions). \r\n‚Ä¢ Approach: open-source software development; literature review. \r\n‚Ä¢ Deliverable: library/tool/app; paper; presentation. \r\n‚Ä¢ Two deadlines:\u2028\r\n1. Paper and software: Week 8, April 4, 2025\u2028\r\n2. Presentation: Week 9, April 11, 2025 \r\n‚Ä¢ Group size: 4‚Äì5\r\n34\r\n\r\nGuest Lectures\r\nNergis T√∂men \r\nComputer Vision lab | TU Delft \r\nWeek 4, Wed, Mar 5, 2025\r\n35\r\n\r\nCommunity \r\nHow to get involved?', 'It‚Äôs more important that we learn how to \r\ndiscuss this topic and come up with new ideas than learning all the theory. \r\nCritical thinking over checkboxes. \r\n‚Ä¢ Mix of content and discussion \r\n‚Ä¢ Ultimately, the lectures aim to give you food for thought and the necessary \r\nknowledge to excel in Project 2. (We will talk about it later)\r\n30\r\n\r\nhttps://luiscruz.github.io/course_sustainableSE/\r\n31\r\nContent of the course üëá\r\n\r\n32\r\nhttps://mattermost.tudelft.nl/signup_user_complete/?id=1nj9tk6usjf8xmsws8wpq3s5uy&md=link&sbr=su\r\n\r\nProject 1\r\n‚Ä¢ Goal: Measure the energy consumption of software applications. \r\n‚Ä¢ Approach: energy measurement tools; use case testing. \r\n‚Ä¢ Deliverable: blog-style report (approx. 2500 words) \r\n‚Ä¢ Deadline: Week 3, Feb 28, 2025 \r\n‚Ä¢ Group size: 4‚Äì5\r\n33\r\n\r\nProject 2\r\n‚Ä¢ Goal: Create a solution/tool/technique that helps building green software. (You \r\ncan come up with your own idea or choose one from a list of suggestions). \r\n‚Ä¢ Approach: open-source software development; literature review. \r\n‚Ä¢ Deliverable: library/tool/app; paper; presentation. \r\n‚Ä¢ Two deadlines:\u2028\r\n1. Paper and software: Week 8, April 4, 2025\u2028\r\n2. Presentation: Week 9, April 11, 2025 \r\n‚Ä¢ Group size: 4‚Äì5\r\n34\r\n\r\nGuest Lectures\r\nNergis T√∂men \r\nComputer Vision lab | TU Delft \r\nWeek 4, Wed, Mar 5, 2025\r\n35\r\n\r\nCommunity \r\nHow to get involved?\r\n36\r\n\r\nGreen TU\r\n‚Ä¢ https://www.tudelft.nl/sustainability/get-\r\ninvolved/greentu \r\n‚Ä¢ Student organisation at the TU Delft devoted \r\nto stimulating sustainability in education, \r\nresearch, university operations and \r\ncommunity engagement.\r\n37\r\n\r\nClimateAction.tech\r\n‚Ä¢ Great community for outreach \r\n‚Ä¢ Based on Slack  \r\n‚Ä¢ Regular meetings, talks, social events \r\n‚Ä¢ You can join as a volunteer or simply to \r\nconnect to other techies \r\n‚Ä¢ Also good to for job hunting on green tech.\r\n38\r\n\r\nClimateAction.tech\r\n39\r\n\r\nBranch magazine\r\n‚Ä¢ Stay up-to-date on sustainable tech \r\n‚Ä¢ Creativity booster \r\n‚Ä¢ Carbon-aware UI \r\n‚Ä¢ https://branch.climateaction.tech üîó\r\n40\r\n\r\nThis is the fourth edition\r\n‚Ä¢ Any feedback is welcome! Email or DM!\r\n41\r\n\r\n42\r\n\r\nCarolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nLu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\n1. Intro Class\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl', 'Interviews?) & rich \r\ndescription of outcomes focus of grading\r\nhttps://eip.pages.ewi.tudelft.nl/eip-website/queue.html\r\n\r\nC1. Compare energy consumption of docker images for \r\nML workloads.\r\n‚Ä¢ Similar to what we have seen in the lectures but for ML-specific workloads. \r\n‚Ä¢ We can reuse existing experiment replication packages.\r\n22\r\n\r\nC2. Plugin to visualize Hugging Face carbon emissions.\r\n‚Ä¢ https://huggingface.co/blog/leaderboard-emissions-\r\nanalysis \r\n‚Ä¢\r\nYoo, Taewon, et al. ""Visualizing the Carbon Intensity of Machine Learning Inference for Image Analysis on TensorFlow Hub.""\r\n\r\nC3. Plugin for ChatGPT\r\n‚Ä¢ Users seldom know how much carbon they are emitting when they interact \r\nwith chat GPT. \r\n‚Ä¢ Let‚Äôs make it transparent to the users. Browser plugin?\r\n24\r\nCO2\r\n\r\nC4. NutriScore for software libraries\r\n25\r\n‚Ä¢ NutriScore labels are not perfect but they are a good starting point! \r\n‚Ä¢ What if we could do the same thing for the energy efficiency of software. \r\n‚Ä¢ (Also open to individual or social sustainability) \r\n‚Ä¢ This work can be scoped in particular domains/ecossystems/use cases. \r\n‚Ä¢ Libraries for stats? ML? Web Dev? Cloud?\r\n\r\nC5. Add energy-awareness to existing software\r\n26\r\n‚Ä¢ Streamlit, Notebooks, JSFiddle, \r\nPyScript, zsh, etc. \r\n‚Ä¢\r\n\r\nC6 - Green Shift Left\r\n‚Ä¢ Estimate energy efficiency using static code analysis. \r\n‚Ä¢ We don‚Äôt need an accurate value. \r\n‚Ä¢ It is useful to know which code is more likely to \r\nintroduce energy hotspots and that should be \r\nreviewed with more attention. \r\n‚Ä¢ Can be scoped to a particular domain (react, php, data \r\nscience, web, etc., etc.)\r\n27\r\n\r\nC7 - Education\r\n‚Ä¢ Educational game for Software \r\nSustainability practices \r\n‚Ä¢ Purpose: use within software teams to \r\ndiscuss or learn about different sustainable \r\nIT practices: at the organisation level, \r\nsoftware, etc.\r\n28\r\nhttps://github.com/OttoKaaij/Ticket-To-Sustainability/?tab=readme-ov-file\r\n\r\nProject ideas (old)\r\n‚Ä¢ Plugin from EnergiBridge (GUI, report generator, python library, etc.) \r\n‚Ä¢ Plugin for ChatGPT (carbon emissions per chat window) \r\n‚Ä¢ Seamless measurements for AI libraries \r\n‚Ä¢ Energy patterns for Green AI \r\n‚Ä¢ Sustainable SW dev gamification \r\n‚Ä¢ Sustainability auditor for AI projects \r\n‚Ä¢ Energy Profiling of screen colour filter tools (or display settings) \r\n‚Ä¢ ‚Ä¶ you can also propose yours!\r\n\r\nhttps://edu.nl/64gpk\r\nedu.nl/64gpk', '8. Green AI\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nLu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\nCarolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl\r\n\r\n- Overview of Green AI \r\n- Large language models \r\n- Green data-centric AI \r\n- Model simplification \r\n- Hyper parameter tuning \r\n- Mixture of Experts and DeepSeek \r\n- Green AI at Meta \r\n\r\nAI\r\n‚Ä¢ Artificial Intelligence (AI) is the branch of computer science that deals with \r\nautomating tasks that typically require human intelligence. \r\n‚Ä¢ In the past years AI has been widely applied across different domains.\u2028\r\nE.g., health care, transportation, finance. \r\n‚Ä¢ To deploy AI systems, we test them against benchmarks (or validation sets). \r\n‚Ä¢ The goal is to outperform the previous existing models. \r\n‚Ä¢ E.g., in Machine Learning we usually resort to accuracy metrics. The \r\nhighest the accuracy, the better the model.\r\n3\r\n\r\nSince 2012, the amount of computing used for AI \r\ntraining has been doubling every 6 months\r\n‚Ä¢ https://epoch.ai/blog/compute-trends\r\n4\r\n\r\n‚Ä¢ To create better AI systems we are currently adding \r\n‚Ä¢ More data \r\n‚Ä¢ More experiments \r\n‚Ä¢ Larger models\r\n5\r\n\r\nThe Equation of Red AI\r\nCost(R) ‚àùE¬∑D¬∑H\r\nCost of a single (E)xample\r\nSize of (D)ataset\r\nNumber of (H)yperparameters\r\nBy Schwartz et al. (2020)\r\n\r\nIssues of Red AI\r\n‚Ä¢ High costs (hardware, electricity, data access, etc.) \r\n‚Ä¢ Limited reproducibility.  \r\n‚Ä¢ Energy consumption. \r\n‚Ä¢ Carbon emissions. \r\n‚Ä¢ SMEs can hardly be competitive. \r\n‚Ä¢ Groundbreaking AI research is mostly done by tech giants.\r\n7\r\n\r\nA few examples of Red AI\r\n‚Ä¢ Google‚Äôs BERT-large \r\n‚Ä¢ 350 million features \r\n‚Ä¢ Trained for 2.5 days using 512 TPU chips, costing $60K+ \r\n‚Ä¢ Open-GPT3 (now GPT-4/o1) \r\n‚Ä¢ 550 tonnes CO2-eq (Patterson, 2021) \r\n‚Ä¢ 175 billion features \r\n‚Ä¢ API is open but no-pretrained model is available \r\n‚Ä¢ AlphaGo \r\n‚Ä¢ 1920 CPUs, 280 GPUs, costing $35M\r\n8\r\n\r\nRed AI in Large Language Models (LLMs)\r\n‚Ä¢ OPT by Meta reports 75 tons CO2-eq (1/7 of OpenGPT‚Äôs footprint).\u2028\r\n(Also 175billion params) \r\n‚Ä¢ However, Llama 3 reported 2,290 tons of CO2-eq (7.7M GPU hours \r\ntraining ) \r\n‚Ä¢ Open science: release includes both the pretrained models and the code \r\nneeded to train and use them. \r\n‚Ä¢ DeepSeek-V3 claims ‚Äúonly‚Äù 2.78M GPU hours \r\n‚Ä¢ Bloom by Huggingface reports 25 tons, 51 when considering embodied \r\nand operational carbon footprint. (176billion params)\r\n9\r\n\r\nRed AI\r\nAccuracy: 0.999999999\r\nGreen AI\r\n‚Ä¢ Energy \r\n‚Ä¢ Time \r\n‚Ä¢ Reproducibility \r\n‚Ä¢ Reusage\r\n\r\nHow can we adopt Green AI\r\n‚Ä¢ Check whether AI is needed. \r\n‚Ä¢ Select green datacenters. \r\n‚Ä¢ Run on low carbon intensity hours. \r\n‚Ä¢ Opt for GPU-optimised solutions (?) \r\n‚Ä¢ Opt for low-power hardware (e.g., Nvidia Jetson boards) \r\n‚Ä¢ Or GPUs that provide energy metrics (e.g., NVIDIA GPUs via the nvidia-smi tool) \r\n‚Ä¢ Report energy/carbon metrics (e.g., embed in MLFlow?)', '‚Ä¢ Comparing different programming languages is not an easy task. \r\n‚Ä¢ They differ in many mechanisms: \r\n‚Ä¢ Interpreted vs Compiled \r\n‚Ä¢ Optimisations at the compiler level \r\n‚Ä¢ Virtual machine \r\n‚Ä¢ Garbage collector \r\n‚Ä¢ Available libraries\r\n30\r\n\r\nResearch Questions\r\n‚Ä¢ Can we compare the energy efficiency of software languages?  \r\n‚Ä¢ Is the faster language always the most energy efficient? \r\n‚Ä¢ How does memory usage relate to energy consumption? (We don‚Äôt cover this one) \r\n‚Ä¢ Can we automatically decide what is the best programming language \r\nconsidering energy, time, and memory usage?  \r\n‚Ä¢ How do the results of our energy consumption analysis of programming \r\nlanguages gathered from rigorous performance benchmarking solutions \r\ncompare to results of average day-to-day solutions? \u2028\r\n31\r\n\r\nMethodology\r\n\r\nThe Computer Language Benchmarks Game \r\n‚Ä¢ https://benchmarksgame-team.pages.debian.net/benchmarksgame/\r\n33\r\n\r\nProblems in the Computer Language Benchmarks Game\r\n34\r\n\r\n‚Ä¢ 27 Programming languages across different paradigms  \r\n‚Ä¢ Functional (e.g., Ocaml, F#, Haskell) \r\n‚Ä¢ Imperative (e.g., C, Go, Python) \r\n‚Ä¢ Object-oriented (e.g., C++, C#, Java) \r\n‚Ä¢ Scripting (or interpretative) (e.g., JavaScript, Python, Ruby) \r\n‚Ä¢ (These are not mutual exclusive) \r\n‚Ä¢ Intel RAPL‚Äôs C library to measure energy consumption\r\n35\r\n\r\n‚Ä¢ Execute each benchmark solution 10 times. \r\n‚Ä¢ Collect energy data and timestamps. \r\n‚Ä¢ Two-minute interval between executions\r\n36\r\n\r\n\r\n\r\n\r\nCritical thinking\r\n‚Ä¢ There is no doubt this is an excellent study. Yet, as any excellent study, there‚Äôs \r\na lot we can discuss and criticise constructively. \r\n‚Ä¢ What kind of issues you see in drawing conclusions from such a table of \r\nresults? \r\n‚Ä¢ Is the benchmark representative of the most common usage behaviour? \r\n‚Ä¢ Are the implemented solutions representative? \r\n‚Ä¢ Does it make sense to use the average to compare energy consumption \r\nacross different problems? \r\n‚Ä¢ ‚Ä¶\r\n40\r\n\r\nReproducing with Rosetta Code \r\n‚Ä¢ Rosetta Code is a programming chrestomathy repository \r\n \r\n‚Ä¢ 900 usecases/tasks solved across 700 different programming languages \r\n‚Ä¢ Purpose: if you know a programming language we can easily learn how the \r\nsame task is solved in a language you are not familiar with.\r\n41\r\n(?)\r\n\r\n\r\n\r\nRevisiting Research Questions\r\n‚Ä¢ Can we compare the energy efficiency of software languages?  \r\n‚Ä¢ Is the faster language always the most energy efficient? \r\n‚Ä¢ How does memory usage relate to energy consumption?  \r\n‚Ä¢ Can we automatically decide what is the best programming language considering \r\nenergy, time, and memory usage?  \r\n‚Ä¢ How do the results of our energy consumption analysis of programming \r\nlanguages gathered from rigorous performance benchmarking solutions \r\ncompare to results of average day-to-day solutions?  \r\n‚Ä¢ What would happen if we cherry picked the tasks?\u2028\r\n44\r\n\r\n\r\nLu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\n3. Scientific Guide for Reliable \r\nEnergy Experiments\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nCarolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl', '‚Ä¢ Improve parameter-tuning strategy.\r\n11\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ We need benchmarks. \r\n‚Ä¢ AllenAI leaderboard\u2028\r\nhttps://leaderboard.allenai.org \r\n‚Ä¢ No carbon metrics, yet \r\n‚Ä¢ Report comparable proxies for energy \r\nconsumption. \r\n‚Ä¢ ‚ö† Learning algorithms behave in a non-\r\ndeterministic \r\n‚Ä¢ ‚ö† Different data-points lead to different \r\nenergy consumption\r\n12\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ Reporting measured energy consumption \r\n‚Ä¢ + Accurate \r\n‚Ä¢ + Easy to map to carbon emissions \r\n‚Ä¢ - Hard to measure \r\n‚Ä¢ - Low replicability \r\n‚Ä¢ Reporting time / estimation based on time & hardware \r\n‚Ä¢ + Easy to measure \r\n‚Ä¢ + Correlates with energy consumption in most cases. \r\n‚Ä¢ -  Difficult to compare with measurements from other setups \r\n‚Ä¢ E.g., floating point operations (FPOs) (?) \r\n‚Ä¢ + comparable across different setups \r\n‚Ä¢ + cheap \r\n‚Ä¢ - does not factor in memory energy consumption \r\n‚Ä¢ - does not reflect carbon emissions\r\n13\r\n\r\nData-centric AI\r\n\r\nData-centric AI\r\n‚Ä¢ Emerging discipline that deals with systematically engineering data to build AI \r\nsystems. \r\n‚Ä¢ Shift from improving the training strategy to improving the data. \r\n‚Ä¢ It is better to have small but reliable datasets than large but noisy \r\ndatasets. \r\n‚Ä¢ => Improve data collection, data labelling, and data preprocessing. \r\n‚Ä¢ More about data-centric AI by Andrew Ng:\u2028\r\nhttps://www.youtube.com/watch?v=06-AZXmwHjo\r\n15\r\n\r\n\r\nGreen Data-centric AI\r\n‚Ä¢ How do different ML algorithms compare \r\nin terms of energy consumption? \r\n‚Ä¢ How does number of rows relate to the \r\nenergy consumption of ML models? \r\n‚Ä¢ How does number of features relate to \r\nthe energy consumption of ML models? \r\n‚Ä¢ What is the impact of reducing data in the \r\nperformance of the model? \r\n‚Ä¢ Method -> results -> discussion\r\n17\r\n\r\nMethod\r\n‚Ä¢ Single object of study: natural language model to detect spam messages. \r\n‚Ä¢ 6 machine learning algorithms: SVM, Decision Tree, KNN, Random Forrest, \r\nAdaBoost, Bagging Classifier. \r\n‚Ä¢ Reduce the number of rows. 10%, 20%, .., 100% \r\n‚Ä¢ Stratified random sampling (?) \r\n‚Ä¢ Reduce the number of features. 10%, 20%, .., 100% \r\n‚Ä¢ Feature importance metric based on the Chi-Square Test (Chi2) \r\n‚Ä¢ Estimate energy consumption using a RAPL-based tool. (?)\r\n18\r\n\r\n‚Ä¢ Repeat 30 times \r\n‚Ä¢ Fix random seeds \r\n‚Ä¢ ‚Ä¶ \r\n‚Ä¢ Data was not Normal => tailed Normal distribution.\r\n19\r\n(?)\r\n\r\nResults: energy consumption of algorithms\r\n\r\nResults: energy vs data shape\r\n\r\nResults: performance vs data shape\r\n\r\nDiscussion\r\n‚Ä¢ Other data properties should be investigated. \r\n‚Ä¢ E.g., data types \r\n‚Ä¢ Reporting energy data is essential. It can lead to different model selection \r\nwithout hindering model performance. \r\n‚Ä¢ There is a big opportunity in Model and Data Simplification.\r\n23\r\n\r\nData/Model Simplification\r\n‚Ä¢ (?) \r\n‚Ä¢ Data selection \r\n‚Ä¢ Data quantisation. Posit? \r\n‚Ä¢ Data distillation \r\n‚Ä¢ Coreset extraction (?) \r\n‚Ä¢ Model distillation \r\n‚Ä¢ Model quantisation \r\n‚Ä¢ Model pruning \r\n‚Ä¢ ‚Ä¶\r\n24\r\n\r\nPosit vs Float\r\nMore about this: https://spectrum.ieee.org/floating-point-numbers-posits-processor\r\nBetter for DL use cases\r\n\r\nHow can we tune \r\nlearning \r\nparameters \r\nefficiently?\r\n\r\nHyper parameter tuning\r\n‚Ä¢ When training an ML model, there are several parameters that need to be \r\ntuned. \r\n‚Ä¢ E.g., in SVM we have the Regularization parameter C, the kernel function, \r\nthe degree of the kernel function, and depending on the case, many other. \r\n‚Ä¢ The common approach revolves around grid search.', 'Different \r\nscreen brightness, different results. \r\n‚Ä¢ You need to reduce tasks to the bare minimum: \r\n‚Ä¢ Set brightness to a fixed value; turn off notifications, kill all user-owned \r\nprocesses, turn off cellular data, bluetooth, location services, account \r\nsyncs; uninstall all unnecessary apps, etc.\r\n11\r\n\r\nWhen it comes to desktop/cloud software, the sources \r\nof noise are different but the same concerns apply. \r\n \r\nEach case is different ‚Äì think it through!\r\n‚ö†\r\n\r\nEnergy Profilers\r\n‚Ä¢ Simple setup! Quite reliable (if you choose the profiler wisely). \r\n‚Ä¢ Recently, they are starting to rely on internal power sensors. \r\n‚Ä¢ Still sensitive to noise from concurrent processes/tasks! ‚ö†\r\n13\r\n\r\nExamples of Energy Profilers\r\n\r\n15\r\nhttps://www.websitecarbon.com\r\n\r\n16\r\nhttps://mlco2.github.io/impact/\r\n\r\nIntel Power Monitor\r\n‚Ä¢ Install: https://software.intel.com/content/www/us/en/\r\ndevelop/articles/intel-power-gadget.html \r\n‚Ä¢ To collect: Logging > Log to File \r\n \r\n‚Ä¢ It will store a CSV file with all the collected power data. \r\n(File location is specified in the settings) \r\n‚Ä¢ Based on Intel RAPL. Works with Intel-based Windows \r\nand Macs. \r\n‚Ä¢ Alternative-twin for M1-based Macs: Mx Power Gadget.\u2028\r\nhttps://www.seense.com/menubarstats/mxpg/\r\n17\r\n‚ö† No longer supported by Intel ‚ö†  \r\n\r\n18\r\nüîó https://luiscruz.github.io/\r\n2021/07/20/measuring-energy.html\r\n(Missing Apple m1 tools: mxpg, powermetrics)\r\n\r\n19\r\nEnergiBridge\r\nhttps://github.com/tdurieux/energibridge\r\n> target/release/energibridge -o results.csv --summary sleep 10\r\n\r\nHands-on 1\r\n‚Ä¢ Install your energy profiler (EnergiBridge). \r\n‚Ä¢ Collect the energy data of using Coral BodyPix for 30 seconds.\u2028\r\nhttps://storage.googleapis.com/tfjs-models/demos/body-pix/index.html \r\n‚Ä¢ Report the total energy consumption. \r\n‚Ä¢ Extra-mile: \r\n‚Ä¢ Compare the energy consumption in different browsers. \r\n‚Ä¢ Check the spikes and drops in Power and Temperature.\r\n20\r\n\r\nRetrospection\r\nHands-on 1\r\n‚Ä¢ Are the measurements repeatable? \r\n‚Ä¢ What were the confounding factors? \r\n‚Ä¢ How can we automate this process?\r\n21\r\n\r\nEnergy testing\r\n(Different from energy monitoring)\r\n1. Create a reproducible scenario of the execution of your software. Preferably \r\nthis should be an automated script ‚Äì e.g., using a bash or python script. \r\n2. Execute the scenario in a version of your software. Use the energy profiler to \r\nmeasure the energy consumption. \r\n3. Improve your software in parts of the code that you suspect have low \r\nperformance. \r\n4. Execute the same scenario with the new version. Compare the energy data \r\nin this version with the previous one.\u2028\r\nEnergy is lower, test passes; energy is higher test fails.\r\n22\r\n\r\nHands-on 2\r\n‚Ä¢ Create a reproducible scenario. (Usually easier with command-line interfaces) \r\n‚Ä¢ Automatically start/stop energy profiling.\r\n23\r\n\r\nProject 1\r\n‚Ä¢ Deadline: March 1 \r\n‚Ä¢  Compare energy consumption in common software use cases. \r\n‚Ä¢ Examples: \r\n‚Ä¢ Different versions of the same app; \r\n‚Ä¢ Same use case but different apps \r\n‚Ä¢ Same version, same app, but different user settings (e.g., enable/disable GPU optimisation) \r\n‚Ä¢ Same version, same app, but different running environment \r\n‚Ä¢ Submission via PR (markdown). \r\n‚Ä¢ Blog-style report (markdown, approx 2500 words). \r\n‚Ä¢ Replication package. \r\n‚Ä¢ Points if the experiment is automated.', '‚Ä¢ Collect the energy data of using Coral BodyPix for 30 seconds.\u2028\r\nhttps://storage.googleapis.com/tfjs-models/demos/body-pix/index.html \r\n‚Ä¢ Report the total energy consumption. \r\n‚Ä¢ Extra-mile: \r\n‚Ä¢ Compare the energy consumption in different browsers. \r\n‚Ä¢ Check the spikes and drops in Power and Temperature.\r\n20\r\n\r\nRetrospection\r\nHands-on 1\r\n‚Ä¢ Are the measurements repeatable? \r\n‚Ä¢ What were the confounding factors? \r\n‚Ä¢ How can we automate this process?\r\n21\r\n\r\nEnergy testing\r\n(Different from energy monitoring)\r\n1. Create a reproducible scenario of the execution of your software. Preferably \r\nthis should be an automated script ‚Äì e.g., using a bash or python script. \r\n2. Execute the scenario in a version of your software. Use the energy profiler to \r\nmeasure the energy consumption. \r\n3. Improve your software in parts of the code that you suspect have low \r\nperformance. \r\n4. Execute the same scenario with the new version. Compare the energy data \r\nin this version with the previous one.\u2028\r\nEnergy is lower, test passes; energy is higher test fails.\r\n22\r\n\r\nHands-on 2\r\n‚Ä¢ Create a reproducible scenario. (Usually easier with command-line interfaces) \r\n‚Ä¢ Automatically start/stop energy profiling.\r\n23\r\n\r\nProject 1\r\n‚Ä¢ Deadline: March 1 \r\n‚Ä¢  Compare energy consumption in common software use cases. \r\n‚Ä¢ Examples: \r\n‚Ä¢ Different versions of the same app; \r\n‚Ä¢ Same use case but different apps \r\n‚Ä¢ Same version, same app, but different user settings (e.g., enable/disable GPU optimisation) \r\n‚Ä¢ Same version, same app, but different running environment \r\n‚Ä¢ Submission via PR (markdown). \r\n‚Ä¢ Blog-style report (markdown, approx 2500 words). \r\n‚Ä¢ Replication package. \r\n‚Ä¢ Points if the experiment is automated.\r\n24\r\n\r\nGroup registration\r\n‚Ä¢ Brightspace > Collaboration > Groups and sign up for one of the groups \r\nunder ""Project Groups (P1 and P2)""  \r\n‚Ä¢ If you are looking for a group or teamembers, use the mattermost channel \r\n‚Äú~Searching-group-members‚Äù. \r\n‚Ä¢ The deadline for self-registering as a group is end of this week, so by Sunday, \r\n16th of February, 23:59. \r\n‚Ä¢ We might do final adjustments afterwards.\r\n25\r\n\r\n26\r\nKay Singh. Apple Silicon M1 Power Consumption Deep Dive Part 1: Safari vs Chrome\u2028\r\nhttps://singhkays.com/blog/apple-silicon-m1-video-power-consumption-pt-1/\r\n(For project 1, you don‚Äôt need to dive deep into hardware details)\r\n\r\n27', 'google.com/view/energy-efficiency-languages\r\n21\r\nAna Radovanovic ÃÅ, Ross Koningstein, Ian Schneider, Bokan \r\nChen, Alexandre Duarte, Binz Roy, Diyue Xiao, Maya \r\nHaridasan, Patrick Hung, Nick Care, Saurav Talukdar, Eric \r\nMullen, Kendal Smith, MariEllen Cottman, and Walfredo Cirne \r\n\r\n\r\n‚Ä¢ Google‚Äôs Carbon-Intelligent Computing System (CICS) \r\n‚Ä¢ Main idea: use carbon-intensity data to shift datacenter jobs in time \r\n‚Ä¢ Typically, job schedulers use a metric of cluster capacity to schedule a job in \r\na particular cluster. \r\n‚Ä¢ CICS overrides this metric with the virtual capacity curve (VCC) that \r\nfactors in Carbon intensity \r\n‚Ä¢ When a new job comes in, the scheduler estimates its CPU load and power \r\nusage and assigns it to a cluster if the VCC is not exceeded.\r\n23\r\n\r\n‚Ä¢ Jobs are divided between flexible and inflexible. \r\n‚Ä¢ Flexible load is considered shapeable/shiftable as long as its total daily \r\ncompute (CPU) demand is preserved \r\n‚Ä¢ The system needs to consider that, while running a job, the virtual capacity \r\ncurve (VCC) might drop. Hence, this job should not start in the first place. \r\n‚Ä¢ They forecast VCC for the next day\r\n24\r\n\r\n\r\nVirtual Cluster Capacity (VCC)\r\n‚Ä¢ Aims at reducing the peak load at carbon intensive hours but in total it should allow for the \r\nsome amount of daily computation! \r\n‚Ä¢ Considers Carbon intensity \r\n‚Ä¢ Using data from electricityMap.org \r\n‚Ä¢ It does not use carbon intensity directly.\u2028\r\nCarbon intensity is converted to a cost (kgCO2 -> $$) \r\n‚Ä¢ This way, they can factor in other metrics that can also be converted to money. E.g., the \r\ncost saved by preventing peak load \r\n‚Ä¢ Peak workload entails extra cost at the infrastructure level (e.g., control faclities‚Äô \r\ntemperature). \r\n‚Ä¢ By using money cost instead of carbon cost, they have more data available.\r\n26\r\n\r\nVirtual Cluster Capacity (VCC)\r\n‚Ä¢ If the forecast of VCC fails it shift flexible workload more than expected.  \r\n‚Ä¢ This happens because the amount of workload forecasted was below the \r\nworkload needed, and VCC was ‚Äúaggressively‚Äù low. \r\n‚Ä¢ The systems fall back to the real cluster capacity for 1 week until results \r\nstart being realistic again.\r\n27\r\n\r\nNext steps\r\n‚Ä¢ They will consider spatial flexibility. \r\n‚Ä¢ I.e., tasks that can be shifted over time and over space. \r\n‚Ä¢ It needs to factor in relocation overheads, though.\r\n28\r\n\r\nCritical questions\r\n‚Ä¢ Who defines what is flexible and inflexible? \r\n‚Ä¢ How do you estimate the CPU load of a given task?\r\n29\r\n\r\nEnergy Regression Testing\r\n‚ÜíEnergy?\r\nGreener? Greener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\n\r\nE-compare\r\nGithub Actions\r\n‚ûú https://koenhagen.github.io/E-Compare/\r\n\r\nEnergy Regression Testing \r\n\r\n4. Debugging Energy with \r\nDocker Images\r\n\r\nUnveiling the Energy Vampires \r\nA methodology for debugging Software \r\nEnergy Consumption\r\n ‚úÖ ICSE 2025\r\n\r\nData Centers and Docker\r\n‚Ä¢ Containers are the most popular way to deploy apps into the cloud \r\n‚Ä¢ Base image is an important choice when building an image \r\n‚Ä¢ Criteria \r\n‚Ä¢ Linux distribution and binaries \r\n‚Ä¢ Image size \r\n‚Ä¢ Energy?\r\n35\r\n\r\nRedis energy consumption\r\n‚Ä¢ Ubuntu/Alpine base images have different energy consumption for Redis\r\n36\r\n\r\nRedis Energy Consumption\r\n‚Ä¢RQ1: What is the difference \r\nin energy consumption \r\nbetween glibc and musl? \r\n‚Ä¢RQ2: Can we use tracing \r\nto compare energy \r\nconsumption in shared \r\nlibraries?', '‚Ä¢ Groundbreaking AI research is mostly done by tech giants.\r\n7\r\n\r\nA few examples of Red AI\r\n‚Ä¢ Google‚Äôs BERT-large \r\n‚Ä¢ 350 million features \r\n‚Ä¢ Trained for 2.5 days using 512 TPU chips, costing $60K+ \r\n‚Ä¢ Open-GPT3 (now GPT-4/o1) \r\n‚Ä¢ 550 tonnes CO2-eq (Patterson, 2021) \r\n‚Ä¢ 175 billion features \r\n‚Ä¢ API is open but no-pretrained model is available \r\n‚Ä¢ AlphaGo \r\n‚Ä¢ 1920 CPUs, 280 GPUs, costing $35M\r\n8\r\n\r\nRed AI in Large Language Models (LLMs)\r\n‚Ä¢ OPT by Meta reports 75 tons CO2-eq (1/7 of OpenGPT‚Äôs footprint).\u2028\r\n(Also 175billion params) \r\n‚Ä¢ However, Llama 3 reported 2,290 tons of CO2-eq (7.7M GPU hours \r\ntraining ) \r\n‚Ä¢ Open science: release includes both the pretrained models and the code \r\nneeded to train and use them. \r\n‚Ä¢ DeepSeek-V3 claims ‚Äúonly‚Äù 2.78M GPU hours \r\n‚Ä¢ Bloom by Huggingface reports 25 tons, 51 when considering embodied \r\nand operational carbon footprint. (176billion params)\r\n9\r\n\r\nRed AI\r\nAccuracy: 0.999999999\r\nGreen AI\r\n‚Ä¢ Energy \r\n‚Ä¢ Time \r\n‚Ä¢ Reproducibility \r\n‚Ä¢ Reusage\r\n\r\nHow can we adopt Green AI\r\n‚Ä¢ Check whether AI is needed. \r\n‚Ä¢ Select green datacenters. \r\n‚Ä¢ Run on low carbon intensity hours. \r\n‚Ä¢ Opt for GPU-optimised solutions (?) \r\n‚Ä¢ Opt for low-power hardware (e.g., Nvidia Jetson boards) \r\n‚Ä¢ Or GPUs that provide energy metrics (e.g., NVIDIA GPUs via the nvidia-smi tool) \r\n‚Ä¢ Report energy/carbon metrics (e.g., embed in MLFlow?) \r\n‚Ä¢ Use pre-trained models (Transfer Learning) \r\n‚Ä¢ Preprocess dataset to reduce size. \r\n‚Ä¢ Improve parameter-tuning strategy.\r\n11\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ We need benchmarks. \r\n‚Ä¢ AllenAI leaderboard\u2028\r\nhttps://leaderboard.allenai.org \r\n‚Ä¢ No carbon metrics, yet \r\n‚Ä¢ Report comparable proxies for energy \r\nconsumption. \r\n‚Ä¢ ‚ö† Learning algorithms behave in a non-\r\ndeterministic \r\n‚Ä¢ ‚ö† Different data-points lead to different \r\nenergy consumption\r\n12\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ Reporting measured energy consumption \r\n‚Ä¢ + Accurate \r\n‚Ä¢ + Easy to map to carbon emissions \r\n‚Ä¢ - Hard to measure \r\n‚Ä¢ - Low replicability \r\n‚Ä¢ Reporting time / estimation based on time & hardware \r\n‚Ä¢ + Easy to measure \r\n‚Ä¢ + Correlates with energy consumption in most cases. \r\n‚Ä¢ -  Difficult to compare with measurements from other setups \r\n‚Ä¢ E.g., floating point operations (FPOs) (?) \r\n‚Ä¢ + comparable across different setups \r\n‚Ä¢ + cheap \r\n‚Ä¢ - does not factor in memory energy consumption \r\n‚Ä¢ - does not reflect carbon emissions\r\n13\r\n\r\nData-centric AI\r\n\r\nData-centric AI\r\n‚Ä¢ Emerging discipline that deals with systematically engineering data to build AI \r\nsystems. \r\n‚Ä¢ Shift from improving the training strategy to improving the data. \r\n‚Ä¢ It is better to have small but reliable datasets than large but noisy \r\ndatasets. \r\n‚Ä¢ => Improve data collection, data labelling, and data preprocessing. \r\n‚Ä¢ More about data-centric AI by Andrew Ng:\u2028\r\nhttps://www.youtube.com/watch?v=06-AZXmwHjo\r\n15\r\n\r\n\r\nGreen Data-centric AI\r\n‚Ä¢ How do different ML algorithms compare \r\nin terms of energy consumption? \r\n‚Ä¢ How does number of rows relate to the \r\nenergy consumption of ML models? \r\n‚Ä¢ How does number of features relate to \r\nthe energy consumption of ML models? \r\n‚Ä¢ What is the impact of reducing data in the \r\nperformance of the model?', '‚Ä¢ By using money cost instead of carbon cost, they have more data available.\r\n26\r\n\r\nVirtual Cluster Capacity (VCC)\r\n‚Ä¢ If the forecast of VCC fails it shift flexible workload more than expected.  \r\n‚Ä¢ This happens because the amount of workload forecasted was below the \r\nworkload needed, and VCC was ‚Äúaggressively‚Äù low. \r\n‚Ä¢ The systems fall back to the real cluster capacity for 1 week until results \r\nstart being realistic again.\r\n27\r\n\r\nNext steps\r\n‚Ä¢ They will consider spatial flexibility. \r\n‚Ä¢ I.e., tasks that can be shifted over time and over space. \r\n‚Ä¢ It needs to factor in relocation overheads, though.\r\n28\r\n\r\nCritical questions\r\n‚Ä¢ Who defines what is flexible and inflexible? \r\n‚Ä¢ How do you estimate the CPU load of a given task?\r\n29\r\n\r\nEnergy Regression Testing\r\n‚ÜíEnergy?\r\nGreener? Greener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\n\r\nE-compare\r\nGithub Actions\r\n‚ûú https://koenhagen.github.io/E-Compare/\r\n\r\nEnergy Regression Testing \r\n\r\n4. Debugging Energy with \r\nDocker Images\r\n\r\nUnveiling the Energy Vampires \r\nA methodology for debugging Software \r\nEnergy Consumption\r\n ‚úÖ ICSE 2025\r\n\r\nData Centers and Docker\r\n‚Ä¢ Containers are the most popular way to deploy apps into the cloud \r\n‚Ä¢ Base image is an important choice when building an image \r\n‚Ä¢ Criteria \r\n‚Ä¢ Linux distribution and binaries \r\n‚Ä¢ Image size \r\n‚Ä¢ Energy?\r\n35\r\n\r\nRedis energy consumption\r\n‚Ä¢ Ubuntu/Alpine base images have different energy consumption for Redis\r\n36\r\n\r\nRedis Energy Consumption\r\n‚Ä¢RQ1: What is the difference \r\nin energy consumption \r\nbetween glibc and musl? \r\n‚Ä¢RQ2: Can we use tracing \r\nto compare energy \r\nconsumption in shared \r\nlibraries? \r\n‚Ä¢RQ3: Can we verify the \r\norigin of energy \r\nconsumption differences by \r\nrecreating the workload \r\nbehavior closely?\r\n37\r\n\r\nTracing\r\n‚Ä¢ Find libc function running at the end of the benchmark \r\n‚Ä¢ Tracing: Capture calls made to libc \r\n‚Ä¢ Introduces non-linear overhead\r\n38\r\n\r\nSynchronization\r\n‚Ä¢ Tracing slows down execution and increase energy consumption \r\n‚Ä¢ Run separately and synchronize with logs\r\n39\r\n\r\nTracing Analysis\r\n40\r\n\r\nTracing Analysis\r\n41\r\n\r\nBenchmarking memcpy\r\n‚Ä¢ Copy bytes from one part of memory to \r\nanother \r\n‚Ä¢ Depending on function parameters, different \r\nassembly-level optimizations \r\n‚Ä¢ Some not included in musl\r\n42\r\n\r\nBenchmarking memcpy\r\n‚Ä¢ Copy 4 bytes from fixed \r\npointer to moving pointer \r\n‚Ä¢ (100,300,500,600) x 1M \r\nrequests \r\n‚Ä¢  15% more power and 3X time\r\n43\r\n\r\nConclusions\r\n‚Ä¢ Significant difference in energy consumption for memcpy \r\n‚Ä¢ 8.6% difference for Redis workload and 13% in our benchmark \r\n‚Ä¢ musl trades performance for a smaller codebase \r\n‚Ä¢ No official documentation \r\n‚Ä¢ No awareness about energy performance\r\n44\r\n\r\n5. Energy Efficiency vs Code \r\nQuality\r\n\r\nMeasuring Maintainability\r\n‚Ä¢ According to ISO/IEC 25010, Maintainability is ‚Äúthe degree of \r\neffectiveness and efficiency with which a software product or \r\nsystem can be modified to improve it, correct it or adapt it to \r\nchanges in environment, and in requirements‚Äù \r\n‚Ä¢ We use the code analysis tool Better Code Hub to assess \r\nmaintainability \r\n‚Ä¢ Better Code Hub maps the ISO/IEC 25010 standard on \r\nmaintainability into a set of guidelines derived from static analysis\r\n46\r\n\r\nMaintainability of Energy Changes\r\n‚Ä¢ What is the impact of making energy-oriented code changes on \r\nthe maintainability of mobile apps?', 'Carolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nLu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\n1. Intro Class\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl\r\n\r\n1. Intro to Sustainable SE \r\n2. Intro to the course\r\n2\r\n\r\nof the electricity consumed worldwide \r\nby 2040 will stem from ICT\r\n14%\r\n\r\n4\r\nhttps://xkcd.com/1007/\r\n\r\nBuzz words\r\n‚Ä¢ Eco-friendly \r\n‚Ä¢ Climate change, action, adaption \r\n‚Ä¢ Energy efficiency \r\n‚Ä¢ Environmental-responsible \r\n‚Ä¢ Carbon-neutral; Climate-neutral; Net zero \r\n‚Ä¢ Carbon-offsetting \r\n‚Ä¢ Carbon-free \r\n‚Ä¢ Clean technology \r\n‚Ä¢ E-waste\r\n5\r\n\r\nhttps://www.menti.com/uns9d89kzn\r\nWhat is Sustainable \r\nSoftware Engineering?\r\n?\r\n6\r\n\r\nSustainable Software \r\nEngineering is‚Ä¶\r\n7\r\n‚Ä¶the discipline that studies the process of creating software systems that are able \r\nto create value in the long term without hindering its surrounding environment.\r\n\r\n8\r\nEconomical\r\nSocial\r\nTechnical\r\nIndividual\r\nEnvironmental\r\nSustainable\r\nSoftware\r\nEngineering\r\n‚≠ê\r\nTechnical\u2028\r\n‚öô\r\nEconomical\u2028\r\nüí∞\r\nSocial\u2028\r\nüë©üíºüë®üíºüë©üíºüë©üíº\r\nIndividual\u2028\r\nüë©üíª\r\nEnvironmental\u2028\r\nüå±\r\nSustainable\u2028\r\nSoftware \r\nEngineering\r\n\r\nEconomical\r\n‚Ä¢ Focused on assets, capital and added value\u2028\r\n(wealth creation, prosperity, profitability, capital \r\ninvestment, income, etc.) \r\n‚Ä¢ Nr of customers  \r\n‚Ä¢ Man-day-rate estimate \r\n‚Ä¢ Next round of funding \r\n‚Ä¢ Meet requirements in the contract\r\n9\r\n\r\nTechnical\r\n‚Ä¢ Longevity of information, systems, and infrastructure and their \r\nadequate evolution with changing surrounding conditions. \r\n‚Ä¢ Examples: \r\n‚Ä¢ Technical Debt \r\n‚Ä¢ Does it scale? \r\n‚Ä¢ Software testing \r\n‚Ä¢ Bus-factor \r\n‚Ä¢ Data integrity \r\n‚Ä¢ Innovation \r\n‚Ä¢ ‚Ä¶\r\n10\r\n\r\nIndividual\r\n‚Ä¢ Well-being of the individuals in an organisation.\u2028\r\nNote that it also includes how well individuals interact \r\nwith each other within the org. \r\n‚Ä¢ Examples: \r\n‚Ä¢ mental and physical well-being \r\n‚Ä¢ self-respect \r\n‚Ä¢ education/skills \r\n‚Ä¢ career development \r\n‚Ä¢ ‚Ä¶\r\n11\r\n\r\nSocial\r\n‚Ä¢ concerned with societal communities (groups of people, \r\norganisations) and the factors that erode trust in society. \r\n‚Ä¢ Examples: \r\n‚Ä¢ Social equity \r\n‚Ä¢ Justice \r\n‚Ä¢ Employment \r\n‚Ä¢ Democracy \r\n‚Ä¢ ‚Ä¶ \r\n‚Ä¢ Also includes compliance with policies and regulations \r\n12\r\n\r\nEnvironmental Sustainability\r\n‚Ä¢ the branch of Software Engineering that studies \r\nthe development of software that has minimal \r\nimpact in our planet throughout its whole \r\nlifecycle. \r\n‚Ä¢ Looking at software at different levels: \r\n‚Ä¢ Developing, Using, Serving, ‚Ä¶ \r\n‚Ä¢ Also includes e-waste. \r\n‚Ä¢ Almost identical to Green Software. (?)\r\n13\r\nBordallo II\r\n\r\nGreen Software\r\n‚Ä¢ Sustainability and energy efficiency. \r\n‚Ä¢ Building energy-efficient software is important also from a \r\ntechnical sustainability POV. \r\n‚Ä¢ Smartphones, smart wearables, IoT devices, etc. run on limited \r\npower resources. \r\n‚Ä¢ Developing software to these devices require energy-efficiency \r\ntesting and improvement. \r\n‚Ä¢ It also leads to environmental sustainability (e.g., less battery \r\ncycles) \r\n‚Ä¢ Important for UX (e.g., no need to walk around with power banks)\r\n14\r\n\r\nhttps://www.menti.com/uns9d89kzn\r\nWhat is the sustainability \r\ndimension you are most \r\ninterested in?\r\n?', '‚Ä¢RQ3: Can we verify the \r\norigin of energy \r\nconsumption differences by \r\nrecreating the workload \r\nbehavior closely?\r\n37\r\n\r\nTracing\r\n‚Ä¢ Find libc function running at the end of the benchmark \r\n‚Ä¢ Tracing: Capture calls made to libc \r\n‚Ä¢ Introduces non-linear overhead\r\n38\r\n\r\nSynchronization\r\n‚Ä¢ Tracing slows down execution and increase energy consumption \r\n‚Ä¢ Run separately and synchronize with logs\r\n39\r\n\r\nTracing Analysis\r\n40\r\n\r\nTracing Analysis\r\n41\r\n\r\nBenchmarking memcpy\r\n‚Ä¢ Copy bytes from one part of memory to \r\nanother \r\n‚Ä¢ Depending on function parameters, different \r\nassembly-level optimizations \r\n‚Ä¢ Some not included in musl\r\n42\r\n\r\nBenchmarking memcpy\r\n‚Ä¢ Copy 4 bytes from fixed \r\npointer to moving pointer \r\n‚Ä¢ (100,300,500,600) x 1M \r\nrequests \r\n‚Ä¢  15% more power and 3X time\r\n43\r\n\r\nConclusions\r\n‚Ä¢ Significant difference in energy consumption for memcpy \r\n‚Ä¢ 8.6% difference for Redis workload and 13% in our benchmark \r\n‚Ä¢ musl trades performance for a smaller codebase \r\n‚Ä¢ No official documentation \r\n‚Ä¢ No awareness about energy performance\r\n44\r\n\r\n5. Energy Efficiency vs Code \r\nQuality\r\n\r\nMeasuring Maintainability\r\n‚Ä¢ According to ISO/IEC 25010, Maintainability is ‚Äúthe degree of \r\neffectiveness and efficiency with which a software product or \r\nsystem can be modified to improve it, correct it or adapt it to \r\nchanges in environment, and in requirements‚Äù \r\n‚Ä¢ We use the code analysis tool Better Code Hub to assess \r\nmaintainability \r\n‚Ä¢ Better Code Hub maps the ISO/IEC 25010 standard on \r\nmaintainability into a set of guidelines derived from static analysis\r\n46\r\n\r\nMaintainability of Energy Changes\r\n‚Ä¢ What is the impact of making energy-oriented code changes on \r\nthe maintainability of mobile apps? \r\nMaintainability \r\nDifference \r\nvE-2\r\nvE-1\r\nvE\r\nEnergy \r\nCommit\r\nvE+1\r\nM(vE-1)\r\nM(vE)\r\nParent \r\nCommit\r\n‚àÜM\r\n47\r\n\r\nThreshold Marks\r\n48\r\n\r\nBetter Code Hub\r\nMaintainability\r\nCombine\r\ndatasets\r\nEnergy\r\nCommits\r\nBaseline\r\nCommits\r\nBao et al. \r\n(2015)\r\nMoura et al. \r\n(2016)\r\nCruz et al. \r\n(2018)\r\nCruz et al. \r\n(2019)\r\nEnergy Code Changes \r\nDataset\r\n539 commits\u2028\r\nfrom 306 mobile apps\r\n539 baseline commits\u2028\r\nfrom 306 mobile apps\r\n49\r\n\r\nImpact of energy changes on \r\nmaintainability\r\n50\r\n\r\nWhich energy \r\npatterns are more \r\nlikely to affect \r\nmaintainability?\r\n51\r\n\r\nTypical maintainability issue I\r\nhttps://github.com/einmalfel/PodListen/commit/2ed5a65\r\n4 changed files with 28 additions and 0 deletions.\r\n‚Ä¶\r\n‚Ä¶\r\n52\r\n\r\nTypical maintainability issue II\r\nhttps://github.com/mozilla/MozStumbler/commit/6ea0268\r\n5 changed files with 66 additions and 14 deletions.\r\n53\r\n\r\n54', 'Neuromorphic computing\r\nCS4575\r\nSustainable Software Engineering\r\n05.03.2025\r\nNergis T√∂men\r\n\r\nIntroduction\r\nComputer Vision Lab\r\nBiomorphic Intelligence Lab\r\nBiomedical Intervention Optimisation Lab\r\nNergis\r\n\r\nNeuromorphic computing\r\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\r\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\r\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing\r\n\r\nHow many of you are familiar \r\nwith neural networks?\r\n\r\nSimple model of an artificial neuron\r\nhttps://medium.com/@cprasenjit32/perceptron-a-simple-yet-mighty-machine-learning-algorithm-9ff6b7d86a71\r\n\r\nWhat is a neural network?\r\nhttps://www.tibco.com/reference-center/what-is-a-neural-network\r\n\r\nWhy is it called a \'neural network\'?\r\nhttps://www.tibco.com/reference-center/what-is-a-neural-network\r\n\r\nWhat is a neural network?\r\nWhy is it called a \'neural network\'?\r\nMcCulloch-Pitts neuron [1, 2] (1943)\r\nWarren Sturgis McCulloch\r\n(Neurophysiologist)\r\nWalter Pitts\r\n(Logician)\r\n\r\nHow do biological neurons work?\r\nhttps://commons.wikimedia.org/wiki/File:Coincidence_detection_in_dendrites_of_pyramidal_neurons.gif\r\n\'Input current\' travels down the dendrites (top),\r\nget integrated (summed!) in the cell body\r\nwhich generates an \'output current\' (bottom)\r\nwhich is chemically transmitted to the dendrites of \r\nother neurons.\r\n\r\nSimplified picture\r\nReal neuron\r\nArtificial neuron\r\nhttps://vajiramandravi.com/quest-upsc-notes/artificial-neural-network/\r\n\r\nWhat is a neural network?\r\nMcCulloch-Pitts neuron [1, 2]\r\n1940s: How do biological neurons compute basic \r\nlogic functions? (e.g. logic gates)\r\nNote: Ref. [3] gives a nice brief history on the ideas which lead to the \r\nMcCulloch-Pitts neuron.\r\n\r\nWhat is a neural network?\r\n1950s: How are neurons organized to perform \r\nsensory perception?\r\n\r\nWhat is a neural network?\r\n1950s: How are neurons organized to perform \r\nsensory perception?\r\nThe first ""neural network"": Perceptron (1958). [4]\r\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\r\nFrank Rosenblatt (Psychologist)\r\nwith a Mark I Perceptron computer in 1960\r\n\r\nWhat is a neural network?\r\n1950s: How are neurons organized to perform \r\nsensory perception?\r\nThe first ""neural network"": Perceptron (1958). [4]\r\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\r\nFrank Rosenblatt (Psychologist)\r\nwith a Mark I Perceptron computer in 1960\r\nPower-efficient\r\n\r\nNeuromorphic computing\r\nWhy neuromorphic computing?\r\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\r\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\r\n\r\nNeuromorphic computing\r\nWhy neuromorphic computing?\r\n‚ÄòBiological inspiration‚Äô for artificial neural networks (ANNs) is not a new idea.\r\nEmulation (as opposed to simulation) of neural networks in hardware is not a new idea.', '‚Ä¢ Examples: \r\n‚Ä¢ Technical Debt \r\n‚Ä¢ Does it scale? \r\n‚Ä¢ Software testing \r\n‚Ä¢ Bus-factor \r\n‚Ä¢ Data integrity \r\n‚Ä¢ Innovation \r\n‚Ä¢ ‚Ä¶\r\n10\r\n\r\nIndividual\r\n‚Ä¢ Well-being of the individuals in an organisation.\u2028\r\nNote that it also includes how well individuals interact \r\nwith each other within the org. \r\n‚Ä¢ Examples: \r\n‚Ä¢ mental and physical well-being \r\n‚Ä¢ self-respect \r\n‚Ä¢ education/skills \r\n‚Ä¢ career development \r\n‚Ä¢ ‚Ä¶\r\n11\r\n\r\nSocial\r\n‚Ä¢ concerned with societal communities (groups of people, \r\norganisations) and the factors that erode trust in society. \r\n‚Ä¢ Examples: \r\n‚Ä¢ Social equity \r\n‚Ä¢ Justice \r\n‚Ä¢ Employment \r\n‚Ä¢ Democracy \r\n‚Ä¢ ‚Ä¶ \r\n‚Ä¢ Also includes compliance with policies and regulations \r\n12\r\n\r\nEnvironmental Sustainability\r\n‚Ä¢ the branch of Software Engineering that studies \r\nthe development of software that has minimal \r\nimpact in our planet throughout its whole \r\nlifecycle. \r\n‚Ä¢ Looking at software at different levels: \r\n‚Ä¢ Developing, Using, Serving, ‚Ä¶ \r\n‚Ä¢ Also includes e-waste. \r\n‚Ä¢ Almost identical to Green Software. (?)\r\n13\r\nBordallo II\r\n\r\nGreen Software\r\n‚Ä¢ Sustainability and energy efficiency. \r\n‚Ä¢ Building energy-efficient software is important also from a \r\ntechnical sustainability POV. \r\n‚Ä¢ Smartphones, smart wearables, IoT devices, etc. run on limited \r\npower resources. \r\n‚Ä¢ Developing software to these devices require energy-efficiency \r\ntesting and improvement. \r\n‚Ä¢ It also leads to environmental sustainability (e.g., less battery \r\ncycles) \r\n‚Ä¢ Important for UX (e.g., no need to walk around with power banks)\r\n14\r\n\r\nhttps://www.menti.com/uns9d89kzn\r\nWhat is the sustainability \r\ndimension you are most \r\ninterested in?\r\n?\r\n15\r\n\r\nEconomical sustainability tops the environment\r\n‚Ä¢ In general, a software project will not survive if it‚Äôs not economical \r\nsustainable \r\n‚Ä¢ Yet, a project can survive even if it is not environmental sustainable \r\n‚Ä¢ The mindset is changing! \r\n‚Ä¢ Software consumers have started to worry about the climate impact \r\nof their behaviour as users. \r\n‚Ä¢ Being environmentally sustainable is now an important competitive \r\nfactor \r\n‚Ä¢ Marketing teams are already using all eco-friendly labels. Technical \r\nteams are not there yet, though. \r\n‚Ä¢ It‚Äôs easier said than done!\r\n$\r\n16\r\n\r\nGreen Washing\r\n‚Ä¢ Deceptively use marketing techniques to \r\nclaim being eco-friendly. \r\n‚Ä¢ Opting for green-coloured designs. \r\n‚Ä¢ Red/orange is usually perceived as \r\ntasty. \r\n‚Ä¢ Green is perceived as eco-friendly. \r\n‚Ä¢ The VW case. (?)\r\n17\r\n\r\nThe VW scandal\r\nGreenwashing\r\n‚Ä¢ Used software to cheat on vehicle emissions \r\ntests. \r\n‚Ä¢ The vehicle‚Äôs software could detect whether they \r\nwere being tested, changing the performance \r\naccordingly to improve results. \r\n‚Ä¢ Affected 11M cars worldwide, 8M in Europe.\r\n18\r\n\r\nHow can we drive sustainability \r\nin the SE industry?\r\n\r\nGreen Procurement\r\n‚Ä¢ Customers decide on providers that share their values \r\n‚Ä¢ This is currently the main trigger reason why organisations \r\nworry about Sustainability and Green Software. \r\n‚Ä¢ Examples of green procurement: \r\n‚Ä¢ Customers that only buy green services/products \r\n‚Ä¢ Companies that only use green providers \r\n‚Ä¢ Developers that only work for green companies \r\n‚Ä¢ Green procurement makes environmental sustainability \r\nessential for economical sustainability.\r\n20\r\n\r\nSustainability via compliance\r\n‚Ä¢ EU wants to be carbon neutral by 2030 \r\n‚Ä¢ This also affects the ICT sector. Estimated to impact \r\n14% of the global carbon footprint by 2040. \r\n‚Ä¢ Some initiatives are already being negotiated. \r\n‚Ä¢ Extending the smartphone lifetime to 7 years. \r\n‚Ä¢ Right-to-repair movement. https://repair.eu \r\n‚Ä¢ Making IT services relying on clean energy more \r\naccessible (e.g., less taxes).\r\n21\r\n\r\nSoftware for Sustainability \r\n‚Ä¢ We are not covering it in this course.', 'Lu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\n7. Green SE ‚Äì Research\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nCarolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl\r\n\r\n1. Energy patterns for mobile apps \r\n2. Carbon-aware datacenters \r\n3. Energy Regression Testing \r\n4. Debugging Energy with Docker images \r\n5. Energy Efficiency vs Code Quality \r\n\r\n‚Ä¢ While learning about these works, try to be critical about them and find their \r\npitfalls.\r\n3\r\n\r\n‚Ä¢ We have seen that measuring energy consumption is not trivial \r\n‚Ä¢ It is not practical considering that developers have other priorities above \r\nenergy efficiency \r\n‚Ä¢ At the same time, every now and then there are some efforts to improve \r\nenergy efficiency in some cases. This is time consuming and requires \r\nexpertise. \r\n‚Ä¢ How can we reuse these efforts?\r\n4\r\n\r\nEnergy Patterns for Mobile \r\nApps\r\nhttps://tqrg.github.io/energy-patterns/\r\n\r\nMethodology\r\n5. Catalog of Energy Patterns\r\n22 \r\npatterns\r\nF-droid\r\nCurated Lists\r\n1. App Collection\r\n1783 \r\napps\r\n3. Manual Refinement of Subjects of \r\nInterest\r\n1563 \r\nchanges\r\n4. Thematic Analysis\r\n431 \r\nreusable \r\nchanges\r\n2. Collect Changes With Potential Interest\r\n/.*(energy|power|battery).*/\r\n6028 \r\nchanges\r\n\r\nThematic Analysis\r\n1. Familiarization with data \r\n2. Generating initial labels \r\n3. Reviewing themes\r\n4. Defining and naming themes\r\n\r\n‚Ä¢ Energy Pattern: design pattern to improve energy efficiency.. \r\n‚Ä¢ 22 energy patterns. \r\n‚Ä¢ Each pattern is described by Context, Solution, Example, References from \r\nliterature, and Occurences (links to code changes from git repositories).\r\n8\r\n\r\nhttps://tqrg.github.io/energy-patterns\r\n\r\nDark UI Colors \r\nProvide a dark UI color theme to \r\nsave battery on devices with \r\nAMOLED screens.\r\n‚Ä¢ Context: [‚Ä¶] Apps that require heavy usage of screen can \r\nhave a substantial negative impact on battery life. \r\n‚Ä¢ Solution: Provide a UI theme with dark background colors. [‚Ä¶]\r\n‚Ä¢ Example: In a reading app, provide a theme with a dark \r\nbackground using light colors to display text. [‚Ä¶] \r\n10\r\n\r\nDark UI Colors \r\nProvide a dark UI color theme to \r\nsave battery on devices with \r\nAMOLED screens.\r\n‚Ä¢ Context: [‚Ä¶] Apps that require heavy usage of screen can \r\nhave a substantial negative impact on battery life. \r\n‚Ä¢ Solution: Provide a UI theme with dark background colors. [‚Ä¶]\r\n‚Ä¢ Example: In a reading app, provide a theme with a dark \r\nbackground using light colors to display text. [‚Ä¶] \r\n11\r\n\r\nDynamic Retry Delay\r\n‚Ä¢ Context: [‚Ä¶] In a mobile app, when a given resource is \r\nunavailable, the app will unnecessarily try to connect the resource \r\nfor a number of times, leading to unnecessary power consumption. \r\n‚Ä¢ Solution: Increase retry interval after each failed connection. [‚Ä¶]\r\n‚Ä¢ Example: Consider a mobile app that provides a news feed and \r\nthe app is not able to reach the server to collect updates. [‚Ä¶] use \r\nthe Fibonacci series to increase the time between attempts.\r\nWhenever an attempt to access a \r\nresource fails, increase the time \r\ninterval before retrying.\r\n12\r\n\r\nBatch Operations \r\n‚Ä¢ Context: Executing operations separately leads to extraneous \r\ntail energy consumptions  \r\n‚Ä¢ Solution: Bundle multiple operations in a single one. [‚Ä¶]\r\n‚Ä¢ Example: Use system provided APIs to schedule background \r\ntasks. These APIs, guarantee that device will exit sleep mode \r\nonly when there is a reasonable amount of work to do or when a \r\ngiven task is urgent.']","['<1-hop>\n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise\n‚Ä¢ But studying government software is diÔ¨Écult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation?\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!', '<2-hop>\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption\n‚Ä¢ B3. Energy proÔ¨Åling of static analysis tools\n‚Ä¢ B4. Detailed energy proÔ¨Åling of build pipelines\n‚Ä¢ B5. Tool supporting SusAF workshop / process\n‚Ä¢ B6. Dataset of government-developed OS software\n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability', '<1-hop>\n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise\n‚Ä¢ But studying government software is diÔ¨Écult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation?\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!', '<2-hop>\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption\n‚Ä¢ B3. Energy proÔ¨Åling of static analysis tools\n‚Ä¢ B4. Detailed energy proÔ¨Åling of build pipelines\n‚Ä¢ B5. Tool supporting SusAF workshop / process\n‚Ä¢ B6. Dataset of government-developed OS software\n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability', '<1-hop>\n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise\n‚Ä¢ But studying government software is diÔ¨Écult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation?\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!', '<2-hop>\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption\n‚Ä¢ B3. Energy proÔ¨Åling of static analysis tools\n‚Ä¢ B4. Detailed energy proÔ¨Åling of build pipelines\n‚Ä¢ B5. Tool supporting SusAF workshop / process\n‚Ä¢ B6. Dataset of government-developed OS software\n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability', '<1-hop>\n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise\n‚Ä¢ But studying government software is diÔ¨Écult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation?\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!', '<2-hop>\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption\n‚Ä¢ B3. Energy proÔ¨Åling of static analysis tools\n‚Ä¢ B4. Detailed energy proÔ¨Åling of build pipelines\n‚Ä¢ B5. Tool supporting SusAF workshop / process\n‚Ä¢ B6. Dataset of government-developed OS software\n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability', '<1-hop>\n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise\n‚Ä¢ But studying government software is diÔ¨Écult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation?\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!', '<2-hop>\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption\n‚Ä¢ B3. Energy proÔ¨Åling of static analysis tools\n‚Ä¢ B4. Detailed energy proÔ¨Åling of build pipelines\n‚Ä¢ B5. Tool supporting SusAF workshop / process\n‚Ä¢ B6. Dataset of government-developed OS software\n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability']","The project idea related to creating a dataset of government-developed open-source (OS) software involves compiling a comprehensive dataset that includes data to understand the state of such software. This includes information on whether the software is buildable, has an open development history, and includes requirements documentation. The project could start with the Netherlands (NL) but would benefit from including data from other countries as well. The motivation behind this project is that while governments develop and use software to support society, studying this software is challenging due to a lack of visibility and language barriers. This dataset aims to address these challenges and promote open-source development and policies.","The project idea is to create a dataset of government-developed OS software, which would help in understanding the state of such software, including whether it is buildable, has open development history, and has requirements documentation.",0.999999999975,1.0,0.9090909090909091,0.57,,0.9508451509147346
What is the project idea related to creating a dataset of government-developed OS software?,"['Lu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\n10. Project 2\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nCarolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl\r\n\r\n1. Goal/assignment \r\n2. Deliverables \r\n3. Strategy \r\n4. Ideas\r\n\r\nAssignment\r\n‚Ä¢ Goal: Solve a Sustainable Software Engineering problem. \r\n‚Ä¢ Identify 1 problem that should be fixed to help enabling sustainability in \r\nthe software engineering industry/community. \r\n‚Ä¢ Propose a solution. A tool, framework, guidelines, etc. \r\n‚Ä¢ Implementation. \r\n‚Ä¢ Validation. (Depending on the idea) \r\n‚Ä¢ Dissemination/social impact. (Solution should be open source, welcome \r\ncontributors, post on social media? Tool website? Available in a package \r\nmanager?)\r\n3\r\n\r\nDeliverables\r\n‚Ä¢ Paper-like article. (Min 4 pages, max 10) \r\n‚Ä¢ Online git repo with open source codebase and/or replication package. \r\n‚Ä¢ Presentation: 5 min + 5min Q&A\r\n4\r\n\r\nArticle\r\n‚Ä¢ Different projects will have different expectations -> Make agreements with \r\nyour coach. \r\n‚Ä¢ Some projects are more technical and some projects more theoretical. \r\n‚Ä¢ Common requirements: \r\n‚Ä¢ Motivation, formulation of the problem being addressed, etc. \r\n‚Ä¢ Description of the solution. \r\n‚Ä¢ Validation of the solution (if applicable -> discuss with coach) \r\n‚Ä¢ Discussion of the solution. (Including limitations)\r\n5\r\n\r\nStrategy\r\n‚Ä¢ Starting next week, there are no lectures  \r\n‚Ä¢ Steering meetings from week 5 till week 9 (either online or in person).  \r\n‚Ä¢ 1 steering meeting per week. (4+1 sprints) \r\n‚Ä¢ Every week, you need to plan different tasks and assignments. \r\n‚Ä¢ Deadline April 4.\r\n6\r\n\r\nStrategy\r\n‚Ä¢ Week 0 \r\n‚Ä¢ Decide project idea (today) \r\n‚Ä¢ Define steering meeting schedule \r\n‚Ä¢ Create working document of the \r\narticle: Problem statement and solution \r\nproposal! \r\n‚Ä¢ Define and assign tasks for each week. \r\n‚Ä¢ Week 1 \r\n‚Ä¢ Implementation \r\n‚Ä¢ Agreements with supervisor. \r\n‚Ä¢ Week 2 \r\n‚Ä¢ Implementation \r\n‚Ä¢ Week 3 \r\n‚Ä¢ Implementation, Full draft of article, \r\ndissemination. \r\n‚Ä¢ Week 4 \r\n‚Ä¢ Final refinements \r\n‚Ä¢ Prepare presentation\r\n7\r\n\r\nProject ideas\r\n‚Ä¢ A1. Prototype cross-machine comparable benchmarks \r\n‚Ä¢ A2. Add energy metrics to LMstudio/Ollama \r\n‚Ä¢ A3. Visualizations built-in with EnergiBridge \r\n‚Ä¢ A4. Service-based version of EnergiBridge\r\n\r\nProject ideas\r\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \r\n‚Ä¢ B2. Study test generation energy consumption \r\n‚Ä¢ B3. Energy profiling of static analysis tools \r\n‚Ä¢ B4. Detailed energy profiling of build pipelines \r\n‚Ä¢ B5. Tool supporting SusAF workshop / process \r\n‚Ä¢ B6. Dataset of government-developed OS software \r\n‚Ä¢ B7. Queue - but better for the student / TA society\r\nQuality Assurance & Testing\r\nSocial & Individual \u2028\r\nSustainability\r\n\r\nProject ideas\r\n‚Ä¢ C1. Compare energy consumption of docker images for ML workloads. \r\n‚Ä¢ C2. Create a plugin to visualize Hugging Face carbon emissions in detail. \r\n‚Ä¢ C3. Plugin for ChatGPT (footprint per chat window) \r\n‚Ä¢ C4. NutriScore for software libraries. \r\n‚Ä¢ C5. Add energy-awareness to existing software \r\n‚Ä¢ C6. Green Shift Left \r\n‚Ä¢ C7. Education for Sustainable SE\r\n\r\nA1.', '‚Ä¢ Deadline April 4.\r\n6\r\n\r\nStrategy\r\n‚Ä¢ Week 0 \r\n‚Ä¢ Decide project idea (today) \r\n‚Ä¢ Define steering meeting schedule \r\n‚Ä¢ Create working document of the \r\narticle: Problem statement and solution \r\nproposal! \r\n‚Ä¢ Define and assign tasks for each week. \r\n‚Ä¢ Week 1 \r\n‚Ä¢ Implementation \r\n‚Ä¢ Agreements with supervisor. \r\n‚Ä¢ Week 2 \r\n‚Ä¢ Implementation \r\n‚Ä¢ Week 3 \r\n‚Ä¢ Implementation, Full draft of article, \r\ndissemination. \r\n‚Ä¢ Week 4 \r\n‚Ä¢ Final refinements \r\n‚Ä¢ Prepare presentation\r\n7\r\n\r\nProject ideas\r\n‚Ä¢ A1. Prototype cross-machine comparable benchmarks \r\n‚Ä¢ A2. Add energy metrics to LMstudio/Ollama \r\n‚Ä¢ A3. Visualizations built-in with EnergiBridge \r\n‚Ä¢ A4. Service-based version of EnergiBridge\r\n\r\nProject ideas\r\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \r\n‚Ä¢ B2. Study test generation energy consumption \r\n‚Ä¢ B3. Energy profiling of static analysis tools \r\n‚Ä¢ B4. Detailed energy profiling of build pipelines \r\n‚Ä¢ B5. Tool supporting SusAF workshop / process \r\n‚Ä¢ B6. Dataset of government-developed OS software \r\n‚Ä¢ B7. Queue - but better for the student / TA society\r\nQuality Assurance & Testing\r\nSocial & Individual \u2028\r\nSustainability\r\n\r\nProject ideas\r\n‚Ä¢ C1. Compare energy consumption of docker images for ML workloads. \r\n‚Ä¢ C2. Create a plugin to visualize Hugging Face carbon emissions in detail. \r\n‚Ä¢ C3. Plugin for ChatGPT (footprint per chat window) \r\n‚Ä¢ C4. NutriScore for software libraries. \r\n‚Ä¢ C5. Add energy-awareness to existing software \r\n‚Ä¢ C6. Green Shift Left \r\n‚Ä¢ C7. Education for Sustainable SE\r\n\r\nA1. Prototype cross-machine comparable benchmarks\r\n‚Ä¢ Energy-usage comparisons require running both baseline + software on the \r\nsame machine ‚Üí limits how extensive our experiments can be \r\n‚Ä¢ Research community is in need of benchmarks that make energy \r\nmeasurements comparable even if executed on different machines \r\n‚Ä¢ Focus on a single task or model (i.e. computing vision, classification)\r\n\r\nA2. Adding energy metrics to LMstudio/Ollama\r\n‚Ä¢ Make energy consumption visible to users \r\nwithin local chat-interface for LLMs \r\n‚Ä¢ LMstudio/Ollama are tools for easy \r\ndeployment of LLMs \r\n‚Ä¢ Do not show energy metrics \r\n‚Ä¢ Add energy metrics to LMstudio-python \r\nor Ollama\r\nhttps://lmstudio.ai/\r\n\r\nA3. Visualizations built-in with EnergiBridge\r\n‚Ä¢ EnergiBridge simplifies energy measurement, but analysis & visualization is \r\nstill left to the user \r\n‚Ä¢ Extend the tool with well-chosen visualizations and analyses directly from the \r\nprovided data\r\n\r\nA4. Service-based version of EnergiBridge\r\n‚Ä¢ Simplify interaction & setup with EnergiBridge \r\n‚Ä¢ Service that runs independently, start/stop signals over RPC to manage \r\nexperiments \r\n‚Ä¢ Potential: create EnergiBridge interface for other prog. lang\r\n\r\nB1. Measure energy consumption of single JUnit tests\r\n‚Ä¢ We‚Äôd like to identify energy anti patterns in unit tests \r\n‚Ä¢ As a first step, we need tooling to measure and compare the energy \r\nconsumption of single unit tests \r\n‚Ä¢ Ideally including preliminary analysis looking at potential reasons for high-\r\nenergy-consuming tests\r\n\r\nB2. Study test generation energy consumption\r\n‚Ä¢ Automatic test generation mainly focuses on making strong test suites \r\n‚Ä¢ Do different techniques and configurations impact the energy consumption \r\nduring generation? \r\n‚Ä¢ Preferably focus on non-LLM test generation methods (EvoSuite, Pyguin, \r\nDSpot)\r\n\r\nB3. Detailed energy profiling of build pipelines\r\n‚Ä¢ Automatic builds have become a cornerstone of quality assurance.', 'computing vision, classification)\r\n\r\nA2. Adding energy metrics to LMstudio/Ollama\r\n‚Ä¢ Make energy consumption visible to users \r\nwithin local chat-interface for LLMs \r\n‚Ä¢ LMstudio/Ollama are tools for easy \r\ndeployment of LLMs \r\n‚Ä¢ Do not show energy metrics \r\n‚Ä¢ Add energy metrics to LMstudio-python \r\nor Ollama\r\nhttps://lmstudio.ai/\r\n\r\nA3. Visualizations built-in with EnergiBridge\r\n‚Ä¢ EnergiBridge simplifies energy measurement, but analysis & visualization is \r\nstill left to the user \r\n‚Ä¢ Extend the tool with well-chosen visualizations and analyses directly from the \r\nprovided data\r\n\r\nA4. Service-based version of EnergiBridge\r\n‚Ä¢ Simplify interaction & setup with EnergiBridge \r\n‚Ä¢ Service that runs independently, start/stop signals over RPC to manage \r\nexperiments \r\n‚Ä¢ Potential: create EnergiBridge interface for other prog. lang\r\n\r\nB1. Measure energy consumption of single JUnit tests\r\n‚Ä¢ We‚Äôd like to identify energy anti patterns in unit tests \r\n‚Ä¢ As a first step, we need tooling to measure and compare the energy \r\nconsumption of single unit tests \r\n‚Ä¢ Ideally including preliminary analysis looking at potential reasons for high-\r\nenergy-consuming tests\r\n\r\nB2. Study test generation energy consumption\r\n‚Ä¢ Automatic test generation mainly focuses on making strong test suites \r\n‚Ä¢ Do different techniques and configurations impact the energy consumption \r\nduring generation? \r\n‚Ä¢ Preferably focus on non-LLM test generation methods (EvoSuite, Pyguin, \r\nDSpot)\r\n\r\nB3. Detailed energy profiling of build pipelines\r\n‚Ä¢ Automatic builds have become a cornerstone of quality assurance. But how \r\nmuch energy do they even consume? \r\n‚Ä¢ Create a tool that reports on the energy consumed during the (different stages \r\nof the) whole build (compile, build, test, package, ‚Ä¶) \r\n‚Ä¢ Should be integrated with build system(s), making setup for developers easy \r\n‚Ä¢ For local setup (to enable true energy measurements)\r\n\r\nB4. Energy profiling of static analysis tools\r\n‚Ä¢ What is the energy consumption of a ""typical run"" for a few OSS projects? \r\n‚Ä¢ Does the type of analysis matter? Are certain analysis more expensive? Does \r\nthe number of rules that are activated in a static analysis tool important for the \r\nenergy consumption? \r\n‚Ä¢ Differences between static analysis tools [lower priority]\r\n\r\nB5. Tool supporting SusAF workshop / process\r\n‚Ä¢ Lead engineers through process & questions \r\n‚Ä¢ Interface to create & document the two diagrams \r\n‚Ä¢ (!) Should be easy to start using & set up \r\n‚Ä¢ You may also create a simplified version / \u2028\r\nyour favorite sustainability framework\r\nEnvironmental\r\nEconomic\r\nTechnical\r\nIndividual\r\nSocial\r\nImmediate\r\nEnabling\r\nStructural\r\nAirbnb\r\ngreater \r\nearnings\r\nincrease \r\nin rents\r\ngentrification\r\ngreater racial \r\ndisparities\r\nrent \r\nrooms\r\n5\r\n1\r\n3\r\n4\r\n2\r\n \r\n \r\n \r\n \r\n \r\n \r\nVery \r\nunlikely \r\nVery \r\nlikely \r\n\r\nB6. Dataset of government-developed OS software\r\n‚Ä¢ Governments develop & use software for supporting society\u2028\r\nOpen-source development & policies are on the rise \r\n‚Ä¢ But studying government software is difficult b/c we don‚Äôt know what is out \r\nthere\u2028\r\n‚Üí Lack of incentive to make popular \u2028\r\n‚Üí Language barriers \r\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \r\nbuildable?, open dev. history?, requirements documentation? \r\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!\r\n\r\nB7. Queue - but better for the student / TA society\r\n‚Ä¢ Requirements analysis regarding social and individual sustainability effects \r\nof Queue \r\n‚Ä¢ Other EIP / TUD used software also possible: e.g., Answers EWI \r\n‚Ä¢ Non-technical project ‚Üí proper process (workshops?', 'Energy profiling of static analysis tools\r\n‚Ä¢ What is the energy consumption of a ""typical run"" for a few OSS projects? \r\n‚Ä¢ Does the type of analysis matter? Are certain analysis more expensive? Does \r\nthe number of rules that are activated in a static analysis tool important for the \r\nenergy consumption? \r\n‚Ä¢ Differences between static analysis tools [lower priority]\r\n\r\nB5. Tool supporting SusAF workshop / process\r\n‚Ä¢ Lead engineers through process & questions \r\n‚Ä¢ Interface to create & document the two diagrams \r\n‚Ä¢ (!) Should be easy to start using & set up \r\n‚Ä¢ You may also create a simplified version / \u2028\r\nyour favorite sustainability framework\r\nEnvironmental\r\nEconomic\r\nTechnical\r\nIndividual\r\nSocial\r\nImmediate\r\nEnabling\r\nStructural\r\nAirbnb\r\ngreater \r\nearnings\r\nincrease \r\nin rents\r\ngentrification\r\ngreater racial \r\ndisparities\r\nrent \r\nrooms\r\n5\r\n1\r\n3\r\n4\r\n2\r\n \r\n \r\n \r\n \r\n \r\n \r\nVery \r\nunlikely \r\nVery \r\nlikely \r\n\r\nB6. Dataset of government-developed OS software\r\n‚Ä¢ Governments develop & use software for supporting society\u2028\r\nOpen-source development & policies are on the rise \r\n‚Ä¢ But studying government software is difficult b/c we don‚Äôt know what is out \r\nthere\u2028\r\n‚Üí Lack of incentive to make popular \u2028\r\n‚Üí Language barriers \r\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \r\nbuildable?, open dev. history?, requirements documentation? \r\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!\r\n\r\nB7. Queue - but better for the student / TA society\r\n‚Ä¢ Requirements analysis regarding social and individual sustainability effects \r\nof Queue \r\n‚Ä¢ Other EIP / TUD used software also possible: e.g., Answers EWI \r\n‚Ä¢ Non-technical project ‚Üí proper process (workshops? Interviews?) & rich \r\ndescription of outcomes focus of grading\r\nhttps://eip.pages.ewi.tudelft.nl/eip-website/queue.html\r\n\r\nC1. Compare energy consumption of docker images for \r\nML workloads.\r\n‚Ä¢ Similar to what we have seen in the lectures but for ML-specific workloads. \r\n‚Ä¢ We can reuse existing experiment replication packages.\r\n22\r\n\r\nC2. Plugin to visualize Hugging Face carbon emissions.\r\n‚Ä¢ https://huggingface.co/blog/leaderboard-emissions-\r\nanalysis \r\n‚Ä¢\r\nYoo, Taewon, et al. ""Visualizing the Carbon Intensity of Machine Learning Inference for Image Analysis on TensorFlow Hub.""\r\n\r\nC3. Plugin for ChatGPT\r\n‚Ä¢ Users seldom know how much carbon they are emitting when they interact \r\nwith chat GPT. \r\n‚Ä¢ Let‚Äôs make it transparent to the users. Browser plugin?\r\n24\r\nCO2\r\n\r\nC4. NutriScore for software libraries\r\n25\r\n‚Ä¢ NutriScore labels are not perfect but they are a good starting point! \r\n‚Ä¢ What if we could do the same thing for the energy efficiency of software. \r\n‚Ä¢ (Also open to individual or social sustainability) \r\n‚Ä¢ This work can be scoped in particular domains/ecossystems/use cases. \r\n‚Ä¢ Libraries for stats? ML? Web Dev? Cloud?\r\n\r\nC5. Add energy-awareness to existing software\r\n26\r\n‚Ä¢ Streamlit, Notebooks, JSFiddle, \r\nPyScript, zsh, etc. \r\n‚Ä¢\r\n\r\nC6 - Green Shift Left\r\n‚Ä¢ Estimate energy efficiency using static code analysis. \r\n‚Ä¢ We don‚Äôt need an accurate value. \r\n‚Ä¢ It is useful to know which code is more likely to \r\nintroduce energy hotspots and that should be \r\nreviewed with more attention. \r\n‚Ä¢ Can be scoped to a particular domain (react, php, data \r\nscience, web, etc., etc.)', 'Carbon-free giants\r\n‚Ä¢ Google, Microsoft, Meta/Facebook want to be carbon free by 2030 \r\n‚Ä¢ Carbon free is different from carbon neutral \r\n‚Ä¢ Green IT experts are needed to meet these goals\r\n23\r\n\r\n\r\nRebound effect*\r\n‚Ä¢ Energy consumption decreases ‚Üì‚Üì but demand also increases ‚Üë‚Üë. \r\n‚Ä¢ *a.k.a. Jevons Paradox in economics; Downs‚ÄìThomson paradox in\xa0mobility.\r\nEnergy per prompt\r\nPrompts\r\n100\r\n80\r\n30\r\n38\r\nChat \r\nGPT\r\n‚ÄúEnergy-efficient‚Äù \r\nChat GPT\r\n0\r\n\r\nIs sustainability an\u2028\r\nethical issue?\r\n‚Ä¢ Climate change is more likely to affect the \r\npoorest countries. \r\n‚Ä¢ Less financial resources to adapt \r\n‚Ä¢ Climate-impact does not necessarily affect \r\npolluting countries. \r\n‚Ä¢ Poorest countries have contributed less to the \r\nclimate change. \r\n‚Ä¢ We need to figure out how to do more using \r\nless resources.\r\n26\r\n\r\nMorality ‚â† Moralising\r\n‚Ä¢ We should not use climate action as a \r\nshaming weapon \r\n‚Ä¢ Climate action should be agnostic of political \r\nviews, ideology, social status, etc. \r\n‚Ä¢ We need everyone to take action!\r\n27\r\n\r\nWhy?\r\n‚Ä¢ Throughout your career you might: \r\n‚Ä¢ Design/maintain/contract data centers \r\n‚Ä¢ Set up operations/devops \r\n‚Ä¢ Develop AI for IoT devices \r\n‚Ä¢ Be the next CEO/CTO of a software company \r\n‚Ä¢ Sustainability can be your main role: \r\n‚Ä¢ Green Software Developer \r\n‚Ä¢ Sustainability Consultant \r\n‚Ä¢ Green Advocate  \r\n‚Ä¢ Founder of a Green Tech startup (B2B?)\r\n28\r\n\r\nFormat of classes\r\n‚Ä¢ In-person. \r\n‚Ä¢ Collegerama recordings. \r\n‚Ä¢ Lectures and Labs. \r\n‚Ä¢ Guest lectures. \r\n‚Ä¢ Steering meetings (after week 5, new schedule)\r\n29\r\n\r\nFormat of classes\r\n‚Ä¢ There‚Äôs no exam in this course. It‚Äôs more important that we learn how to \r\ndiscuss this topic and come up with new ideas than learning all the theory. \r\nCritical thinking over checkboxes. \r\n‚Ä¢ Mix of content and discussion \r\n‚Ä¢ Ultimately, the lectures aim to give you food for thought and the necessary \r\nknowledge to excel in Project 2. (We will talk about it later)\r\n30\r\n\r\nhttps://luiscruz.github.io/course_sustainableSE/\r\n31\r\nContent of the course üëá\r\n\r\n32\r\nhttps://mattermost.tudelft.nl/signup_user_complete/?id=1nj9tk6usjf8xmsws8wpq3s5uy&md=link&sbr=su\r\n\r\nProject 1\r\n‚Ä¢ Goal: Measure the energy consumption of software applications. \r\n‚Ä¢ Approach: energy measurement tools; use case testing. \r\n‚Ä¢ Deliverable: blog-style report (approx. 2500 words) \r\n‚Ä¢ Deadline: Week 3, Feb 28, 2025 \r\n‚Ä¢ Group size: 4‚Äì5\r\n33\r\n\r\nProject 2\r\n‚Ä¢ Goal: Create a solution/tool/technique that helps building green software. (You \r\ncan come up with your own idea or choose one from a list of suggestions). \r\n‚Ä¢ Approach: open-source software development; literature review. \r\n‚Ä¢ Deliverable: library/tool/app; paper; presentation. \r\n‚Ä¢ Two deadlines:\u2028\r\n1. Paper and software: Week 8, April 4, 2025\u2028\r\n2. Presentation: Week 9, April 11, 2025 \r\n‚Ä¢ Group size: 4‚Äì5\r\n34\r\n\r\nGuest Lectures\r\nNergis T√∂men \r\nComputer Vision lab | TU Delft \r\nWeek 4, Wed, Mar 5, 2025\r\n35\r\n\r\nCommunity \r\nHow to get involved?', 'It‚Äôs more important that we learn how to \r\ndiscuss this topic and come up with new ideas than learning all the theory. \r\nCritical thinking over checkboxes. \r\n‚Ä¢ Mix of content and discussion \r\n‚Ä¢ Ultimately, the lectures aim to give you food for thought and the necessary \r\nknowledge to excel in Project 2. (We will talk about it later)\r\n30\r\n\r\nhttps://luiscruz.github.io/course_sustainableSE/\r\n31\r\nContent of the course üëá\r\n\r\n32\r\nhttps://mattermost.tudelft.nl/signup_user_complete/?id=1nj9tk6usjf8xmsws8wpq3s5uy&md=link&sbr=su\r\n\r\nProject 1\r\n‚Ä¢ Goal: Measure the energy consumption of software applications. \r\n‚Ä¢ Approach: energy measurement tools; use case testing. \r\n‚Ä¢ Deliverable: blog-style report (approx. 2500 words) \r\n‚Ä¢ Deadline: Week 3, Feb 28, 2025 \r\n‚Ä¢ Group size: 4‚Äì5\r\n33\r\n\r\nProject 2\r\n‚Ä¢ Goal: Create a solution/tool/technique that helps building green software. (You \r\ncan come up with your own idea or choose one from a list of suggestions). \r\n‚Ä¢ Approach: open-source software development; literature review. \r\n‚Ä¢ Deliverable: library/tool/app; paper; presentation. \r\n‚Ä¢ Two deadlines:\u2028\r\n1. Paper and software: Week 8, April 4, 2025\u2028\r\n2. Presentation: Week 9, April 11, 2025 \r\n‚Ä¢ Group size: 4‚Äì5\r\n34\r\n\r\nGuest Lectures\r\nNergis T√∂men \r\nComputer Vision lab | TU Delft \r\nWeek 4, Wed, Mar 5, 2025\r\n35\r\n\r\nCommunity \r\nHow to get involved?\r\n36\r\n\r\nGreen TU\r\n‚Ä¢ https://www.tudelft.nl/sustainability/get-\r\ninvolved/greentu \r\n‚Ä¢ Student organisation at the TU Delft devoted \r\nto stimulating sustainability in education, \r\nresearch, university operations and \r\ncommunity engagement.\r\n37\r\n\r\nClimateAction.tech\r\n‚Ä¢ Great community for outreach \r\n‚Ä¢ Based on Slack  \r\n‚Ä¢ Regular meetings, talks, social events \r\n‚Ä¢ You can join as a volunteer or simply to \r\nconnect to other techies \r\n‚Ä¢ Also good to for job hunting on green tech.\r\n38\r\n\r\nClimateAction.tech\r\n39\r\n\r\nBranch magazine\r\n‚Ä¢ Stay up-to-date on sustainable tech \r\n‚Ä¢ Creativity booster \r\n‚Ä¢ Carbon-aware UI \r\n‚Ä¢ https://branch.climateaction.tech üîó\r\n40\r\n\r\nThis is the fourth edition\r\n‚Ä¢ Any feedback is welcome! Email or DM!\r\n41\r\n\r\n42\r\n\r\nCarolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nLu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\n1. Intro Class\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl', 'Interviews?) & rich \r\ndescription of outcomes focus of grading\r\nhttps://eip.pages.ewi.tudelft.nl/eip-website/queue.html\r\n\r\nC1. Compare energy consumption of docker images for \r\nML workloads.\r\n‚Ä¢ Similar to what we have seen in the lectures but for ML-specific workloads. \r\n‚Ä¢ We can reuse existing experiment replication packages.\r\n22\r\n\r\nC2. Plugin to visualize Hugging Face carbon emissions.\r\n‚Ä¢ https://huggingface.co/blog/leaderboard-emissions-\r\nanalysis \r\n‚Ä¢\r\nYoo, Taewon, et al. ""Visualizing the Carbon Intensity of Machine Learning Inference for Image Analysis on TensorFlow Hub.""\r\n\r\nC3. Plugin for ChatGPT\r\n‚Ä¢ Users seldom know how much carbon they are emitting when they interact \r\nwith chat GPT. \r\n‚Ä¢ Let‚Äôs make it transparent to the users. Browser plugin?\r\n24\r\nCO2\r\n\r\nC4. NutriScore for software libraries\r\n25\r\n‚Ä¢ NutriScore labels are not perfect but they are a good starting point! \r\n‚Ä¢ What if we could do the same thing for the energy efficiency of software. \r\n‚Ä¢ (Also open to individual or social sustainability) \r\n‚Ä¢ This work can be scoped in particular domains/ecossystems/use cases. \r\n‚Ä¢ Libraries for stats? ML? Web Dev? Cloud?\r\n\r\nC5. Add energy-awareness to existing software\r\n26\r\n‚Ä¢ Streamlit, Notebooks, JSFiddle, \r\nPyScript, zsh, etc. \r\n‚Ä¢\r\n\r\nC6 - Green Shift Left\r\n‚Ä¢ Estimate energy efficiency using static code analysis. \r\n‚Ä¢ We don‚Äôt need an accurate value. \r\n‚Ä¢ It is useful to know which code is more likely to \r\nintroduce energy hotspots and that should be \r\nreviewed with more attention. \r\n‚Ä¢ Can be scoped to a particular domain (react, php, data \r\nscience, web, etc., etc.)\r\n27\r\n\r\nC7 - Education\r\n‚Ä¢ Educational game for Software \r\nSustainability practices \r\n‚Ä¢ Purpose: use within software teams to \r\ndiscuss or learn about different sustainable \r\nIT practices: at the organisation level, \r\nsoftware, etc.\r\n28\r\nhttps://github.com/OttoKaaij/Ticket-To-Sustainability/?tab=readme-ov-file\r\n\r\nProject ideas (old)\r\n‚Ä¢ Plugin from EnergiBridge (GUI, report generator, python library, etc.) \r\n‚Ä¢ Plugin for ChatGPT (carbon emissions per chat window) \r\n‚Ä¢ Seamless measurements for AI libraries \r\n‚Ä¢ Energy patterns for Green AI \r\n‚Ä¢ Sustainable SW dev gamification \r\n‚Ä¢ Sustainability auditor for AI projects \r\n‚Ä¢ Energy Profiling of screen colour filter tools (or display settings) \r\n‚Ä¢ ‚Ä¶ you can also propose yours!\r\n\r\nhttps://edu.nl/64gpk\r\nedu.nl/64gpk', '8. Green AI\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nLu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\nCarolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl\r\n\r\n- Overview of Green AI \r\n- Large language models \r\n- Green data-centric AI \r\n- Model simplification \r\n- Hyper parameter tuning \r\n- Mixture of Experts and DeepSeek \r\n- Green AI at Meta \r\n\r\nAI\r\n‚Ä¢ Artificial Intelligence (AI) is the branch of computer science that deals with \r\nautomating tasks that typically require human intelligence. \r\n‚Ä¢ In the past years AI has been widely applied across different domains.\u2028\r\nE.g., health care, transportation, finance. \r\n‚Ä¢ To deploy AI systems, we test them against benchmarks (or validation sets). \r\n‚Ä¢ The goal is to outperform the previous existing models. \r\n‚Ä¢ E.g., in Machine Learning we usually resort to accuracy metrics. The \r\nhighest the accuracy, the better the model.\r\n3\r\n\r\nSince 2012, the amount of computing used for AI \r\ntraining has been doubling every 6 months\r\n‚Ä¢ https://epoch.ai/blog/compute-trends\r\n4\r\n\r\n‚Ä¢ To create better AI systems we are currently adding \r\n‚Ä¢ More data \r\n‚Ä¢ More experiments \r\n‚Ä¢ Larger models\r\n5\r\n\r\nThe Equation of Red AI\r\nCost(R) ‚àùE¬∑D¬∑H\r\nCost of a single (E)xample\r\nSize of (D)ataset\r\nNumber of (H)yperparameters\r\nBy Schwartz et al. (2020)\r\n\r\nIssues of Red AI\r\n‚Ä¢ High costs (hardware, electricity, data access, etc.) \r\n‚Ä¢ Limited reproducibility.  \r\n‚Ä¢ Energy consumption. \r\n‚Ä¢ Carbon emissions. \r\n‚Ä¢ SMEs can hardly be competitive. \r\n‚Ä¢ Groundbreaking AI research is mostly done by tech giants.\r\n7\r\n\r\nA few examples of Red AI\r\n‚Ä¢ Google‚Äôs BERT-large \r\n‚Ä¢ 350 million features \r\n‚Ä¢ Trained for 2.5 days using 512 TPU chips, costing $60K+ \r\n‚Ä¢ Open-GPT3 (now GPT-4/o1) \r\n‚Ä¢ 550 tonnes CO2-eq (Patterson, 2021) \r\n‚Ä¢ 175 billion features \r\n‚Ä¢ API is open but no-pretrained model is available \r\n‚Ä¢ AlphaGo \r\n‚Ä¢ 1920 CPUs, 280 GPUs, costing $35M\r\n8\r\n\r\nRed AI in Large Language Models (LLMs)\r\n‚Ä¢ OPT by Meta reports 75 tons CO2-eq (1/7 of OpenGPT‚Äôs footprint).\u2028\r\n(Also 175billion params) \r\n‚Ä¢ However, Llama 3 reported 2,290 tons of CO2-eq (7.7M GPU hours \r\ntraining ) \r\n‚Ä¢ Open science: release includes both the pretrained models and the code \r\nneeded to train and use them. \r\n‚Ä¢ DeepSeek-V3 claims ‚Äúonly‚Äù 2.78M GPU hours \r\n‚Ä¢ Bloom by Huggingface reports 25 tons, 51 when considering embodied \r\nand operational carbon footprint. (176billion params)\r\n9\r\n\r\nRed AI\r\nAccuracy: 0.999999999\r\nGreen AI\r\n‚Ä¢ Energy \r\n‚Ä¢ Time \r\n‚Ä¢ Reproducibility \r\n‚Ä¢ Reusage\r\n\r\nHow can we adopt Green AI\r\n‚Ä¢ Check whether AI is needed. \r\n‚Ä¢ Select green datacenters. \r\n‚Ä¢ Run on low carbon intensity hours. \r\n‚Ä¢ Opt for GPU-optimised solutions (?) \r\n‚Ä¢ Opt for low-power hardware (e.g., Nvidia Jetson boards) \r\n‚Ä¢ Or GPUs that provide energy metrics (e.g., NVIDIA GPUs via the nvidia-smi tool) \r\n‚Ä¢ Report energy/carbon metrics (e.g., embed in MLFlow?)', '‚Ä¢ Comparing different programming languages is not an easy task. \r\n‚Ä¢ They differ in many mechanisms: \r\n‚Ä¢ Interpreted vs Compiled \r\n‚Ä¢ Optimisations at the compiler level \r\n‚Ä¢ Virtual machine \r\n‚Ä¢ Garbage collector \r\n‚Ä¢ Available libraries\r\n30\r\n\r\nResearch Questions\r\n‚Ä¢ Can we compare the energy efficiency of software languages?  \r\n‚Ä¢ Is the faster language always the most energy efficient? \r\n‚Ä¢ How does memory usage relate to energy consumption? (We don‚Äôt cover this one) \r\n‚Ä¢ Can we automatically decide what is the best programming language \r\nconsidering energy, time, and memory usage?  \r\n‚Ä¢ How do the results of our energy consumption analysis of programming \r\nlanguages gathered from rigorous performance benchmarking solutions \r\ncompare to results of average day-to-day solutions? \u2028\r\n31\r\n\r\nMethodology\r\n\r\nThe Computer Language Benchmarks Game \r\n‚Ä¢ https://benchmarksgame-team.pages.debian.net/benchmarksgame/\r\n33\r\n\r\nProblems in the Computer Language Benchmarks Game\r\n34\r\n\r\n‚Ä¢ 27 Programming languages across different paradigms  \r\n‚Ä¢ Functional (e.g., Ocaml, F#, Haskell) \r\n‚Ä¢ Imperative (e.g., C, Go, Python) \r\n‚Ä¢ Object-oriented (e.g., C++, C#, Java) \r\n‚Ä¢ Scripting (or interpretative) (e.g., JavaScript, Python, Ruby) \r\n‚Ä¢ (These are not mutual exclusive) \r\n‚Ä¢ Intel RAPL‚Äôs C library to measure energy consumption\r\n35\r\n\r\n‚Ä¢ Execute each benchmark solution 10 times. \r\n‚Ä¢ Collect energy data and timestamps. \r\n‚Ä¢ Two-minute interval between executions\r\n36\r\n\r\n\r\n\r\n\r\nCritical thinking\r\n‚Ä¢ There is no doubt this is an excellent study. Yet, as any excellent study, there‚Äôs \r\na lot we can discuss and criticise constructively. \r\n‚Ä¢ What kind of issues you see in drawing conclusions from such a table of \r\nresults? \r\n‚Ä¢ Is the benchmark representative of the most common usage behaviour? \r\n‚Ä¢ Are the implemented solutions representative? \r\n‚Ä¢ Does it make sense to use the average to compare energy consumption \r\nacross different problems? \r\n‚Ä¢ ‚Ä¶\r\n40\r\n\r\nReproducing with Rosetta Code \r\n‚Ä¢ Rosetta Code is a programming chrestomathy repository \r\n \r\n‚Ä¢ 900 usecases/tasks solved across 700 different programming languages \r\n‚Ä¢ Purpose: if you know a programming language we can easily learn how the \r\nsame task is solved in a language you are not familiar with.\r\n41\r\n(?)\r\n\r\n\r\n\r\nRevisiting Research Questions\r\n‚Ä¢ Can we compare the energy efficiency of software languages?  \r\n‚Ä¢ Is the faster language always the most energy efficient? \r\n‚Ä¢ How does memory usage relate to energy consumption?  \r\n‚Ä¢ Can we automatically decide what is the best programming language considering \r\nenergy, time, and memory usage?  \r\n‚Ä¢ How do the results of our energy consumption analysis of programming \r\nlanguages gathered from rigorous performance benchmarking solutions \r\ncompare to results of average day-to-day solutions?  \r\n‚Ä¢ What would happen if we cherry picked the tasks?\u2028\r\n44\r\n\r\n\r\nLu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\n3. Scientific Guide for Reliable \r\nEnergy Experiments\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nCarolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl', 'Different \r\nscreen brightness, different results. \r\n‚Ä¢ You need to reduce tasks to the bare minimum: \r\n‚Ä¢ Set brightness to a fixed value; turn off notifications, kill all user-owned \r\nprocesses, turn off cellular data, bluetooth, location services, account \r\nsyncs; uninstall all unnecessary apps, etc.\r\n11\r\n\r\nWhen it comes to desktop/cloud software, the sources \r\nof noise are different but the same concerns apply. \r\n \r\nEach case is different ‚Äì think it through!\r\n‚ö†\r\n\r\nEnergy Profilers\r\n‚Ä¢ Simple setup! Quite reliable (if you choose the profiler wisely). \r\n‚Ä¢ Recently, they are starting to rely on internal power sensors. \r\n‚Ä¢ Still sensitive to noise from concurrent processes/tasks! ‚ö†\r\n13\r\n\r\nExamples of Energy Profilers\r\n\r\n15\r\nhttps://www.websitecarbon.com\r\n\r\n16\r\nhttps://mlco2.github.io/impact/\r\n\r\nIntel Power Monitor\r\n‚Ä¢ Install: https://software.intel.com/content/www/us/en/\r\ndevelop/articles/intel-power-gadget.html \r\n‚Ä¢ To collect: Logging > Log to File \r\n \r\n‚Ä¢ It will store a CSV file with all the collected power data. \r\n(File location is specified in the settings) \r\n‚Ä¢ Based on Intel RAPL. Works with Intel-based Windows \r\nand Macs. \r\n‚Ä¢ Alternative-twin for M1-based Macs: Mx Power Gadget.\u2028\r\nhttps://www.seense.com/menubarstats/mxpg/\r\n17\r\n‚ö† No longer supported by Intel ‚ö†  \r\n\r\n18\r\nüîó https://luiscruz.github.io/\r\n2021/07/20/measuring-energy.html\r\n(Missing Apple m1 tools: mxpg, powermetrics)\r\n\r\n19\r\nEnergiBridge\r\nhttps://github.com/tdurieux/energibridge\r\n> target/release/energibridge -o results.csv --summary sleep 10\r\n\r\nHands-on 1\r\n‚Ä¢ Install your energy profiler (EnergiBridge). \r\n‚Ä¢ Collect the energy data of using Coral BodyPix for 30 seconds.\u2028\r\nhttps://storage.googleapis.com/tfjs-models/demos/body-pix/index.html \r\n‚Ä¢ Report the total energy consumption. \r\n‚Ä¢ Extra-mile: \r\n‚Ä¢ Compare the energy consumption in different browsers. \r\n‚Ä¢ Check the spikes and drops in Power and Temperature.\r\n20\r\n\r\nRetrospection\r\nHands-on 1\r\n‚Ä¢ Are the measurements repeatable? \r\n‚Ä¢ What were the confounding factors? \r\n‚Ä¢ How can we automate this process?\r\n21\r\n\r\nEnergy testing\r\n(Different from energy monitoring)\r\n1. Create a reproducible scenario of the execution of your software. Preferably \r\nthis should be an automated script ‚Äì e.g., using a bash or python script. \r\n2. Execute the scenario in a version of your software. Use the energy profiler to \r\nmeasure the energy consumption. \r\n3. Improve your software in parts of the code that you suspect have low \r\nperformance. \r\n4. Execute the same scenario with the new version. Compare the energy data \r\nin this version with the previous one.\u2028\r\nEnergy is lower, test passes; energy is higher test fails.\r\n22\r\n\r\nHands-on 2\r\n‚Ä¢ Create a reproducible scenario. (Usually easier with command-line interfaces) \r\n‚Ä¢ Automatically start/stop energy profiling.\r\n23\r\n\r\nProject 1\r\n‚Ä¢ Deadline: March 1 \r\n‚Ä¢  Compare energy consumption in common software use cases. \r\n‚Ä¢ Examples: \r\n‚Ä¢ Different versions of the same app; \r\n‚Ä¢ Same use case but different apps \r\n‚Ä¢ Same version, same app, but different user settings (e.g., enable/disable GPU optimisation) \r\n‚Ä¢ Same version, same app, but different running environment \r\n‚Ä¢ Submission via PR (markdown). \r\n‚Ä¢ Blog-style report (markdown, approx 2500 words). \r\n‚Ä¢ Replication package. \r\n‚Ä¢ Points if the experiment is automated.', '‚Ä¢ Collect the energy data of using Coral BodyPix for 30 seconds.\u2028\r\nhttps://storage.googleapis.com/tfjs-models/demos/body-pix/index.html \r\n‚Ä¢ Report the total energy consumption. \r\n‚Ä¢ Extra-mile: \r\n‚Ä¢ Compare the energy consumption in different browsers. \r\n‚Ä¢ Check the spikes and drops in Power and Temperature.\r\n20\r\n\r\nRetrospection\r\nHands-on 1\r\n‚Ä¢ Are the measurements repeatable? \r\n‚Ä¢ What were the confounding factors? \r\n‚Ä¢ How can we automate this process?\r\n21\r\n\r\nEnergy testing\r\n(Different from energy monitoring)\r\n1. Create a reproducible scenario of the execution of your software. Preferably \r\nthis should be an automated script ‚Äì e.g., using a bash or python script. \r\n2. Execute the scenario in a version of your software. Use the energy profiler to \r\nmeasure the energy consumption. \r\n3. Improve your software in parts of the code that you suspect have low \r\nperformance. \r\n4. Execute the same scenario with the new version. Compare the energy data \r\nin this version with the previous one.\u2028\r\nEnergy is lower, test passes; energy is higher test fails.\r\n22\r\n\r\nHands-on 2\r\n‚Ä¢ Create a reproducible scenario. (Usually easier with command-line interfaces) \r\n‚Ä¢ Automatically start/stop energy profiling.\r\n23\r\n\r\nProject 1\r\n‚Ä¢ Deadline: March 1 \r\n‚Ä¢  Compare energy consumption in common software use cases. \r\n‚Ä¢ Examples: \r\n‚Ä¢ Different versions of the same app; \r\n‚Ä¢ Same use case but different apps \r\n‚Ä¢ Same version, same app, but different user settings (e.g., enable/disable GPU optimisation) \r\n‚Ä¢ Same version, same app, but different running environment \r\n‚Ä¢ Submission via PR (markdown). \r\n‚Ä¢ Blog-style report (markdown, approx 2500 words). \r\n‚Ä¢ Replication package. \r\n‚Ä¢ Points if the experiment is automated.\r\n24\r\n\r\nGroup registration\r\n‚Ä¢ Brightspace > Collaboration > Groups and sign up for one of the groups \r\nunder ""Project Groups (P1 and P2)""  \r\n‚Ä¢ If you are looking for a group or teamembers, use the mattermost channel \r\n‚Äú~Searching-group-members‚Äù. \r\n‚Ä¢ The deadline for self-registering as a group is end of this week, so by Sunday, \r\n16th of February, 23:59. \r\n‚Ä¢ We might do final adjustments afterwards.\r\n25\r\n\r\n26\r\nKay Singh. Apple Silicon M1 Power Consumption Deep Dive Part 1: Safari vs Chrome\u2028\r\nhttps://singhkays.com/blog/apple-silicon-m1-video-power-consumption-pt-1/\r\n(For project 1, you don‚Äôt need to dive deep into hardware details)\r\n\r\n27', 'google.com/view/energy-efficiency-languages\r\n21\r\nAna Radovanovic ÃÅ, Ross Koningstein, Ian Schneider, Bokan \r\nChen, Alexandre Duarte, Binz Roy, Diyue Xiao, Maya \r\nHaridasan, Patrick Hung, Nick Care, Saurav Talukdar, Eric \r\nMullen, Kendal Smith, MariEllen Cottman, and Walfredo Cirne \r\n\r\n\r\n‚Ä¢ Google‚Äôs Carbon-Intelligent Computing System (CICS) \r\n‚Ä¢ Main idea: use carbon-intensity data to shift datacenter jobs in time \r\n‚Ä¢ Typically, job schedulers use a metric of cluster capacity to schedule a job in \r\na particular cluster. \r\n‚Ä¢ CICS overrides this metric with the virtual capacity curve (VCC) that \r\nfactors in Carbon intensity \r\n‚Ä¢ When a new job comes in, the scheduler estimates its CPU load and power \r\nusage and assigns it to a cluster if the VCC is not exceeded.\r\n23\r\n\r\n‚Ä¢ Jobs are divided between flexible and inflexible. \r\n‚Ä¢ Flexible load is considered shapeable/shiftable as long as its total daily \r\ncompute (CPU) demand is preserved \r\n‚Ä¢ The system needs to consider that, while running a job, the virtual capacity \r\ncurve (VCC) might drop. Hence, this job should not start in the first place. \r\n‚Ä¢ They forecast VCC for the next day\r\n24\r\n\r\n\r\nVirtual Cluster Capacity (VCC)\r\n‚Ä¢ Aims at reducing the peak load at carbon intensive hours but in total it should allow for the \r\nsome amount of daily computation! \r\n‚Ä¢ Considers Carbon intensity \r\n‚Ä¢ Using data from electricityMap.org \r\n‚Ä¢ It does not use carbon intensity directly.\u2028\r\nCarbon intensity is converted to a cost (kgCO2 -> $$) \r\n‚Ä¢ This way, they can factor in other metrics that can also be converted to money. E.g., the \r\ncost saved by preventing peak load \r\n‚Ä¢ Peak workload entails extra cost at the infrastructure level (e.g., control faclities‚Äô \r\ntemperature). \r\n‚Ä¢ By using money cost instead of carbon cost, they have more data available.\r\n26\r\n\r\nVirtual Cluster Capacity (VCC)\r\n‚Ä¢ If the forecast of VCC fails it shift flexible workload more than expected.  \r\n‚Ä¢ This happens because the amount of workload forecasted was below the \r\nworkload needed, and VCC was ‚Äúaggressively‚Äù low. \r\n‚Ä¢ The systems fall back to the real cluster capacity for 1 week until results \r\nstart being realistic again.\r\n27\r\n\r\nNext steps\r\n‚Ä¢ They will consider spatial flexibility. \r\n‚Ä¢ I.e., tasks that can be shifted over time and over space. \r\n‚Ä¢ It needs to factor in relocation overheads, though.\r\n28\r\n\r\nCritical questions\r\n‚Ä¢ Who defines what is flexible and inflexible? \r\n‚Ä¢ How do you estimate the CPU load of a given task?\r\n29\r\n\r\nEnergy Regression Testing\r\n‚ÜíEnergy?\r\nGreener? Greener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\n\r\nE-compare\r\nGithub Actions\r\n‚ûú https://koenhagen.github.io/E-Compare/\r\n\r\nEnergy Regression Testing \r\n\r\n4. Debugging Energy with \r\nDocker Images\r\n\r\nUnveiling the Energy Vampires \r\nA methodology for debugging Software \r\nEnergy Consumption\r\n ‚úÖ ICSE 2025\r\n\r\nData Centers and Docker\r\n‚Ä¢ Containers are the most popular way to deploy apps into the cloud \r\n‚Ä¢ Base image is an important choice when building an image \r\n‚Ä¢ Criteria \r\n‚Ä¢ Linux distribution and binaries \r\n‚Ä¢ Image size \r\n‚Ä¢ Energy?\r\n35\r\n\r\nRedis energy consumption\r\n‚Ä¢ Ubuntu/Alpine base images have different energy consumption for Redis\r\n36\r\n\r\nRedis Energy Consumption\r\n‚Ä¢RQ1: What is the difference \r\nin energy consumption \r\nbetween glibc and musl? \r\n‚Ä¢RQ2: Can we use tracing \r\nto compare energy \r\nconsumption in shared \r\nlibraries?', '‚Ä¢ Groundbreaking AI research is mostly done by tech giants.\r\n7\r\n\r\nA few examples of Red AI\r\n‚Ä¢ Google‚Äôs BERT-large \r\n‚Ä¢ 350 million features \r\n‚Ä¢ Trained for 2.5 days using 512 TPU chips, costing $60K+ \r\n‚Ä¢ Open-GPT3 (now GPT-4/o1) \r\n‚Ä¢ 550 tonnes CO2-eq (Patterson, 2021) \r\n‚Ä¢ 175 billion features \r\n‚Ä¢ API is open but no-pretrained model is available \r\n‚Ä¢ AlphaGo \r\n‚Ä¢ 1920 CPUs, 280 GPUs, costing $35M\r\n8\r\n\r\nRed AI in Large Language Models (LLMs)\r\n‚Ä¢ OPT by Meta reports 75 tons CO2-eq (1/7 of OpenGPT‚Äôs footprint).\u2028\r\n(Also 175billion params) \r\n‚Ä¢ However, Llama 3 reported 2,290 tons of CO2-eq (7.7M GPU hours \r\ntraining ) \r\n‚Ä¢ Open science: release includes both the pretrained models and the code \r\nneeded to train and use them. \r\n‚Ä¢ DeepSeek-V3 claims ‚Äúonly‚Äù 2.78M GPU hours \r\n‚Ä¢ Bloom by Huggingface reports 25 tons, 51 when considering embodied \r\nand operational carbon footprint. (176billion params)\r\n9\r\n\r\nRed AI\r\nAccuracy: 0.999999999\r\nGreen AI\r\n‚Ä¢ Energy \r\n‚Ä¢ Time \r\n‚Ä¢ Reproducibility \r\n‚Ä¢ Reusage\r\n\r\nHow can we adopt Green AI\r\n‚Ä¢ Check whether AI is needed. \r\n‚Ä¢ Select green datacenters. \r\n‚Ä¢ Run on low carbon intensity hours. \r\n‚Ä¢ Opt for GPU-optimised solutions (?) \r\n‚Ä¢ Opt for low-power hardware (e.g., Nvidia Jetson boards) \r\n‚Ä¢ Or GPUs that provide energy metrics (e.g., NVIDIA GPUs via the nvidia-smi tool) \r\n‚Ä¢ Report energy/carbon metrics (e.g., embed in MLFlow?) \r\n‚Ä¢ Use pre-trained models (Transfer Learning) \r\n‚Ä¢ Preprocess dataset to reduce size. \r\n‚Ä¢ Improve parameter-tuning strategy.\r\n11\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ We need benchmarks. \r\n‚Ä¢ AllenAI leaderboard\u2028\r\nhttps://leaderboard.allenai.org \r\n‚Ä¢ No carbon metrics, yet \r\n‚Ä¢ Report comparable proxies for energy \r\nconsumption. \r\n‚Ä¢ ‚ö† Learning algorithms behave in a non-\r\ndeterministic \r\n‚Ä¢ ‚ö† Different data-points lead to different \r\nenergy consumption\r\n12\r\n\r\nReporting energy/carbon footprint\r\n‚Ä¢ Reporting measured energy consumption \r\n‚Ä¢ + Accurate \r\n‚Ä¢ + Easy to map to carbon emissions \r\n‚Ä¢ - Hard to measure \r\n‚Ä¢ - Low replicability \r\n‚Ä¢ Reporting time / estimation based on time & hardware \r\n‚Ä¢ + Easy to measure \r\n‚Ä¢ + Correlates with energy consumption in most cases. \r\n‚Ä¢ -  Difficult to compare with measurements from other setups \r\n‚Ä¢ E.g., floating point operations (FPOs) (?) \r\n‚Ä¢ + comparable across different setups \r\n‚Ä¢ + cheap \r\n‚Ä¢ - does not factor in memory energy consumption \r\n‚Ä¢ - does not reflect carbon emissions\r\n13\r\n\r\nData-centric AI\r\n\r\nData-centric AI\r\n‚Ä¢ Emerging discipline that deals with systematically engineering data to build AI \r\nsystems. \r\n‚Ä¢ Shift from improving the training strategy to improving the data. \r\n‚Ä¢ It is better to have small but reliable datasets than large but noisy \r\ndatasets. \r\n‚Ä¢ => Improve data collection, data labelling, and data preprocessing. \r\n‚Ä¢ More about data-centric AI by Andrew Ng:\u2028\r\nhttps://www.youtube.com/watch?v=06-AZXmwHjo\r\n15\r\n\r\n\r\nGreen Data-centric AI\r\n‚Ä¢ How do different ML algorithms compare \r\nin terms of energy consumption? \r\n‚Ä¢ How does number of rows relate to the \r\nenergy consumption of ML models? \r\n‚Ä¢ How does number of features relate to \r\nthe energy consumption of ML models? \r\n‚Ä¢ What is the impact of reducing data in the \r\nperformance of the model?', '‚Ä¢ By using money cost instead of carbon cost, they have more data available.\r\n26\r\n\r\nVirtual Cluster Capacity (VCC)\r\n‚Ä¢ If the forecast of VCC fails it shift flexible workload more than expected.  \r\n‚Ä¢ This happens because the amount of workload forecasted was below the \r\nworkload needed, and VCC was ‚Äúaggressively‚Äù low. \r\n‚Ä¢ The systems fall back to the real cluster capacity for 1 week until results \r\nstart being realistic again.\r\n27\r\n\r\nNext steps\r\n‚Ä¢ They will consider spatial flexibility. \r\n‚Ä¢ I.e., tasks that can be shifted over time and over space. \r\n‚Ä¢ It needs to factor in relocation overheads, though.\r\n28\r\n\r\nCritical questions\r\n‚Ä¢ Who defines what is flexible and inflexible? \r\n‚Ä¢ How do you estimate the CPU load of a given task?\r\n29\r\n\r\nEnergy Regression Testing\r\n‚ÜíEnergy?\r\nGreener? Greener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\nGreener?\r\n\r\nE-compare\r\nGithub Actions\r\n‚ûú https://koenhagen.github.io/E-Compare/\r\n\r\nEnergy Regression Testing \r\n\r\n4. Debugging Energy with \r\nDocker Images\r\n\r\nUnveiling the Energy Vampires \r\nA methodology for debugging Software \r\nEnergy Consumption\r\n ‚úÖ ICSE 2025\r\n\r\nData Centers and Docker\r\n‚Ä¢ Containers are the most popular way to deploy apps into the cloud \r\n‚Ä¢ Base image is an important choice when building an image \r\n‚Ä¢ Criteria \r\n‚Ä¢ Linux distribution and binaries \r\n‚Ä¢ Image size \r\n‚Ä¢ Energy?\r\n35\r\n\r\nRedis energy consumption\r\n‚Ä¢ Ubuntu/Alpine base images have different energy consumption for Redis\r\n36\r\n\r\nRedis Energy Consumption\r\n‚Ä¢RQ1: What is the difference \r\nin energy consumption \r\nbetween glibc and musl? \r\n‚Ä¢RQ2: Can we use tracing \r\nto compare energy \r\nconsumption in shared \r\nlibraries? \r\n‚Ä¢RQ3: Can we verify the \r\norigin of energy \r\nconsumption differences by \r\nrecreating the workload \r\nbehavior closely?\r\n37\r\n\r\nTracing\r\n‚Ä¢ Find libc function running at the end of the benchmark \r\n‚Ä¢ Tracing: Capture calls made to libc \r\n‚Ä¢ Introduces non-linear overhead\r\n38\r\n\r\nSynchronization\r\n‚Ä¢ Tracing slows down execution and increase energy consumption \r\n‚Ä¢ Run separately and synchronize with logs\r\n39\r\n\r\nTracing Analysis\r\n40\r\n\r\nTracing Analysis\r\n41\r\n\r\nBenchmarking memcpy\r\n‚Ä¢ Copy bytes from one part of memory to \r\nanother \r\n‚Ä¢ Depending on function parameters, different \r\nassembly-level optimizations \r\n‚Ä¢ Some not included in musl\r\n42\r\n\r\nBenchmarking memcpy\r\n‚Ä¢ Copy 4 bytes from fixed \r\npointer to moving pointer \r\n‚Ä¢ (100,300,500,600) x 1M \r\nrequests \r\n‚Ä¢  15% more power and 3X time\r\n43\r\n\r\nConclusions\r\n‚Ä¢ Significant difference in energy consumption for memcpy \r\n‚Ä¢ 8.6% difference for Redis workload and 13% in our benchmark \r\n‚Ä¢ musl trades performance for a smaller codebase \r\n‚Ä¢ No official documentation \r\n‚Ä¢ No awareness about energy performance\r\n44\r\n\r\n5. Energy Efficiency vs Code \r\nQuality\r\n\r\nMeasuring Maintainability\r\n‚Ä¢ According to ISO/IEC 25010, Maintainability is ‚Äúthe degree of \r\neffectiveness and efficiency with which a software product or \r\nsystem can be modified to improve it, correct it or adapt it to \r\nchanges in environment, and in requirements‚Äù \r\n‚Ä¢ We use the code analysis tool Better Code Hub to assess \r\nmaintainability \r\n‚Ä¢ Better Code Hub maps the ISO/IEC 25010 standard on \r\nmaintainability into a set of guidelines derived from static analysis\r\n46\r\n\r\nMaintainability of Energy Changes\r\n‚Ä¢ What is the impact of making energy-oriented code changes on \r\nthe maintainability of mobile apps?', '‚Ä¢RQ3: Can we verify the \r\norigin of energy \r\nconsumption differences by \r\nrecreating the workload \r\nbehavior closely?\r\n37\r\n\r\nTracing\r\n‚Ä¢ Find libc function running at the end of the benchmark \r\n‚Ä¢ Tracing: Capture calls made to libc \r\n‚Ä¢ Introduces non-linear overhead\r\n38\r\n\r\nSynchronization\r\n‚Ä¢ Tracing slows down execution and increase energy consumption \r\n‚Ä¢ Run separately and synchronize with logs\r\n39\r\n\r\nTracing Analysis\r\n40\r\n\r\nTracing Analysis\r\n41\r\n\r\nBenchmarking memcpy\r\n‚Ä¢ Copy bytes from one part of memory to \r\nanother \r\n‚Ä¢ Depending on function parameters, different \r\nassembly-level optimizations \r\n‚Ä¢ Some not included in musl\r\n42\r\n\r\nBenchmarking memcpy\r\n‚Ä¢ Copy 4 bytes from fixed \r\npointer to moving pointer \r\n‚Ä¢ (100,300,500,600) x 1M \r\nrequests \r\n‚Ä¢  15% more power and 3X time\r\n43\r\n\r\nConclusions\r\n‚Ä¢ Significant difference in energy consumption for memcpy \r\n‚Ä¢ 8.6% difference for Redis workload and 13% in our benchmark \r\n‚Ä¢ musl trades performance for a smaller codebase \r\n‚Ä¢ No official documentation \r\n‚Ä¢ No awareness about energy performance\r\n44\r\n\r\n5. Energy Efficiency vs Code \r\nQuality\r\n\r\nMeasuring Maintainability\r\n‚Ä¢ According to ISO/IEC 25010, Maintainability is ‚Äúthe degree of \r\neffectiveness and efficiency with which a software product or \r\nsystem can be modified to improve it, correct it or adapt it to \r\nchanges in environment, and in requirements‚Äù \r\n‚Ä¢ We use the code analysis tool Better Code Hub to assess \r\nmaintainability \r\n‚Ä¢ Better Code Hub maps the ISO/IEC 25010 standard on \r\nmaintainability into a set of guidelines derived from static analysis\r\n46\r\n\r\nMaintainability of Energy Changes\r\n‚Ä¢ What is the impact of making energy-oriented code changes on \r\nthe maintainability of mobile apps? \r\nMaintainability \r\nDifference \r\nvE-2\r\nvE-1\r\nvE\r\nEnergy \r\nCommit\r\nvE+1\r\nM(vE-1)\r\nM(vE)\r\nParent \r\nCommit\r\n‚àÜM\r\n47\r\n\r\nThreshold Marks\r\n48\r\n\r\nBetter Code Hub\r\nMaintainability\r\nCombine\r\ndatasets\r\nEnergy\r\nCommits\r\nBaseline\r\nCommits\r\nBao et al. \r\n(2015)\r\nMoura et al. \r\n(2016)\r\nCruz et al. \r\n(2018)\r\nCruz et al. \r\n(2019)\r\nEnergy Code Changes \r\nDataset\r\n539 commits\u2028\r\nfrom 306 mobile apps\r\n539 baseline commits\u2028\r\nfrom 306 mobile apps\r\n49\r\n\r\nImpact of energy changes on \r\nmaintainability\r\n50\r\n\r\nWhich energy \r\npatterns are more \r\nlikely to affect \r\nmaintainability?\r\n51\r\n\r\nTypical maintainability issue I\r\nhttps://github.com/einmalfel/PodListen/commit/2ed5a65\r\n4 changed files with 28 additions and 0 deletions.\r\n‚Ä¶\r\n‚Ä¶\r\n52\r\n\r\nTypical maintainability issue II\r\nhttps://github.com/mozilla/MozStumbler/commit/6ea0268\r\n5 changed files with 66 additions and 14 deletions.\r\n53\r\n\r\n54', 'Carolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nLu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\n1. Intro Class\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl\r\n\r\n1. Intro to Sustainable SE \r\n2. Intro to the course\r\n2\r\n\r\nof the electricity consumed worldwide \r\nby 2040 will stem from ICT\r\n14%\r\n\r\n4\r\nhttps://xkcd.com/1007/\r\n\r\nBuzz words\r\n‚Ä¢ Eco-friendly \r\n‚Ä¢ Climate change, action, adaption \r\n‚Ä¢ Energy efficiency \r\n‚Ä¢ Environmental-responsible \r\n‚Ä¢ Carbon-neutral; Climate-neutral; Net zero \r\n‚Ä¢ Carbon-offsetting \r\n‚Ä¢ Carbon-free \r\n‚Ä¢ Clean technology \r\n‚Ä¢ E-waste\r\n5\r\n\r\nhttps://www.menti.com/uns9d89kzn\r\nWhat is Sustainable \r\nSoftware Engineering?\r\n?\r\n6\r\n\r\nSustainable Software \r\nEngineering is‚Ä¶\r\n7\r\n‚Ä¶the discipline that studies the process of creating software systems that are able \r\nto create value in the long term without hindering its surrounding environment.\r\n\r\n8\r\nEconomical\r\nSocial\r\nTechnical\r\nIndividual\r\nEnvironmental\r\nSustainable\r\nSoftware\r\nEngineering\r\n‚≠ê\r\nTechnical\u2028\r\n‚öô\r\nEconomical\u2028\r\nüí∞\r\nSocial\u2028\r\nüë©üíºüë®üíºüë©üíºüë©üíº\r\nIndividual\u2028\r\nüë©üíª\r\nEnvironmental\u2028\r\nüå±\r\nSustainable\u2028\r\nSoftware \r\nEngineering\r\n\r\nEconomical\r\n‚Ä¢ Focused on assets, capital and added value\u2028\r\n(wealth creation, prosperity, profitability, capital \r\ninvestment, income, etc.) \r\n‚Ä¢ Nr of customers  \r\n‚Ä¢ Man-day-rate estimate \r\n‚Ä¢ Next round of funding \r\n‚Ä¢ Meet requirements in the contract\r\n9\r\n\r\nTechnical\r\n‚Ä¢ Longevity of information, systems, and infrastructure and their \r\nadequate evolution with changing surrounding conditions. \r\n‚Ä¢ Examples: \r\n‚Ä¢ Technical Debt \r\n‚Ä¢ Does it scale? \r\n‚Ä¢ Software testing \r\n‚Ä¢ Bus-factor \r\n‚Ä¢ Data integrity \r\n‚Ä¢ Innovation \r\n‚Ä¢ ‚Ä¶\r\n10\r\n\r\nIndividual\r\n‚Ä¢ Well-being of the individuals in an organisation.\u2028\r\nNote that it also includes how well individuals interact \r\nwith each other within the org. \r\n‚Ä¢ Examples: \r\n‚Ä¢ mental and physical well-being \r\n‚Ä¢ self-respect \r\n‚Ä¢ education/skills \r\n‚Ä¢ career development \r\n‚Ä¢ ‚Ä¶\r\n11\r\n\r\nSocial\r\n‚Ä¢ concerned with societal communities (groups of people, \r\norganisations) and the factors that erode trust in society. \r\n‚Ä¢ Examples: \r\n‚Ä¢ Social equity \r\n‚Ä¢ Justice \r\n‚Ä¢ Employment \r\n‚Ä¢ Democracy \r\n‚Ä¢ ‚Ä¶ \r\n‚Ä¢ Also includes compliance with policies and regulations \r\n12\r\n\r\nEnvironmental Sustainability\r\n‚Ä¢ the branch of Software Engineering that studies \r\nthe development of software that has minimal \r\nimpact in our planet throughout its whole \r\nlifecycle. \r\n‚Ä¢ Looking at software at different levels: \r\n‚Ä¢ Developing, Using, Serving, ‚Ä¶ \r\n‚Ä¢ Also includes e-waste. \r\n‚Ä¢ Almost identical to Green Software. (?)\r\n13\r\nBordallo II\r\n\r\nGreen Software\r\n‚Ä¢ Sustainability and energy efficiency. \r\n‚Ä¢ Building energy-efficient software is important also from a \r\ntechnical sustainability POV. \r\n‚Ä¢ Smartphones, smart wearables, IoT devices, etc. run on limited \r\npower resources. \r\n‚Ä¢ Developing software to these devices require energy-efficiency \r\ntesting and improvement. \r\n‚Ä¢ It also leads to environmental sustainability (e.g., less battery \r\ncycles) \r\n‚Ä¢ Important for UX (e.g., no need to walk around with power banks)\r\n14\r\n\r\nhttps://www.menti.com/uns9d89kzn\r\nWhat is the sustainability \r\ndimension you are most \r\ninterested in?\r\n?', 'Neuromorphic computing\r\nCS4575\r\nSustainable Software Engineering\r\n05.03.2025\r\nNergis T√∂men\r\n\r\nIntroduction\r\nComputer Vision Lab\r\nBiomorphic Intelligence Lab\r\nBiomedical Intervention Optimisation Lab\r\nNergis\r\n\r\nNeuromorphic computing\r\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\r\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\r\nhttps://en.wikipedia.org/wiki/Neuromorphic_engineering, https://www.informationweek.com/software-services/what-you-need-to-know-about-neuromorphic-computing\r\n\r\nHow many of you are familiar \r\nwith neural networks?\r\n\r\nSimple model of an artificial neuron\r\nhttps://medium.com/@cprasenjit32/perceptron-a-simple-yet-mighty-machine-learning-algorithm-9ff6b7d86a71\r\n\r\nWhat is a neural network?\r\nhttps://www.tibco.com/reference-center/what-is-a-neural-network\r\n\r\nWhy is it called a \'neural network\'?\r\nhttps://www.tibco.com/reference-center/what-is-a-neural-network\r\n\r\nWhat is a neural network?\r\nWhy is it called a \'neural network\'?\r\nMcCulloch-Pitts neuron [1, 2] (1943)\r\nWarren Sturgis McCulloch\r\n(Neurophysiologist)\r\nWalter Pitts\r\n(Logician)\r\n\r\nHow do biological neurons work?\r\nhttps://commons.wikimedia.org/wiki/File:Coincidence_detection_in_dendrites_of_pyramidal_neurons.gif\r\n\'Input current\' travels down the dendrites (top),\r\nget integrated (summed!) in the cell body\r\nwhich generates an \'output current\' (bottom)\r\nwhich is chemically transmitted to the dendrites of \r\nother neurons.\r\n\r\nSimplified picture\r\nReal neuron\r\nArtificial neuron\r\nhttps://vajiramandravi.com/quest-upsc-notes/artificial-neural-network/\r\n\r\nWhat is a neural network?\r\nMcCulloch-Pitts neuron [1, 2]\r\n1940s: How do biological neurons compute basic \r\nlogic functions? (e.g. logic gates)\r\nNote: Ref. [3] gives a nice brief history on the ideas which lead to the \r\nMcCulloch-Pitts neuron.\r\n\r\nWhat is a neural network?\r\n1950s: How are neurons organized to perform \r\nsensory perception?\r\n\r\nWhat is a neural network?\r\n1950s: How are neurons organized to perform \r\nsensory perception?\r\nThe first ""neural network"": Perceptron (1958). [4]\r\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\r\nFrank Rosenblatt (Psychologist)\r\nwith a Mark I Perceptron computer in 1960\r\n\r\nWhat is a neural network?\r\n1950s: How are neurons organized to perform \r\nsensory perception?\r\nThe first ""neural network"": Perceptron (1958). [4]\r\nhttps://www.reddit.com/r/interestingasfuck/comments/e8a8oy/frank_rosenblatt_with_a_mark_i_perceptron/\r\nFrank Rosenblatt (Psychologist)\r\nwith a Mark I Perceptron computer in 1960\r\nPower-efficient\r\n\r\nNeuromorphic computing\r\nWhy neuromorphic computing?\r\nNeuromorphic computing is an approach to computing that is inspired by the structure and function of the human brain.\r\nA neuromorphic computer/chip is any device that uses physical artificial neurons to do computations.\r\n\r\nNeuromorphic computing\r\nWhy neuromorphic computing?\r\n‚ÄòBiological inspiration‚Äô for artificial neural networks (ANNs) is not a new idea.\r\nEmulation (as opposed to simulation) of neural networks in hardware is not a new idea.', 'Lu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\n7. Green SE ‚Äì Research\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nCarolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl\r\n\r\n1. Energy patterns for mobile apps \r\n2. Carbon-aware datacenters \r\n3. Energy Regression Testing \r\n4. Debugging Energy with Docker images \r\n5. Energy Efficiency vs Code Quality \r\n\r\n‚Ä¢ While learning about these works, try to be critical about them and find their \r\npitfalls.\r\n3\r\n\r\n‚Ä¢ We have seen that measuring energy consumption is not trivial \r\n‚Ä¢ It is not practical considering that developers have other priorities above \r\nenergy efficiency \r\n‚Ä¢ At the same time, every now and then there are some efforts to improve \r\nenergy efficiency in some cases. This is time consuming and requires \r\nexpertise. \r\n‚Ä¢ How can we reuse these efforts?\r\n4\r\n\r\nEnergy Patterns for Mobile \r\nApps\r\nhttps://tqrg.github.io/energy-patterns/\r\n\r\nMethodology\r\n5. Catalog of Energy Patterns\r\n22 \r\npatterns\r\nF-droid\r\nCurated Lists\r\n1. App Collection\r\n1783 \r\napps\r\n3. Manual Refinement of Subjects of \r\nInterest\r\n1563 \r\nchanges\r\n4. Thematic Analysis\r\n431 \r\nreusable \r\nchanges\r\n2. Collect Changes With Potential Interest\r\n/.*(energy|power|battery).*/\r\n6028 \r\nchanges\r\n\r\nThematic Analysis\r\n1. Familiarization with data \r\n2. Generating initial labels \r\n3. Reviewing themes\r\n4. Defining and naming themes\r\n\r\n‚Ä¢ Energy Pattern: design pattern to improve energy efficiency.. \r\n‚Ä¢ 22 energy patterns. \r\n‚Ä¢ Each pattern is described by Context, Solution, Example, References from \r\nliterature, and Occurences (links to code changes from git repositories).\r\n8\r\n\r\nhttps://tqrg.github.io/energy-patterns\r\n\r\nDark UI Colors \r\nProvide a dark UI color theme to \r\nsave battery on devices with \r\nAMOLED screens.\r\n‚Ä¢ Context: [‚Ä¶] Apps that require heavy usage of screen can \r\nhave a substantial negative impact on battery life. \r\n‚Ä¢ Solution: Provide a UI theme with dark background colors. [‚Ä¶]\r\n‚Ä¢ Example: In a reading app, provide a theme with a dark \r\nbackground using light colors to display text. [‚Ä¶] \r\n10\r\n\r\nDark UI Colors \r\nProvide a dark UI color theme to \r\nsave battery on devices with \r\nAMOLED screens.\r\n‚Ä¢ Context: [‚Ä¶] Apps that require heavy usage of screen can \r\nhave a substantial negative impact on battery life. \r\n‚Ä¢ Solution: Provide a UI theme with dark background colors. [‚Ä¶]\r\n‚Ä¢ Example: In a reading app, provide a theme with a dark \r\nbackground using light colors to display text. [‚Ä¶] \r\n11\r\n\r\nDynamic Retry Delay\r\n‚Ä¢ Context: [‚Ä¶] In a mobile app, when a given resource is \r\nunavailable, the app will unnecessarily try to connect the resource \r\nfor a number of times, leading to unnecessary power consumption. \r\n‚Ä¢ Solution: Increase retry interval after each failed connection. [‚Ä¶]\r\n‚Ä¢ Example: Consider a mobile app that provides a news feed and \r\nthe app is not able to reach the server to collect updates. [‚Ä¶] use \r\nthe Fibonacci series to increase the time between attempts.\r\nWhenever an attempt to access a \r\nresource fails, increase the time \r\ninterval before retrying.\r\n12\r\n\r\nBatch Operations \r\n‚Ä¢ Context: Executing operations separately leads to extraneous \r\ntail energy consumptions  \r\n‚Ä¢ Solution: Bundle multiple operations in a single one. [‚Ä¶]\r\n‚Ä¢ Example: Use system provided APIs to schedule background \r\ntasks. These APIs, guarantee that device will exit sleep mode \r\nonly when there is a reasonable amount of work to do or when a \r\ngiven task is urgent.', '‚Ä¢ Examples: \r\n‚Ä¢ Technical Debt \r\n‚Ä¢ Does it scale? \r\n‚Ä¢ Software testing \r\n‚Ä¢ Bus-factor \r\n‚Ä¢ Data integrity \r\n‚Ä¢ Innovation \r\n‚Ä¢ ‚Ä¶\r\n10\r\n\r\nIndividual\r\n‚Ä¢ Well-being of the individuals in an organisation.\u2028\r\nNote that it also includes how well individuals interact \r\nwith each other within the org. \r\n‚Ä¢ Examples: \r\n‚Ä¢ mental and physical well-being \r\n‚Ä¢ self-respect \r\n‚Ä¢ education/skills \r\n‚Ä¢ career development \r\n‚Ä¢ ‚Ä¶\r\n11\r\n\r\nSocial\r\n‚Ä¢ concerned with societal communities (groups of people, \r\norganisations) and the factors that erode trust in society. \r\n‚Ä¢ Examples: \r\n‚Ä¢ Social equity \r\n‚Ä¢ Justice \r\n‚Ä¢ Employment \r\n‚Ä¢ Democracy \r\n‚Ä¢ ‚Ä¶ \r\n‚Ä¢ Also includes compliance with policies and regulations \r\n12\r\n\r\nEnvironmental Sustainability\r\n‚Ä¢ the branch of Software Engineering that studies \r\nthe development of software that has minimal \r\nimpact in our planet throughout its whole \r\nlifecycle. \r\n‚Ä¢ Looking at software at different levels: \r\n‚Ä¢ Developing, Using, Serving, ‚Ä¶ \r\n‚Ä¢ Also includes e-waste. \r\n‚Ä¢ Almost identical to Green Software. (?)\r\n13\r\nBordallo II\r\n\r\nGreen Software\r\n‚Ä¢ Sustainability and energy efficiency. \r\n‚Ä¢ Building energy-efficient software is important also from a \r\ntechnical sustainability POV. \r\n‚Ä¢ Smartphones, smart wearables, IoT devices, etc. run on limited \r\npower resources. \r\n‚Ä¢ Developing software to these devices require energy-efficiency \r\ntesting and improvement. \r\n‚Ä¢ It also leads to environmental sustainability (e.g., less battery \r\ncycles) \r\n‚Ä¢ Important for UX (e.g., no need to walk around with power banks)\r\n14\r\n\r\nhttps://www.menti.com/uns9d89kzn\r\nWhat is the sustainability \r\ndimension you are most \r\ninterested in?\r\n?\r\n15\r\n\r\nEconomical sustainability tops the environment\r\n‚Ä¢ In general, a software project will not survive if it‚Äôs not economical \r\nsustainable \r\n‚Ä¢ Yet, a project can survive even if it is not environmental sustainable \r\n‚Ä¢ The mindset is changing! \r\n‚Ä¢ Software consumers have started to worry about the climate impact \r\nof their behaviour as users. \r\n‚Ä¢ Being environmentally sustainable is now an important competitive \r\nfactor \r\n‚Ä¢ Marketing teams are already using all eco-friendly labels. Technical \r\nteams are not there yet, though. \r\n‚Ä¢ It‚Äôs easier said than done!\r\n$\r\n16\r\n\r\nGreen Washing\r\n‚Ä¢ Deceptively use marketing techniques to \r\nclaim being eco-friendly. \r\n‚Ä¢ Opting for green-coloured designs. \r\n‚Ä¢ Red/orange is usually perceived as \r\ntasty. \r\n‚Ä¢ Green is perceived as eco-friendly. \r\n‚Ä¢ The VW case. (?)\r\n17\r\n\r\nThe VW scandal\r\nGreenwashing\r\n‚Ä¢ Used software to cheat on vehicle emissions \r\ntests. \r\n‚Ä¢ The vehicle‚Äôs software could detect whether they \r\nwere being tested, changing the performance \r\naccordingly to improve results. \r\n‚Ä¢ Affected 11M cars worldwide, 8M in Europe.\r\n18\r\n\r\nHow can we drive sustainability \r\nin the SE industry?\r\n\r\nGreen Procurement\r\n‚Ä¢ Customers decide on providers that share their values \r\n‚Ä¢ This is currently the main trigger reason why organisations \r\nworry about Sustainability and Green Software. \r\n‚Ä¢ Examples of green procurement: \r\n‚Ä¢ Customers that only buy green services/products \r\n‚Ä¢ Companies that only use green providers \r\n‚Ä¢ Developers that only work for green companies \r\n‚Ä¢ Green procurement makes environmental sustainability \r\nessential for economical sustainability.\r\n20\r\n\r\nSustainability via compliance\r\n‚Ä¢ EU wants to be carbon neutral by 2030 \r\n‚Ä¢ This also affects the ICT sector. Estimated to impact \r\n14% of the global carbon footprint by 2040. \r\n‚Ä¢ Some initiatives are already being negotiated. \r\n‚Ä¢ Extending the smartphone lifetime to 7 years. \r\n‚Ä¢ Right-to-repair movement. https://repair.eu \r\n‚Ä¢ Making IT services relying on clean energy more \r\naccessible (e.g., less taxes).\r\n21\r\n\r\nSoftware for Sustainability \r\n‚Ä¢ We are not covering it in this course.', 'Lu√≠s Cruz \r\nL.Cruz@tudelft.nl \r\n2. Tools to Measure Software Energy \r\n(lab)\r\nSustainable Software Engineering\u2028\r\nCS4575\r\nSustainableSE 2025\r\nCarolin Brandt \r\nC.E.Brandt@tudelft.nl \r\nEnrique Barba Roque \r\nE.BarbaRoque@tudelft.nl\r\n\r\n1. Tools \r\n2. Hands-on \r\n3. Project 1\r\n\r\n3\r\nHardware Power \r\nMonitors\r\nEnergy Profilers\r\n\r\nHardware Power Monitors\r\n‚Ä¢ Connects directly to the power source of the device/\r\ncomponent. \r\n‚Ä¢ Some power monitors also replace the power source. \r\n‚Ä¢ Example: \r\n‚Ä¢ Monsoon Power Monitor (for IoT and smartphones).  \r\n‚Ä¢ Can be fully automated using a Python API. \r\n‚Ä¢ It measures and powers small electronic devices. \r\n‚Ä¢ There are many power/energy meters out there but for \r\nsoftware use cases we need to be able to control them \r\nusing an API.\r\n4\r\n\r\nConnecting Monsoon to a Smartphone\r\n‚Ä¢ 1. Disassemble the smartphone and find the \r\nconnectors of the battery.  \r\n‚Ä¢ iFixit usually has nice tutorials and blueprints. \r\nhttps://www.ifixit.com\r\n5\r\n\r\nConnecting Monsoon to a Smartphone\r\n‚Ä¢ 2. Extract the electronic component of the battery \r\n‚Ä¢ Modern batteries are connected through 4 terminals: \r\n‚Ä¢ Positive \r\n‚Ä¢ Negative \r\n‚Ä¢ BTEMP, battery temperature (used for safety) \r\n‚Ä¢ BST, battery system indicator (provides info about \r\nthe battery) \r\n‚Ä¢ Hence, one cannot simply connect + and - pins\r\n6\r\n\r\n‚Ä¢ 3. Connect the electronic component \r\ndirectly to the monitor.\r\nConnecting Monsoon to a Smartphone\r\n7\r\n\r\nConnecting Monsoon to a Smartphone\r\n‚Ä¢ 4. Use the library PyMonsoon to control the power \r\nmonitor. \r\n‚Ä¢ https://github.com/msoon/PyMonsoon \r\n‚Ä¢ 4.1. Set the monsoon to desired Voltage. Choose \r\nthe typical voltage of the original battery. For the \r\nNexus 5X, 3.8V was equivalent to its battery at \r\naround 60% capacity. \r\n‚Ä¢ 4.2. Start measuring\r\n8\r\n\r\nConnecting Monsoon to a Smartphone\r\n‚Ä¢ 5. Automate User Interface interaction \r\n‚Ä¢ The last thing you want to do is to manually interact with the smartphone \r\nwhile you measure energy consumption. Tests are less accurate, less \r\nreproducible, and, in this case, the screen cannot not be easily accessed. \r\n‚Ä¢ Tools to automate interaction with Android phones: \r\n‚Ä¢ To open, install, close apps: adb \r\n‚Ä¢ To interact with the app: Appium, Robotium, UIAutomator, espresso, \r\netc. \r\n‚Ä¢ Alternative: physalia is a library that automates all adb interactions and \r\nPyMonsoon calls.\r\n9\r\n\r\nIssue 1: USB cable!\r\n‚Ä¢ You need the USB cable to automate the interaction with the phone. \r\n‚Ä¢ When you connect the USB cable, measurements become\u2028\r\nunreliable. \r\n‚Ä¢ Solution: \r\n‚Ä¢ Monsoon has a feature to control the USB connection (switch on/off) \r\n‚Ä¢ Option 1: Right before starting measurements, the USB connection is stopped. \r\n‚Ä¢ Works fine when when all the interaction instructions can be sent in advance and the time for the \r\nexecution is already known. \r\n‚Ä¢ Option 2: using USB, set up a wireless ADB connection. Stop USB connections afterwards. \r\n‚Ä¢ How to: https://stackoverflow.com/a/3623727\r\n10\r\n\r\nIssue 2: your app is not exclusive\r\n‚Ä¢ Many activities run in a smartphone device. E.g., getting push notifications, \r\nchecking nearby bluetooth devices, etc. \r\n‚Ä¢ Moreover, brightness may change according to environment. Different \r\nscreen brightness, different results.']","['<1-hop>\n\nB6. Dataset of government-developed OS software\n‚Ä¢ Governments develop & use software for supporting society\u2028\nOpen-source development & policies are on the rise\n‚Ä¢ But studying government software is diÔ¨Écult b/c we don‚Äôt know what is out \nthere\u2028\n‚Üí Lack of incentive to make popular \u2028\n‚Üí Language barriers\n‚Ä¢ Create a comprehensive dataset, incl. data to understand state of software: \nbuildable?, open dev. history?, requirements documentation?\n‚Ä¢ Could start with NL, but including your / other countries greatly appreciated!', '<2-hop>\n\nProject ideas\n‚Ä¢ B1. Measure energy consumption of single JUnit tests \n‚Ä¢ B2. Study test generation energy consumption\n‚Ä¢ B3. Energy proÔ¨Åling of static analysis tools\n‚Ä¢ B4. Detailed energy proÔ¨Åling of build pipelines\n‚Ä¢ B5. Tool supporting SusAF workshop / process\n‚Ä¢ B6. Dataset of government-developed OS software\n‚Ä¢ B7. Queue - but better for the student / TA society\nQuality Assurance & Testing\nSocial & Individual \u2028\nSustainability']","The project idea related to creating a dataset of government-developed OS software involves compiling a comprehensive dataset that includes data to understand the state of software developed and used by governments to support society. This is important because open-source development and policies are on the rise, but studying government software is difficult due to a lack of information about what is available, lack of incentive to make it popular, and language barriers. The dataset could start with the Netherlands but would benefit from including other countries as well.","The project idea is to create a comprehensive dataset of government-developed OS software to understand the state of such software, including its buildability, open development history, and requirements documentation. This addresses challenges like the lack of incentive to make software popular and language barriers.",0.999999999975,1.0,,0.62,0.0,0.9884436620714513
